[
  {
    "segment_id": "224fa6ee-5c41-4a83-973f-58f900ab73dc",
    "episode_id": "e7fc976d-9a0a-4d89-898a-3f216ce2d714",
    "episode_number": 60,
    "segment_number": 7,
    "text": "Не дай бог там ГУУ-ту какие-нибудь еще будут появляться. Что он, кстати, с ГУУ-ту говорит? Ничего не говорит пока. Умалчивает. В общем, работать можно, но это требует от человека много. Мне кажется, C и Embedded это вообще для сильных духов. Духом как бы, не для студентов. Ну, наверное, да. Хотя у меня было несколько студентов, знакомых, которые именно Embedded увлекались. Ну, вот, задается, у них там и было вот эти 20 объектов, там, не знаю, куча ищиков и так далее. Да. Не знаю. Лучше все на C писать. Да, согласен. Полностью поддержанно. Переходим на C. Бросай свою скалу, я брошу свой рланг. И на C. Договорились. Окей. Супер. Это я недавно смотрел докку. Есть такая штука, кластеризация тоже контейнеров. И она написана на чистом баше. Это просто супер. Прям вот смотришь и баш везде. Вот я, прям ностальгия у меня. Я на баше в свое время много писал. Я прям читаю, и у меня слезы текут по щекам. Это какой-то стокгольмский синдром у тебя. А слезы радости или счастья, простите? Просто слезы. Много слез. Меня тоже назвали, что у меня стал стокгольмский синдром. Так, ну что, перейдем к теме слушателей. Ну да, раз ты уже заговариваешься. Да, если же я начинаю заговариваться. Так, у вас под рукой, а то что-то мне сейчас открывать надо. Походу всем надо открывать. Ну, я тогда, наверное, пока начну. Первая тема от слушателей Якоб Якоб про Сцелы Диби. А это Сцелы читается, да, именно? Ну, я так понял, что Сцелы. Как ты ее читал? Не знаю. Это же отсылка к мифологии Кассандра, Сцела. А, о, я бы там даже не подумал. Вот оно откуда пошло. Вот оно, что Михалыч. Точно, мужики-то не знают. Ну да-да-да, продолжайте. Это про Сцелу или про что? Да. Про Сцелу. Ну, я в двух словах, короче, скажу, что это... Это не к мифологии, это к Одиссеи. К Гомера, по-моему. Чуваки сели и написали на крестах клон Кассандры. При этом они отмечают, что у них нет пауз на сборку мусора. Это действительно проблема в Кассандре, я подтверждаю. Каким-то образом у них нет больших пауз на компакшн. Этого я пока не совсем понял, как они этого достигли. И более того, там в комментариях пишут, что они чуть ли не напрямую с интерфейсами работают в обход ядра. В результате по синтетическим невоспроизводимым и ничего на практике не означающим бичмаркам они в 10 раз побили Кассандру. Но остается открытым вопрос, сколько там багов у нас остается открытым. Да, и все это совместимо с Кассандрой на уровне протокола. Короче, как я считаю, штука очень интересная, хотя и новая, и надо осторожно быть. Валера, тебе слово. По поводу Сцелы? Ну или там мифологии, или вот этой Одиссее. Это мифология, я еще проверила. Ну, видимо, просто и там, и там. Все-таки неудивительно, что Одиссее использовала греческую мифологию. Сюрприз, сюрприз. Ну, не знаю, мне абсолютно согласен с Ажей. Я ничего кроме этого сказать не могу. А у них много там кода? Я сейчас гляжу на код, и пока мне сложно оценить. Сейчас посмотрим, а кажется, что там все на баше. Какая команда там? Большая? Два человека, я так понял. Они там вроде какие-то дико известные. А, Саша, кстати, я тут не заметил, в какой-то момент с тем исчезла блок про рендеринг кадра Intel Sex Demon Revolution. Она подвинулась ниже, потому что Ваня предложил активным слушателям перейти. Окей, окей. Может, еще дойдем сегодня. Вань, давай дальше, а я пока строчки кода попробую посчитать. Давай, давай. Я смотрю, просто у них тут структура какая-то. Один, два, три. Ты считай про себя, пожалуйста. И когда мы будем выключаться, не забывай, что надо продолжать считать. Следующая тема. Так, тут большое-большое обсуждение. Следующая тема – это Артем Зин спрашивает про новый бинарный протокол Netflix OS, который может работать по VTCP, WebSocket или Aeron. И вот. Вы читали про него? Ребята говорят, ну я так пробежался по ссылкам, ребята говорят, что их не устраивает HTTP, потому что он документ-ориентед, то есть ориентированный на веб-сайты и все такое, а им хочется отсылать побольше сообщений по TCP, им хочется контролировать control flow, в общем, иметь воздействие с точки зрения приложения. И вот они надеются, что их этот протокол как-то поможет. Мне сложно сказать, то есть надо какие-то большие бенчмаркинги проводить и смотреть, насколько это вообще оправдано. Если вы имеете что добавить, добавляйте, потому что я не смогу прямо сейчас ничего оценить. Как это, еще один протокол, да? Стандарт. Давайте объединим пять и сделаем один. Да. Я посчитал строчки, значит, в цели 45 тысяч строк кода на крестах и заголовочных файлов еще 30 тысяч строк. Я очень быстро считаю, если что. Ты прямо ускорился, ты начинал медленно. Ну что ж, если они это писали, я посмотрел, там не двое, а как минимум трое четверо, если они это дописали даже в четвером. 10 тысяч на каждого и довольно сложная логика и структура. Ну не знаю, там покрыто тестами? Да какие тесты? Давайте просто переведем продакшен на новую базу данных, написанную на крестах четырьмя чуваками за пару недель, что может пойти не так. Да, да. Зато не будет latency от горучей коллекции. Зато не будет времени ходить на спиддейтинге. Когда корочки валятся и секфолты появляются, это можно считать latency от горучей коллекции? Неудачно пошутил. Ну давайте дальше. А дальше вы, наверное, сможете больше прокомментировать. Роман Гребенников делится ссылкой про дотти. Это анализируем, осматриваем будущее скалы. Ну я посмотрел эту презентацию. Да, Свет, говори. Говори, говори. Я извиняюсь, что я так часто всех перебиваю. У меня опять все latency под 400 миллисекунд. Ну презентация как презентация. Как всегда непонятно, но очень интересно. Ребята обещают решить проблему с бинарной совместимостью, потому что сейчас там может быть так, что у тебя разные зависимости тянут. Не знаю, одну и ту же библиотеку, но одна зависимость для скалы 2.12, другая для скалы 2.11. Все очень плохо. Они обещают это как-то решить. Они обещают более крутые макросы, еще более крутые типы. То есть, например, сейчас у тебя в скале А виз В и Виз А это два разных типа. Вот они еще хотят сделать вместо ключевого слова виз оператор. Ну не оператор. В общем, синтексис с амперсандом такой, что у тебя порядок будет не важен. Какие-то еще странные непонятные вещи начнут. Порядок будет не важен. Они же благодаря порядку разруливают ситуацию с, скажем, как это называется, стекингом для интерфейса, для трейтов. Да, все так и есть. А как они это будут разруливать, если порядок не будет важен? Сдаюсь, как? Ай хз, как? Я думаю, ты знаешь. Нет, но я же не адерский, я глупый, я таких вещей не знаю. Это непонятно. Я вспомнила ситуацию про... Я говорю, непонятно, но очень интересно. Про версии. У меня сегодня такой интересный кейс был, могу рассказать про Spark. Я теперь со Spark работаю именно со стримингом. Я словила баг. Баг следующего характера. Вот у меня есть RDD, и мне нужна RDD от int. Пример такой. Я хочу в этот RDD от int преобразовать в RDD от string. И для этого мне нужно в функцию map передать внешний параметр. При передаче внешнего параметра в это замыкание у тебя Spark не может сериализовать этот параметр. Параметр обычный, скажем, тоже строка. И он на этом валится с ошибками сериализации. Я ломала над этим голову, я не понимала, почему он себя так ведет. Оказалось, что просто перевести Spark стриминг на последнюю версию 1.5, которая вышла, и все пофиксилось. Вот такая история. Но идем дальше. Я посмотрел остальные темы. Тут из тех, которые нас интересуют, я программист, но это не моя страсть. Остальные, по-моему, не заслуживают большого внимания. Подожди, подожди, подожди. Как же? А написание конфигов nginx на JavaScript? Серьезно? Конфиги nginx? Давай обсудим. Так интересно. Что ты об этом думаешь? А ты помнишь, мы с тобой вместе были на Highload, когда Sysoev сказал, что в следующей версии nginx вы будете на JavaScript все это писать? Все там обрадовались очень сильно в кавычках. А теперь вот у него блокпост появился, где он показывает пример, как это надо делать. Вот все готово. Мужик сказал, мужик сделал. Вас с Kalo еще не начали конфигурировать с помощью nginx? Нет, JavaScript, да. Я вот предлагаю вам тоже уже внедрить. Скажи нет, отчасти ты прав, потому что для Skala конфиги пишутся в этом формате hackon. Это такой подтип JSON. JSON это не nginx. Там же всякий полный, то есть как бы тюринг полный. Не смотри, тут же написано, что написание конфигов на JavaScript, потом будет прослеживание к JSON, а потом к hackon. Понимаешь, цепочку. Вот так мы дойдем до еще более простых структур. Нет, тут надо, чтобы были if, while или еще что-нибудь такое. Действительно, у нас же не тюринг, полный конфиг. Ну как так жить? Это же слишком легко понять, ребят. Подожди, Валер. Представь, у тебя есть конфиг, представил? И ты хочешь из этого конфига сделать запрос к REST-сервису. Что ты хочешь сделать? Давайте идем до конфига маленький, только клиент. У нас же все слишком понятно. Зачем упрощать себе жизнь? Это неинтересно. Нужны новые клубочки, сам понимаешь. Здорово, как из конфига. Супер. На самом деле там еще есть еще одна тема, но я ее сам бампнул. Тут спрашивают снова про Elixir и Ruby. Я на всякий случай отвечу. Во-первых, Elixir к Ruby имеет отношение только такое, что его делают люди, которые много писали на Ruby. Больше никакого отношения. Там еще некоторые конвенции в библиотеках. Они в принципе напоминают некоторые конвенции из мира Ruby. Так вообще в целом никакого отношения к Ruby это не имеет. Это в общем-то Erlang. Отличия от Erlang примерно в двух с половиной местах. Самая главная штука, с которой регулярно приходится сталкиваться, это наличие протоколов так называемых. Это что-то сродни Typeclass. Это не столько интерфейс, сколько именно Typeclass. Ты берешь и говоришь, что я считаю, что эта штука энумерируемая. Например, или какая-нибудь еще такая. Я хочу метод такого-то протокола позвать на этой структуре. Слушай, а как это реализовано? Там динамический диспатч. То есть получается, что у тебя в рентайме будет ухудшение? Нет, на самом деле, там есть несколько режимов компиляции. Один из режимов компиляции предполагает, что будет ухудшение performance, но тебе будет удобно девелопить. Другой производит так называемый протокол consolidation. И в этом случае у тебя для протокола собирается один-единственный модуль, в котором у тебя паттерн-матчинг с структурой, которую его реализуют. То есть из всех модулей, в котором реально есть реализация этого протокола для того, что у тебя есть, тебя это все надергивает. В один модуль есть просто большой... Ну, паттерн-матчинг у тебя вызывается на каждый вызов функции. Соответственно, если у тебя он стоит последним из 20, у тебя получается 20 проверок, прежде чем вызовется твоя. Ну, вполне может быть, но ты же не обязан так писать на каждый чих, во-первых. То есть ты должен понимать, что ты делаешь, когда ты используешь. Да, само собой. Просто для некоторых вещей этого очень не хватает. Типичный пример сериализации-десериализации. То есть в Erlang это... сделать расширяемую сериализацию-десериализацию – это проблема, например. Вторая такая приятная возможность, которая тоже... Прямо такое существенное отличие от Erlang – это возможность удобно метапрограммировать. В Erlang, конечно же, есть пространсформы, но они на порядок сложнее в применении. И, собственно, Elixir делается в первую очередь как язык для веб-разработки. Ну, то есть, если посмотреть на экосистему, это в первую очередь про веб-разработку. И в веб-разработке, ну, там рано или поздно приходится стакиваться с тем, что появляется куча бэллпрэйта. И вот, когда есть удобное метапрограммирование, с ним бороться проще. И также, как следствие наличия удобного метапрограммирования, есть крайне вменяемая библиотека доступа к данным, называется ECTO. Она, по сути, выглядит похожей на SLEEK, скаловский, или похожей на LINK из мира .NET. Крайне удобно, очень хорошо работает. Есть, конечно, мелкие проблемы, но я тут репортил несколько ишью. С большинством ишей того, что я репортил, разбираются в течение дня, например. Некоторые чуть посложнее были, я там тесты контрибутил, в принципе, их там за пару дней закрывали. Абсолютно все, что я репортил, было связано с функционалом, который добавили вчера, например, который я хотел использовать. То есть, как бы функционал, который там долго живет, он стабилен. Поэтому мне кажется, что ECTO очень хороший проект, достаточно хорошее предстояние. И ELEXIR, с его метапрограммированием, по сути, дал возможность сделать ECTO. Потому что очень много говорили про Erlang и его пространсформы, что на этом тоже что-то такое можно сделать, но в основном не там. Никакого конкурента ECTO такой же степени допиленности на чистом Erlang, как, увы, нет. Ну можно же использовать уже прямо этот же ECTO из Erlang? Нет. Почему? Потому что макросы ELEXIR работают в ELEXIR, а не в Erlang. А ты должен макросы в вызывающем коде иметь? Да. То есть ты не можешь просто функции какие-то дергать и все, да? Нет. Ну ты можешь написать свой доступ по данным освоен на ELEXIR, а потом его дергать из Erlang. Вот так ты сделать можешь, в принципе, уже без проблем. Понятно. Ну то есть там стык не совсем бесшовный, там и в обратную сторону швы есть, то есть из ELEXIR далеко не весь Erlang удобно звать. Дополню про Parts Transform, что в Erlang он, по-моему, парочку раз его или один-то раз точно ломали при переходе с версии на версию, то есть там есть какие-то недокументированные вещи, которые многие пользовали и которые отказывались работать в следующей версии. И плюс я бы сказал, что ELEXIR приятнее, вот мне показалось приятным с точки зрения доступа к работе со всякими дикшнери листами и так далее. Да, это безусловно. То есть там в мелочах он просто сильно удобнее. Но другое дело, что мелочь это не то, что определяет выбор языка на самом деле. Согласен. Это просто удобство ежедневного использования. А давайте про вот это разработчики не моя страсть. Давай. Это как раз про SPDY вот этот вот разработчик, это не моя страсть. Давай. Ну, в общем, в темах слушателей предлагается эта тема. Статья на хабре, я так понимаю, помимо меня ее еще Света прочитала как минимум. Я прав? Светлана? Совершенно верно. Ну вот. И в сущности это перевод, если я правильно понимаю. Да. И автор пишет, что ну да, я программист, но меня в программировании интересует бабло. И ничего кроме бабла. Я хожу там из компании в компанию, ищу для себя там более лучшие условия. И сейчас я там нашел совсем отличные условия, когда я там работаю из дома. И не знаю, и с баблом все нормально, и соцпакет офигительный, и вот так далее. И я что-нибудь упустил? Ну, он немножко не одобряет стартапы за то, что они мало платят, дают играться с клубочками. Но по деньгам это намного хуже. Ну и в конце там вроде как поднимается вопрос, насколько для вас программирование страсть, или может быть для вас это просто только работа. Вообще я считаю, что действительно люди бывают разные. Кто-то, не знаю, ему дали мячик, например, и он всю жизнь играет с этим мячиком, и ему больше ничего не нужно. Кому-то мало мячика, ему еще нужны клубочки, ленточки, и с чем еще там поиграться. А есть совсем такие наркоманские котики, которые там упарываются по полной лазерной указкой. И как бы, ну да, люди разные, все хотят разного от жизни. Кому-то для кого-то это просто работа, для кого-то это прям цель в жизни.",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 6992. Please try again in 13.984s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 6992. Please try again in 13.984s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
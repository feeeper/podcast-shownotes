[
  {
    "segment_id": "857525da-491d-47ee-a2be-6fcec80eec02",
    "episode_id": "37979056-870c-4f2a-93df-79b1eab9fd6e",
    "episode_number": 111,
    "segment_number": 8,
    "text": "То есть, сделать это на живом кластере, это нетривиальная операция. Возможно поставить рядом новый кластер и сказать, среплицируйся. Это сведение к случаю, когда у нас уже и так всё работает. И на практике это на самом деле довольно хорошее решение. Но с точки зрения удобства, да, developer experience страдает, но моя админская душенька, мне кажется, была бы спокойнее. И вот точно я сейчас добью эту тему. Во-первых, веб-админка довольно глючная, я советую про неё забыть, дёргайте, рестайпи курлом. Потому что не юзабельна пока. Что довольно смешно, считаю, что у них хватит ценового веб-админка. Ну она у меня тупо не создала кластер, я создавал кластер курлом. И ещё я не нашёл поддержку TTL в документах, что, ну не знаю, мне кажется, это нетрудно при компакшене грохать старые документы. Но опять же, смотри выше про APA-системы. Мой совет пока, что CouchDB 2.0 это довольно сыро и суперэкспериментально. Либо заюзать его для чего-то совсем-совсем лайтового, типа на будущее, а лучше возьмите что-то другое, потому что пока стрёмно. У меня с этой темой всё. Там дальше, Валер, по-моему, ты добавлял ссылки. Ну я добавлял там немножко набросываю, я не хочу её обсуждать. А вот в тему ты хочешь что-то изменить? Подожди, смотри. По поводу CRT-T, я, во-первых, нам уже в темы слушателей-то занесли. На самом деле я хочу позвать одного товарища, который у нас уже был. Я думаю, ты понимаешь, о ком ты говоришь. О ком я говорю сейчас. Я хочу дозавать, чтобы с ним об этом поговорить, потому что он точно в Twitter трейде засветился по этому посвящённому. И по-моему, даже доходит, я его видел, хотя могу ошибаться. Вот. И мне кажется... То есть ты сейчас не хочешь это говорить? Я не то что не хочу, я предпочёл, если получится с кем-то, с кем получится интересная дискуссия. Мне кажется, это... Прокауч, ему уже всё, да? Нет, ну в смысле... Давай, давай что-то. Можно в принципе обсудить с тобой, просто скандалить. Нет-нет-нет, подожди, Валер. Андрею есть что сказать про Кауч, насколько я понял. А, про Кауч? Нет, я про CRT-T на самом деле. Просто у нас был Виктор Грищенко один раз, и он прям великий мастер CRT-T. И мне кажется, тему CRT-T лучше отложить до того, как мы его снова заполучим. Я хотел по Каучу добавить, что на самом деле, как бы, всё, что... Ну, не всё, но 90% того, что объявили в Кауч ZB20, это всё пришло из проекта, который назывался Big Couch. И этому проекту было 100 лет в обед, и он довольно долго существовал. То есть было время, когда было несколько компаний, которые предоставляли Кауч ZB as a service. И одна из них как раз так и называлась, и у них всё лежало в open-source, и это был отдельный проект. По-моему, оно потом стало Клаудантом, который потом купил IBM. Да, как-то так. И оно, в общем-то, давно-давно существует. Ты рассказывал про аттачменты. Самый весёлый пример использования аттачментов из сферы «как не надо делать» NPM в репозитории первые 4 года своего существования использовал Кауч ZB как основное хранилище. И вот торговолы с кодом, который раздавал NPM, лежали аттачментами в Кауч ZB. Это как раз нормальный юзкейс, но, возможно, хреновая имплементация этих аттачей. То есть они все лежали в этой штуке. Первые несколько лет народ хвастался, что можно весь репозиторий одной команды синк скачать себе на флешку или ещё что-то. Затем он вырос до каких-то невероятных размеров. Затем аттач из него был вытаскиван. Вернее, они в основном в репозитории лежали в аттачах. Но при этом предоставлялись два варианта. Был настроен кластер с фильтром, чтобы не синхронизировать себе аттачи. И предлагалось, что если ты хочешь синхронизировать себе NPM, делать себе локальное зеркало, то ты синхронизируешься от лёгкой базы. Аттачи все лежали потом, перед ним лежал кэш, перед ним лежал циден. И получалось так, что ты обращался по углу, но при этом фастли тебе отдавал эти такболы со своих сил. Поэтому большой разницы не было. Сейчас там кауч-деби нет вообще. Буквально последние пару лет его уже выкинули. На момент, когда кауч-деби существовал, он спокойно хендлил 40 миллионов NPM-модулей. Не версий, а именно пакетов. И в принципе чувствовал себя хорошо, хотя все в кауч-деби за многого пытались. Зачем они так делают? Кауч-деби очень долго используется в мобильной разработке и в веб-разработке тоже. Когда пытаются сделать с помощью репликации и синхронизации документов между пользователями. То есть типа если там а-ля Google Docs или еще что-то. Потому что все, ну не то что все, больше очень самые взрослые решения для того, чтобы делать какой-то там офлайн хранилище документов на вебе. Они все на основе вот этого кауч-деби, который в свою очередь это имплементация протокола, имплементация клиента на JavaScript, маленькая видеотечка. Поэтому довольно популярен он у нас, у фротендеров, именно как механизм синхронизации. То есть часто бывает, что есть какая-то основная база данных для бизнес-данных, а уже там вещи, которые мы хотим синхронизировать лежат в кауче. Это то, что я хотел добавить. В принципе версия 2.0 этой серии мы смерджили в ветку и после этого мы потратили года-два на то, чтобы пофиксить не все баги. И в общем-то довели до какого-то состояния, когда можно пользоваться. Хочу порекомендовать кауч-деби как вот open-source проект, на который вы хотите потратить свое свободное время, если вам что-то такое интересно. Именно в вопросе нужно еще дохреначьего сделать, и очень отзывчивые ребята, и очень охотно принимают любые pull-requests. Там за часы за считанные. В этом смысле проект очень клевый. Так, ссылочки просили идти. Вот честно, я бы лучше пошел в Elixir по Contributor. Там тоже быстро и хорошо отвечают, но мне кажется... Скажем так, я понимаю юзкейс базы данных для синхронизации с мобильным девайсом, ну при том, что да, все логика мерзши руками, конечно же. Но честно говоря, если вопрос нужен документ ориентированной базы для JSON, сейчас есть гораздо более лучшая штука, называется RethinkDB. На крестах. И че? Нет, но я могу ответить и че. Connection pooling, у тебя знаком такой термин? Ну это... Да. Имеется в виду, что легковесных процессов... А, у них такая своя имплементация. Да, да. Ну хрен его знает. Понимаешь, вот одно из неприятных... Там дальше будет тема, небольшой спойлер про почему я ненавижу Postgres. Одна из причин — это низкоуровневый язык, и при условии, что большую часть времени мы байтики с дисков сеть перекладываем. Ну, давай быть честным. Симпсонс плюс не лучший язык для базы данных. Ну смотри, давай быть честным, мы на самом деле, как класс вообще людей, которые что делают, особенно backend-разработка, это люди, которые перекладывают байтики с сети в диск и из диска в крипт, чтобы каким-то образом при этом удалить бизнес-требования. Не правда, потому что backend-разработчикам иногда нужно по числу доробить. Я с этим сталкивался. Так что вот. Да, возможно, но в общем случае, в любом случае, даже если нужно по числу доробить, тебе точно так же нужно взять что-то с диска и положить в СОПИТ и обратно. Но вот согласись, это неотъемлемая часть. Да, и? Ну и к тому, что какая разница, какой там язык. Ну я люблю ирландку, но я набрасываю сейчас на самом деле. Я сильно набрасываю. Я хочу добавить команду плюс сто пятьсот к тому, что сказал Саша, потому что команда KOSDB это такие видные ребята в мире и JS, и ирландга, и еще там чего-то. Ну насчет ирландга не знаю, но они у нас делают JSConf EU, они делают вот это все общее движение, там, JavaScript конференции, и это они там начали вот эту тему с Code of Conduct, с Inclusivity и все такое прочее. И именно вот самые приятные люди, с которыми приятно работать независимо от того, что там делают. Очень клевые чуваки, все это одно. Ссылочки про сер-детей я могу сгрохнуть? Ты их сохранил куда-нибудь? Переложи их в очередь. Да, у меня они все сохранены. Ну на самом деле, ты свой наброс можешь на час набросить. Не, я не знаю. У меня ссылочки на твой наброс нет. Я передумал про этот наброс, если честно. Ну там была ссылка в блоге Трейса, что у чувака там в его твиттер-ленте запостился твит, который писал не он, и он считает, что это баг. Ну да, бывает с кем не случайно. Ну как бы на самом деле, ты знаешь, это как бы из разряда тут дело не в консистенции, а в, скорее всего, порт-читанах. То есть это немножко разные версии. Что в чем? Криворукость, да. Вот. Света нам хочет поведать про конференцию. Да, Света? Насколько я помню, там целая большая такая портянка из конференций. Ну да, и мы сейчас все по очереди расскажем. Так, хорошо. Наш подкаст хочет поддержать конференцию, которая пойдет в Минске. Будет в Минске. Ура! Конференция посвящена высоким нагрузкам. Это, по сути, такая, минский аналог HiLoid'а. Называется HiLoid DevConf. Это ежегодная международная конференция о высоких нагрузках. И она пройдет 22 октября в Минске уже в третий раз. И, насколько я понимаю, здесь добавляется новый трек, который посвящен машинному обучению. Чему я несказанно рада. К сожалению, я не смогу посетить эту конференцию в Минске. Но большой плюс, что для наших слушателей доступна скидка по промокоду DEVZEN. Маленькими буквами, латиницей. И мы всячески приглашаем людей на эту конференцию. Приходите. Там будет интересно и будет автопати. Что же они нас в инфопартнеры не добавили? Они добавят, как только мы опубликуем выпуск. Какие? Я пытаюсь по списку докладчиков спалить. Это те же люди, которые потом на HiLoid в Москве будут выступать или не те же? Частично. Там есть довольно большое пересечение. В Киеве пройдет элективный тап 1 октября. Это уже третий раз. Проводят те же ребята, что проводят Ruby Meditation. Команда организаторов хорошая. Контент тоже неплохой. Тусовка, слово обещает, будет хорошей. В плане того, чтобы были приятные люди. Традиционно Ruby Meditation делает метапы немножко платные. Но цена там очень небольшая. Делают больше для того, чтобы сподназировать, сколько там будет людей. И там еда, запись видео всякая. Я не знаю, кстати, будут видео записывать, обещали. Что будут. В Москве тоже был метап. Да, он уже прошел. Понимаю, Валера добавил ссылочку на видос. Да, я добавил. Я еще видос не смотрел, но вот прошел. Ну а качество проверил, может. А вдруг хреновое качество? Паленые видосы с пиратским переводом. С пиратским переводом на английский? Алексей... И в 8 октября пройдет конференция, которая называется UConn. Пройдет она в Саратове, как ни странно. Но самое главное, что конференция будет бесплатной. Из интересных докладчиков я там вижу Дениса Шевченко. Он у нас, по-моему, не один раз был в гостях. И из компании PVS Studio будет Сергей Васильев. Ну и там есть много других докладчиков. Это просто то, что мне лично в глаза бросилось. Вот, это все, что мы знаем про конференции, которые будут в ближайшем будущем. Ну там Highload будет в ближайшем будущем. Я не знаю, его рекламируют совершенно. Лишеного смысла, все знают. Як они закрыли вроде. Да, уже все. Технофорум. А есть какие-то причины закрытия ЯК? Ну, типа передумали. Мне всегда казалось, это такой большой хайринг-эвент на самом деле. Туда приходило 100-500 студентов, решали лабы на последних рядах. И всем раздавали визиточки, типа, поработайте в Яндекс. Раз, во-вторых, постепенно падала степень технических докладов. То есть, очень много всегда было таких откровенных маркетинговых докладов. То есть, Яндекс такой собирает друзей, все друг другу рассказывают, как круто покупать у них, там, не знаю, InfiniBand, на библиотечку, какие активы у них классные, или как, не знаю, как классно в Фейсбуке живется. Приходите к нам в Фейсбук на Яндекс.Эвенте. И так далее. То есть, количество докладов реально технических, хороших, оно год от года падало. И последний, як который был открытый, он был... Там было, может быть, два интересных доклада. А потом як был закрытым, я на нем не было. Но, судя по всему, у них тоже было пуговато с докладами. Я могу ошибаться. Да, так было, средненько. И, помню, кормили плохо. В смысле, в длинной очереди. Ну, тебе охота, не знаю, 40 минут в очереди стоять. Я понимаю, что бесплатно и все такое, но зачем так много людей пускать? Да, следующую тему добавил Андрей. Да, тема на самом деле технический пост от Cloudflare о том, как они на своей стороне внедряют перевод Loss HTTP на HTTP с помолчанием. Это новая фича, которую можно включить у них. И после того, как вы ее включаете, получается, если у вас кто-то из ваших пользователей стучится по HTTP URL, и есть ему соответствующие HTTPS, то Cloudflare заменяет в HTML HTTP на HTTPS. Пост примечательен тем, что написал его Ингвар Степанян, который активно участвовал в нашем Frontend Community в Киеве. Ингвар всегда специализировался именно на всяких парсерах и все такое прочее. И вот очень пригодился его опыт здесь, потому что по факту они взяли базу данных, улов, которые делает Electronic Frontier Foundation в рамках проекта HTTPS Everywhere. Это такой набор плагинов для разных браузеров, для Chrome, для Firefox, которые делают вот этот URL rewriting на стороне браузера.",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 5962. Please try again in 11.924s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 5962. Please try again in 11.924s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
[
  {
    "segment_id": "f60c1ae7-87d1-42be-b9bf-2a21d4ae6ebc",
    "episode_id": "a0766e0e-7a14-4a69-b67f-0848871fc195",
    "episode_number": 194,
    "segment_number": 3,
    "text": "И есть те, которые немножечко упираются вначале, но, как правило, получается убедить. Слушай, а ну, а как это выглядит? Вот, смотри, ты такой пишешь на код-ревью, слушайте, ребят, тут ничего непонятно, перепишите проще, вот, ну, как бы на такую претензию логичный ответ был бы «А чё непонятного-то?» Нет, там не столько непонятно бывает, там, скорее, бывает оверинжиниринг, но оверинжиниринг, как бы, вот, самую практику общей разработки, на чём бы то ни было, на том же питоне, я встречал кучу раз на питоне, просто паттерны лепят друг на друга, тут человек пытается слишком обобщить, например, хаскинисты вообще любят обобщать, так как ему хаски этому способствуют, иногда просто получается слишком общо, и человеку просто говорят, что ну-ка остановись, и так достаточно общо уже, вот, такое бывает. Но это обычный оверинжиниринг, просто немножечко своей спетивки есть в хаскеле, но просто потому что это другой язык, а так оверинжиниринг, это оверинжиниринг, он в других местах не отличается никак. Просто я думаю, новичку будет сложно такое сказать, потому что это может быть воспринято как «ну ты же новичок, ну конечно тебе будет сложно, смирись с этим». Или кто ты такой вообще? Вопрос из чата. Как часто в своих проектах вы используете техники метапрограммирования, в частности DSL? Ну, немножечко у нас DSL есть, который занимается тем, что описывает swap-сервис, который мы хотим потреблять, то есть структуру для данных. Там такой type-label DSL, из которого является код соответствующий. Нельзя сказать, что у нас на каждом шагу по DSL. Ну смотря что DSL мы считаем, потому что если взять, допустим, линзы, они у нас просто кругом, у нас все проекты на линзах написаны. Это тоже можно считать EDSL, хотя это просто библиотечка. Своих у нас не так уж много написано, и они очень локально применяются. Есть DSL, который используется для того, чтобы записывать шаблоны для админки, с которыми мы сейчас затрем геремию, но это как у всех. Вопросы по Haskell подходят к концу, а мы еще не перешли на другие функциональные языки. Давайте может перейдем... Сколько у вас PhD в команде? Нет, не одного. Более того, у нас нет людей, которые даже в компьютер-сайенс образование получали. То есть у нас сплошь всякие, чуть ли не физики, переученные и так далее. Вот я технолог, инженер, переученный. Вот именно все так и есть. Я пишу на Haskell, потому что я слишком глупый, чтобы писать на Python, я это понял спустя 5-6 лет.",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 1401. Please try again in 2.802s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 1401. Please try again in 2.802s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
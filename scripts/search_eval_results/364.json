[
  {
    "segment_id": "aae063aa-8f0f-4602-a975-04a3d4996e16",
    "episode_id": "2e2e6d28-3542-4482-85e9-ef2f03fb0017",
    "episode_number": 364,
    "segment_number": 12,
    "text": "Ты на Spark, JB, JB можешь писать на Python, у тебя проблема не из паркета в Spark достать, потому что тебе там все равно нужно будет делать преобразование, ну то есть у тебя паркет, он не совместим по memory layout, то есть паркет в принципе не описывает memory layout, а arrow описывает memory layout именно вот в памяти. Собственно, почему он совместим? Вот когда Саша говорит про совместимость формата, я чут это о двух вещах, о том, что у них flight совместимый, протокол остался, и что у них memory layout остается тоже совместимый между версиями библиотеки, то есть если у вас есть, скажем, кусок shared memory, один из процессов работает с ним, скажем, с C++, с версии библиотеки 6.0, другой, кстати, уже куском памяти работает, из раз библиотеки версии там 4.0, они ничего друг другу не напортят. Вот, и соответственно, когда мы говорим про Apache Spark, там проблема основная, это передать данные из Spark, который на джаве десертирует себя куда-то в джавный хип, данные, передать их потом в питон и в питонячую джабу, и чтобы желательно не копировать все эти весит массив данных. Я думаю, то, что имелось в виду на слайдах, что у тебя твой паркет и твой Spark могут быть друг о друга далеко, и тебе чем-то, чем ты читаешь паркет, нужно переслать данные в Spark, желательно не сервализую и десервализую всю эту фигню. Ну, это просто немножко странно, я не знаю, я не доставал до того места, но это немножко странная формировка, потому что паркет занимает меньше места, чем arrow, и тебе выгоднее непрочитанные кусочки паркета прислать и на ворке Spark его разжать в память. Ну, я думаю, это справедливое замечание к докладу, и там была картинка такая, что у тебя в серединке такой кружочек arrow, а вверху и внизу много разных других кружочков, которые с другом общаются через arrow, и вот Spark к Sparket, это просто один из примеров, возможно, самый неудачный. Другой пример – это вот нужно из Cassandra что-то в Spark передать или из Spark в Pandas. Тут нужно сделать пару отступлений, и во-первых сказать, что такое паркет для полноты картины, потому что я типа тоже вроде как знаю, что это вот файлик с данными, да, и вроде он как бы про колоночки, вот, но сам я паркет вообще никогда не трогал, опять же, просто было не нужно. Паркет, Валера меня поправит, это формат хранения данных на диске, колоночный формат, и оптимизирован он при этом под занимание как можно уменьшего места на диске, т. б. поджатия этих данных. Опять же, напомню, они колоночные. Да, то есть, как бы поскольку он колоночный, он еще автоматически оптимизирован про то, чтобы читать, как можно меньше. Ну, т. е. даже если у вас много данных, чтобы вы могли найти и прочитать только то, что вам реально надо. И он имеет вот в это дельты, дельты и так далее? Да, дельты, словари, поверх этого все обычные, на крушеве еще обычная компрессия, плюс там есть ограниченная поддержка методанных, ну, собственно, одна из таких странных проблем с паркетом, там можно по-разному одну эту статую данных представить, он немножко в этом плане как XML, т. е. там есть паркет, есть как формат серилизации, есть как формат, с которым работают фреймворки и Spark, например, и некоторые другие, я ничем не вспомню, что там, я точно помню, что была проблема, собственно, между тем, как встроенный в Arrow C++ D-serializator или наоборот, серилизатор, D-serializator, да, мы писали Spark, читали C++ Arrow имплементации паркета, там были несовместимости, вот, например, их можно починить, но, т. е. методанные там местами под вопросиком. А вот, кстати, интересный момент, одна из вещей, которую говорит Доглащик, что он, собственно, вот то, что ты говоришь, говорит, то, что паркет это не самый лучший у нас этих форматов, он создавался, ну, его основная претензия, то, что он создавался в 2011-м, и за 10 лет что-то в мире изменилось, диски стали быстрее, чем были, а с другой стороны, там, процессоров не то, чтобы сильно больше заносили, плюс вот то, что ты описал, он это описывает как паркет, он такой немножко Frankenstein, в смысле, что ты не можешь его вот, короче, его беспокоит, что процедура чтения паркета с диска, она достаточно нетривиальная, и она дороже по CPU, чем могла бы быть, т. е. его беспокоит вот именно лишнее потребление циклов CPU во время чтения паркета, и одна из его идей, что можно сделать что-то получше в 2022 году, но это просто как бы он идея озвучивает, у него нет никаких доработок, ничего такого, еще он вспоминает альтернативный формат паркету, называется ORC или ORG, вот мне интересно, ты можешь на вскидку объяснить в чем его принципиальное отличие? На вскидку нет, слушай, там, короче, основная история в том, что есть несколько разных big data систем, есть вот Spark, есть еще всякие Hyve, есть более приприоритарные вещи вроде Teradata, и у них у всех есть предпочитаемые ими форматы данных, то есть Spark, например, предпочитает работать с паркетом. Я, насколько и звучал вопрос, там на сегодняшний день именно в плане формата хранения, там более-менее все как-то наравне, у ORC, мне кажется, чуть менее в сыратый дизайн метаданных, то есть это понятно, что ORC больше на себя берет ответственности, чем паркет, соответственно, там немножко больше, ну немножко лучше история про то, как метаданные хранятся, и более все однозначно, но я так понимаю, что он менее популярен в итоге. А вот продолжая тему там интересных наработок, которые появились, например, когда ты работаешь с аналитикой, ты не факт, что работаешь с диском напрямую, вот прям с диска читаешь свой паркет, а возможно ты его читаешь с какого-нибудь СЕФа. Оказывается, ребята за проектом СЕФ, они сделали прикольную наработку по пушанию, я вот не очень понял, честно говоря, до конца этот момент, но видимо есть наработка, которая позволяет тебе, вот у тебя лежит какие-то данные в СЕФе, а тебе прям СЕФ может в тебя стрелять РО, понимаешь, то есть тебе не нужно в своем приложении реализовывать, десерилизация данных пропушнута в уровень СЕФа, вот так. Ну мне тоже кажется, я бы так такой спорной идеей, ну то есть потому что, опять же, ROW не то чтобы самый эффективный формат хранения на диске, то есть ROW он вообще не хранит. Подожди, ROW на диске вообще никто не хранит, я так понял. Ну просто смысл тогда его передавать по сети, понимаешь, то есть тебе все равно нужно десерилизовать, но то есть да, ты передал его. Его не нужно, именно в том-то идее, что когда ты его передаешь, тебе его не нужно десерилизовывать, он типа зеррокопия. Я вот что пытаюсь сказать, у тебя есть какой-то диск, ну в конце концов, где-то вот на этой машине с СЕФом есть какой-то хранилище SSD или крутящийся диск, что там у вас такое, может там закошевелено в памяти, неважно, оно скорее всего вы хотите это хранить в максимально хорошо зажимающем формате. В ROW сейчас на данный момент обсуждается компрессия, на данный момент, насколько я знаю, никакой компрессии нет, он колоночный в том смысле, что он в памяти нарезает данные по колонкам, и соответственно, если вы там будете киндисимт оптимизированные операторы писать, он для этого будет хорошо подходить, но для передач данных он довольно большой, то есть и чтобы понимали, насколько какой-нибудь паркет может быть пожат, это могут быть десятки раз на некоторых данных, и я слабо себе представляю практическую пользу от того, что мы не десерилизуем потом на Worker, проделав десерилизацию на машине с хранилищем, то есть единственная ситуация, когда я",
    "result": {
      "query": "parquet vs orc differences"
    }
  }
]
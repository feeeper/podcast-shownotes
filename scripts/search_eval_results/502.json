[
  {
    "segment_id": "7790be4d-2ac1-4795-909d-069b7a028dfd",
    "episode_id": "8c5f7b45-4bfa-4675-a683-336e6caca661",
    "episode_number": 502,
    "segment_number": 4,
    "text": "Тогда думаю можно и сразу переехать в DPS с кнопкой Search. Ты решил с этой начать? Хорошо. Я не то что решил, она просто так легла. Карта. Ну ладно, ладно, не суть важно. Я помню, что в прошлых двзэнах Валера расхваливал, кажется, Perplexity называется, да? Да. И недавно я заметил, что в DeepSeek появились две новых кнопки. Одна из них называется Think чего-то там. Давайте я вам открою, чтобы не набрать, как они назывались конкретно, потому что я по памяти говорю. Одна называется Deep Think, а а вторая называется Search. Вот что делает Deep Think я не знаю, но кнопочка Search это вот то, что Валера раньше описывал, как я выяснил. И я решил попробовать этим попользоваться. И это прямо прикольно. То есть когда ты задаешь вопрос, то И если эта кнопочка нажата, то ДикСик может за тебя погуглить, собрать какие-то статьи, резюмировать их и на основании этих статей дать тебе ответ или как другой пример он может дать тебе ответ не гугля если он достаточно в себе уверен что он знает правильный ответ но можно попросить его а сошли сошлись пожалуйста, на какие-нибудь источники, которые подтверждают эту точку зрения, или Приведи цитату, где, например, какой-то термин используется вот в таком-то контексте, и он всё это может. Это прямо прикольно. Я поймал себя на том, то есть когда я вот это обнаружил две недели назад, потому что на прошлой неделе мы не записывались, я поймал себя на том, что я в DeepSig открываю его чаще, чем в Google, потому что зачастую это для меня работает как более удобная поисковая система, что неожиданно. Я никогда не воспринимал LLM как замену поисковым системам. И при этом нужно проявлять осторожность, когда ты этим пользуешься. Например, если попросить его порекомендовать тебе 3D-принтер, то да, он разумеется загуглит, выберет статьи, но это будут статьи с высоким PageRang или как сейчас сортируют поисковые сети, какой-нибудь сайт, магазин 3D-принтеров производства к реалити в России. И он найдет там статьи, которые описывают, что 3D-принтеры к реалити самые лучшие, а потом он туда подмешает еще какую-нибудь вторую статью, что Flying Bear Ghost Six это прям супер актуальный 3D принтер, который надо брать, и он из всего этого намешивает и даёт тебе результат. То есть понимаете, да? С помощью LLM выбирать 3D принтер не рекомендую. Он очень настойчиво продавал мне идею, что вот Ghost Six это прямо тема, надо брать. Так отличный принтер. Что ты гонишь? Это отличный принтер на 2002 год, наверное. Сейчас 3D принтер за 30 тысяч рублей на Марлине. Это не лучший выбор в плане отношения цена-качество, по моему скромному мнению. Но возможно это вам виднее. Что это такое, чтобы спорить с нашими оверлордами? Да, да. То есть не в обиду владельцам Ghost Six. Если у вас есть этот 3D-принтер, он решает стоящие перед вами задачи, вы им довольны, еще лучше, его его на клипер перевели, то принтер хороший, просто его нет смысла брать сейчас новый. Что еще? А тут в этом контексте у меня в чатике, как это правильно сказать, на канале в telegram канале, который к моему блогу прилеплен. В общем у меня есть блог, а комментарии к нему в телеграме. Там возникла конструктивная дискуссия буквально вчера на предмет, что такое горизонтальное разделение. То есть вот у тебя есть TMUX, ты в нём вводишь команду и у тебя два варианта исхода: у тебя слева окно и справа окно или сверху окно и снизу окно. Что из этого является горизонтальным разделением? Если я правильно помню логику TMUX, это слева и справа окно считается горизонтальным разделением. Валера, ты согласен с таким определением, как горизонтальный уровень? Мне кажется, тоже да. Я тоже с этим согласен. И со мной согласен самое главное ман тэмукс. Но это сильно контритуитивно. Во-первых, это для меня, мне нужно прямо сесть и основательно подумать, почему мне так кажется, а если сесть и подумать, то просто есть прецеденты использования, горизонтальные масштабирования до которые обычно вот рисуют горизонтальные реплики да и несмотря на то что у тебя вот эти линии которые как сказать виртуально делят они идут вертикально, линии разделения они вертикальные, тем не менее, это горизонтальное разделение. Горизонтальное может и количество предметов увеличивается в горизонтали. Да-да-да. Точно так же вертикальное письмо и горизонтальное письмо, в смысле вот в некоторых языках пишут сверху вниз, несмотря на то, что буквы разделены вслух, если мы берем горизонтальное письмо, как вот мы в русском языке пишем, ты виртуально делишь буквы вертикальными чертами, но это тем не менее горизонтальное письмо, потому что элементы идут горизонтально. И в ТМОКсе такая же логика. Но это прям было, знаете, на грани срача. Так вот, а при чем здесь depsig? То, что я эксперимента ради задавал ему этот вопрос, что является горизонтальным, что вертикальным разделением. Тут, кстати, тоже интересный момент, как надо задавать LLM вопросы, то есть если ты ему скажешь что-то уровня, а вот есть там разделение да левое правое окно верно ли что это вертикальное разделение и он скажет тебе да да да это абсолютно верно что это вертикальное разделение но если ты ему задашь вопрос а является ли это вертикальным или горизонтальным разделением то это более лучший вопрос для LLM, потому что тогда он действительно попытается как-то поискать в своей модели. Я, кстати, тоже замечал, у моделей прям очень сильные Confirmation Bias, Если ты им даешь ответ в вопросе, они почти наверняка выберут этот ответ. Я еще проверял на Вообще DeepSec хорошо решает некоторые математические задачи. И я на самом деле могу в чат скинуть пример. Это не полностью реализовано не полностью написано DeepSig, но я взял мне было короче я писал пост про резервуарную выборку и задумался над вопросом: верно ли утверждение, что все элементы попадут в выборку с равной вероятностью? Потому что это далеко не очевидно, если серьезно об этом подумать и попытаться прямо строго математически доказать. Я посидел с бумажкой и понял, что тервер был на третьем курсе. Это было очень давно, и как-то я по образованию наполовину математик, но это было давно и неправда. И мне как-то тяжело, поэтому я попробовал задать вопрос AI, и он дал доказательства почти правильно, Т. Е. Я на него смотрю, я понимаю, что нужно поправить, но он там граничные случаи некоторые не рассмотрел, т. Е. У него доказательство выглядит похоже на правду, но оно не строгое, математики такое не примут. Поэтому если сесть, его аккуратненько переписать, то оно становится правильным доказательством. Но прикол в том, что если ты берёшь алгоритм, т. Е. Как выглядел мой запрос? Я показываю ему код на Питоне и говорю: Рассчитай, какая будет вероятность попадания каждого элемента в конечную выборку, и он дает результат, который на 99% правильный. Но если ему можно задать вопрос: верно ли, что каждый элемент попадет в выборку с равной вероятностью? И он тоже тебе выведет тот же ответ, потому что они действительно попадают с равной вероятностью. Но ты можешь исправить код, внести в него ошибку и задать тот же вопрос: верно ли, что все элементы попадают с равной вероятностью? Это уже неправда, но он докажет тебе, что они попадают туда с равной вероятностью. Вывод такой, что если вы пользуетесь ЛЛМ, не задавайте ему вопрос докажи что? Или верно ли что? А давайте ему вопрос, где ответ открытый, может быть произвольным, тогда больше шансов получить что-то похожее на правду. Но вообще можете посмотреть PDF, которую я прилинковал. Я повторюсь, она почти целиком сгенерирована AI, потому что мне было лень это делать самому, и результат он прямо впечатляет. То есть это прям прям круто. Вроде бы я более-менее все рассказал, что хотел по этой теме. Остальное я тут еще всякого повыписывал, но в ретроспективе это наверное не очень важно. То есть коротко в дипсике теперь есть кнопочка Search. Она работает хорошо если вы понимаете как это работает под капотом то есть мне прям понравилось я рекомендую это забавно потому что вот как раз примерно две недели назад независимо от тебя я вспомнил что валера рекламировал perplexity ай AI и я его поставил себе как дефолтный поисковый движок в браузере. Сделал я это потому, что я давно хотел им пользоваться, я просто всегда забываю, у меня машина мышечная память, просто печатать в строке адреса и искать. Так вот, к чему я это говорю. У меня впечатления немножко смешанные и чуть более прохладные, чем у тебя, потому что, с одной стороны, вот этот типа умный поиск, он хорош, когда тебе нужен ответ про какой-то легко доступный факт, про который ты ничего не знаешь, типа вот Дать тебе какие-то первые кусочки информации, чтобы дальше начать изучать незнакомую тему, это в принципе работает неплохо. Где это работает не очень, это когда тебе хочется что-то очень быстро найти, потому что все таки ти лмки они думают не очень быстро. Ты отправляешь запрос и сидишь 5, 6, 10 секунд пока он там погуглит, подумает, сгенерирует ответ и в общем как я сказал мой тот attention span тут же уже начинает переключаться на мемасики и твиттеры и это не очень хорошо для продуктивности. Вторая проблема с которой я столкнулся, это я очень часто нахожусь в ситуациях, когда мне нужно найти документ, который я знаю существует или какую-то страничку или ресурс. Но вот в лучшем случае перплексити покажет мне одну из ссылок вверху и может если повезет это будет нужно ссылок, но чаще всего Поэтому мне пришлось в итоге добавить этот шорткат для того, чтобы в гугле тоже искать. Я заметил, что я очень часто в шорткат теперь хожу. В общем, Такое смешное впечатление. В принципе перплексить это интересный эксперимент, но мне кажется что по общей сумме удобства гугловый поиск все равно побеждает. Тем более что у них теперь тоже такой небольшой я и наверху показывается. Я вообще не пользуюсь препятствием местного Гугла, если посмотреть, что у него последнее время спрашивал, могу даже открыть свою историю запросов. Я просил его по истории с LeadOS поискать некоторые там факты о том поддерживает ли эта библиотека IO ulink что там у него с перфомансом какие другие проекты используют, то есть типа чтобы не искать по всему гитхабу спрашивал почему концерт для скрипки Баха номер один постоянно всплывает в кино, то есть такого рода вещи, там не знаю. Такой максимальный размер сообщения в Kafki и RedPindy, вот, то есть типа какие-то такие вещи, которые А вот кстати про последнее я тебе скажу, что вещи, которые вероятно меняются со временем, вот про них очень плохо спрашивают. У меня был конкретный пример, я хотел спросить с какой точностью работает целочисленная математика в Fish, который Shell. Перплексики очень убедительно настаивал на том, что у них бесконечно длинные интеджеры и они могут любой длины математику. И были почти правы, потому что когда-то несколько версий назад Фиш не умел делать математику сам и он ее аутсорсил и тилити би си, которые чего-то там калькулятор, короче, которая на большинстве юниксов есть. А потом, несколько релизов назад, они сказали зачем нам внешняя зависимость, тем более что её может не быть, давайте мы внутреннюю библиотеку будем использовать. И стали использовать библиотеку под названием TinyExport или что-то такое сишная. И эта библиотечка она как раз всю математику делает Float 64. Вот, и поэтому там точность интеджеров получается 53 бита, ну короче вот размер мантиссы, который там есть у флота, и все. И это предел. Вот, но, к сожалению, perplexity это не понял, несмотря на то, что изменение произошло. Точнее даже так, он не то что не понял, он упомянул, что они в какой-то момент переключились на tinyexper, но при этом он продолжал настаивать, что tinyexper тоже умеет бесконечно длинную математику. Если нас слушают разработчики подобных систем, мой скромный фичер реквест, сделайте так чтобы ваша машина могла пойти прочитать source код и понять правда ли это или не правда когда у вас вопросы про опенсорсные приложения потому что у вас есть киктрап ты же можешь но иногда это делает просто у тебя нет возможности ты можешь или явно прям совсем явно контекст набросить или у тебя нет возможности толком проконтролировать какие источники предпочитать типа ты не можешь типа хочется отдельным промптом запромтить каким источникам отдавать предпочтение Может быть, ну не знаю, мне кажется, что в принципе как бы в чем смысл всех этих лм поисков, в том что у них есть вот эта лм часть, при этом у нее есть как бы вот эта агентная часть, которая может проверять гипотезы и теории, используя настоящий поиск. Просто сделайте ей дополнительный инструмент, чтобы она могла понять, что вы говорите про какую-то опенсорсную программу, скачайте исходник и проскопируйте этот исходник, чтобы ответить на вопрос точно. Мне кажется, что это была бы крутая фича, наверное, очень дорогая с точки зрения инференс, но блин, чуваки, принесите будущее, пожалуйста будет так круто. Резюмируя, оно хорошо подходит когда тебе нужно не одну ссылку найти, когда тебе хочется чтобы оно не знаю грубо говоря пооткрывало страницы стопок угла суммарно и выплюнуло тебе это как бы коротким текстом. Ты уж потом решишь хочется с этим потом дальше разбираться или нет. Это да. Для этого он отлично работает. Согласен. Но мне кажется что он не умеет, я видел по максимуму 40 в себя всосал. Я не сказал 100, я сказал с топа. Я услышал это 100. Я видел, что он обычно берет 15 максимум. Я видел, по-моему, 40 ссылок он Еще я посмотрел на MAN BC, потому что мне стало интересно, как расшифровывается BC. И в MAN ответа я не нашел, то есть как будто бы никак не расшифровывается. И имя автора там ни при чем. Значит так, все закрыли LLM и перестали вводить туда вопрос почему BC так называется? Я так сейчас не делал, это неправда. Так, ладно, едем дальше. Алекс такой: Ну блин, ничего ты. Да правда.",
    "result": {
      "query": "перплексити ai vs deepseek"
    }
  }
]
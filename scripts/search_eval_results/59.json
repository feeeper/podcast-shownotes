[
  {
    "segment_id": "1504af38-ee3c-4ba7-b2b6-8cd210556560",
    "episode_id": "0f08da33-23de-4ce2-a2d9-f030904e1eec",
    "episode_number": 59,
    "segment_number": 4,
    "text": "И идея здесь в том, чтобы иметь доступ к какому-то пошаренному между трендами ресурсу, но при этом не держать, чтобы ни один из потоков не вставал намертво, а пытался продолжать делать какую-то работу. Там есть на самом деле несколько гарантий. Есть Abstraction Freedom, есть Lock Freedom, есть Wait Freedom. Про всё это можно на вики почитать. Я не буду сейчас углубляться, потому что я тогда уйду далеко от темы. Но суть в том, что у всех этих алгоритмов, у них есть ряд сложностей в имплементации, потому что в такой среде трудно управлять памятью. То есть, зачастую можно написать неплохой Lock-Free алгоритм, он будет неплох во всем, кроме того, что его управление памятью будет тормознее, то есть, грубо говоря, вас тормозит управление памятью вместо того, чтобы тормозила структура данных. Потому что управление памятью, в самом себе, не бесплатное. И оно будет втыкаться в синхронизацию. Это раз. Во-вторых, даже если это как-то обойти, то это нетривиальная задача, на самом деле. А в то же время, Lock-Free структуры данных, как я уже сказал, являются крайне полезным примитивом для имплементации. Во-первых, других более высокоуровневых абстракций, а во-вторых, иногда бывает так, что хочется именно эту низкоуровневую Lock-Free какую-нибудь штуку такую себе запилить, потому что нужна что-то такое кастомное, чтобы вот здесь хорошо работало. И считается традиционно, что Lock-Free очень удобно пилить на платформах, где есть GC. Потому что GC за нас сделает всю сложную работу. Он за нас уже может быть хорошо распараллелен, если это... Или за нас сделан concurrent GC и тормозит. Но даже если и будет, то он будет тормозить вместе со всем остальным GC, которое в любом случае неизбежно случится. Поэтому накладные расходы на управление памятью в такой вот Lock-Free структуре данных, которые поверх GC-рантайма, они будут размазаны пополам с накладными расходами на просто управление памятью на этой платформе. И, собственно, дальше он приводит технику управления памятью в не-managed-рантаймах, которая была предложена каким-то чуваком в какой-то дизере. Суть заключается в том, что есть три поколения, в каждом из которых живут кусочки данных. Вместо освобождения мы суем... Каждое поколение, это по сути, номер на счетчике. И связаны с ним лист освобожденных данных в это поколение. При том, лист освобожденных данных, он, понятное дело, не глобальный. Он у каждого треда свой, локальный. То есть, когда какой-то тред хочет какие-то данные освободить, он просто берет и линкует в этот лист. А когда это поколение становится самым старым, то по этому алгоритму есть гарантия, что туда уже никто точно ссылок не имеет. И значит, то, что в линк-листе текущего треда, можно просто взять и выкинуть. И таким образом мы память чистим. Дальше там приводятся бенчмарки. Кроссбим удачно рвет просто... Многие имплементации похожи. Он примерно похож на низкоуровневый адовый код Rust Channel. По производительности он практически в нос к носу идет. И он быстрее, чем Java с GCRuntime. Или чем встроенные в Java конкурентные структуры данных. Собственно, причем здесь, казалось бы, Rust. Ну, здорово, можно по китам тоже самое заимплементировать на C. Зачем нам вдруг понадобился Rust? Rust здесь интересен тем, что описанный алгоритм можно таким образом вписать в систему типов Rust, что система типов за нас проверит, что мы не делаем, недопустимых операций, что мы не ссылаемся на объекты, на которые не должны ссылаться. Или наоборот, что если мы пытаемся освободить, то мы там освободим все, что нужно. Что если мы там делаем какую-то thread-local операцию, она будет только в этом local thread-е. И при этом, что у нас эпохи будут автоматически инкрементироваться каждый раз, когда мы делаем соответствующие операции, потому что мы должны там guard к себе таскать, ну и так далее и тому подобное. Я не могу это сейчас все целиком описывать. Статья довольно короткая, можно пойти по ссылочке и посчитать. Она довольно интересная. Даже если вы не интересуетесь Rust, то эта статья может быть вам интересна. К сожалению, она, в принципе, как и стоило бы ожидать, от такого низкого уровня примитива, как lock-free структуры данных, там в итоге совсем без unsafe кода обойтись нельзя. Но его там буквально в готовом примитиве, уже построенном на CROSSBIM, буквально 2-3 unsafe строчки, которые по сути распаковывают из поинтера в целевой тип данных. Что, в общем-то, от довольно небольшого количества unsafe кода, и с этим как раз уже можно жить. И CROSSBIM как раз берет на себя самую основную, такую вот хардкорную часть по управлению памятью. И благодаря системе типа Rust они дают вам себя использовать неправильно. Вот, такие дела. Причем CROSSBIM поверх нее делают вот эти очереди, качестве примера вот этих структур данных. Очереди серии. Несколько продюсеров, один консумер, несколько продюсеров и несколько консумеров. Но CROSSBIM это не скролл в нее библиотека, и можно поверх нее... Она именно для управления памятью, а не для того, чтобы эти структуры данных создавать. Просто уже на основе нее можно создавать разные структуры данных. Ну, я бы сказал так, она в первую очередь... Это управление памятью, которое в первую очередь заточено на то, чтобы быть использовано для построения локфри структур. Да-да-да. Спасибо, надо почитать. А есть какие-нибудь идеи по портированию вот этой истории на другие платформы? Ну, смотри, в какой-нибудь скале Java тебе это просто не нужно, потому что у тебя GC. И в-третьих, у тебя есть встроенные всякие штуки и море их. А на какой-нибудь C или C++ ты это особо не портируешь, потому что здесь прелесть этой библиотеки в том, что она дает кучу статических гарантий просто потому, что тебе система типа FRASTA их дает. Ну, то есть я не уверен, что это можно сделать где-то в другом месте. То есть тебе нужна система типов, очень похожая на систему типа FRASTA. Я не знаю, где еще такая есть. Наверное, в какой-нибудь ATS, наверное, такое можно сделать. Ну, в принципе, в языке должны быть линейные типы. И ресурсы acquisition из initialization, как pattern, должны быть возможны. Поэтому мне кажется, что на каком-нибудь ATS или на каком-нибудь Mercury или на каком-нибудь Kliny что-то такое похожее изобретить можно. Хотя я не уверен, что он там везде будет выглядеть один в один. В общем-то, да, это скорее такая... Она расспецифичная в плане того, как оно выглядит. Но статья в целом интересна просто потому, что она заодно показывает этот подход к управлению памятью. Сам по себе подход можно заимплементировать где угодно, наверное. Да, наверное, даже на JVM это можно сделать. Только нужно учитывать, что, наверное, он может быть полезен, если имплементишь какую-то штуку поверх unsafe, поверх ручного управления памятью. Может быть интересно в таких случаях. Но я не знаю. Ну, такая богата идея. ГЦ для unsafe такого плана. Да-да-да. То есть это не совсем ГЦ. Ну, скажем, собственно, ручный. Некоторые вариации. Мне в нем нравится именно тот факт, что фактически получается каждый трет, когда он создает какой-то мусор, он фактически этот мусор потом за собой убирает. То есть у нас нет отдельно выделенных каких-то ГЦ-тредов или чего-то такого. Вместо этого... И при этом у нас есть вот этот список, вот этот линк-лист, куда мы складываем отработанные, скажем так, объекты, данные и все такое прочее, когда мы переходим с одной эпохи до другой. Но в принципе три эпохи это минимум, который нужно держать. То есть третью эпоху мы чистим, а две другие как бы активная и новая. Но в принципе никто же не говорит нам убирать, очистить мусор именно в этот момент. То есть в принципе это может быть какая-то юристика поверх, которая решает, когда мы что-то очистим. А следующая тема моя. Точно, Андрей, твоя тема, да. Интересная статья в блоге одного из, я так понял, студентов, интернов, который летом, этим летом работал в компании MongoDB. Соответственно писал MongoDB и рассказывает о том, как они специально для Монги сделали свой такой маленький-маленький движок JavaScript. Казалось бы, зачем Монге свой JavaScript? Дело в том, что есть как бы SpiderMonkey, есть V8, это хорошие быстрые движки. Но в Монге можно делать вот эти запросы, их языком запросов. Один из видов запросов это такой $V. Туда можно передать какую-то кастомную функцию, которая может дать нам критерии серии, принимать или не принимать ту или иную запись в запрос, в ответ. В Монге есть куча-куча какие-то функций стандартных, но вот этот V это такой Escape Hatch, чтобы можно было делать что-то совершенно кастомное. Когда-то давно Монга использовал SpiderMonkey для того, чтобы вот эти кастомные функции интерпретировать. Потом они через несколько релизов перешли на V8, со словами V8 быстрее и круче, поэтому мы будем использовать его. Но вот в их конкретном варианте использования это все большие накладные расходы. Во-первых, данные у них хранятся в формате BSON, а не JSON. Это binary JSON упакованный. Соответственно, каждый раз, когда им нужно эту функцию выполнить, им нужно мало того, что загрузить эту функцию в виртуальную машину, так еще и все данные, какие-то данные нужно распаковывать из бинарного JSON в обычный JSON, для того, чтобы в этой виртуальной машине можно было эти данные прочитать. Плюс еще все эти виртуальные машины, в них как бы JIT, но JIT срабатывает же не сразу, а постепенно. И получается, что изначально, когда делается эвельюшн этой функции, кастомная из V8, виртуальная машина запускает всякие планировщики, профайлеры и все такое прочее, чтобы собирать метрики, для того, чтобы решать, что JIT-ить, а что нет. Обычно эти функции, это такие 2-3 строчки, поэтому JIT-ить там особо ничего не нужно. И вместо этого, как бы виртуальная машина, вместо того, чтобы быстро-быстро эту функцию выполнить, она тратит кучу времени, для того, чтобы инициализировать всякие там объекты для профайлинга, делать букки, все такое прочее. И вот они решили в результате писать кастомный интерпретатор, очень-очень простой, который просто сможет очень быстро стартовать с этими функциями, и при этом читать данные из BSON напрямую, без конвертации в JSON. В статье описывается, как они это сделали, есть какие-то метрики, и метрики там действительно такие серии в разы, в разы они обгоняют и SpiderMonkey V8. И у них есть какие-то планы по дальнейшему улучшению, но непонятно, насколько... Во-первых, этого всего, насколько я понял, сейчас еще нет в MongoDB, то есть сейчас MongoDB продолжает использовать V8, и непонятно, продолжится ли работа над вот этим TinyJS, как они назвали этот движок, после того, как их интершип закончился. Но статья интересная сама по себе, для тех, кто любит всякие интерпретаторы и все такое. Отлично. С другой стороны, мне вот, например, не очень понятно, дело в том, что как бы эта же функция, которая вот кастомная маленькая, она подгоняется для всей коллекции, или там для каких-то частей коллекции. Почему они не могут использовать один и тот же контекст виртуальной машины, для того, чтобы читать разные документы, я, к сожалению, не очень понял. Может, у них просто ручки, как обычно. Ну, то есть у меня вообще большие сомнения в компетенции разработчиков Монги. Вот у меня фига, это самая первая реакция, потому что в Монго настолько все время broken by design, что я не удивляюсь уже ничему. Ну, дело в том, что в том же Couch'е точно так же кастомные функции выполняются в SpiderMonkey, и, насколько я знаю, там просто в какой-то момент вот этот контекст, в котором работает вот эта функция, она загружается туда один раз, после этого она через сколько-то записей, допустим, записей 10 или 100, она джитится, и после этого она фактически выполняется с нативным кодом. То есть в момент, когда прогоняется твой, я не знаю, MapReduce какой-то запросик в Couch'е, там первые несколько записей обрабатываются медленно, а потом обрабатываются быстро. Зачем было делать вот такие вот пертурбации с отдельным движком, отдельным интерпретатором, мне, честно говоря, не очень понятно. Мне кажется, что подход неправильный. Особенно учитывая, что JSON зачастую вообще и хронимка, то на самом деле с джитиной представление, я подозреваю, в некоторых случаях можно даже кэшировать. Да-да-да, может быть. В этих виртуальных машинах как бы нет механизма своего из коробки, чтобы кэшировать, куда-то на диск пересестить вот это вот за джитиное представление. Но я думаю, что если этот механизм для хронимок, для простых вот этих функций добавлять, то, наверное, это какой-то небольшой патч, который можно мейнтринить внутри компании. Ну или просто взять и сконтрибьютить в конце концов. Мне кажется, браузер тоже это может выиграть, потому что представим, что у нас почти все ассеты больших сайтов лежат на CDN-ах. Мы можем просто почитать его MD5, и он там, не знаю, у нас дня 2-3 файл не меняется, мы берем просто для него, дадим его 1 раз джите, мы 2-3 дня живем на с джитином файлике вообще, пока кто-нибудь в очередной раз не выкатит апдейт. Мне кажется, это просто прекрасно. А сайты помельче, они вообще не так часто апдейты катят. Да, по-моему, даже сами разработчики браузера обсуждают между собой какую-то спецификацию. Насколько я знаю, какой-то открытой спецификации еще нет, но постоянно идут разговоры над тем, чтобы иметь какое-то представление, которое можно было бы куда-то складывать. И возможно, эта работа над WebAssembly, которую они готовят, возможно, она приведет к тому, что у нас будет какое-то представление. Подожди, мне кажется, WebAssembly, он все-таки больше про то, чтобы перестать компилировать все в JavaScript, из JavaScript, потом в Bytecode, из Bytecode, потом в джиты, хотя бы просто выкинуть JavaScript к промежуточному представлению. Мне казалось, в WebAssembly он про это. Да, про это, но он же близок очень к LLVM, к LLVM вот этому ассемблю. И мне кажется, что его же, вот этот вот мат, можно использовать для того, чтобы какое-то промежуточное представление в том же SpiderMonkey или в GVS тоже хранить. Нет, ну подожди, одно дело промежуточное представление хранить, другое дело с джитиной хранить. Мне кажется, с джитиной оно не может быть совместимым по формату, потому что, мне кажется, там у каждого интерпретатора будут свои особенности. Особенно если знаешь, не знаю, взять какую-нибудь, я не помню, как называется, виртуальная машина, которая в Safari пловском, у них там вообще, у них несколько тайеров джита, и они могут быть немножко разные. У всех сейчас несколько тайеров джита. Нет, ну в смысле там разные компиляторы. Да, да, да. То есть последний тайер у них сейчас LLVM, прям вот LLVM, и они просто делают прямо туда какую-то, не знаю, как это сказать, какую-то трамплину, или как это называется, чтобы перепрыгнуть на джитину LLVM-код. И он вообще не сильно похож на то, что там от всего остального бывает. Да, да, да. Да, да, да. Ну, на самом деле у V8 и у SpiderMonkey то же самое. Несколько джит-компиляторов разной как бы степени оптимизации, да, и все они примерно по одному же пути работают сейчас. И, наверное, надо двигаться дальше. Ну, дальше снова твоя тема. Дальше пошли мои темы, да. Следующая тема. Следующая тема. В блоге Servo выложили такую запись о том, как они пытаются профилировать Servo с точки зрения потребления, с точки зрения мегапотребления. Мне кажется, интересно, интересная такая тема в плане того, что большинство браузеров сейчас оптимизируются именно с точки зрения потребления памяти или скорости рендеринга, или обработки JS, или еще чего-то. Все больше и больше людей пользуются сейчас как бы вебом на каких-то там, на телефонах, на планшетах, где вот время жизни тоже важно. И сейчас вот, например, даже если мы возьмем макбуки наши, на макбуках Safari дает вам там, допустим, 11 часов без подзарядки, а если вы ставите Chrome, то 11 часов резко превращаются в 8. И в блоге рассказывают о том, что сложно на самом деле мерить потребление памяти, что в разных процессорах, в разных этих, в разных системах есть разные вот эти сенсоры, ну, как какой-то API для сбора метрик по потреблению. Ну, например, они могут получить на Intel процессор потребление энергии процессором, контроллером памяти, возможно, оперативной памятью, но не могут получить данные о потреблении энергии диском и экраном. И рассказывают о том, как они сейчас с этим работают, но это все в таком зачаточном состоянии, у них есть какие-то графики или еще что-то, и будет интересно посмотреть, как это все будет двигаться дальше. Интересно, что самые хорошие показатели на Intel процессорах они получили, когда использовали количество потоков рендеринга, равное количеству ядер, которые у процессора есть, то есть, допустим, если это 4-3 ядерный процессор, то 4 потока на рендеринг, это оптимальный вариант с точки зрения потребления памяти. Вместо того, чтобы иметь одно активное ядро, лучше иметь 4 менее активных. То есть, не с точки зрения памяти или энергии? Энергии. Я все время оговариваюсь, наверное. То есть, вопрос именно с точки зрения потребления энергии. У меня в этом как раз в Mac OS, вот этот Activity Monitor, у него есть сортировка по CPU, сортировка по памяти, кто сколько памяти, и в том числе есть отдельный таб для... то те процессы, которые жрут больше всего энергии. Да, я тоже постоянно пользуюсь, чтобы знать кто виноват. Обычно виноваты всякие программки, там из серии Messenger или еще что-то, которые сделаны как обертки вокруг веб-версии. То есть, там тот же слэк или еще там что-то, они обычно едят слишком много. У меня обычно там VirtualBox сидит. Ну да, VirtualBox тоже вечно впереди планеты всей. Да, отлично. Пошли дальше? Следующая тема опять моя. Потому что выпустили книжку, которая называется WireRust. Книжка, 60 страниц. Написал ее, сейчас скажу как зовут, Джим Бленди. Бленди, это хороший такой товарищ, один из создателей Suddershan в свое время. Один из мейнтейнеров GDB, это дебаггер для GCC. Один из мейнтейнеров в прошлом и Max, он сейчас работает в Mozilla. Этот товарищ написал книжку на 60 страниц, которая объясняет Rust, именно внутренности работы Rust, вот этого боллчекера и всего такого прочего. Объяснение, как создаются какие-то объекты, какие-то структуры, как они в памяти хранятся, как они передаются из одних функций в другую. Книжка построена следующим образом, что там буквально 1, 2, 3 примера. И он разбирает на уровне, а вот в этой строчке у нас там, допустим, вот эта структура передается сюда, урныши передаются так, при этом, смотрите, память не копируется и все такое прочее. Очень хорошая книжка, которая объясняет, как Rust работает на самом низком уровне. Все разжило настолько, что понимание того, как работает этот боллчекер, становится очень-очень хорошим. Мне кажется, что книжка может быть полезна тем людям, которые сейчас программируют на C++ и говорят, что Rust это ничего особенного, что у нас в CLang или в GCC есть 2-3 этих common line флага, что мы тоже себе можем все эти проверки сделать. А книжка покажет, что этих флагов недостаточно, что Rust действительно умнее. А тем, кому интересен Rust, книжка полезна именно с точки зрения того, чтобы понимать, как внутри работает вот этот боллчекер, для того, чтобы меньше наступать на грабли, связанные с тем, как вы объявляете типа и прочее.",
    "result": {
      "query": "Rust borrow checker explained"
    }
  }
]
[
  {
    "segment_id": "c4b55f3d-fb80-49e4-b8ab-156f105ef081",
    "episode_id": "f97d17d5-6496-44d5-8c9c-6a10ec7e088c",
    "episode_number": 231,
    "segment_number": 4,
    "text": "Они связаны, то есть если ты, например, видишь лог и видишь, что в нем, не знаю, какая-то ошибка произошла, ты можешь нажать на ссылку и увидеть, что в этот момент было по метрикам. Круто. Правильно ли я понимаю, что сейчас ELK должны переименовать, потому что K больше не релевантно? ELK нерелевантен целиком, то есть Graphana и локи, они целиком заменяют ELK, полностью. Ну не знаю, насчет того, что полностью? Ну, по крайней мере, пока что нет, пока что не хватает всяких штук для транспорта, логов для их прообразования и так далее. Ну, просто я думаю, хорошо, если при таких возможностях, зачем надо такие баны? Незачем, она и не нужна. Хранить пока рано, пока еще локи не вышли на этот уровень, когда выйдет, то может быть, посмотрим. Я, честно говоря, не имею очень большого опыта с ELK, так получилось, что когда он был моден и все такое, я работал в компании, которая предпочитала использовать SAS решения, поэтому как назывался, log entries мы использовали, ну или сейчас есть okmetr, да, вот это вот все, поэтому я на самом деле не очень осведомлен о вот этих потрясающих возможностях ELK, о которых идет речь, но если вам нужно просто одно место, куда вы агрегируете логи, и чтобы оно там не разваливалось при сплитах и не очень сильно тормозило, то в принципе локи уже можно сейчас ставить, он зарелизлен, он стабилен и все такое. Вопрос, насколько он хорошо поддерживает, то есть ELK все-таки уже прошел проверку временем, и там известны какие-то баги, которые там можно обходить, локи это пока темная лошадка. Ну давай так скажем, насколько мне известно, эластик до сих пор не очень хорошо переживает над сплитом, поэтому когда твоя система с потрясающими фичами развалится, ну развалится это вопрос как бы времени, а с локи этого в принципе не может произойти, потому что он в принципе не особо распределенный по дефолту, по крайней мере. Ну в этом может быть и проблема, то есть у нас огромное количество логов. Настолько огромное, что не вылезает в одну машину с тарабайтными дисками, серьезно? Ну да, то есть у нас несколько, я сейчас про данные не помню, и я не уверен даже, что могу говорить, но у нас очень много логов. И вы как бы не упираетесь в производительность ELK? Мы упираемся в производительность ELK, но на грани живем. И кстати, поэтому я не хочу конечно рекламировать, но мы перешли на Dashbase, но мы перешли не потому, что мы упирались в ELK, потому что Dashbase предложил более дешевую цену, мы в ELK упираемся в стоимость, количество машин, на которых нам нужно иметь диски для того, чтобы хранить и записывать на нужной скорости. Dashbase сказал, что мы готовы сделать то же самое в два раза дешевле, но потому что они по-другому как-то позиционируют, хранят и так далее, да, но они просто посчитали наш трафик. А сколько вы храните, какой у вас ретеншин? Не скажу. Ну хотя бы знаешь, полгода, либо там, либо меньше. Ладно, это приватный вопрос. Да-да-да. На самом деле я хотел бы просто добавить, мне кажется тоже этого не упомянули, что ключевое различие от Локи и почти всего основного, что Локи вообще говорит, что там нет полнотекстового поиска. То есть они хранят исключительно информацию по лейблам, по стримам, ну то есть вот эта часть, как раз из Prometheus, она взята изначально, то есть там, когда у тебя приходит лок, это не просто какая-то текстовая строка, это event, в котором есть какие-то k-value пары, лейбы, и собственно по ним можно искать. Полнотекстового поиска там нет, за счет этого там индекс сильно-сильно меньше, и за счет этого он во многом выигрывает размер. Ты меня просто с языка снял, да, то есть он с одной стороны может быть уступает по функционалу, что ты не можешь произвольную строку искать, но в то же время он выигрывает по перформансу, потому что ты явно задаёшь метки, которые надо проиндексировать, а всё остальное он не индексирует. То есть с другой стороны, а может это плюс, а не минус? Я и говорю, что с моей перспективы это большой плюс, я не могу сказать, что прям очень часто по логам прям строчечки Во-первых, это, во-вторых, чаще всего, когда ты создаёшь логи, ты понимаешь, где есть ключевая информация, можешь их вынести в метки. Большой минус в том, что ты не можешь делать это задним числом. Да, да. А ещё обратить внимание, что тебе ничто не мешает поднимать больше одного инстанса логи, и каждый из них добавлять как отдельный сорс в графану, и это будет достаточно адекватно работать. Мне кажется, мы достаточно неплохо обсудили. Мы в полном объёме обсудили эту новость. Можно я тут добавлю, я немножко поискал, на всякий случай тоже, немножко я накопал на Cortex, Cortex взяли в сеть Ancifi инкубатор, вот как Cloud Native Computer Foundation инкубатор, и в общем, судя по всему, Cortex будет жить, так что рано его ещё закапывать. А вот ELK и всё остальное, если не закапывать, то уже по камере копать. Прикапывать, начинать. Кстати, а какие, если не считать соосов, какие есть ещё более-менее живые альтернативы, кроме логи и ELK, во что ещё можно писать? Greylock. То есть из таких крупных есть Greylock, который тоже довольно давно, который проиграл в своё время битву ELK, Fluent и ELK, но всё равно он относительно большой всё ещё. Есть какие-то мелкие решения, которые делают, во-первых, как саосом, типа там LogHouse, например. Но, кстати, у него похожая проблема на ELK, что чтобы его поднять, сначала поднимите ClickHouse, для которого вы сначала должны поднять как бишь его ZooKeeper. Ну, это да. Кстати, по поводу соосов, вы же обсуждали новость о том, что Splunk организовал свою стратегию и теперь не работает с Россией. Да, в прошлом выпуске. Так что вот к слову про сооса, которые дешевле до тех пор, пока они сами работают. Место ведущего ругающего сооса уже занято. Что они придумали. Шучу, шучу. Есть свободное место рассказывающего про новый релиз ГО? Пока свободно, занимайте. Да-да-да, вышел новый релиз ГО 1.12, ничего нового, следующая тема. Но если серьезно, то вышел очередной релиз ГО. Теперь они их выпускают каждые полгода, а этот релиз вышел почти вовремя, если не считать того, что на месяц позже. Модули не завезли. Модули изначально хотели год назад, когда они только появились, хотели, что модули будут с нертом в 1.12. Не случилось, летом они будут с нертом, пока что только исправление и улучшение и все такое. Версия 1.3 тоже не без проблем пока что, поэтому он opt-in. Следующая версия уже будет по умолчанию включена, а здесь им надо специальное применение к движению ставить для того, чтобы она работала. Ну, не знаю, там из крупного можно отметить гораздо лучшую поддержку в АРМ64, там рейс-текстур теперь работает нормально, крит, какой-то еще туинг тоже работает, сегво работает, в общем. Теперь можно сказать, что АРМ64 стал платформой первого класса, что немаловажно. И вообще куча мелких изменений, я не знаю даже, о чем еще говорить. Подожди, стой. GoTur удалили из компилятора и теперь надо его устанавливать в АРМ64. Нет, GoTur удалили из стандартного дистрибутива, на самом деле этим никто не пользовался. Это самое важное изменение, мне кажется. Да? Перестань. Не, ну тут есть на самом деле, ладно, окей, можно найти какие-то сейчас изменения. Первый билдкаш теперь обязательный, до этого его можно было отключать, теперь его отключить нельзя. Напомни, что это? Ну, в какой-то там версии 3 назад в GOP появился билдкаш, который автоматически кэширует все результаты компиляции и результаты тестов вне GOP-ов. Дальше, когда делаешь компиляцию того кода, который уже компилировал, он достает ее из кэша. Это как бы сильно ускоряет повторную компиляцию, повторную запуску тестов. А определяют повторность они с помощью hash-сум? Да, для компиляции да, для тестов hash-сум и выводы. При этом в тестах немножко хитрее, потому что там в хэш и вообще в это как бы общий котел, где они читают хэш-сум и кэшируют, тебе попадает не только самый сходный код, но и переменное окружение, которое используется, файлы, которые открываются. Кстати, мне кажется, я это как-то в дизайне рассказывал. Единственное, что бы там хорошо было, но нет, это нет сетевого трафика, поэтому если у вас тест против какого-то внешнего сетевого сервиса, то имеет смысл кэш сбрасывать, если вы хотите сделать повторное тестирование. Но вообще штука очень полезная и безбажная, поэтому никаких проблем тут нет. Насчёт безбажной слышал версию, что на некоторых платформах вот в этом новом релизе слегка не очень хорошо работает профилирование ещё что-то, оно чуть-чуть сломано, поэтому наверное как с любой минорной версией надо подождать 12.4 или как-нибудь так. Не, ну 12.4 с большой вероятностью не случится, на самом деле. То есть обычно в среднем релизы Go не доходят до 4-ой версии, то есть вот предыдущий релиз был исключением, потому что там было несколько секьюрити-извимости, во-первых, что довольно редко всё-таки бывает, во-вторых, они в патч-релизах улучшали обратную совместимость для модулей, то есть чтобы старые версии Go-Get, например, могли минимально работать с модулями. Ну не то, чтобы о них прям вставить, но во всяком случае они не ругались на странные импорт-пути, которые они видели первый раз. А в среднем Go до 2-ой, до 3-ей патча всегда доходит. Ну то есть да, точка 0 в продакшенах потащить пока не надо, но точка 1 я думаю вполне. Вообще когда Google релизит первый релиз-кандидат, это означает, что по умолчанию он используется внутри Гугла. То есть в целом релиз-кандидаты и релизы нулевые уже довольно стабильны. Насчёт профилирования я не знаю. И что так быстро всё, и мы больше ничего не будем рассказывать про новую версию Go? Твоего любимого языка ты им недостаточно любишь. Ну хорошо, нет. Нет, ну ладно, хорошо, ладно. Остановите меня, когда нужно закончить. Значит, что изменилось? Изменилось... Всё, хватит. Пошли к следующей теме. Нет, если серьёзно есть, что рассказать, давай, если нет, пошли дальше. Читайте релиз-ноуты, да, то есть там в целом довольно всё неплохо написано. Группных сменений нет, дженериков нет, новой обработки ошибок нет, моделей нет. Вообще нечего обсуждать. Да. Ну и почему он тогда быстрый язык? Почему он хороший? Саша, расскажи, пожалуйста, эту тему, почему Go невообразимо быстрый. А про что тема? Про строительство дафа. Так, секундочку, я карточку открою. А, тут есть ссылка на статью. Я не помню, насколько она новая или не очень новая. Она старая, ей 3-4. Но она вот про что, я как бы в начале недели читал, поэтому да, простите, если я буду врать. И там автор этой статьи решил посмотреть на то, какой машинный код используется в Go. И открыв его, он увидел такие длинные-длинные последовательности, по-моему там 100 зб, 100 зб, 100 зб. Такие дела. И на что он как бы отмечает, что да, это так называемое устройство дафа, то есть, грубо говоря, разворачивание циклов, когда у вас там не в цикле делается инт, там плюс-плюс-плюс как бы в цикле, а вы разворачиваете его тело, и у вас получается такая большая-большая простыня из команд, которая занимает кучу-кучу места, но она работает на современных процессорах быстрее, потому что не нужен branch prediction, а branch prediction, он не бесплатный на современных платформах. Поэтому как бы вот развернутый цикл, он работает быстрее. Или если цикл большой, ну как бы вы скажете, а там же что, если там 500 тысяч операций, то развернуть его хотя бы частично, то есть, например, вы каждую, ну там, не знаю, 128 операций вы развернули, а потом возвращаясь в начало цикла, это всё равно даёт довольно ощутимое ускорение. И оказывается, что в ГО в особо узких местах используется вот подобного рода оптимизация, поэтому, собственно, ну как бы ГО достаточно немедленный, давайте так скажем. И ещё меня удивило, что на самом деле используется вот здесь используется инструкция sq, на конце sq. Меня это удивило, потому что, честно говоря, я думал, что она на современных процессорах работает медленнее, чем move, add и так далее, вот это сочетание. То есть как бы вот эта инструкция, которая сочетает в себе перемещение и изменение регистров, как мне казалось, она должна работать медленнее на современных процессорах, тем не менее разработчики ГО выяснили, что в среднем на современных процессорах они могут работать быстрее. Такое вот интересное наблюдение. Ну и, конечно, меня радует, что в третьем тысячелетии есть место подобного рода оптимизации, им всё ещё нужно помнить про машинный код и так далее. Я ещё посмотрел статью, кстати, я действительно 4 года, этого кода в ГО уже нет. Ну то есть там поменяли, там теперь за счёт некоторых оптимизаций, когда вот такое прям ручное полностью разработка, не нужно, но в некоторых местах, ну функции всё ещё, zeroDaf и DafCopy они всё ещё есть. Комментария типа «не меняйте функцию без того, чтобы пообщаться с робом» тоже нету, потому что ведь в роб уже ни с кем не общается. Вообще, если вам интересный исходник кода, я там вам рекомендую посмотреть такой файл, называется magic.go в рентайме, очень любопытный. Они не боятся называния. Да, нет, ну там действительно магия, там код, который делит число на число, и там меньше, чем 200 строчек, из них 2 трети, даже 3 части, это комментарии, которые описывают алгоритм деления переменной на константу, без использования операции деления, конечно. Вот такая. Да, там в некоторых местах можно куски лисп найти. Чего-чего? Ну не лиспы, конечно, а SXPression, там часть, которая делает SSA, там набор правил описан вот на таком собственном псевдоязыке. Очень-очень много скобочек. Ну и отлично, тогда следующая тема, которую я думал, что она связана с языком Go, она, кажется, не связана с языком Go. Безусловно связана. Расскажи про неё. Расскажи про неё. В общем, Сальвадора Санфилиппа, который он же автор редиса, он же антирес, написал у себя в блоге пост, который по его утверждению он изначально планировал публиковать на 1 апреля, но ему очень не терпелось, поэтому он опубликовал его в феврале, в конце февраля, про то, что он добавил в редис поддержку протокола Goffer. И да, в современном мире у большинства людей слово Goffer ассоциируется с языком Go и подобной хипстотой, а вот кто постарше, у него ассоциации совершенно другие, потому что Goffer это ещё и протокол предшественника HTTP, если можно так выразиться. То есть во многом похожий на HTTP, только полностью текстовый. И я, честно говоря, не то чтобы его очень сильно застал, и я довольно поверхностно представляю, как он на самом деле работает, но моё понимание, что поверх него можно с тем же успехом сделать какую-то API, как и поверх HTTP, что и было сделано. Ну и с одной стороны это сделано как шутка, с другой стороны, потому что это заняло по заверению автора 100 строк кода, и почему бы нет. Ну, как бы поддержка ещё одного протокола, с другой стороны, польза не сильно понятна. И всё это с таким посылом, что я не очень до конца понял, как это связано с Redis, что современный веб, он уже совсем не такой, каким был раньше, что любое конструктивное обсуждение на форуме, в твиттере, где угодно через три сообщения превращается в флут с наездой и так далее, что, не знаю, условно заходишь на любой новостной сайт, и тебе такая всплывашка «Ой, чувак, разреши куки, ой, чувак, разреши уведомления, ой, чувак, подпишись на новости, а у тебя ещё этот блог включен, чувак». Вот это всё всплывает, всплывает, всплывает, не говоря уже про картинки 10-мегабайтные и подобные вещи. То есть он под впечатлениями от современного веба, я не знаю, в знак протеста, в общем, на эмоциях сделал поддержку Гофера в Redis. И на самом деле, я понимаю этот эмоциональный отклик, это не является одной из причин, почему мне стало интересно любительское радио, потому что там чуть меньше всплывающих сообщений про Adblock Plus и подобные вещи, и вообще реклама запрещена. Да, интересно ещё посмотреть статью на Википедии, что ресурсы, использующие протокол Гофера, они всё ещё существуют, их в мире, я не помню точно, штук 100 или 500, но тем не менее. И есть отличная от нуля вероятность, что может быть их будет становиться больше, там, кстати, если посмотреть динамику по годам, их действительно становится больше где-то с 2016 года. То есть люди реально запускают больше Гофер ресурсов. А какой смысл сейчас это делать? Как альтернатива вебу. Прямо такой же, как бы БС сейчас держать. Или радио. Ну там, УКВ, вот, или КВ. Извините, слишком толстый. А вот сейчас объединено было, да? Вот, но мне интересно, ну вот серьёзно, ты заходишь читать новость, тебя не напрягают вот эти 15 всплывашек, вот эти полоски на третьей экрану снизу, всякая такая хрень? Раздражает, но возвращаться на Фидор ради этого я не готов. А ты не хотел бы иметь, ну сейчас забудем на секундочку про Гофер, да? Что, если я тебе предложу веб, который вот как современный веб, даже с картинками, возможно, если мы не говорим конкретно про Гофер, но прям конкретно без рекламы, без джаваскрипта, возможно, только контент, текст, картинки, ну там какой-нибудь UI-чик симпатичный более-менее. И кто там будет? Там будешь ты и все, кому бомбит от современного веба. У меня там практически никого, ну то есть как бы у меня нет сайта своего, большого интересного сайта у меня нет. Допустим, будешь там ты, допустим, будет там еще парочка знакомых мне, блогеров, включая там антиреза какого-нибудь, но Хаббра там точно не будет, скажем. Зачем тебе, подожди, ты еще Хаббра читаешь? Я хочу сказать, а хорошо, какие ты читаешь новостные сайты, которые не единоличниками ведутся? Честно говоря, в последнее время немногие, потому что это еще один проблем современного веба. Хорошо, вайкомбинатор там не будет. Я не читаю вайкомбинатор. Реддита там не будет. И реддит я особо не читаю. Понял. Ну то есть реально большая проблема современного веба, и почему мне в нем в последнее время мало и интересно, что люди гонятся за бабками. Ну вот раньше как было, ты покупаешь бумажную газету, ты отдал деньги, получил контент. Как бы просто и понятно. Поэтому люди старались давать качественный контент, потому что ты за него платишь деньги, как бы все просто и понятно. В вебе модель другая. Тебе сайт, новостной или какой еще, дает контент на халяву, бесплатно, но зарабатывает на просмотрах. Поэтому задача не ставится дать качественный контент, за который ты согласишься отдать деньги, а задача — получить как можно больше просмотров. А для этого нужны набросы, желтые заголовки, вот это вот все. И поэтому мы имеем вот такое качество контента на том же хабре или новостных ресурсов, какой имеем. Ну кстати, Саша, это ведь не только для веба относится. Ведь сейчас есть газеты и журналы, которые раздаются бесплатно, и они не требуют от тебя какой-то суммы. То есть они работают по такому же принципу, не надо ругать веб, это скорее развитие нашего общества идёт в эту сторону. Ну, скажем так, любой контент найдёт своего читателя, но я вот бесплатные газеты не беру, сколько бы их ни раздавали. Ну разве что мне нужна какая-нибудь, не знаю, подстилка, когда я что-нибудь клею или ну в такое применение. Ты знаешь, Саша, ты сейчас хороший пример. Про газеты сказал. Я когда маленький был, у меня в городе было несколько городских газет. Знаешь, какую я покупал? Не в которой там была хорошая качественная журналистика, интересные новости и не было вот этой всей желтизны и так далее, а ту, в которой были анекдоты. То есть когда ты говоришь о том, что ты покупаешь газеты, или раньше можно было покупать газеты, которые с качественным контентом, это минорити. Это совсем минорити. Большинство людей покупало обычные желтые газеты с самыми громкими заголовками, и они продавались лучше. Я думаю, что если... Ты знаешь, извини, пожалуйста, это аргумент из разряда Я думаю, большинство людей там пьют Кока-Колу, поэтому чай не нужен. Ну, то есть примерно такого порядка. Я за Сашу. Но, Саш, это... Давай так, смотри. Это фактически сейчас делать новый интернет, BBS, в котором будут жить только вещи с запрещенной рекламой. Там ведь должна быть запрещена реклама. Давай представим, что этот мир существует. Туда, возможно, придет Википедия, верно? Потому что теоретически на страницах Википедии нет рекламы, кроме дайте нам денег. Но это не считается рекламой. И там будет, возможно, несколько блогеров. И, может быть, что-то из этого получится. В целом, я за такое будущее. То есть я готов иметь альтернативный интернет, в котором я буду читать все, что мне интересно, и платить за это какие-то деньги. Но это будут делать только те, кто готов, во-первых, платить деньги, верно? Во-вторых, это будут делать только те, которые зарабатывают достаточно для этого. Но там не будет денег. И там не будет Википедии, потому что не будет денег. Потому что никто не будет давать деньги. Википедия выгодна быть везде. Чем больше людей в нее заходят, тем больше людей видят «помогите нам». Поэтому она будет везде. Но для того, чтобы держать такую вещь, тебе нужно время, усилие, электричество. И поэтому это будут делать только те, у кого есть интерес или деньги. А лучше и то, и то. А скорее всего, и то, и то. Я не комментирую, потому что я небольшой любитель фантазировать, что будет, если… Подпишите мне. Вот, я могу сказать, что потребность в таком есть. Насчет реализации надо думать. Ну и Гофер нанес ответный удар. Это так называлась наша тема. Да, оказывается, есть несколько реализаций Гофера под таковым ногом. Так что вполне возможно, те Гоферы, те из Севра, которые сейчас поднимаются, или как они сейчас электроники называются, они многие ногу поднимаются. А кто хорошо знаком с этим протоколом? Он прям сильно на HTTP похож или совсем не похож? Он похож на меню. То есть это такой простой текстовый технический протокол, или знаешь даже, на что он похож? Он похож на хождение по каталогам в нашей команды концептуальной. Нет, концептуальный я его видел. То есть его концептуально легко проверить, любым линксом заходишь по любой Гофер-ссылке. Я имею в виду, внутри он как протокол. На что похож? Ну вот, не знаю, на HTTP, на Redis, на IRC в чём-то. Но они все же до определенной степени друг у друга похожи. Текстовые запросы, текстовые ответы, заголовки. А какую общую проблему решает, напомните? Низкого контента, как минимум, мусора и вот этого всего. Низкого качества современного веба. Ну нет. Ну вообще, таким же успехом можно HTTP использовать. Нет, Гофер протокол сейчас не решает никакую проблему, он просто появился раньше, чем всемирная паутинка, вот и всё.",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 10125. Please try again in 20.25s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 10125. Please try again in 20.25s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
[
  {
    "segment_id": "c1a2858e-6c88-4556-b7ba-91d18ceb5907",
    "episode_id": "aa70cab5-fd4c-493b-8f85-ab8f26d7d090",
    "episode_number": 400,
    "segment_number": 7,
    "text": "Вот для меня тоже. Но покурив документацию, я узнал, что если у тебя есть set of record, его можно брать в скобочки и применять к нему ту же фигню, которую ты применял бы к нормальному record. И ты получишь... Получается для каждого tuple он типа сделает... он его развернёт в несколько tuples на выходе, так получается? Получается, что так. Ага. Вот. Но если вам проще через letterl join, конечно, использовать letterl join, он тоже клёвый. У меня всё. Я, в общем, ходил на конференцию, про которую я ещё позже поговорю, но просто вещь, которая у меня прям типа... I've been living a lie. Вот много лет. В Linux есть такой параметр VM.dirtyratio, который отвечает за то, какое количество, так скажем, грязных страниц, то есть какой процент потопчивой памяти, которая... Я всегда считал, что от вообще всей свободной памяти... Нет, что от всей вообще памяти это ratio... Типа какой процент могут быть страницы, которые вызывают ваше приложение думает, что записало, ещё не сделала fsync. Вот как бы я всегда думал, что это процент от общего количества памяти, сколько у вас может быть выделена память, потом кто-то не за fsync она. Нет, это процент от available memory. Что такое available memory в Linux? Это отдельная интересная история. Это вся free memory плюс память, которую можно там как-нибудь что-нибудь из неё выкинуть и запользовать под нужные вещи. В общем, во-первых, это очень странный подход к настройке этого параметра, потому что вы не знаете, сколько у вас... То есть это не какое-то фиксированное количество. Это хрень меняется со временем. Во-вторых, ну типа да, available memory, это само по себе довольно странный концепт для меня. Ну как, в смысле, я понимаю, почему... Ну ладно, не важно. Не буду вдаваться в детали. Я залинковал блог-пост, где про это написано, и в принципе я... Слайды с конференции тоже есть. Ссылка на вообще всю конференцию будет позже по тексту. Вот, в общем, я в лёгком шоке. Но на этом всё. Как будто бы следующая тема моя. Я на этой неделе занимался странной штукой. Дело в том, что у нас подкаст и мой блог, а также почта и блога и подкасты хостятся в DigitalOcean. Так сложилось, что выводом денег с Патреона, оплатой хостинга, там то, что остаётся распределить по ведущим, этим долгое время занимался я. С этим заниматься стало сложненько, потому что... Ну Патреон-то он котик, а вот PayPal, он в России больше не работает. И в марте был закинут побольше денег на DigitalOcean, на которых аккаунт всё это время жил. А теперь они кончаются.",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 1391. Please try again in 2.782s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 1391. Please try again in 2.782s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
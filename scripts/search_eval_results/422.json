[
  {
    "segment_id": "dea63acc-a844-4dbf-bf00-a385fdebde09",
    "episode_id": "47ff5a0a-995e-4947-9a81-6a35dd3df6f2",
    "episode_number": 422,
    "segment_number": 5,
    "text": "Я рискну предположить, что будучи средой со встраиваемым языком, что у них там Basic, по-моему, наверное, у Basic есть какая-то система сборки у них, возможно, с зависимостями. Об этом речь. Все на самом деле проще. Проще в том плане, что если рассмотреть, например, у нас есть ячейка A1, есть ячейка A2, в них числа, а потом есть ячейка A3, в которой есть какая-то формула, то по факту у нас есть система сборки объектов в ячейке A3, которая зависит от A1 и A2. И причем эти формулы без даже Visual Basic или каких-то дополнительных программных модулей, а именно по синтаксису и семантике самого Excel'я, там могут быть вплоть до того, что там какие-нибудь в paper переводится indirect, когда ты можешь в ячейке определить что-то, потом это представить в виде текста, а потом поглядеть, что находится в ячейке с текстовой репрезентацией. То есть A, Ampersand, C1, там в C1 стоит значочек единичка, значит у тебя получится A1, и давайте прочитаем, что находится в ячейке A1. Вот такие вот непрямые зависимости. И если с такой точки зрения судить, то на самом деле получается, что Excel это реально система сборки, в которой ты определяешь цели, ты определяешь, что от чего зависит, а потом ты определяешь граф вычисления, и соответственно можешь обновлять этот граф вычисления. И в статье здесь очень здорово приводится то, что они каждую систему пытаются разобрать с точки зрения нескольких функтов, то есть как мы строим граф вычисления, как мы начинаем обновлять систему, в смысле как мы пытаемся обновлять этот граф вычисления при изменении внешнего мира, введении новых правил, введении новых данных в старые правила и так далее. Да, и вот у Excel есть такая идея, как называется цепочка вычисления, calculation chain, и соответственно внутри себя Excel строит эту цепочку вычисления, и вот эта цепочка вычисления это некий аналог того, что делает Make, когда внутри себя строит граф зависимости. Соответственно цепочка вычисления, она вся включает ячейки и может включать в себя ячейки, в которых мы точно не знаем, есть ли там что-то или нет. Например, вот этот пример с формулой indirect, мы заранее не знаем, что там будет получаться, и поэтому можем включить, что вот эту ячейку надо вычислять всегда, вне зависимости от того, произошло ли обновление в B1 или в C1 и так далее. Да, и соответственно в Excel появляются динамические зависимости, в отличие от Make файла. В Make файле нет динамических зависимостей, а в Excel они появляются. Соответственно, Make файл хорош тем, что он очень прост и минимален с точки зрения вычисления того, что надо обновить, какие объекты надо обновить. А с помощью динамических зависимостей мы сильно усложняем модель, саму модель построения, и поэтому вот эта вот минимальность становится невыполнимой. Давайте еще раз. К примеру, у нас было два C-шных файла и один H-файл. При изменении C-шного файла мы могли обновить только один объектник, и потом собрать бинарник. И мы точно знали, что и как надо пересобирать. В Excel, если у вас есть большая таблица, в которой есть куча всяких ссылок, вот, и если вы обновили в одной ячейке, то понятное дело, что все, кто ссылается на эту ячейку, тоже должны обновить свои значения, и все, кто ссылаются на те ячейки, в свою очередь должны обновить значения. У нас получается такой граф выполнения. Но плюс к этому, из-за того, что у нас есть динамические правила в виде вот этих вот непонятно куда указывающих ячеек, вот, мы должны еще их тоже обновлять все время. Даже мы, если даже не знаем, как бы, из-за того, что мы не знаем, что и как будет обновляться. То есть цепочка выполнения становится не минимальной. Мы иногда будем делать работу напрасно. Я попытался объяснить. Да, тут есть еще более простой аспект, то, что не только значения, там, где-то в ячейках дальше меняются, и эти ссылки, они даже не обязательны, чтобы иметь динамическую, вот эту динамическую формулу. То есть у тебя в ячейке формула тоже может менять свои зависимости. То есть ты переписал с A1 на A2, и вот у тебя теперь от A1 зависимости нету, а от A2 появляется. Все, план на смарку, все выбрасываем. Ну, вот это же равносильно тому, что ты в Makefile поменял зависимость. То есть, на самом деле, здесь вот у меня к этой статье у меня есть несколько вопросов, которые в статье как-то не очень явно отвечены, описаны. И мне вот этот вот, вот этот довод мне непонятен. То есть они говорят, да, вот у нас есть, если происходит изменение формулы цепочки, у нас происходит усложнение вычисления, потому что мы не знаем, что и как делать, давайте обновлять большую часть. Ну и в Makefile точно так же. То есть, если ты производишь обновление Makefile, тебе точно так же надо сборку пересматривать, что тебе обновлять, где какие файлы старые, новые и так далее. Нет? Ну, тут получается, что у тебя Makefile, ты спустил Make, и он такой, окей, вот мой план, вот мои таргеты, сортируем, кто на ком стоит, и все, побежали исполнять. Если по мере работы, по ходу работы, там кто-то, где-то, что-то поменяется, то тебе только Ctrl-C нажать. В противном случае Make такой и не чухнет даже, что там что-то менялось. Excel точно так же. А Excel, в отличие от этого, нет, ну Excel постоянно запущен. Ну, это то же самое, что ты Make постоянно запускаешь, и потом врешь у тебя объектные файлы, как обновляются и не обновляются. Типа того. В принципе, есть же вот эти билд-сервера, которые поднимаются и мониторят как раз всю эту фигню, они как раз этот аспект добавляют в системы, которые раньше этого не умели. То есть, в принципе, если у тебя билд-сервер мониторит эту всю штуку и передергивает сборку, когда там что-то меняется, то наверное, можно считать, что это эта же история появляется. Но у Make что интересного, что если он отработал, то у него все, у него атомарный билд, если ты ничего не поменял, если ты запускал его в геометричной среде, то он прокатится, и ему на ходу больше ничего додумывать не надо будет. Ну, то есть, если ты поменял Excel, грубо говоря, и сидишь, ждешь, пока он отработает, наверное, это тоже можно сказать, что мы построили план и дальше его работаем. Он слишком простой, чтобы его сравнивать даже. Ну, вот он построил, если свой план, то он по нему уже идет. И он по нему пойдет до конца, не меняя в этом аспекте, они как бы выходят на какую-то общую дорогу. Но в начале пути, когда еще никакого плана нет, когда еще никакой движок вычислений не запущен, первое, что он делает, это не идет там, грубо говоря, свои таргеты распарсивает, а смотрит, что там еще можно накинуть, что там поменять. И тут мы плавно переходим... Для пользователя это все совершенно прозрачно. Да, да, да. И неважно. Лишь бы работало. И тут мы плавно переходим к третьей системе, а третья система – это Shake. Я ни разу не работал с Shake и никогда его не запускал, поэтому для меня это было тире инкогнито. И единственное, что меня удивило в Shake, это то, что все правила сборки, они написаны на чистом Haskell. Тебе удалось почитать его страничку? Там еще чего-нибудь? Не пытался даже. Вот со самой сборки. У них... Ладно, потом что-то добавлю. У них сам вот этот DSL, который реализован через Haskell и Synthesis, он сделан максимально, ну, мейкоподобным, наверное, даже. То есть, в принципе, если закрыть глаза на какие-то там особенности, ну, как бы, ну, у мейка там табы нужно ставить, а у Shake, там, ну, какие-то там скобочки свои тоже. Вот. И если ты открываешь документацию по Shake, то ты, даже не зная Haskell, просто читаешь, как, что делается, и там довольно примитивными и, в принципе, аналогичным мейк способом добавляются тоже те же самые таргеты, добавляются те же самые штуки, но, помимо всего прочего, там еще и появляется возможность как это, программатик генерации таргетов на ходу. То есть, если у тебя есть, ну, как бы, макросы, можно сказать, встроенные в сам язык, и ты можешь сказать, что вот у меня есть список, там, от одного до десяти, и построй мне десять картинок, которые будут называться вот так, а вот тебе общее для них правило. И в результате ты пишешь, как бы, одно правило такое в общей форме, а оно уже, там, инстанцируется десять раз и начинает так дальше трекаться само. Трекаться именно, их использовать как цели? Да. В смысле, как узлы графа? Ну, да. Ну, то есть, я не знаю, может быть, как если бы ты в Excel написал, типа, вот, там, от A1 перелей, там, в другую, а потом взял, растянул эту ячейку, она такая сама проставила, там, из A1 сделай, из A2 сделай, из A3 сделай. Я представляю себе, как можно... Аккумуляция на уровне сборки. Я представляю себе, как можно то же самое в Make сделать. Ну, наверное. Ну, то есть, как бы, если я знаю, что у меня есть десять целей, я добавляю, там, от одного A1 до A10, а потом я в цикле for генерирую, там, чё-то. Это будет костыльно, криво, но можно сделать. Да, а здесь, благо, это, как бы, embed of DSL, это встроено, как бы, в язык, который не допускает фигни, у тебя есть какие-то гарантии, что ты не опечатался, там, примерно хотя бы не налажал, вот, в каких-то тупых вещах, если ты пишешь сборку, там, в 4 утра, вдруг почему-то, у тебя больше шансов это сделать с шейком, чем с Make. Чем уникальна данная система сборки, по словам авторов статьи? Тем, что, во-первых, как уже рассказали, это динамическое добавление, динамическое отслеживание узлов, т.е. вы можете на лету сказать, здесь будет несколько узлов, и они все будут приняты во внимание. Во-вторых, то, что в связи с этой динамической системой надо как-то отслеживать, каким образом они все зависят между другим, друг другом, и как бы как обновлять систему, как обновлять финальную цель сборки. И шейк ради этого хранит предыдущую сборку, а точнее граф зависимостей от этой предыдущей сборки. И соответственно, когда вы в следующий раз запускаете команду, он будет ее переиспользовать до тех пор, пока не увидит, что что-то поменялось в системе, и там формулы переписаны, и теперь граф поменялся. Тогда его перестроят. Это сильно ускоряет работу и увеличивает как это, минимизирует сборку. То есть, это прям полезная такая штука. Приближаются они по минимизации к мейку в этом смысле. Вот. Плюс они ввели понятие ожидания выполнения, пока билд не закончится для нужного узла. Ну, то есть, если у вас здесь большое дерево выполнения, и вот вы дошли до узла, который нужно собрать, ну, как бы, то есть, например, узел А зависит от узла Б и С. И вот Б уже готов, а С еще не готов. Вот. И сборка в этом моменте она просто зауснет на какое-то время, пока узел С не соберется, а потом продолжится. Это звучит очень просто, но на самом деле это такое серьезное нововведение. То есть, как вы помните, в мейке мы заранее знаем, что и как надо строить, там нету динамического зависимости. Поэтому мы заранее знаем, что А зависит от Б и от С, и мы не начинаем строить А, пока Б и С не построены. А С там зависит еще от чего-то. И вот как бы мы начинаем с листьев и идем вверх по дереву до корня или вниз по дереву, смотря как глядеть. Вот. А здесь получается из-за динамической системы и из-за того, что мы умеем ожидать, мы можем запускать вообще на любом уровне. Или на всех уровнях одновременно. И, соответственно, ожидать, впадать в спячку или как она это реализовано непонятно, система, вот. Но мы будем ожидать появления этих узлов и когда узлы появятся, будем продолжать с этого места. Плюс у шейка есть поддержка раннего, как это, раннего останова. То есть, как бы, если он детектирует, что сборка была запущена, а потом оказывается, что сборка не изменилась, мы ничего не будем делать. Ну, например, мы поменяли комментарий и в каком-нибудь сейшене файле поменяли одну букву, вот. Запустили пересборку, у нас объектник получился точно такой же, как предыдущий. Он не отличается по хэш сумме. Вот. И система сборки говорит, о, мы ничего не поменяли, так что дальше мы пересбирать не будем, финальная цель не изменится. И останавливается. В отличие от мейка, который увидит, что новый объектник, который собран, у него дата новее, чем все остальное, и он будет пересбирать дальше по цепочке, пока не дойдет до конца. Вот эта вот точка останова, она очень, как это, ранние остановки, я не знаю, как это правильно перевести, она очень ценна в больших сборках, когда у вас могут быть изменения, которые не повлияют на финальный результат. Олег, что-то есть по нему, или пойдем к Базилу? Ну, там еще есть интересная штука, называемая Оракулы, которая позволяет как раз вот эти, ну, то, что в мейк, наверное, называется фоне таргеты, ну, нет, фоне это просто промежуточные таргеты, короче, Оракулы позволяют зацепить какой-нибудь параметр из внешней среды, типа, там, не знаю, текущая дата, там, git commit, подобная хренатень, и превратить ее, там, в зависимость, не в таргет, а в зависимость. Вот, и, соответственно, это тоже начинается, начинает мемоизироваться, кэшироваться, вот это все, и это тоже позволяет отрезать и эффективно добавлять внешние данные в сборку. Вот, тут может показаться, что, ну, подумаешь, что такого сейчас во всех этих сборках есть, но тут, наверное, стоит сказать, что Шейку уже лет десять, и тогда никаких базелей, ничего такого не было, и, в общем, это была такая пионерия. Так, а ты с базелем работал? Да. Тогда, может быть, ты про него и расскажешь, потому что я его никогда не использовал. Ух, как бы не наврать. Да не отрубят меня гугловые сотрудники. Базель это изначально, в общем, система сборки, заточенная под как это... Облачное вычисление. Ну, да, с одной стороны, облачное вычисление, а перед этим она еще требует вот эти как раз герметичные сборки. То есть, если, грубо говоря, у вас один набор входных данных, то на выходе будет ровно то же самое. То есть, например, если вы там, грубо говоря, сертифицировали какой-нибудь исходничек, и построили с него бинар, то вы можете сказать, что, ну вот, если вы хотите проверить, что я сертифицировал действительно этот бинар, то запустите вот эту сборку на таком-то срезе, и у вас получится точно такой же бинар. Это как раз важное свойство для некоторых... Вот, и за счет этого... Герметичность. Да, герметичность и герметичность, вот. И там дальше... За счет этого они как раз могут себе позволить сборку в облаке, и... Если что-то у вас есть, то, например, уже собиралось у ваших коллег, вы, скорее всего, можете просто скачать эти артефакты и продолжить свои какие-то локальные правочки уже оттуда. Вот, и это, опять же, для огромных проектов это сильно ускоряет. Но у него есть такая неприятная особенность, что он очень любит подминать под себя все и как бы бутстрапиться по максимуму, как раз, чтобы сделать вот эти вот изолированные абсолютно детерминистичные среды сборки, то есть еще больше, чем Make. То есть Make-то пользуется хостовыми штуками, а чтобы это все затащить в байс, надо еще потрудиться. Привести пример. Что значит подминает под себя и бутстрапит? Ну, то есть, если у тебя есть какая-нибудь... Ну, грубо говоря, вендор зависимости. В идеале ты... То есть, надо понимать, что это в Google монорепа, ты ее выкачиваешь, и ты выкачивал весь мир. И Базель умеет и любит с этим работать. Поэтому, если у тебя есть такой источник данных, то... который, опять же, шарится между всеми сотрудниками, то у тебя очень удобная среда, в которой ты выкачивал только уже готовый компилятор, уже готовые библиотеки, и продолжил компилировать свой код. Но если ты вдруг скачиваешь это к себе на ноут и улетаешь в самолете и забыл скачать, то будь добр, собери GCC, собери там еще что-нибудь, собери все свои тулчейны, которые от него зависят. Ну, в общем, удачи. Вот. А что он очень не любит, так это как раз динамические таргеты. То есть, если у вас какой-то код генерируется и хочется его куда-то там положить, и какие-то дальнейшие процедуры с ним сделать, то будьте добры, это все в плане приколотить, все описать и больше не трогать. Дополню, что скажем, пример с GCC, тем, что GCC вы должны полностью выкачать, это на самом деле очень важное замечание, потому что, ну, представьте, вы собираете версии компилятора GCC там a.b.c, а потом кто-то следующий будет собирать компилятором a.b.c плюс один. И казалось бы, там изменилось мизер, если поглядеть по changelog, но ведь у вас получится совершенно другой результат с точки зрения бинарного файла, у вас он будет полностью другой. И соответственно, у вас повторяемость будет нарушена, поэтому для того, чтобы полностью понять и полностью повторить сборку, вам нужно иметь полностью все, что на нее может повлиять, включая какие-то заголовочные файлы внутри GCC для какой-то операционной системы, под какую-то архитектуру. Да? Ну, да, и было бы неплохо, что когда вам присылают какой-нибудь баг, чтобы можно было быстро воспроизвести этот баг у себя, соответственно, воспроизводимость тоже здесь очень сильно играет. Ну и если вы меняете там GCC какой-нибудь, там какая-то минорная оптимизация, что-нибудь, переставляете один байт зад-вперед, в самом раннем таргете, то, как в случае с Make, все начинает пересобираться. Чем еще Базил интересен и что он нового добавил, это то, что он добавил кэш, который content-addressable cache, не знаю, как это правильно перевести, в том плане, что если у вас есть... Content-addressable storage, наверное. Да, да, который, ну, или storage, или кэш, разницы нет в данном случае. То есть, если он собрал какой-то бинар и положил его в кэш, то в дальнейшем он может вытащить из кэша по хэшу этот бинар и использовать его, потому что, как бы, у нас же герметичность и гетерминистичность, поэтому нам без разницы, мы собрали его сначала или мы его уже до этого собирали, поэтому мы можем вытащить его откуда-то из кэша. В данном случае у нас это будет одинаковый результат, не влияет. И поэтому, для того, чтобы ускорить сборку, особенно в распределенном сетапе, вы можете делать инкрементальные сборки очень быстро, потому что вы большую часть проекта не будете пересобирать, а будете просто из кэша доставать уже что-то и дособирать то, что вы обновили или как, чтобы ваш результат как-то изменился, что поменялось в начальных условиях, то и будет пересобираться. Ну, по этому же пути шоу идет до сих пор еще Nix. Который делает, ну, в принципе, то же самое, только у него фактически таргетом является не какой-то, там, не знаю, набор артефактов, а как бы артефактом у него является весь ваш софт. И если вы используете NixOS, где Nix такой типа Package Manager, то артефактом является весь софт на вашем компе. И вот здесь опять же вот это контентно-адресовое Storage, как хеш-хеш, оно позволяет экономить гигабайты и гигагерцы за счет того, что весь мир с вами собирает этот же Snapshot. В плане... Контентно-адресового Storage я хочу сказать, вдруг кто не знает, это ну, если у вас есть какой-то binary, у которого там хеш-сумма там фулл бар 56, то после сборки система знает, что результатом отработки этой штуки является как некий файл с хеш-суммом там фулл бар 56, и если от него кто-то зависит в будущем, то он может пропустить шаг сборки, если в удаленном хранилище уже есть это... есть этот файл, и ему не надо знать, как он называется, ему не надо знать, как он располагается, ему не надо вообще ничего знать, он просто говорит дай мне блок, который вот имеет такой хеш и удаленный ну или его же локальный хеш просто говорит, а вот твой блок. И Nix в этом отношении он просто делает симлинк в свое блобохранилище, и в результате окружение, построенное Nix выглядит как что все папки на месте, всякие юзер локалы, все как обычно только там все симлинками сделано это довольно необычно может выглядеть вот, ну у Базиля примерно то же самое, только у него тоже есть окружение, которое он строит и в котором выполняются дальнейшие правила и там тоже все так лично провязано и пока у Базиля не было еще таким прям мейнстримом у нас в команде например часто звучало в обсуждении какого мейка, там и сессии мейка типа опять где-то что-то не собирается, опять что-то там зависло или пересобирается слишком много Nix уже предлагали за то, чтобы интересовались коллеги вот, и предложение не было ни разу принято, зато когда вышел Базиль за авторством и поддержкой Google AdWords в общем движение пошло в плане шедулера в отличие от Шейка, который как мы помним как это останавливает, засыпает подвешивает систему сборки при сборке какого-то узла ожидая пока этот узел появится или зависимости появится в отличие от этого и у Excel и у Базила используется другой подход, другой концепция это restart, то есть если мы видим, что что-то поменялось или что-то изменилось или что-то чего-то не хватает, в частности в Базиле, как у нас отмечает в чате Алекс Базил умеет работать с генерируемым кодом просто надо заранее написать таргет который этот код сгенерирует и соответственно в этом случае у нас как бы на лету подменяется вот этот вот как это дерево зависимостей и для",
    "result": {
      "query": "различия Make Shake Bazel"
    }
  }
]
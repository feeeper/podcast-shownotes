[
  {
    "segment_id": "e99c2196-e336-4ba6-b46f-f9aa167dcdd7",
    "episode_id": "a8cdfb0a-74cf-4bd2-91ec-c9483430ec55",
    "episode_number": 395,
    "segment_number": 11,
    "text": "Наверное, последняя боль, которую я поделюсь в плане построения и поддержки сообщества, это в том, что документации, ее в проекте было очень мало. То есть даже стандартного Getting Started Tutorial, его по сути не было. То есть было немножко примеров в ReadMe, было немножко FAQ в GitHub Wiki. И это все. Ну и еще есть довольно большое количество блокпостов в интернете, которые можно гуглить. Но мягко говоря, на нормальную дружелюбную пользователю документацию это не тянет. Соответственно, одна из скучных задач, которые обычно достаются мейнтейнером, это вот как раз писать документацию, которой не хватает. Опять же, это не так весело, как многим хотелось бы, но шансы, что кто-то придет и законтреблитит, к сожалению, не очень высоки. Вот, наверное, это плюс-минус все, что я хотел рассказать. Мы, кажется, наговорили больше, чем на час, так что если есть какие-то вопросы, может, обсудим вопросы или поедем дальше. Может быть, ты опишешь немножко в деталях, кого ты ищешь, если у нас ослушатель, кто-то заинтересуется, чтобы он понимал, что сейчас наиболее как бы насущная проблема, которую надо закрыть. Слушай, это, кстати, классное напоминание. Я хотел немножко порекламироваться и сказать, что да, мы ищем контрибьюторов, мы ищем любых контрибьюторов. Если вы хотите писать тюториал или записывать видео, прекрасно, присылайте нам ссылки, мы будем добавлять там в наши вики, ресурсы и каталоги. Если вам хочется просто сидеть и пилить фичи ради искусства, примерно как я это делаю, то, пожалуйста, у нас есть целый набор разного размера реквестов, которые можно найти и начать над ними работать. Дженерики это, наверное, самые горящие и, скорее всего, если мы не найдем волонтеров в ближайшие, там, не знаю, недели-две, я начну над ними работать сам, но, во-первых, помочь их реализовать мне, скорее всего, будет неплохой идеей, потому что это довольно много работы. Кроме того, у нас есть много фичей, которые специфичны для проекта, которые мы хотели бы реализовать. Например, сейчас мы генерируем просто один большой JavaScript файл на все пакеты, на все, что мы используем. Что нам хотелось бы поддержать и что у нас пользователи просили, это чтобы мы генерировали ECMAScript модули на каждый пакет, который мы компилируем. То есть, чтобы это хорошо потом сочеталось со всякими бандлерами вроде Webpack, которые позволяют хитро там делить бандлы на небольшие кусочки и загружать их по необходимости. Вот, поддержка таких фич, поддержка более плотной интеграции с JavaScript, это то, что мы хотим сильно улучшать. Поэтому, если вы хотите поконтребьюдить в Open Source, приходите. Если вы не очень опытны в Go, это не проблема. Я лично буду рад помочь вам разобраться, как в проекте, так и в самом Go. Просто потому что это тоже одна из таких вещей, которые мне нравится делать. Вот как-то так, минутка рекламы в DivZen. Почти бесплатно. Всего лишь за контент, всего лишь за час разговоров про ваш проект. Знаешь, это валюта, которой я могу расплачиваться почти бесконечно. А что еще можно делать до бесконечности? Это смотреть лекции семьи базданных, правда, Саша? Нет, они вполне конечны. В этот раз я посмотрел лекцию номер 18, где рассказывается про MVCC. Напомню, это не пересказ, это моя попытка выделить что-то из лекции, что мне запомнилось и как-то зацепило. Лекция не то чтобы... Короче, лекция, она хорошая, она вот прям классически объясняет, что такое multi-version concurrency control. Но что-то вот прям принципиально новое, я не могу сказать, что я из нее узнал. Говорится, что практически любая суббота сейчас использует MVCC, даже если это NoSQL базы данных, потому что это очень выгодно. Читатели не блокируют не читателей, не писателей. Писатели не блокируют читателей, только других писателей. Притом, в теории тебе ничто не мешает реализовать оптимистичную запись, где даже писатели не блокируют других писателей, но обычно это не очень выгодно, потому что одна из транзакций будет скорее всего откатываться, если у тебя будет конфликтующая запись. Поэтому, например, в Postgres у тебя, если есть две пишущие транзакции, они конфликтуют, то одна из них встанет на блокировке. Здесь также немножко рассказывается про вакуум, здесь говорится про то, что когда у тебя есть разные версии кортежей, то ты можешь цепочки их версий строить от новых к старым, или от наоборот более старых к более новым. Есть плюс и минус у этих подходов. Когда ты дописываешь новую версию в конец цепочки, то тебе не нужно обновлять ссылки, например, в индексах, в праймерике, если у тебя СУБД требует наличия праймерики на все, потому что по цепочке всегда можно найти более новую версию. Но обычно тебе нужно найти как можно более новую версию, поэтому казалось бы выгоднее добавлять новую версию в начало цепочки, но тогда у тебя проблема, тебе нужно обновлять все индексы, добавлять новую запись во все индексы, если кортеж был проиндексирован. Это можно пытаться мегагировать, например, у тебя индексы могут быть, что называется, логическими, когда у тебя вторичный индекс, они на самом деле хранят первичный ключ проиндексированного кортежа. Но этого тоже есть при недостатке, потому что любой лукап из вторичного индекса означает, что тебе нужно потом сходить в первичный индекс, а уже потом в кучу. В общем, есть разные компромиссы. Что еще? Ну просто есть база данных вроде MySQL, которые организованы, так что у них вместо кучи первичный индекс. Ну да, хорошо, да, принимается. Но все равно это означает, что тебе нужно вместо того, что ты ссылаешься прям на страницу и слот, ты ссылаешься на первичный ключ, тебе нужно спускаться по индексу, у этого тоже есть недостаток. Это правда. Ну опять же, там типа, если, ну да, согласен, там вообще-то трейдов и притом такие, там еще можно, мне кажется, в обоих базах, я не уверен, уже на счет MySQL давно с ним работал, в пазгрейсе всегда совершенно точно можно какие-то вещи, которые часто оттаскаешь, просто доложить в индекс. Ты имеешь в виду covering индексы или это о чем? Когда-то можно include написать и короче. Да, это покрывающий индекс, но он тебя не особо спасает. Спасает похождения в кучу, если ты покрываешь эти колонки, которые тебе часто нужны. Ну да, но я в моем виду, что если ты меняешь то, что у тебя включено в индекс, тебе все равно надо будет записи добавиться. Да, это правда, тебе нужно будет в обоих писах. Вот, еще согласно этой лекции, помимо варианта писать новые версии кортежей, теоретически есть возможность писать дельты, то есть, можно сказать, что вот в этом, ну то есть ты строишь такую же цепочку, но цепочки ты пишешь не полную копию кортежа, а пишешь, что вот у меня такой-то ключик стал, вот его новое значение. И опять же, можно сначала писать в начале цепочки новой версии или можно писать их в конец, с теми же компромиссами. Ну опять же, преимущество дельт, что занимает они меньше места, но недостаток, что тебе эти дельты нужно применять. И по-видимому так делает Oracle, хотя я не знаю много про детали реализации Oracle, поэтому вот приходится принять на веру. По большому счету это все, лекция нормальная, просто мне кажется это такая классика из мира баз данных, если вы не очень хорошо понимаете, как работает MVTC, то вот рекомендую там очень красиво с картинками наглядно. У меня по этой теме все, вопросы, возражения, комментарии. А так, в таком случае я передаю слово Валерия, который яросно жмет кнопку F. Да, как-то время дать честь Акки, которая служила нам долгие годы. Что произошло? Есть такая компания, вот жалко Света нет, потому что Света раньше была как-то большой любительницей Акки в этом подкасте, а Саша был чуть меньше любителем Акки, а я всегда был не любителем Акки. Что произошло?",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 3710. Please try again in 7.42s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 3710. Please try again in 7.42s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
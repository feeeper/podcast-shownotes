[
  {
    "segment_id": "1f1e9f6a-e041-431b-9dec-efe83692c87b",
    "episode_id": "ee7cc804-18cf-46fd-8263-4ad3fe3eb225",
    "episode_number": 125,
    "segment_number": 4,
    "text": "Это, пожалуй, очень большое изменение, то есть вот за два... наверное, я начал наблюдать за патронами с версии 2.5.24, такого крутого изменения я не наблюдал. Посему видно, что комьюнити созрело, чтобы двигаться в сторону создания джета или рантайм-оптимизаторов кода более лучших, чем pHole и то, что сейчас имеется. Люди создают инструментарий и в первую очередь задумываются об API, то есть если у нас есть API, мы порождаем конкуренцию. Я думаю, понятно, что может быть несколько инструментов, которые пытаются использовать API, делать какие-то трансформации кода или какие-то улучшения в этом коде. Это очень важный этап для всей для всего сообщества, потому что иначе бы язык Python остался как язык исключительно интерпретируемый и джит был бы где-то сбоку в PyPy или в Piston, или где там видео разрабатывать сейчас. Сейчас было бы в самом реальном. Юджин. Правда, считаю, что джит прям очень нужен. Я имею ввиду вот ускорение, вот эти все попытки, усложнение, большое усложнение виртуальной машины ради этого, добавление каких-то непонятных вещей. Да, я считаю, что это нужно. Легко очень посмотреть. Давайте так, если кто-то... Я тут буквально месяца два назад делал кросс-анализ за последние года три, допустим, в Intel-ский процессор за последние три года частота не растет, а площадь кристаллов все больше занимает графический адаптер. Да, у нас нет выхода, вся индустрия должна задуматься не только о том, что частота перестала расти, но и количество ядер перестало расти, а все уперлось в графический адаптер в Mass Media, и у нас уже драйвер роста закончился, и нужно теперь все последние внутренние ресурсы тратить на то, чтобы улучшать... вот все крохи собирать, которые возможно, лишь бы получить performance gap. Это очень важно. Юджин. Тут вопрос знаешь в чем? Получается, что Python начинает бороться уже с Java за производительность и универсальность, хотя, по сути, он не настолько универсален, как Java. То есть для меня всегда Python это просто какая-то штука, на которой ты делаешь оберты для всего чего угодно, а ты уже хочешь, чтобы нацеливать его на какие-то сервер-сайт, быстрое вычисление и подключение видеоадаптера для того, чтобы быстрое вычисление эти делать. А можно тебя попросить дать определение универсальности? Универсальность это то, куда стремится Java, на мой взгляд. То есть ты запускаешь на любой платформе программу и надеешься, что она будет, по крайней мере, очень быстрой, а желательно еще быстрее всех остальных, которые ты сможешь запрограммировать. То есть они поэтому соревнуются с C, с плюсами постоянно, хотя и проигрывают пока что. Юджин. Нет, девиз Java right wants run everywhere. Никто не говорил никогда, что Java видит JVM быстрее или слабее кого-то. Всегда говорили, что производительность производить удовлетворительно. Юджин. Да ладно тебе. Они реально всегда спорят по производительности. Смотрите, мы здесь ускорили код настолько, что он быстрее, чем оригинальный C, какая-то библиотечка и еще что-нибудь такое. И они реально на это бьются. Улучшают же, как его, гарбыч-коллектор, чтобы он не страдал. Кучу всего делают. Стоп-стоп-стоп, какой гарбыч-коллектор и кто улучшает? С этого момента подробнее. Юджин. Я не большой специалист в Java, но я много читал, что они там пытаются... Гарбыч-коллектор. Наташа. Они давно пилят J1 и этот коллектор скоро станет стандартным. И да, они по-прежнему его улучшают, совершенно верно. Юджин. Стандартно включены по дефолту и поэтому они его улучшают. Ну окей, если у вас есть колесо, которое вы считаете стандартно включенным по дефолту в вашу машину, наверное стоит его улучшать. Ну окей, в чем вопрос. Если у вас есть какой-то стандартный компонент, то стоит потратить на него усилия. Наташа. В то же самое время есть и другие коллекторы, над ними тоже работают, их не забрасывают. Юджин. Я это введу к тому, что получается, Python начинает конкурировать с Java. Судя по твоим словам... Юджин. Нет, Python не начинает конкурировать с Java. Я говорю, что Python до Java очень далеко, но допустим, по моим какие-то кодеты, я психанул, пообщавшись с разными людьми, примерно оценил количество человек-часов, которые потрачены в garbage collecting в Java на реализацию всех пейперов и всех идей, которые есть, примерно в биллиард человек-часов. Я сомневаюсь, что в Python на то же garbage collecting кто-то закопал миллиард человек-часов. Юджин. Зачем тогда ускорять? Хотите быстрее, пишите на Java C и C++. Юджин. Нет, тут история такая, что есть много вещей, которые можно вполне неплохо сделать на Python, это будет достаточно. Вопрос достаточности производительности. Понимаешь, такая сложная грань. Если ты хочешь, допустим, брать и делать какой-то трансходинг-видео, то, может быть, тебе будет нужен C, а может быть, достаточно будет Java. Python тебе уже явно будет недостаточно. Но если хочешь мультиплексировать HTTP-соединения, то тебе Python в подавляющем большинстве случаев подойдет. И это очень важная грань, за которую борются. Потому что сейчас при человечеством, как все знают, что такое C10K-проблема. Слушай, если я захочу мультиплексировать, я Python в любом случае брать не буду. Потому что я знаю, что есть куча решений уже готовых на более производительных языках, которые 100% уделают Python. А ты пробовал AsyncIO? Ну, во-первых, AsyncIO не такой уж старый, для того, чтобы его тащить в продакшн. Не такой уж старый или такой уж новый? Не такой уж старый. Ну и мы его используем в продакшн, и с ним всё ок. Плюс вот... 5 лет ему нет, но это не аргумент. Если он стейб... вот в 3.6 сказали, что вообще-то у нас всё уже стейбл, и плюс они сделали AsyncIO Future, AsyncIO Task, они вообще его заоптимизили и сделали C-implementation, то есть быстрее не будет. Да, конечно. Замечание. Так, а во-первых, Python 3.6 ещё не существует, потому что его даже в Arch не добавили, но это ненадолго, я уверен. Я в Homebrew поставил, Arch отстаёт. Ребята, Arch отстаёт, что делать? Да, я, кстати, недавно попробовал AsyncIO, я прям очень сильно впечатлился, то есть я понял, что скала не нужна, Erlang не нужен, то есть прямо это реально большое счастье. Ну то есть это для тех, кто всё ещё не изучал, это похоже на футуры в скале, только обёрнуто в такой более красивый синдекс, оно как бы с одной стороны торчит наружу, потому что ты пишешь там Async, await и так далее, с другой стороны оно не так сильно торчит наружу, потому что у тебя нету прям объекта, с которыми ты можешь очень много чего-то сделать, то есть там какой-то объект вроде бы доступен, но опять же, если не можешь сделать немного в общем и целом, прям я всем рекомендую посмотреть внимательно на AsyncIO, это правда очень клёвая тема. Да, прости, я перебью, всем стоит посмотреть на AsyncIO, это клёво, мучительное сочетание, но я очень не соглашусь, как человек, который последние там много, полгода, если не больше, пишет на скале и на питоне одновременно, я не соглашусь, что фут фьючер в скале, они эквивалентны фьючер в питоне, потому что",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 3348. Please try again in 6.696s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 3348. Please try again in 6.696s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
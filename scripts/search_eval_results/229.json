[
  {
    "segment_id": "5cec96c9-7c58-4c28-a960-8de83e7ad2bd",
    "episode_id": "57a1d4c2-88cc-46ac-be9e-6282aceed41a",
    "episode_number": 229,
    "segment_number": 3,
    "text": "И вот так у них просто при помощи какой-то тулы, которая у них там была для деплоя, оно как-то работало потрясающе, и они начали по мере масштабирования их проекта, у них там какие-то сотни миграций в месяц, видимо, потому что много клиентов, и что-то сильно много меняют, они начали периодически упираться в интересные всякие случаи. Во-первых, по-загрессовываю транзакции, они умеют хватать локи иногда, эксклюзивные, и это обычно не проблема, потому что сам по себе миграция довольно быстро отрабатывает, и, как правило, никто эти локи особо не замечает. Но если у вас есть какой-то длинный селект или еще что-то, что тяжелое, или еще хуже, если у вас есть несколько конкурирующих залог длинных транзакций, то вот какой-нибудь alter table, который... То есть он даже может делать что-то безобидное, типа добавление колонки, но ему все равно нужен эксклюзив лок на таблицу на очень короткое время, и вот он будет ждать этих долгих ребят. В общем, как правило, это решается тем, что лок тайм-аут и стрейтмент тайм-аут поставляются, и, кстати говоря, мы это применяем на более крупных базах, даже вот на моем же проекте у нас есть база с метаданами, она маленькая, база с самими данными. Вот база с самими данными, да, конечно, почти любая миграция будет обвешана стрейтмент тайм-аутами и лок тайм-аутами, чтобы миграция просто отваливалась, и потом мы ее ретрайм, и постепенно база докатывается до состояния, до того состояния, которое мы хотим, просто не всегда это выходит сделать с одного раза. Ну да, собственно, дальше у ребят история, как они тоже делали авторетрай, как они постдеплой превращали в преддеплой, то есть просто посредством того, что они делали больше деплоев, и так я, в принципе, всегда делал, то есть я на самом деле никогда не видел подход с преддеплоем и постдеплоем, я всегда видел просто подход с тем, что вначале выкатывается код, который обратно совместимый по миграциям, а потом как-то позже происходит подчистка и кода, и подчистка таблиц. То есть я как раз таки, для меня это была норма всегда. Дальше у ребят, они уходят в какие-то интересные вещи, типа они расточили ORM, чтобы как-то более хитро compatibility check сделать, чтобы при переименовании колонки код точно совершенно читал все правильно, и даже какую-то автоматизацию тестирования сделали для миграций. Это что-то такое из разряда... мне такого никогда не нужно было, мне тяжело сказать, насколько это применимо, то есть для них это важно, потому что они мигрируют часто, им хотелось минимизировать вообще какой-то человеческий фактор в мигрировании. В принципе, звучит как прикольные вещи, но не думаю, что это широко применимо. Вот, как-то так. Как мигрируете вы, мои уважаемые коллеги? Обычно мы мигрируем лапками, то есть, в смысле, пишется вручную код, который понимает старую версию данных, пишет новую версию данных, и важный момент, он пишет не только новую версию данных, но и старую версию, потому что если ты на фиче катил, а оказалось, что надо фич откатить, то старая версия кода может работать только со старой версией данных, поэтому на промежуточном этапе ты пишешь и старую версию тоже. Если твоя фича более-менее работает, то в фоне запускается медленный скрипт, который небольшими бачами мигрируется старой версией на новую, пока всё не смигрируется, ну примерно как ты описал.",
    "result": {
      "query": "стратегии миграции баз данных"
    }
  }
]
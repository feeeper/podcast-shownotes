[
  {
    "segment_id": "190a45f3-be9e-4e46-9e7d-61460b5c862f",
    "episode_id": "71fbdc0d-7f18-4f0d-ab02-f3408d2e6f78",
    "episode_number": 95,
    "segment_number": 2,
    "text": "Ну и в качестве первого месяца, Валер, давай, тебе слово. В общем, тут на днях, ну, на самом деле, наверное, даже на прошлой неделе в блоге Cloudflare вышла статья, точнее, статья в серии статей. Мы, по-моему, даже первую статью в этой серии обсуждали. О том, как они ускоряют свой стэк сетевой, чтобы добиться, в общем, чтобы выжать из своих сетевых карт максимум. Ну и у них есть, ну, как бы на то необходимость Cloudflare, если кто не знает, это такой довольно неплохой CDN. Ну, неплохой, у меня нет своего собственного опыта, но некоторые одобряют. Вот. В прошлых статьях они рассказывали о том, как подтюнить приложение и сетевой стэк Линукса, так чтобы как можно больше можно было протащить от сетевой карты до юзерспейс-приложения. Но, в общем, в какой-то момент они все равно упираются, говорят, что как ни раскидывай очереди на прием по ядрам, как ни ничего не делай, там все равно получается 1 миллион пакетов. А у нас, мол, 10-гигабитные карты, и это уже как-то далеко не полная утилизация карточки. И есть такой небезызвестный, не знаю, не подход, это группа подходов к использованию сетевых карт. Это всевозможные юзерспейсы, стэки, kernel-bypass, среди которых есть всякое разное. Всякие пакеты memory-maps, pf-ринги, dpdk. Некоторые, ну, как бы в статье дают мне обзор, я в принципе не буду углубляться, сходите почитайте. Но, в общем, там почти все эти решения, они требуют, они либо накладывают некоторые ограничения, такие, которые мне удобны, либо, как dpdk, говорят, эй, давайте-ка вы мне дадите целиком сетевую карту, а дальше я уже разберусь, как с этим жить. То есть, если вам норма иметь 3-4 сетевых карты в машине, то, ну, наверное, так и можно жить. И, судя по всему, некоторые люди так и живут. Но Cloudflare по некоторым неозвученным причинам так нельзя, им так не хочется. И они ударились в то, чтобы как бы так вот подхатчить что-нибудь, чтобы иметь возможность использовать dpdk или подобные решения, но при этом не отдавать целиком сетевую карту. И, в общем, они там дальше углубляются. Всевозможные вещи типа before created drivers, это когда у нас сетевая карта с многими очередями. Одна из очередей в юзерспейсе торчит как что-то отдельное. Либо как отдельная очередь, которая умеет управлять какие-то специальные юзерспейс стэки. Либо, в случае, если использовать всякие хакерские штучки, ее можно вынаружу вытащить как сетевое устройство, на которое потом можно повесить его интерфейс. Второе, используется активно в виртуализации. Вот. Ну, в общем, на самом деле, никто не мешает такой интерфейс использовать и не для виртуализации. Но это все завязано на хардварной фиче карточек. Дико специфично. И, в общем, насколько я понял, они не получили универсально работающего решения. Но вот, если вам интересно все, что только что озвучил, вам хочется узнать. Но свою проблему они решили? Свою проблему они решили, так понимаю, переходом на какого-то планета. То есть у них есть интеловские карточки, по всему, у них есть какие-то карточки производства с Solar Flare. И Solar Flare у них есть как раз вот Before Cated Driver, он у них просто есть вот у самой карточки. Он проприетарный, но вот он работает так, как надо. То есть ты просто загружаешь приложение с определенным источником, и оно начинает уметь читать из специальной очереди на карточке и успешно обходит ядро. Вот. Они хотели это же сделать на Intel карточках при помощи этого трюка с виртуализацией. Но у них там были какие-то проблемы из-за разряда, оно в теории работает на практике не очень. И пока что они говорят, что пока что вот эта работоспособность создана с Solar Flare, и мы будем дальше хакать Intel. И что мало хочется, чтобы уже что-то такое open-source появилось. Не завязывая нас на куче проприетарных вещей. Слушай, у меня вот такой вопрос к тебе. Я не знаю, к тебе или ко всем, кто разбирается в вопросе. Я вот знаю, что у нас в дата-центре там стойками, все сервера стоят стойками, там то ли по 16, то ли по 32 штуки в стойке, я точно не помню. И на эту стойку приводится, соответственно, там питание свое, приводится вот сетевой интерфейс свой и все такое. И получается вот в наших приложениях, которые очень сильно кушают сеть, и там разводили прерыва, они по разным ядрам оптимизировали как-то по-сильному. Получается так, что если у тебя очень сильно две машины из стойки начнут кушать все, ну в смысле, очень сильно начнут использовать сеть и съедать там все CPU и memory, то они в принципе могут убить всю сеть для всей стойки, потому что там свитч стоит один и он уже не справляется с тем количеством запросов, пакетов. Ну свитч менять, это довольно точно, это же очевидная проблема, если у тебя есть куча машин, на которых 10 гигабитные карты, и свитч, который не может, только машины, которые 10 гигабитные карты на полную мощь молотят, то ну херовый свитч. Ну то есть получается, что ты хоть как должен очень четко работать со своим поставщиком, договариваться с ними о специфичном оборудовании, в своем дата центре самостоятельно рулить, ставить 2-3-5 свитчей вместо одного на стойку и все такое? Ну у меня нет большого опыта именно с 10 гигабитным Ethernet, у меня был некоторый опыт с InfiniBand, и там все было именно так, как ты говоришь, но это было к тому же давно, и на очень специфичном железе. Вот, здесь... Ну то есть я имею ввиду, что скажешь... Ну то есть большинство приложений, извините, что перебиваю, большинство приложений 10 гигабит вроде как не нужны, их пока в мейнстриме, ну вот он начинает появляться в мейнстриме, там во всяких вазонах, ну и уже есть в мейнстриме на некоторое время, на всяких хостеров, которые он премизис, ну вот, как бы, ну не знаю, да, нужно договариваться. Мне тоже кажется, что по идее здесь разработчики приложений должны договариваться с сетевиками по поводу канала, ширины канала, то есть, например, если вот у нас база данных есть и мы их бэкапим постоянно, то мы сами себя ограничиваем, потому что мы можем утилизировать большой канал, соответственно, если мы его будем полностью утилизировать, то другие приложения не смогут просто работать. Поэтому тут нужно себя ограничивать, как-то договариваться, увеличивать, если нужно уменьшать. То есть, получается, это решение не подойдет тем, кто готов там снимать часть дата-центра, который мало конфигурируется и уже готов, то есть берите, приходите, используйте, но вряд ли вам что-то ради вас будут дополнительно менять. Понятно, ладно. Нет, ну с другой стороны, если ты Cloudflare, то ты CDN и CDN в чужом дата-центре хостится, вряд ли будет. Тоже верно. Что самое интересное, вот в этой статье, где люди оптимизируют уже прям ядро и смотрят на железо, и как с этим железом работать, с другой стороны, есть такие сервисы, ну, например, недавно разбирал сервис, который поддерживает большое количество соединений, и просто был в шоке, когда выяснилось, что этот сервис некий пылай в соединении TCP держал, соответственно, у него, когда с другой стороны все умирали, но они соединения не проверялись, что они мертвые, не убивались. Вот я к тому, что люди разные бывают. Ну это если вы сильно заморачиваетесь о деталях. А вот если о деталях не сильно заморачиваться, то можно начать пользоваться новым сервисом Джоэля с Польски. Знаете такого, да, Джоэль с Польски? У него есть сайт такой, joel.onsoftware, там большое количество интересных статей, он раньше писал, сейчас перестал писать бизнесом, стал заниматься. Интересно, что раньше он писал много, и его знали все, ребят, которые приходят на собеседование, они не знают, круто. Раньше это был один из тех, кого читать нужно обязательно. Андрей, ты временами пропадаешь. Я нечаянно. У тебя там как-то нестабильная сеть. Ну да, я согласен, что раньше он писал больше, был больше известен, и многие его знали. Сейчас молодое поколение уже по архивам не лазит и читает уже другую литературу. Они делают треллы, они делают фок багс, это ищет трекер. И вот они выпускают новый продукт, который говорят мы вообще давно не выпускали ничего, решили что-то выпустить. Этот продукт называется HyperDev. И я бы сказал, что это такой джекил на стероидах, наверное, как-то правильно сказать. То есть вы имеете что-то вроде распределенного редактора, что-то вроде Google Docs, в котором вы можете править файлы на сервере, что-то вроде джекила, то есть вы правите исходники, и это автоматически тут же изменяет на лету то, во что он превращает, в какой сайт он превращает ваши исходники. Несколько пользователей одновременно могут все это править. Никаких там git-репозиториев, ничего, но если что, вы можете экспортнуть все в виде файлов. Но так-то все хранится на удаленном сервере. Что-то вроде такого. Я не знаю вот эту полезность. Вы поняли, что я имею в виду, да? У меня сейчас все пропадали. Кстати, плюс один, да. У меня тоже все пропали. Ну вот, это у нас опять серва глючит. Ну, давайте тогда еще раз повторю. Общая статья сводится к тому, насколько все просто и хорошо начинается, если вы начинаете пользоваться этим сервисом. Ну, это как обычно у всех PR. Идея в том, что вы заходите на сервер, и вам автоматически сразу создается проект с главной страничкой, который уже готов и уже работает, хотя вы еще даже не залогинились и ничего не начали делать. А потом вы начинаете править redmi.markdown, начинаете править JS файлы, и ваш маленький сайт может превратиться в большой. Все на лету обновляется, все мультипользователями может быть изменено. То есть несколько человек могут одновременно править файл что-то вроде Google Docs. Никаких там git-репозиториев, ничего, и все работает. Если что, вы можете все экспортнуть в локальную папку и поднять где-то в другом месте. Все работает через Docker контейнеры. И нужно, я так понимаю, для того, чтобы делать распределенно какие-то, вот я не знаю, домашние странички что ли. Я мало понимаю нацельность этого продукта. Как-то так. Кому-то, как вам кажется, будет полезна такая вещь? То есть они говорят, что для серьезных разработчиков они не позиционируются, потому что серьезные разработчики знают сами, что хотят, и они сами все себе настроят. А это так вот, ты нажал кнопку, у тебя уже есть сайт. Ты нажал кнопочку, Markdown поправил, и оно автоматически обновилось. И даже ты можешь сразу страничку кинуть своему кастомеру, пользователю, и он уже зайдет туда и поглядит что-то. По идее практически все то же самое без редактора админки. Это GitHub Pages. То есть ты его правишь, и все автоматически. Здесь еще в многопользовательском режиме ты можешь прайдать. Несколько человек могут зайти туда и одновременно изменять. И они говорят, что они вроде как нормально работают. Но вот этот многопользовательский режим, по опыту нашего собственного продукта, не особо как бы пользуется популярностью. То есть очень редко, когда реально несколько человек что-то правят в real time. А вы что, Google Docs не делаете? Мы постоянно в Google Docs, там 5 человек сидят и что-то забивают одновременно. Видимо это потому, что в последние 5 минут все происходит. А в среднем обычно редко, когда несколько юзеров одновременно работают. Ну здесь согласен, да. Хотел добавить, что такие продукты появляются с завидной регулярностью раз в несколько лет. Теорику точно с такого же начинал. У них была среда онлайн, где можно было вместе редактировать, и оно сразу жило. Правда работало не на JavaScript, а на Ruby on Rails. И потом они просто этот кусок IDE убрали. И все. И появлялись нормальные хвостики. Вот если убрать кусок IDE, то начинает быть похоже на другие появляющиеся проекты. Например, Horizon от создателя Rethink. Они нацелены на то, чтобы если вы не ставите у себя ничего локально, то можете просто взять кусок ключика API и начать писать свое JavaScript-приложение у себя на столе, например. Ну, у себя в редакторе. И оно сразу будет такое из себя реалтаймовое, с поддержкой моднейших хэчей, вроде этих живых запросов ретинковских и прочего реалтаймового обновления и общения между пользователями. И это не имеет IDE, в котором могут трудиться сразу 5 человек, чтобы можно было 5 раз чик-чик и столько же раз в продакшен. Horizon не такой радикальный, там меньше чик-чиков в продакшен, зато похожий тренд. Вот я к чему. Ну, я считаю, что это все бесполезная штука. И я бы вообще не стал добавлять эту новость, если бы это не Джейл добавил себе такой продукт, если честно. Ну, вот, наверное, расчет именно на это. То есть, смотри, есть определенная техническая возможность такие штуки делать. Возможно, есть какая-то ниша, большая, небольшая, непонятно, для таких продуктов. Может быть, где-то в образовании, может быть, там на собеседованиях такую штуку использовать еще как-то. И явно, что если такие продукты будут появляться, то если один из этих продуктов будет продуктом Джейла, то у него будет как бы head start для того, чтобы оказаться лидером в этой нише просто за счет собственной известности, за счет того, что у него есть аудитория, в отличие от других. Но мы это уже обсуждали, молодые его не знают. Ну, это да, но с другой стороны, как бы все равно у него аудитория есть. То есть, я сейчас на это смотрю, есть куча, знаешь, вот таких вот там, jazz bean, jazz fiddle, там, где можно front-end вот так писать из коробки. Есть, они тоже все с коллаборацией, то есть, ну, не все, но многие из них. То же самое, открыл страницу, начал что-то редактировать, сразу же несколько человек редактируют, и сразу виден результат, и оно работает. Тут просто появляются сервами компоненты. То есть, в момент, когда нам нужно из серви мы делаем, мы катетипируем, допустим, какую-то формочку, нам нужно на серве что-то куда-то сохранять. Вот с этой штукой можно это делать. То есть, я вижу как такую штуку, чтобы проводить собеседование, как я уже сказал, чтобы там, может быть, какие-то уроки делать. Google Docs? Google Docs это не то, потому что в Google Docs ты можешь описать алгоритм, и рассказать идею, и набросать примерное решение, но ты не можешь его выполнить в Google Docs. А здесь у тебя есть возможность именно редактировать код, чтобы довести его до состояния, код работает. Я очень часто вожу собеседование, когда я людям даю страницу, и люди редактируют. И часто бывает, что, например, в собеседование положу, я не один, а, допустим, несколько человек, сразу висит и смотрит, как человек пишет. Но я говорю, сейчас это есть для фронтенда, а вот эта штука может это же самое делать на северной стороне. Сейчас только JavaScript. Возможно, с учетом того, что там все Docker, а возможно, там легко можно будет добавлять другие языки. Да, они обещают, что, кроме JavaScript, что-то еще добавят. Скажи, а там подсветка синтаксиса есть? Ну да, почему бы нет? Да, есть. Но все равно мне, например, непонятно, какую все-таки проблему они этим продуктом пытаются решить, и на кого это нацелено. Если это для собеседований, то тогда нужно интеграция, наверное, с каким-то чатом, наверняка, если собеседование проходит. Не знаю, мне кажется, я не понимаю проблему, которая решается этим продуктом. Да, согласен. Мне кажется, это нише WordPress идет. WordPress, да, может быть. А если там какой-то визуальный редактор, то что ты видишь, что получается сразу же, или нет такого? Есть, есть. Печатаешь прямо как в этом. Ну, в Redmi, как в нормальном этом редакторе, как в Atom в каком-нибудь. То есть нету drag-and-drop, никаких там визуальных компонентов, ничего такого, но, грубо говоря, ты пишешь код, и сразу виден результат. То есть, опять же, допустим, ты договариваешься с каким-то человеком делать ему сайтик, и быстренько, сидя рядом с ним, начинаешь набрасывать идею. А слева у нас будет то, а справа у нас будет все, и вот в таком режиме. Вообще, мне кажется, это как в анекдоте про крестик и штаны, потому что сначала он говорит, что этот проект не для девелоперов, а потом предлагает редактировать Markdown, который, как бы, обычный человек тоже не сразу поймет. Да, и все равно предлагает же редактировать код. То есть я сейчас на это смотрю как такая, нишевая штука, минимальные. Они потратили минимальное усилие, чтобы что-то выпустить. У него нет нормальной какой-то главной страницы, у него нет продающего сайта, есть только пост этого желы, и все. А просто выпустились, и взлетит-не взлетает. Кстати, мне понравился интересный стиль, как они описывали, что это такое, зачем это нужно. И там в качестве, а как это работает, а что там внутри, а как вы на этом зарабатываете. И там такой ответ, ну вот, опять началось, ну вам-то это зачем. Ну ладно, ладно, ответим, типа такого. Ну так, интересно, в хорошем стиле написано. А вот еще следующий продукт, я уже предлагаю уйти к следующей новости, тоже нишевый очень, но вот лично для меня это прям ниша идеальная. Цветной E-ink. E-ink в конце мая компания выпустила анонс уже о готовом устройстве, который в цветах чернила, вот эти вот чернильные книги делает. Ну то есть можно будет читать цветные книжки, смотреть цветные картинки и все такое. Как вам такая новость? Я вот прям, я прям очень хочу. Нет, не было, еще ничего не было. Назывался Adam или как-то так. На заре, когда вот только-только кинглы появлялись, еще что-то, был продукт от каких-то ребят, которые делали цветной E-ink. Ну может быть, ну то есть цветной экран на чернилах. Цвета там были очень бледные, очень пастельные, то есть не яркие, не сочные цвета. Но эта штука была, она долго задерживалась, долго выпускалась, потом выпустили, стоило какие-то денег больших. Ну вообще потом появился паттерн, они цветели. Нет, эти, здесь тоже цвета не слишком яркие, я имею в виду не такие сочные, конечно, как на iPad. Но я не помню таких новостей, то есть я если честно следил, потому что мне хотелось купить цветную читалку на E-ink. И я считаю, что такая штука очень нужна, я прям себе очень хочу уже. Вань, а что ты читаешь на E-ink экране? Ну во-первых, читаю не я, а вообще у меня читают многие дома на E-ink экране книжки. Очень удобно читать книжки. То есть у тебя художественная литература больше? Да, да, конечно. А ну да, я согласен. То есть вся научная я либо распечатываю, либо на iPad. Ну короче, никого не обудушевляет. Если честно, я считаю, что это прям революция. А вы тут, понимаете, молчите, мне не нравится она. Ну ладно, давайте тогда следующую новость. А следующую новость нам расскажет Валера. Что-то связанное с Kurosi. Ну это не совсем связано с Kurosi, скорее связано с разработчиками Kurosi. В общем, ребята, ну знаете же, первое правило распиленных систем, это не писать распиленные системы. Ребята решили его нарушить. И кроме того, что у них уже есть всякая разная, в том числе, ну они же и являются разработчиками ETCD. К слову сказать, ETCD штука неплохая. Они решили решить проблему персистентного хранения данных контейнеров, которые у нас платят контейнеры. Таким образом, что будет прям раз навсегда, и у всех все хорошо работало. Ну сразу скажу, что я пока в это не верю. Ну в смысле то, что это полетит и будет хорошо работать. И оно пока в ранней приальфе. Поэтому проверить, работает оно или нет, ну то есть как бы сейчас можно пойти проверить, что оно не работает. Ничего другого сейчас сделать нельзя, наверное. Но в целом я верю в то, что команда хорошая, потому что люди, которые сделали ETCD, они, наверное, совсем полную фигню не сделают. Я все еще считаю, что фича в районе Кубернетеса, не таскать контейнеры с машины на машину, если у него есть персистентный диск. И прочие вещи, которые позволяют системе контейнеризации быть в курсе того, что это что-то, что контейнеризованное приложение уже внутри себя имеет какую-то репликацию переезд данных. Мне кажется, вот это надо было бы сделать раньше, чем вот то, что они делают. И это, кстати говоря, мне кажется сделать проще, чем сделать вот такую универсально масштабируемую, классно работающую систему для персистентных данных. Это первый момент. Второй момент, что уже есть Ceph. Вот чем это должно быть лучше Ceph, мне не очень понятно. То есть, почему оно будет быстрее или стабильнее, или что в этом принципе установки. Может, налегче установки? Это не оправдание писать свою систему, это оправдание сделать более нормальную инсталлятор для Ceph. А может быть такое, что ребята просто начали писать эту систему до того, как появился Ceph? Ну здрасте, Ceph уже сколько лет? Ну, мало ли. Я не слежу за этим. Нет, здесь можно ответить так, что система Ceph имеет фатальный недостаток, она написана не ими. Так вот, нет, это непонятно. Мы же знаем, что правила номер один распределенных систем просто так не нарушают, особенно ребята, которые немножко в курсе распределенных систем. У меня есть подозрение, что они просто хотят более простую интеграцию с кубернетскими контейнерами, контейнеризацией, но на мой взгляд это все еще недостаточное основание. В общем, мне вот интересно, если кто-нибудь знает, за каким чертом они взялись это делать с нуля, придите и расскажите мне. А вы читали трейд на Hacker News, где обсуждали как раз эту систему? И там пришли достаточно злые люди из D-Trace, и по-моему из Ceph тоже один из разработчиков приходил, который как раз высказывал в таком духе, что зачем писать систему с нуля, если мы вот тут 6 лет уже пилим и до сих пор еще ничего не допилили. Вот у нас такие-то проблемы, а вы даже про них еще не знаете. Я думаю, ребятам просто захотелось сделать что-то интересное, прикольное для своей экосистемы, потому что курьоз, прежде всего, это экосистема, и они бизнес делают. И чтобы делать бизнес, им в их экосистеме нужен какой-то продукт, которым проще самим разрабатывать, чем допиливать готовый Ceph, например. Мне кажется, это основная причина. Справновато, на мой взгляд. Кстати, можешь кинуть ссылку на Hacker News thread, потому что я что-то вижу. Да, секунду. Потому что мне интересно, что ответили разработчики в ответ на упреки. Так, ну а пока ссылку кидают, я предлагаю перейти на следующую тему. И следующая тема – это обновление Aeternum 2. Кто-нибудь пользуется Aeternum? Я два раза пытался, оба раза перестал. Очень аналогично. Я пользуюсь, но на самом деле разницы в моем использовании между обычным терминалом и Aeternum никакой нет. Есть, но в терминале же нет. В моем использовании. В терминале, по-моему, до сих пор нельзя настроить, когда ты два раза мышкой жмакаешь, какую область выделять. Да? Да какие значки включать в имя, какие не включать. Но вот это одна из основных вещей, которой мне вообще не хватает. Теперь, честно говоря, не знаю, о чем ты сейчас. Ну, вот у тебя есть длинное имя файла, которое там папка, двоеточие, я не знаю, что-нибудь еще ненужное. Я жмакаю на имя файла, вот этот два раза мышкой или как угодно, тачпадом, и он выделяет до конца, до начала символов. То есть, скажем, я написал ему две точки не включать в это имя. И если я урлу с портом ткнусь, он мне урл выделит, а порт не выделит. Вот эта штука, она очень удобная. Я, честно говоря, не пользовался ни разу, я даже не пытался. У меня претензии обратно к Aeternum. Во-первых, он выглядит как говно, я не знаю, этот релиз должен-то починить. Но пока что он по факту выглядит как говно. Это не самая большая проблема. Ну, не знаю, выглядит как говно. А терминал? А терминал, ну, выглядит так, как остальная ось выглядит. Ну, я могу Aeternum перевести к виду терминала. Вот у меня не получалось, он у меня все еще выглядит как говно. Ну да ладно, это не самое страшное, это можно пережить. У меня самая большая проблема в том, что я очень люблю фичу терминала. Что ты можешь открыть вкладку с такой же команды, как предыдущая. И можно открыть вкладку с командой, которая с SH. Что значит, как предыдущая команда? Вот есть вкладка, с которой ты запустил консоль, не просто с башем. А вот прям, чтобы вот это выполнить и прибиндить к этому тебе виртуальный материнал. И в частности это может быть, например, SH. Если это SH, то на самом деле терминал в курсе того, что там написано SH. И он будет... там есть кнопка сделать вкладку с таким же коннектом. Это чертовски удобно, потому что если у меня открыта SH-сессия на какую-то машину, я могу просто нажмакнуть это сочетание клавиш. У меня откроется вкладка с такой же SH-сессией. Это очень здорово, мне это очень нравится, мне это очень не хватает в iTerm. И мне это гораздо нужнее, чем выделение мышкой умное. Подожди, iTerm поддерживает несколько вкладок на один коннект. Я просто никогда не пользовался горячей клавишей, чтобы создать этот же коннект, засунуть. Я вот не нашел, я вот не видел, что там еще можно делать. Есть, там эта штука есть, и она очень хорошо чувствуется, когда у тебя... Ну то есть, во-первых, он не сразу гасит коннект, к примеру. То есть ты можешь, если там закрыл случайно, открываешь заново, он может подцепиться к старому коннекту. Нет, это другое, я про другое говорю. Я говорю даже не про то, как оно коннектами рулит внутри. Я говорю о том, как у тебя просто вот в iTerm, насколько я знаю, у него есть понятие профиль, в который можно вставить команду. Но вот если у меня нет машины, на которые я все время постоянно хожу, у меня есть, там не знаю, 30 машин, на каждой из которых я могу захотеть пойти. И если я на нее пошел, я могу захотеть пойти на нее второй или третий раз одновременно. И я не нашел, как в iTerm этим удобно рулить, мне это нужно, и мне этого не хватает. Ну, в общем, да. Наверное, это можно сделать, может быть, а может быть нет. Ну давайте я расскажу, что тут вкусненького есть в третьей штуке. Во-первых, она еще в бете, но я не помню вообще iTerm, по-моему, часто делает бету. В смысле в качестве даже основной версии. Во-первых, они перешли на flat вид, на flat отображение. Они сделали большую интеграцию Shell integration, то есть когда вы запускаете iTerm, потом вы можете установить какое-то дополнительное расширение, называется Shell integration. Там очень много всяких разных вкусностей. Я потом про них попозже немножко расскажу. И автоматический свитчинг профилей. Если вы входите куда-то с Асшем, скажем, на какую-то машину, он может определить, куда вы вошли, и сменить профиль. Он умеет... Я вот этого не помню, может, я раньше не пользовался, но вот тут написано, что сейчас он научился сохранять пароли в Keychain, который вы вводите в консоли. Он умеет отображать табы в левой колонке, если у вас их очень много. Он трекает окончание каждой команды, и вы можете потом посмотреть, сколько какая команда выполнялась, вам для этого не надо там ничего делать дополнительного, это прямо в терминале. Так, что-то... Все из вкусного. А Shell integration, это вообще большущая штука. Там дофигища всяких каких-то дополнительных функций. В качестве вкусных функций я бы выделил то, что если вы зашли с Асшем на какую-то машину, и там есть какие-то файлы, и там ls вы нажали, показали список файлов, вы можете кнопку ткнуть, и нужный файл по SCP вам скопируется сюда, к вам сюда. Или, скажем, наоборот, вы дракон-дропом положили файл в терминал, и он автоматически по SCP скопировался туда. Вот тут прикольно. Да. Какой-то список горячих директорий, куда вы можете легко переходить при включении, и последние директории переходить по последним директориям, и куча каких-то всяких вещей, которые я даже не понимаю, как использовать. Кстати, вы не читали статью, по-моему, месяц назад, нет, наверное, полгода назад была, там про отклик приложений различных было. Да. И там в том числе измеряли ITERM и обычный терминал. Да, там отличалось что-то на 20 миллисекунд, что ли, там, с катастрофическое отстановление. Да, у ITERM сильное запоздание. Но, если честно, я пользуюсь ITERM и не вижу никаких тормозов. Может быть, я просто медленный. Я вот его сейчас открыл, и я вижу, что он немножко медленней. То есть, это заметно, он чуть медленнее стартует, и затем, даже когда текст набираешь, иногда видно, что чуть-чуть подтормажил. Но не настолько, чтобы им не пользоваться. Между прочим, господа, у нас же маководная бинга сегодня в подкасте. Точно. Ну, я удивлен, что... У нас сегодня нету Саши. Да, да, он классический нелюбитель маков, по крайней мере, в подкасте. Ну, в общем, вышла версия 3, пожалуйста, пользуйтесь. И если кого что интересует, в смысле, есть какие-то отзывы, пожалуйста, напишите, потому что я точно знаю, что я ITERM пользуюсь на 10% его возможностей. Скажем, я вот Tmux сессию никогда не раскрываю в виде отдельных табов. Вы такое делали? Я себе настраивал как-то раз, но потом забил. Знаете, да, такую фичу нет? Да, да, это, как бы, по-моему, основная продающая его штука. То есть, изначально, когда люди говорят по ITERM, говорят, вау, там можно в Tmux, не знаю, тоже никогда не тянуло. Я не вижу проблем, чтобы иметь Tmux в одной табе. Вот, кстати говоря, возможно, то, что мне бы как раз хотелось, возможно, это то, чего я хочу, но у меня Tmux же, насколько я знаю, он должен быть на обеих сторонах, и у меня немножко нету Tmux с той стороны, и я не очень хочу это менять. Главное, чтобы Tmux был с той стороны, у тебя его не обязательно должен быть. Кстати, я почему перешел на вот этот 3-й ITERM, то есть я еще перешел… Ты уже перешел. Я давным-давно на него пересел, потому что я экспериментировал с NeoVim, и в нем была поддержка тем с 65 тысячами цветов, и была поддержка, по-моему, только в ITERM, я не знаю, терминал обычно поддерживает? Нет, терминал давно уже перешел, это была причина, по которой я перешел на ITERM 2, но там это в Vim еще было пару лет назад, терминал не поддерживал, но, по-моему, с переходом на 10-ю версию они добавили. Кстати, если продолжать тему про просто Shell, то я вот недавно открыл для себя, что у меня ZSH стоит и Omaizsh плагины различные, и в том числе был плагин для отображения бранчи для GitHub, для других систем контроль версий. Так вот, я заметил в какой-то момент, что у меня просто команды вывода с чего-то в директорию, точнее появление вот этого Shell значка, они начинают тормозить, и выяснилось, что там один из плагинов, он постоянно опрашивал git, постоянно проверял, есть ли что-то на сервере, например, и учитывая, что у меня git-репозиторий просто огромный, это очень сильно замедлило мою консоль. И в ZSH есть такая возможность сделать при cmd-команды, то есть в синхронном режиме отрисовывать вот эту информацию, например, про бранч, либо про любую информацию, в общем. Так что если у вас Shell тормозит, возможно, это не терминал, это реально ваш Shell. Да, да, да, плюс один. Так, ну а раз мы заговорили про тормоза, возможно, перейдем на следующую тему про jvm-бейст языки. Да, буквально перед тем, как прийти в подкаст, наткнулся, и я не знал про такую штуку, но в общем есть фанат, который парень, который просто периодически прогоняется по GitHub, по API GitHub и смотрит на активность репозитория по различным jvm-языкам, то есть он показывает, и вот у них есть свежая",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 13682. Please try again in 27.364s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 13682. Please try again in 27.364s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
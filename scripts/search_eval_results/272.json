[
  {
    "segment_id": "9f7936d3-ab10-4a78-9e8e-5a804b441b13",
    "episode_id": "cf40d551-3dcc-404c-b89c-1db8fb9663f4",
    "episode_number": 272,
    "segment_number": 4,
    "text": "Ну да, согласен, 6 лет назад всё было гораздо похуже, но, с другой стороны, когда пишешь свой настолько низкий уровень, ну, то есть, не знаю, Blob Storage, его как-то нужно адаптестировать, что он не теряет данные, что он в правильный момент F-Sync вызывает вот это всё, тогда, соответственно, сразу вопрос, как вы вообще это тестируете? Всё так, тестировать надо. Мне кажется, что здесь достаточно классическая схема. С одной стороны, мы пишем тесты такие классические, юнит-тесты, регрессионные и так далее, а с другой стороны, у нас есть интересные тесты с отказами, то есть, когда мы там финально на кластере достаточно большом, под разными кейсами, под разными нагрузками, всячески издеваемся над системой, роняем её, форматируем диски и так далее. То есть, такой классический хаус-манки, к которому мы приделали свои разные хитрые сценарии. Это продакшн-кластер или это какой-то специальный тестовый кластер с хаусической обезьянкой? Это, конечно, тестовые кластеры. В продакшне мы такое не делаем, потому что немножко стрёмно, там и так разные интересные аппаратные сбои случаются. А обезьяна у вас какая-то своя или где-то взяли готовую? Своя. То есть, мы взяли в своё время... Есть Андрей Сатарин, который нам в своё время напилил подобную систему, мы её немножко развили, расширили и получили то, что получили. Ну да, Андрею мы когда-нибудь доберёмся, когда всё получится, этот спойлер. Ну, если в двух словах, мне просто очень интересно, как автору подобной системы, именно в своё время для этого был использован Kubernetes, как система, которая у всех на маке запускается, и все локально могут подобные тесты гонять при необходимости. Python, ну и тесты там всякие с IP-tables, забыл, как училить, называются, которые позволяют пакеты дропать в Linux. У вас что для подобных задач используется? Фактически базовая инфраструктура, да, это питоны, программные питоны, в общем, всё, что говоришь, те же самые базовые сценарии используются, я не думаю, что здесь что-то есть суперспециальное, но важно побольше нагружать и почаще ронять, и правильно структурировать код, чтобы писать правильные юнит-тесты, это очень хороший историк показывает. Ну, ты говоришь правильно, что такое правильно? Помоги нашим слушателям, и нам тоже встать на правильный путь. Правильно структурировать код? Или что-то другое правильно? Ну, чтобы тесты хорошо писать, да, вот ты говоришь правильно, что значит правильно? Да, это хорошо структурировать код таким образом, чтобы можно было писать тесты на модуле. Это звучит очень просто, но на самом деле... Честно, звучит максимально непонятно, все под этим разные вещи понимают. На самом деле, вот лично мне гораздо больше нравится сценарий, когда на какой-то модуль можно написать тест с хорошим покрытием, который работает локально. То есть вот можно отправлять сообщения, можно ловить всякие хитрые штуки, можно форматировать диск, на котором мы работаем. Ну, как бы форматировать диск? Понятно, что мы его по-настоящему не форматируем, мы теряем данные, и делать это локально. Так, чтобы этот тест работал за удовлетворимое время. Ну, то есть желательно секунды. Когда мы пытаемся такой тест написать, обычно его писать достаточно сложно. В том смысле, что мы понимаем, что у нас зависимость от таких-то, таких-то, сетих-то компонентов. Для того, чтобы сделать простое действие, например, убить диск, надо сначала написать много кода, который там всю систему покинет. Вот это вот сценарий как бы не очень правильный. Если мы для написания теста тратим так много усилий, то это как бы не здорово. Правильно структурировать это таким образом, чтобы на тест, который, не знаю, занимается каким-то компонентом, например, есть синхронизация лока, компонент, который занимается синхронизацией. Если для того, чтобы написать тест на синхронизацию, достаточно поднять только компонент, который занимается синхронизацией, то это правильная система. А если нам нужно поднять всю-всю-всю систему и кучу всего ненужного, то это неправильно. То есть если мы можем так структурировать и разделить на модули, то мы, собственно, должны так делать. Иногда кажется, что это слишком сложно, но тут надо себя заставить подумать, и потом оказывается, что не так уж сложно. Еще такой вопрос. Вы как-то рандомизируете эти тесты, или там всегда один и тот же сценарий бегает? Есть, конечно, тесты, где какие-то разумные рандомные сценарии происходят. То есть там рандомные записи и т.д. и т.п. У меня есть такая горячо любимая у меня штука property-based-тесты. Я когда писал в последний раз что-то распределенное, то есть много и часто мне приходилось писать тесты, которые описывают свойства, которые должны выдерживаться, и после этого система генерирует всякие разные входные данные, которые удовлетворяют некоторому precondition, и смотрят, что postcondition не ломается. То есть вы что-нибудь такое используете или нет? Наверное, что-то такого совсем сложного нет. Мы все-таки предпочитаем тесты с такой стресс-нагрузкой, при этом смотрим на какие-то странные артефакты, которые можно найти, и это такой самый базовый и хороший тест. Но если мы поднимаемся на уровень, например, выше, то есть на уровне таблеток были интересные нюансы и проблемы, там мы, конечно, смотрим на целостность данных, на определенный postcondition. Окей, ладно, давай тогда пойдем уровнем выше, мы обсудили blob-стораж. Есть вопросов, я хотел бы задать вопрос гостям. Не мог бы ты вкратце рассказать, вы пишете распределенную систему, как вы ее отлаживаете, когда видите, например, на тех же, как ты их назвал, манхетестах, вы видите, что какой-то инвариант не держится. Вы это смотрите по логам или как вы это отлаживаете? Наверное, несколько сценариев, особенно когда мы видим что-нибудь сложное, даже на продакшене, где информации часто крайне недостаточно, мы активно пользуемся мониторингом. Это такой достаточно классический time-series мониторинг, то есть мы смотрим графики и ищем какие-то аномалии. Это, наверное, не тот кейс, когда все сломалось, это скорее когда с тем работает, но немножко неожиданно. Мы ожидаем, что она могла бы себя вести получше. В случае с мониторингом, наверное, мониторинг есть у всех, у всех сложных систем есть тот или иной мониторинг, и люди на него смотрят. У нас же достаточно много датчиков, которые мы собираем, и, соответственно, достаточно много графиков. С одной стороны, это, наверное, даже не очень удобно в том смысле, что графиков слишком много, и, скажем так, человеку, внешнему наблюдателю, часто достаточно сложно в этих графиках разобраться. Но, с другой стороны, мы можем достаточно гранулированно опускаться до поведения какого-то компонента и искать аномалии. Дальше мы генерируем гипотезы, и, соответственно, гипотезы уже можно проверять, и они такие более-менее конкретные. Я думаю, для контекста, не могу бы ты коротко охарактеризовать YDB в том смысле, что мое понимание, что эта система не является византийской, то есть там ноды с друг другом не на ножах. Есть ли у вас консенсус, есть ли дату, на чем он построен, и, ну вот, так вкратце, поверхностно, что он собой представляет? Да, все правильно. Все правильно. Византийские отказы мы не рассматриваем. Ну, хотя, конечно, мы не рассматриваем византийские отказы, но чексумы мы считаем, потому что для системы хранения это обязательно чексумы нужно посчитать. Понятно, пришел бит и пакет. Да, и в сети то же самое, там чексумы достаточно. Такой момент, типа битрот на диске, вот это все тоже чексумами покрывается? Да, покрывается. На самом деле, понятно, что такие штуки нужны, потому что на больших масштабах какая-нибудь ерунда случится. В сети мы точно ерунду видели. Давайте, прежде чем к консенсусу перейдем, я, наверное, еще одну важную вещь скажу про Blob Storage. Чуть опущусь на уровень ниже, еще ниже, чем Blob Storage работы с диском. Мы, на самом деле, пошли по тому пути, когда мы работаем напрямую с блочным устройством. Что же ты сразу об этом не сказал? Это такой очень хороший способ утереть нос всем open-source решениям. То есть, ни RocksDB, ни Badger, ни кто-то еще из известных open-source решений напрямую в диск не ходят. Да, это достаточно интересно и позволяет нам всякие интересные штуки делать. Например, когда мы напрямую работаем с диском, мы еще часто почти всегда в production окружении не делим этот диск с кем-то другим. Например, с операционной системой. Система у нас стоит на отдельном диске, данные лежат на отдельном диске. И, соответственно, мы можем и не только можем, но и, собственно, это делаем, планируем операции на диск. То есть, в реальной системе там все как всегда. Есть какой-нибудь асинхронный production, есть такие приоритетные чтения записи и вот, собственно, User Space Планировщик позволяет нам тут достаточно хорошо себя вести. Это с одной стороны. А с другой стороны, мы позволяем в режиме использования системы как multi-tenant системы, мы позволяем потенциально разным пользователям использовать один и тот же девайс. И, соответственно, мы, опять-таки, планируем операции доступа к диску для того, чтобы обеспечивать честность в разделении твудевайса. Но с другой стороны, вам пришлось перезабричь весь IOS-скедулер, всю эту историю кэширования и так далее? В каком-то смысле да. Но на самом деле там есть, наверное, две вещи. Во-первых, это ужасно интересно. Даже если приходится переизобретать. Во-вторых, конечно, потом мы его хорошо настраиваем, тюним и т.д. Потому что, если мы говорим про скедулер операционной системы, то, конечно, как-то часто бывает, скедулер операционной системы понятия не имеет про семантику операции, которую мы на диск отправляем. А вот мы-то знаем. Там, если тему развивать, в кругу дейтабейс-инженеров или дейтабейс-ученых очень популярна тема, особенно тех, которые поближе к железу, что для баз данных нужна операционная система попроще, а не посложнее. Потому что база данных сама многие вещи знает, как надо делать. И важно, чтобы операционная система не то чтобы очень помогала, а скорее не мешала правильно все планировать. Чтобы закрыть предыдущую тему, почему спрашивал про отладку и был удивлен ответом про метрики и всякое такое, потому что у нас на проекте система византийская и часто возникают проблемы типа ой, консенсус развалился BFT. И там метрики не очень помогают, и поэтому у меня первая реакция была, что я был сильно удивлен такому ответу, а потом я понял, что слишком у меня баист мышления уже. Ну, то есть у вас там несколько проще, наверное, отложить систему, поскольку она не пытается решать те проблемы, которыми мы занимаемся. В каком-то смысле, да. Причем если мы берем какие-то совсем сложные протоколы, например, протоколы консенсуса или может быть протоколы синхронизации репликации данных, то там, конечно, сенсоры, мониторинги и так далее, они нужны для того, чтобы посмотреть картинку в целом, что происходит, для того, чтобы какие-то интересные аномалии найти, скорее, что система ведет себя, например, не совсем так, как задумал ее автор. А вот с точки зрения корректности алгоритмов, конечно, лучше этот алгоритм внимательно посмотреть, всякие кейсы проанализировать, коллегам рассказать, показать, чтобы собрать комментарии. И в разные места, которые, казалось бы, вообще не должны случаться, поставить ассерты, чтобы потом при нагрузке, в том числе при хитрой и разной нагрузке, словить эти ассерты, если что-то такое непродуманное, на самом деле посажена ошибка, потом понять и исправить. То есть мы в этом смысле достаточно критически относимся, что лучше мы о проблеме узнаем путем условного падения процесса, и мы именно с этим состоянием разберемся, чем достаточно тихо что-то игнорировать и двигаться дальше. А к вопросу о корректности, не смотрели в сторону ТЛА+, вот вся эта история? Чуть-чуть смотрели, но на самом деле не верифицировали. То есть это такая у нас идея и фикс есть, подобные задачи себе поставить и их порешать. Но обычно такие разговоры ведутся, когда мы с реальными сложностями сталкиваемся, а вот когда какие-то базовые протоколы отлажены и скорее работают, все подобные вопросы на второй план уходят, а на первый план приходят фичи. Скорее так. На самом деле настала пора на секунду закончить с блок-сториджем и подняться на уровень выше, что у вас поверх блок-сториджа процессус начинается или что-то еще, может быть, есть посередине? Посередине есть интерконект. С одной стороны интересная штука, с другой стороны достаточно понятная. Интерконект это фактически наш сетевой протокол между разными элементами системы. Написано, что он поверх ступени. То есть это какой-то RPC, типа gRPC или это что-то более специфичное? Это RPC. Чуть более, наверное, специфичное, потому что у нас там есть поддержка опять-таки quality of service. То есть мы, вообще говоря, не можем, а отличаем один класс трафика от другого, правильно его приоритизируем. Это как бы необходимо, потому что вот как я чуть дальше расскажу, сеть мы умеем съедать так очень неплохо и поэтому если не обращать внимания, например, на bandwidth сети, ну, она потом, система может в какой-то момент очень неудачно заткнуться. Поэтому, конечно, нам приходится думать о том, что трафик нужно приоритизировать. Подожди, хочется сказать, что вы внутри одной диспетрубы что-то приоритизируете. Да, конечно. То есть у вас такая ситуация, что у вас маленькие сообщения и куча, и просто их очень много, поэтому это работает, потому что мне кажется, если там будут большие сообщения, то просто перестанет работать. Все так. Ну, то есть на самом деле сообщения у нас, конечно же, бывают достаточно большими на логическом уровне, но если они большие, они разбиваются на транспортном уровне на много маленьких. Понятно для того, чтобы в какой-то момент уместить приоритетный пакет. То есть, по сути, вы внутри TCP делаете еще свой фрейминг и вы любые большие сообщения разбиваете на маленькие фреймы, так? Да, все так. А тогда почему было не взять, собственно, gRPC? Опять-таки, когда мы это все писали, gRPC не был настолько популярен, насколько сейчас. А вот gRPC у нас как раз тот протокол, который используется на верхнем уровне, то есть мы на оружию для клиентов торчим gRPC. И если честно, мы, конечно, там уже находим хенное количество не самых приятных вещей, ну, начиная от багов и заканчивая просто как бы странностями. То есть, на самом деле, для интероперабельности gRPC, несомненно, очень хороший, классный из любых языков программирования к нему можно обращаться в пузырьксервисах, которые поддерживают gRPC. А вот с точки зрения, например, качества кода открытой реализации gRPC для языка C++ мы там сильно не в восторге, если честно, просто сильно. Окей. Такой момент еще. Ты говоришь, что у вас между между Blob Storage и Consensus Interconnect означает ли это, что у вас Blob Storage работает как отдельный демон от Consensus, или они все-таки в одном процессе в OS крутятся? Мы и так, и так делали. То есть, в какой-то момент на самом деле был один процесс, но теперь это разные процессы. На самом деле, очень хороший вопрос. Он в нашем случае демонстрирует очень понятную вещь. У нас Blob Storage то есть уровень стоража, он фактически всегда доступен по сети. То есть, сейчас сформулирую. Ваш Blob Storage это просто такой, ну условный RocksDB, который не RocksDB, но условный RocksDB, который просто торчит в сеть своей API, и потом к нему кто-то приходит его дергает, и по сути, Consensus может крутиться где-то вообще отдельно. Да, очень похоже. Но тут RocksDB он не распределенный, он же, насколько я по крайней мере знаю, это локальная инсталляция. Я пытаюсь выяснить как раз таки, вот у вас ваш Blob Storage, отдельный инстанс Blob Storage, просто каждый отдельный, там не знаю, на машине, скажем, у меня есть, не знаю, ноутбук дома один, и там, не знаю, компьютер, который у меня к телевизору подключен, скажем, на каждый из них я поставлю по Blob Storage, каждый из них будет торчать в сеть какой-то API еще без всякого Consensus, так? Да, все так, только протокол там приватный, который именно рассчитан на то, что в него будет ходить доверенная сущность. Ну да, окей. Такой момент, если у вас так много демонов, они крутятся на разных машинах, плюс под это нужно специальная разметка диска явно, а как, черт возьми, вы это оркестрируете? То есть даже до того, как вы пытались запустить Consensus, вам нужно накатить как минимум два типа демонов на какой-то флот машин, и потом, когда у вас, скажем, вылетает Blob Storage, потому что это отдельная сетевая хрень, вам нужно ее поднять обратно, а потом Consensus должен знать, что там у него хрень отвалилась. Так, ну здесь вот прям сразу много вопросов. Как мы это все оркестрируем? Как-то оркестрируем, то есть на самом деле система вполне себе на уровне эксплуатации, на уровне, не знаю, развернуть программу и запустить ее, она такая гомогенная, то есть, грубо говоря, действительно, я сейчас прощаю, но тем не менее, можно считать, что у нас есть один слой демонов, и это Blob Storage, и второй слой демонов, это условно, это Compute слой, где живет Consensus и все, что там выше вплоть до SQL. А, соответственно, как мы это оркестрируем? На самом деле, на самом деле, я бы не сказал, что здесь есть какие-то очень специфические вещи, оркестрировать можно совершенно по-разному, то есть можно и кубернетерсом, хотя мы делаем не так, можно и, не знаю, какими-нибудь более традиционными системами, типа Salt, Puppet, Chef и т.д. и т.п. И, в общем, раскатать подобные бинарники не проблема. Наверное, есть некоторые проблемы это все конфигурировать, и это некоторые отдельные слои, вот где-то у нас в стороне от деплоя. Фактически, да, у нас, конечно, есть средства для того, чтобы пойти в систему и ее поконфигурировать. Наверное, если мы затрагиваем именно деплой, то есть один важный момент, который прям очень важный. Это так называемое оркестрирование апдейта. Откуда все ноги растут, да? Грубо говоря, в ADB это та система, которая должна работать нон-стоп, постоянно обеспечивать большое количество девяток. И это означает, что такой планируемый апдейт системы это на самом деле штука не самая простая, мы не можем себе позволить погасить кластер и поднять кластер. Поэтому у нас есть оркестрирование так называемого rolling update. Это когда мы понимаем, какой процесс можно запустить и, грубо говоря, с какой скоростью мы все эти процессы на кластере перезапускаем. Для того, чтобы это сделать, у нас есть система, которая называется CMS. Я бы даже сказал, что это на самом деле это таблетка, которая живет в самой системе в ADB. И, соответственно, внешние системы оркестрации ходят в эту CMS и получают некоторое право перезапустить или апдейтить некоторый процесс. То есть, фактически система в ADB я бы не сказал, что она сама себя оркестрирует, но она дает разрешение на определенные действия какой-то внешней программы, которая является программой оркестрации. Интересно. Так, ну давай, наверное, поскольку я, наверное, с опережением спросил этот вопрос, потому что мы еще на неделе не разобрались, как у вас работает консенсус. То есть, чем у вас является ваш алгоритм? Ближе к Fax, Raft или ближе он к чему-нибудь вроде больше как он назывался, является ли скажем, держите ли вы по отдельному какому-то, не знаю, представителю для каждого Blob Storage или у вас, опять же, в том же Corp у них такой, не знаю, как бы со стороны сетевого клиента происходит как-то, я не могу назвать это совсем уж консенсусом, но там смысл в том, что в Corp по сути та штука, которая координирует, она в первую штуку сходила, ответ получила, во вторую штуку сходила, ответ получила, и несмотря на то, что на самих тупых дисках в Corp никакого консенсуса не происходит, однако в целом система как-то консенсус достигает. Или, может быть, вы просто держите на каждую таблетку по, скажем, Fax-акцептору, который общается с таблеткой и потом отвечает всем остальным. То есть, наверное, по порядку какой у вас алгоритм и потом как-то сживется тем, что у вас таблетки Blob Storage сетевые. Так, хорошо, давай расскажу по поводу непосредственно консенсуса. Как у нас все работает? У нас есть вот это понятие таблетки, есть кандидат в то, чтобы стать мастером таблетки. Подожди, подожди, подожди, никаких таблеток еще нет, есть только отдельные Blob Storage. Ага, хорошо. Давай тогда по сути смысл таблетки в том, чтобы обеспечивать распределенный консенсус. То есть, вот эта вот отказоустойчивая сущность, которая грубо говоря, наверх показывает интерфейс апдейта данных и эта сущность ведет себя как классическая паксис-группа. Если пришел какой-то апдейт, этот апдейт подтвержден, то есть получил успех, то все эти действия, которые составляют природу апдейта, они надежно зафиксированы в персистентной памяти и уже никуда не денутся. То есть, вот эта вот таблетка. Есть такое понятие, как, наверное, можно сказать, мастер таблетки. Собственно, мастер таблетки это и есть таблетка, когда нет никаких переходных процессов. Ничего не ломается, никаких перевыборов не происходит и так далее. То есть, вот он мастер. В отличие от паксиса, где, например, есть несколько активных сущностей, то есть, вот классический паксис, это три отдельно стоящие машины. Каждая машина со своим жестким диском, на этот жесткий диск процесс может писать какие-то записи, вести какой-то лог. В отличие от такой классической ситуации с паксисом, у нас сущность мастера, это одна сущность, то есть, это инстанция некоторого класса, который запущен на какой-то машине, не суть важна на какой, но на какой-то он запущен. Если он там умрет, то он перезапустится на какой-нибудь другой машине. Может быть, даже на этой, если машина ушла, сломалась, потерялась и так далее, то он перезапустится на какой-нибудь другой машине. Собственно, когда происходит некоторая запись, приходит некоторый апдейт в этот мастер, то мастер отправляет запрос на Blob Storage и, собственно, на Blob Storage он получает этот кворум. То есть, апдейт успешен тогда, когда с точки зрения всех протоколов и процессов мы записали, например, необходимое количество реплик на определенные правильные элементы Blob Storage. Вот когда это случилось, тогда мы подтверждаем успех пользователя. То есть, на самом деле, я так понимаю, я не знаю, читал ты или нет Corfu, но очень похоже на то, что Corfu описывается в пейпере. В пейпере Corfu. То есть, у вас, наверняка, другая раскладка данных, но именно этот подход с тем, что у вас, на самом деле, координирующий запись процесс, он один голосует по сути реплики. Да, это на самом деле в свое время такая статья даже была что-то вроде replicate state machine over shared log. То есть, идея та же самая. То есть, мы реализуем одну сущность, который функционирует за счет кворума на репликах, которые в этом смысле достаточно неумные. То есть, они просто получают локальный какой-то update или производят его или не производят. Обычно запись даже не апдейт, а контрольной запись. Слушай, а как тогда вы производите... То есть, тут сразу возникает вопрос, где мастер хранит свой стейт и кто его перезапускает? Даже уже два вопроса и третий вопрос тогда. А как происходит перевыбор отдельных реплик, которые являются же заодно blob storage, но я так понимаю, что blob storage штука довольно тупая, а ее кто-то как-то должен переналить, если это новый. Да, понятно. Здесь такая классическая проблема курицы и яйца. Давай я, наверное, расскажу теперь про так называемую группу blob storage. То есть, blob storage это мы рассмотрели, что это за сущность, но он в свою очередь делится на какие-то группы. Есть такое понятие как группа blob storage. Можно считать, что группа blob storage это как раз отказоустойчивый массив дисков. То есть, ну, грубо говоря не самый большой. Можно представить себе кластер из каких-нибудь тысяч машин. Понятно, что групп там тоже будет достаточно много, потому что диски нарезаются например по 8 штук. Одна blob storage группа это 8 дисков. Причем, если погружаться, это на самом деле не совсем честные диски, это кусочки этих дисков объединенные в blob storage группу. Эти диски, понятно, обязательно на разных машинах. По поводу перевыбора мастера и т.д. и т.п. Я начну сейчас немножко не сначала, а вот с середины, но зато будет очень красиво. Подавляющее количество таблеток в системе поднимается специальной таблеткой, которая называется Hive. Грубо говоря, это такой наблюдатель за таблетками, который держит с ними связь. Если он считает, что какая-то таблетка умерла, пропала, потому что больше не пингуется, ушла машина и т.д. и т.п. Он, собственно, инициирует перевыборы. Когда он инициирует перевыборы, то он, собственно, запускает где-то в каком-то другом месте, в котором считает правильным так называемого кандидата в мастера, и тот, соответственно, проходит протокол становления мастером через blob storage. Он должен набрать кворум, блокировок, то есть реплики должны согласиться, что этот новый мастер имеет право быть мастером. У него есть понятие generation, как очень часто бывает в распределенных системах. Очередная инкарнация таблетки инкрементирует этот generation и, соответственно, новый мастер должен подтвердить на репликах, что все нормально, они готовы работать с его generation. Все как всегда, если в этот момент что-то мигает и старый мастер еще жив, за счет такого протокола старый мастер заблокируется от записи на blob storage и умрет через какое-то время достаточно быстро. Мне кажется, ты ответил почти на все, кроме того, что скажем, у нас умер и мастер, и одна из таблеток, допустим, с мастером будет понятно, но кто теперь налит таблетку и сколько наповрений будет наливаться, если старая снова обратно появится, то есть в обычных паксах, рафтах для этого есть какой-то",
    "result": {
      "query": "YDB консенсус и blob storage"
    }
  }
]
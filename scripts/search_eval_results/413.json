[
  {
    "segment_id": "4e91b377-4912-4ef8-a569-582a5f67bc67",
    "episode_id": "51b38cfd-a5c2-4518-81f8-d5ba884b9c92",
    "episode_number": 413,
    "segment_number": 3,
    "text": "Скорость компрессии, конечно, в 10 раз медленнее везде, но все еще очень впечатляюще. И в целом, Zit Standard, насколько я помню, его сравнение со всеми другими, могу наврать, он как раз отличается тем, что у него очень хороший современный, скажем, для современных систем очень хороший трейдов между уровнем компрессии и скоростью компрессии и декомпрессии. То есть, например, какой-нибудь 7-Zip или Gzip, они, сколько я помню, они могут более компактно сжать, но они медленнее. Вот, как-то так, если я ничего не путаю. Да, Zit Standard, он тоже хорошо жмет, может быть, не так идеально, как некоторые другие алгоритмы. Он достаточно быстрый, как видите, там, типа, на декомпрессию там вообще гигабит может выдавать, главное железо, как это подносило бы в байтике, и хорошо масштабируется и работает как на ваших big data pipeline, так и в мобильных устройствах. Не могу сказать, что прям сильно в теме ZSTD и LZ4, в частности. Почему в частности? Потому что у меня вечер. Но это похожие алгоритмы в плане идей, что давайте архивировать, может быть, не так идеально, как 7-Zip, но зато очень-очень быстро. И в Postgres используется для разных задач. Я тоже знаю, что он линкуется с LZ4. Насчет ZSTD я не помню, поддерживается он для сжатия вала или не поддерживается, потому что, как мы выяснили, вал иногда пишутся в большей записи, типа полных копий страниц. И, ну, это достаточно тупо, просто копировать страницу, неплохо бы ее пожать. И вот я не помню, для вала поддерживается ZSTD или нет. Плюс еще есть история про архивирование, и там тоже есть алгоритмы, которые поддерживаются или не поддерживаются для бэкапов. Postgres умеет сжимать бэкапы, насколько я помню сам. Но есть прикольная штука, которую я недавно узнал про LZ4 и ZSTD. Оказывается, у них, даже если вы возьмете консольные утилиты, у них есть флажочек, который говорит, сохранить... То есть, поскольку это словарные методы сжатия, фактически, как они работают, они идут под вашим данным, находят куски данных, которые повторяются, помещают их в отдельной, назовем это абстрактной структуре словарь, и когда ты снова встречаешь ту же последовательность byte, ты можешь не копировать их, а заменить на код из словаря. Размер словаря и всякое такое, это параметры алгоритма, но, что интересно, в ZSTD и в LZ4 у тебя есть ручка, которая позволяет тебе этот словарь сохранить на диск, отдельном файлу. И это открывает богатые возможности, потому что ты можешь на своих типичных данных натренировать словарь, сохранить его, а потом сжимать много похожих данных, используя вот этот натренированный словарь. Этим ты, во-первых, обеспечиваешь лучшее сжатие. Классический пример и контекст, в котором эта идея возникла, это словарное сжатие для Postgres, что-то, что сейчас в сообществе обсуждается, потому что, если мы возьмем JSON и JSONB для примера, а также текст, XML и другие форматы, не суть важна, сейчас Postgres, вот если у тебя есть атрибут, в атрибуте у тебя хранится какое-то большое значение. Для примера пусть будет JSONB, но это не суть важна. Как Postgres его пытается хранить? Он его сжимает, нарезает начанки, складывает в Toast таблицу и заменяет так называемым ToastPointer. Когда он встречает второй JSONB документ, он его также отдельно сжимает, нарезает начанки, кладет в Toast таблицу, заменяет ToastPointer. А несложно догадаться, что если у тебя большая таблица, в ней много JSON, то эти JSON между собой, скорее всего, похожи. И ты мог бы тренировать словарик и сжимать эти документы, используя один общий словарь. И тогда каждый отдельный документ будет сжиматься сильно лучше, чем по отдельности. Это одна из людей, которая сейчас в сообществе обсуждается, и в целом она не вызывает резкого отторжения. Это что-то, что мы, скорее всего, рано или поздно увидим, но вопрос времени, когда именно, потому что достичь консенсуса, как конкретно это должно быть реализовано, он занимает время. Надеюсь, что-то исказанное было интересно и полезно. Краткое содержание, да, ZXCD и LZ4 находят применение в базах данных, это прямо тема. Тут слушали Антон Каяков и тот, кто принес тему Александр Шайпотко, извините, твою фамилию неправильно произношу. Кому говорят, что они тоже хвалят ZXCD, говорят, что используют в продакшене, что очень хороший диапазон сжатия, очень хороший диапазон кручения ручки сжатия в скорость. И Антон уточняет, что при ручке в позиции F11, если вы ее туда повернуть, то получается по скорости чуть быстрее, чем G-Zip, но при этом на десятки процентов лучше, как я понимаю, сжатия. Прекрасно же. По-моему, это чудесно. И это была последняя тема, поэтому мы заканчиваем с обычной частью и переходим к GameZen. Оп, притащил. Я тем временем еще поискал по Git-логу для Postgres. Тут Александр Шайпотко, я опять же извиняюсь здесь транслитом, спрашивать про ZXCD в Postgres, нет ли идеи занести. Вот я просто ищу слово ZXCD по истории Гитая, и тут вот сплошной ZXCD, ZXCD, ZXCD вот прям в хвост и в гриво. Вот я просто боюсь вам наврать про то, где конкретно она используется, а где еще не используется. А мы обсуждаем, да, мы переходим к рублике GameZen, точнее Retro GameZen. Если вам про игры не интересно, на этом моменте можно выключать, других тем у нас дальше не будет.",
    "result": {
      "query": "ZSTD vs LZ4 compression Postgres"
    }
  }
]
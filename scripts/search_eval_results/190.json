[
  {
    "segment_id": "051e93cc-6f27-406e-844a-c08ec9bffca7",
    "episode_id": "456fe141-b404-42f9-bd8f-efb9f767c349",
    "episode_number": 190,
    "segment_number": 3,
    "text": "И сейчас я как раз занимаюсь тем, что пытаюсь взять Jepson и попытаться заменить его чекер, который тестирует linearizability перебором, на вот такой вот с readmap и writemap и посмотреть, действительно ли для этого всё работает. То есть взять, допустим, сетап Jepson для MongoDB, не современный, а более старый, показать, что да, она сломана, затем заменить оригинальный чекер вот этим вот с readmap и writemap и показать опять, что она сломана. И тогда всё круто, у нас есть способ тестировать linearizability без экспонент. Ну, с небольшими оговорками, но всё равно. — Звучит довольно вкусно, надеюсь, это окажется в open source. — Да, это окажется в open source. Я это делаю в свободное время. — А, окей. А на работе ты о чём занимаешься? Ты же тем же сам занимаешься, нет? — Тем же самым. Ну, в смысле, на работе я допиливаю Jepson, чтобы его можно было применить к Cosmos DB. И, собственно, так как Jepson работает изначально на Linux, то есть там нужно создать агентов, которые работают на каждой отдельной ноде, и заставить Jepson коммуницировать не через SSH, а через, допустим, HTTP. — Понятно. А зачем тогда вообще Jepson? Прикинь, просто ли тогда вообще что-нибудь другое взять? — Ну, то есть разработать что-нибудь своё, что работает, или взять вот это вот Chaos от TIDB. Я думаю, что одна из основных идей, что после того, как это всё сделано и это всё работает, я смогу написать в какой-нибудь блог-пост и рассказать, смотрите, как замечательно, Cosmos DB протестировано Jepson. The toughest industry test. Вот. — Окей. Окей, вы только что услышали кровавую правду про Jepson, и что на самом деле Jepson ненадёжен, как и всё остальное, что мы обсуждаем в этом подкасте. — Jepson надёжен, Jepson медленен. — Окей, да, он очень надёжно не тормозит. На этом мы порешим. У кого-нибудь ещё есть вопросы по тестированию распределённых систем? Я уверен, что Света или Саша найдутся. — Я, честно говоря, жду, когда мы начнём говорить за TLA+. — Ага, он же в темах слушателей. — Ага, ну, значит, ждём-с. — Я, кстати, на днях был на семинаре про TLA+. — Расскажи, пожалуйста, как это было. — А, это... То есть внутри Microsoft проводятся семинары, где... То есть до этого проводились воркшопы, когда Лесли Лампорт учил тебя использовать TLA+, чтобы... — Он же... Извини, что я перебиваю, он сейчас в Microsoft, я правильно понимаю? — Да. — Ну, в Microsoft Research. — Да-да-да. — В котором Microsoft? — В Microsoft Research. Он в Microsoft Research и... Да, вроде даже не сейчас, а уже достаточно давно. То есть лет... Лет 18 точно, если я всё правильно понял. — Я не следил за его карьерой последние лет 18, поэтому... — Да. — Вот, да, в Microsoft Research. И до этого проходили воркшопы, когда учили людей писать TLA+, а тот семинар, на который я попал, там обсуждались результаты вот этого обучения. То есть выступали люди из всяких разных команд и говорили, что вот, мы применили TLA+, и сюрприз-сюрприз, он нашёл какие-то баги, о которых мы не подозревали. И, допустим, TLA++ используется внутри сервис-фабрик, внутри Microsoft. Сервис-фабрик — это что-то типа Zookeeper плюс оркестрация. TLA++, кстати, используется в Cosmos DB. Я своими глазами видел спецификацию на полторы тысячи строчек кода. Когда-нибудь, я надеюсь... Полторы тысячи на TLA+, или там плюс код используется. — На TLA+. — Вот, то есть на МакДоналд. — Это считается очень много, что ли? — Ну ты же... — Ну для серьёзной системы. — Ты видел глазами TLA+. — Ну он нормальный, он вполне себе модульный. Ну в смысле, как модульный? — Да, да, да. — Просто определение равно её. — Я бы сказал так, там количество смысла на строчку очень большое. — Ну и система, видимо, не маленькая. — Ну да, да, это правда. — Ну всё равно. Короче, мне кажется, что это что-то такое, что очень тяжело в голову поместить, наверное. Но это несколько экранов, нормально. — В общем, я надеюсь, я когда-нибудь это смогу поместить в свою голову и разобраться. — Подожди, а это с комментариями или с сырового кода? — Я уже не помню этих деталей. — Это, кстати, хороший вопрос, потому что там может быть больше комментариев, чем кода. — А нет, комментарии есть, но они отдельно в отдельном документе. То есть там просто описывается, что происходит, почему. И вместе с комментариями эти полторы тысячи были бы, не знаю, больше десяти тысяч, наверное. Вот, но TLA+, насколько я понимаю, он очень полезен, потому что прежде чем что-то строить, он тебе позволяет проверить, а вообще то, что ты строишь, имеет какой-нибудь смысл или нет. То есть, я не знаю, давайте мы будем читать со всех машинок, потом выбирать какое-нибудь случайное значение, потом писать его на все и отдавать пользователю. Вроде никаких аномалий не должно быть, давайте как бы вперед и в продакшн. А потом оказывается, что так всё не работает и система на самом деле сломана. А TLA+, тебе позволяет вначале выразить то, что ты хочешь сделать в виде этого кода, а затем этот код, я не знаю, всем тупой перебор или нетупой перебор, просто идёт и перебирает все возможные состояния и выполняет те варианты, которые ты указал с помощью TLA+, или нет. Смотри, я как раз посмотрел видео, которое нам принесли в тему слушателей. Давайте уже обсудим эту тему, разначили. Да, да, кассу завожу. И насколько я понимаю, там тупой перебор со звёздочкой, то есть, например, там есть возможность сказать, что твоё множество, ну, у тебя есть какое-то множество элементов, ты можешь пометить его как симметричное множество, ну, например, у тебя есть три ноды, типа нода 1, нода 2, нода 3. И тебе, в принципе, всё равно в каком они порядке, они однозначны. Поэтому если ты проверил подмножество состояний, где там одна нода имеет состояние А, вторая нода имеет состояние Б, то если ты их поменяешь местами, у тебя будет у ноды один состояние Б, а у ноды второе состояние А, то это, в принципе, то же самое состояние, оно тебе погода не делает. И он умеет отсекать ветви на своём графе поиска, когда ты соответствующим образом пометил элементы, что они симметричны. Но из-за этого можно наплодить, кстати, лишних багов, если ты неправильно пометил. И ещё вот про TLA++ позволяет находить, я же правильно понимаю, что тут есть две очень важные оговорки, что, во-первых, твоя модель должна быть верна в том смысле, что если ты в модель не заложил возможность падения узлов, то ты как бы на это не проверяешь. Ты можешь заложить потерю сообщений, и я так понимаю, что в случае TLA+, проще заложить, чем не заложить, но я там денежную цитату ищу. Денис? Насколько я... извините, я отвлёкся, но насколько я помню, на одной из презентаций говорили, что вот эта вот симметричная... вот этот симметрик, который Александр говорил, это трейд-офф между сториджем и CPU. Ну вот на видеолекции, которые я посмотрел, там прям наглядно показывается, что ты сначала не помечаешь своё множество симметричным, и у тебя там обходится, ну типа перебираются условные 200 состояний. Потом ты помечаешь, и у тебя в отчёте показано, что уже перебралось 80 состояний. То есть как бы у тебя прям... это очень наглядно показано. Но, впрочем, одно другого не исключает. То есть то, что ты сказал, возможно, тоже верно. Да, но я не отвечаю за свои слова, это я где-то слышал, это существует на краю моего сознания, поэтому, возможно, это неправда. Но с TLA+, это действительно так, что то, что ты... То есть он может проверить только то, что ты там написал. То есть это как любой тест, по сути. Ну вот, собственно, два момента, которые важно помнить, что первое, твоя модель должна проверять то, что ты хочешь, в частности, там падение узлов на сплиты и так далее. А второе, что TLA+, не умеет генерить код из твоей спецификации, поэтому ещё... ну то есть он тебе может сказать, что твой алгоритм, он правильный, он вот если как на бумажке, там алгоритм, он правильно работает, но правильно запрограммировать этот алгоритм, это ещё тоже большая проблема. Я хочу такую примарку ввести, что в TLA+, я ни разу не видел, что там прямо вносили падение ноты или что-то такое. На самом деле, что это всё-таки очень абстрактная штука, и там обычно речь идёт, типа, вот есть такое множество сообщений, если такое подмножество сообщений попало в такую-то стоит машину, то, типа, она придёт в такое состояние. И потом в итоге все стоит машины в таком-то множестве стоит машин и мы пришли в такое-то правильное состояние. Там в таких терминах, на самом деле, то есть... Ну, всё правильно. Нет, я думаю, что именно если речь про распределённость системы, не имеет смысла отдельно программировать падение узлов, потому что это равносильно потере всех сообщений к этому узлу в течение какого-то времени, ну, более-менее. Ну, то, о чём я пытаюсь сказать, что вообще, на самом деле, там никто не пишет в терминах узлов, там, скорее, именно в таких супер высокоуровневых терминах, то есть если ты моделируешь там репликацию стоит машин, ты будешь моделировать репликацию стоит машин, ты не будешь вообще ничего говорить о том, где это исполняется и как. Насколько я понимаю, допустим, в некоторых этих TLA+, спецификациях, сеть может смоделироваться через множество. То есть когда какой-то клиент хочет отправить сообщение, он просто берёт и кладёт в это множество. А также в TLA+, там есть не детерминистские операции, то есть взять элемент для любого элемента из множества. Вот как бы, когда я кладу что-то в множество, а потом говорю, что взять любой элемент из множества, это как раз абстракция сети. То есть я не указываю никак порядок, и сообщения могут сколько угодно долго находиться в этом множестве. То есть если хочется сделать потери, то, наверное, там надо сделать отдельную инструкцию в спецификации взять случайное сообщение из этого множества и забыть о нём. В этом видео, которое в тему слушателей принесли, там ещё очень наглядно показано преобразование, ну в другую сторону, правда, из кода в спецификацию. И на удивление, ну то есть это не так тривиально, но как бы есть, прослеживается связь, и этот поток сознания мой идёт к тому, что на правильный язык достаточно легко переписать аккуратно написанную спецификацию. Например, если речь про распределённые системы, то на Erlang он будет выглядеть примерно так, что ты вот смотришь на свою доказанную спецификацию и переписываешь это на Erlang. Ну не один в один, конечно, но со звёздочкой. Мне кажется, на Haskell можно там заимплеменить себе там вот язык в специальной монатке, монатк-телой, и потом из неё себе сделать... Функциональные языки тут очень сильно выигрывают именно в связи спецификации с кодом. А вот мне ещё интересно мнение Дениса как эксперта. Есть ли вообще в природе аналоги TLA+, которые ещё и генерят код, прям из спецификации? Да, такие существуют. По-моему, он называется Ironclad. Ironclad, да, по-моему, даже как раз его упоминали. Ironclad. А почему он генерит на C-шарпе небось? Не то чтобы это было очень принципиально, но любопытно. Я не помню. По-моему, там какой-то дотнетотский язык, но я не уверен. Я давно про него читал. Я на самом деле не знаю, насколько рационально генерировать код по спецификации. Конечно, с точки зрения корректности это очень здорово, но у разных языков у них разные характеристики. Например, у тебя может быть система, которая по спецификации генерирует код на Java, но если ты работаешь над чем-то высокопроизводительным, то есть тебе нужны какие-нибудь более нейтив языки, типа плюсов, а здесь получается конфликт, что у тебя с одной стороны все работает, но там garbage collector, ты не можешь это использовать в продакшене, чисто потому что это невыгодно, либо ты пишешь руками, возможно, совершаешь ошибки. Короче, вот. Я посмотрел на это. Мы это обсуждали аж в бородатом 64-м выпуске подкаста. 64-м! То есть это фактически было 126 выпусков назад. Это было далеко на 2015 году. И Валера это помнит. Нет, я погуглил. Нет, я имел в виду, ты вообще помнишь, что мы это обсуждали. Я не помню, что мы обсуждали в 2015 году. Вот. Ну, потому что я эту тему принес, потому что я помню, наверное. Там действительно, ну, там не совсем C-sharp, есть такой язык для .NET, называется Daphne. Это, не знаю, с чем сравнить? Я бы сказал, что это такой язык с контрактами поверх .NET, и вот в этот Daphne заимбедили что-то такое TLA-подобное, и, в общем, там было типа 3 уровня, если я правильно помню, написания спецификаций, которые там поочередно всякое проверяли, и в итоге даже получался исполняемый код, который, соответственно, этим всем был проверен. Ну и, в принципе, поскольку это .NET, да, там есть garbage collector, но, в принципе, я так понимаю, с некоторой ahead-of-time компиляцией и с некоторым еще, возможно, каким-нибудь, не знаю, то есть выведением к каким-то регионам или чего-нибудь еще, я не знаю, я, возможно, полную чушь несу, но мне кажется, можно, в общем, код на C-sharp и автоматически перевести в более быстро работающий код на, скажем, не знаю, условном LLVM-ассемблере каком-нибудь, там типа с минимальной необходимостью запускать реальный garbage collector. Что я имею сказать про видеокурс, то что он вообще-то клевый, и я всегда воспринимал TLA, что это что-то такое супер задротское, супер сложное, оказалось нет, то есть реально там в, ну не скажу за вечер, но скажем за выходные можно посмотреть, если не весь этот курс, то, скажем, первую его половину, и там действительно нет ничего прям такого мозговыносящего, ты такой смотришь, о, клево, а давайте поищем задачки, которые можно с его помощью верифицировать. У меня 2 ремарки по этому поводу. Во-первых, ты функциональщик уже, ты по кусам, ты причастился, и тебе это не настолько для тебя шокирует, как некоторых, там не знаю, людей, которые тут на СИ писали. Во-вторых, язык простой, это не значит, что на нем легко писать. То есть там регулярно господин Лемпорт делает такой, ага, а вот здесь вы, скорее всего, сейчас подумали, что нужно было написать вот так, но на самом деле нет, нужно было написать вот так, потому что нужно еще сказать TLA, что не должно происходить такого рода вещи, и если вы не привыкли, там, не знаю, писать property-based tests с precondition и postcondition, или там еще с контрактами программировать, и вы вообще этого не видели и не привыкли, это может шокировать, быть непривычным, и даже если вы это делали, это не факт, что вы каждый раз интуитивно будете про это вспоминать. И вот тут как раз получается так, что язык простой, но научиться писать спецификации на полторы тысячи строк, это, наверное, такой скилл, который качается годами. И еще у него есть такая особенность, что в плане области применения, то есть мое понимание такое, что он специально создавался для распределенных систем, и он, соответственно, неплохо на них ложится. Наверное, можно его применить к, в принципе, он хорошо ложится на все, даже если нет распределенности на протоколы, связанные с какой-то concurrency, с чем-то таким, то есть если нужно верифицировать виртуальную машину или процессор, у которого больше одного ядра, то это, в принципе, уже как распределенная система. Но не очень понятно, что, опять же, в примере с виртуальной машиной или процессором, у него некое состояние, есть на вход последовательность команд каких-то, и теоретически последовательность команд и их комбинации и перестановки, бесконечная последовательность, как TLA может перебрать их? Ну, получается, что не очень может. Как это вообще должно работать в теории? TLA+, иногда он может перебрать все состояния, но обычно всякие системы, такие, как Cosmos DB, в Amazon использовали TLA для верификации ластик блок сториджа, они просто пишут спецификацию, и она работает, допустим, месяц, без прекращения пытается перебрать все варианты. И потом через месяц кто-нибудь говорит, отлично, эта система работала достаточно долго, вероятно, она корректна. То есть там не доказывается, что система корректна, а просто повышается вероятность того, что она корректна. Это первый момент. Второй момент, мы можем сказать, что окей, давайте распилим наши интересные наблюдаемые вещи в системе и будем их по отдельности проверять. То есть, грубо говоря, мы можем пытаться проверить распиленный k-value, а можем проверить отдельный примитив, типа просто регистра линерализуемого. А дальше линерализуемость, как мы уже услышали, она композабл. Также мы можем, не знаю, вместо того, чтобы тот же самый пакт состроился, сейчас, понятное дело, есть рафт, и это заняло некоторое количество времени, но никто не делал сразу рафт. Если помните, как там паксис наращивался, он был вначале просто single, decree и synod, потом вокруг него выросли всякие разные варианты. Тут упрощенный, там упрощенный, здесь multi-pacsis, тут еще какой-нибудь паксис, вертикальный, stopable, вот это все. Вот у Дениса есть свой собственный паксис, про который мы чуть позже поговорим. И все эти вещи, там, не знаю, вместо того, чтобы специфицировать полностью multi-pacsis, можно специфицировать отдельно паксис, и потом уже считая, что отдельно, каждый отдельный экземпляр выполнения паксиса работает правильно, специфицировать multi-pacsis, используя, не знаю, упрощенное определение самого паксиса. Понятно, что я имею в виду? Ну да, построить иерархию из абстракции, по сути. Вот, да. Тогда я имею немного на брось этим. Если для сложных систем TLA+, не доказывает корректность на 100%, а повышает вероятность, может быть, на практике не нужно заморачиваться с математичностью и всяким таким непонятным синтексисом, который, если честно, мне не нравится. Я предлагаю это писать для тех, кому лень смотреть курс, типа конъюнкции, дизюнкции, при том все в доске, прямой слэш, обратный слэш. Есть плоскол. Я тебе сразу перебью, есть плоскол. Вот для тех, кому не нравится синтексис, есть специальный язык, у которого синтексис понятный. Так вот, а может быть, достаточно взять фреймворк типа ScalaCheck, или даже вообще без фреймворка на какой-нибудь простой Java, написать модель, протестировать ее, опять же, на 10 машин в течение месяца и сказать, что если модель не ломается, наверное, она работает. Плюс в том, что, во-первых, легче найти программистов, объяснить им, что происходит, но это если мы говорим про прям такую большую разработку, где надо много всего проверифицировать, и потом легко найти людей, которые заменят тех, у кого нервы сдали. Второй плюс, что конкретно фреймворк ScalaCheck и ему подобные, они еще умеют ширинкать примеры, которые ломают твою модель, и это весьма удобно, и тела этого не умеют. Я хотел добавить смеху йочек сюда сразу про Scala, то, что можно писать со ScalaZ и использовать их деньзюнсу, которые выглядят так же, то есть это два разных слэша. Я хочу сказать такую мысль, что, во-первых, совершенно варидный подход, то есть они заняли тот же самый React, как тестировался, когда мы говорим о тестировании ленивизуемости при помощи Jackson, мы тоже поступили в то же самое. На чем они, кстати, писали? React? Ну, тесты к нему. На QuickCheck? Ага. Ну они, получается, все-таки конкретную реализацию тестировали, это, кстати, тоже большое преимущество, а не модель. Да, да. Точнее так, я так понимаю, что там... То есть я не знаю, я в Poshal понятное дело не работал, но судя по тому, что я видел на GitHub, у меня есть подозрение, что некоторые вещи позже они уже начинали делать, начиная с такого простенького property-based-теста, и от него уже наращивали код, а потом его тест усложняли. Это еще одно преимущество, про которое я благополучно забыл, что ты тестируешь конкретную реализацию, и я понимаю в этом плане, что Jetson, что ScalaCheck, QuickCheck и подобные вещи. Защитить, хочу сказать, так, такую вещь. Я бы не сказал, что это вещь, которая друг другу противостоит, я бы сказал, что это дополняющая другая вещь. Если у вас уже есть спленная база данных, пол написанная, и вы хотите начать ее тестировать, понятное дело, что у вас, в общем-то, кроме QuickCheck и Jetson, или там ScalaCheck, у вас на самом деле нет реально смысла брать дело, и скорее всего. Если у вас нет системы, или вы планируете написать какой-то алгоритм, которого у вас еще вообще совсем нет, он у вас только в голове, это может быть тупо быстрее написать его на TLA+, убедиться, что у вас там нет концептуальных проблем, и потом уже начать переносить его в код, который... Что я имею в виду? То есть если мы в TLA+, моделируем посылку сообщений просто, там, не знаю, добавляем сообщения в множество, убирая их оттуда, и всякое такое, то в случае с QuickCheck и ScalaCheck вам реально придется написать актуальную систему, которая реально с записочками обменивается. То есть у вас просто количество делов движений для того, чтобы написать реализацию, оно больше. Я понял твою мысль. То есть если речь идет про верификацию протокола, как для whitepaper или для книжки какой-нибудь... Да даже для вашего собственного, не знаю, вы не по паперу что-то делаете, у вас есть какая-то уникальная задача, вы подумаете, ага, вот так оно решается. Или у вас есть какая-то система, которая работает, вы знаете, как она себя ведет, вы хотите сделать какую-то оптимизацию, вы хотите убедиться, что она вам все не нафиг не сломает, прежде чем ее реально имплементировать. Ну, в принципе, окей, принимается. Вот. И на самом деле я сейчас немножко прерву путок мыслей. А, да, последняя вставка про TLA+. Там еще курсы очень забавные, потому что господин Лемпок очень любит переодеваться, менять шапки и шутить. Вот. Я тем не менее хочу прерваться, и тут в чате есть аж два вопроса. Ну, можно к гостю, можно ко всем, я думаю. Первый вопрос. Изобрели ли люди более масштабируемые способы расследования транзакций, кроме двухфазного коммита? Я помню, как мы, собственно, еще давным-давно обсуждали, еще до того, как Денис к нам впервые пришел, обсуждали его реализацию этой штуки. Это такие, что, как это, не знаю, какие транзакции назвать? Они, похоже, описаны на нескольких пейперах разных. И мне кажется, что это все еще в такие фантазии на тему двухфазного коммита, но, собственно, я дам на это ответить вопрос Денису, потому что, так понимаю, он более в теме, чем я. Есть такая система, как... То есть у Google есть пейпер Percolator, Percolator something, я приложу ссылку. В ней описывается что-то очень похожее на Two-Phase Commit, но он оптимистичный в отличие от Two-Phase Commit. Вообще у Two-Phase Commit есть одна проблема, которую все замечают и на которую все смотрят, это если координатор умирает, или если какая-нибудь отдельная нода умирает, то у нас вся система тормозится, и нужно вмешательство оператора, чтобы ее пофиксить. По крайней мере, насколько я понимаю, это недостаток. Дальше мы можем взять каждый... Если мы говорим о каких-то распределенных системах, мы можем взять координатор и, допустим, запустить его поверх паксоса, преплицированного, и тогда получится, что у нас надежность каждого отдельного компонента в Two-Phase Commit повысится, и у нас пропадет такая проблема. То есть это один подход, который можно использовать. Другой подход можно использовать, то, что было описано в перколейторе. В перколейторе там тоже все поверх преплицированных систем, но там используется, в отличие от Two-Phase Commit, который использует блокировки, там используется оптимистик конкернси, и если есть несколько параллельных клиентов, то они могут друг другу вредить и не давать закоммитить ничего, то есть между ними будет такая дуэль, и они будут развлекаться вместо того, чтобы работу делать. — Там, кстати говоря, у Кокроча давным-давно в блоге была запись, в которой мы обсуждали, как они что-то похожее тоже реализовывали, и там они даже описывали механизмы борьбы с этим. — Есть, кстати, еще RAMP-транзакции от Питера Беллиса. Они, в отличие от Percolator и от Two-Phase Commit, они не сериализуемые, но они поддерживают... Если я правильно помню, Read Committed — уровень изоляции. То есть они чуть более быстрые или чуть более оптимальны по количеству сообщений. — Для меня, кстати, нетривиальным является такой момент, то есть они дизайнились для Eventually Consistent System, и мне неочевидно, будут ли они в принципе работать с линейризуемыми системами, где у тебя не может быть... То есть RAMP-транзакция в теории может... Две разные RAMP-транзакции, трогая еще один и тот же ключ, в теории, так примерно, могут записать значения, которые потом предполагается помержить. Как такое делать при линейризуемой системе, мне не очень понятно. — По-моему, там рассматривалось два варианта. Один вариант — это Read Committed уровень изоляции, когда одна транзакция просто перезаписывает данные поверх другой, как будто ее не было. То есть я очень плохо помню детали, но там либо Read Committed, и тогда мы соглашаемся на те аномалии, которые соответствуют Read Committed уровень изоляции, либо в статье упоминалось, что мы можем сохранять обе версии и использовать что-то типа CRDT, но такого не было нигде описано. Это были просто планы на будущее, которые, по-моему, не произошли. — Окей, окей. Вот. А второй вопрос был про в Trendly... А, ну, кстати, у них есть еще что-то добавить про двуххазный коммит? Видимо, нет. Второй вопрос был, в Trendly все еще Raft и Paxos? Ну, из того, что я видел, Raft — это то, что сейчас все имплементируют, Zookeeper — это зап, который, в общем-то, похож, это вторая вещь, которая сейчас везде заимплементирована, Paxos я вообще в Open Source особо не видел, ну, то есть он где-то у кого-то в проперитарных системах есть. Но он неинтересен, потому что это просто регистр. — Нет, ну в смысле, понятное дело, не чисто Paxos, а про Multi-Paxos, ну вот, положил в Raft, ой, не в Raft, в React Ensemble, там типа такой Multi-Paxos какой-то такой шардированный. Сейчас еще из новых исследований, из того, что я прям видел, заинтересовался, были Egalitarian Paxos и No Paxos, которые я, кстати, до сих пор не прочитал, но там суть в том, что они очень хитрым образом эксплуатируют свойства сети, чтобы меньше летниса еще иметь, если я правильно помню. Но я не читал paper. Вот, может кто-нибудь еще знает какие-нибудь трендовые вещи, которые пока в природе еще не появились, но интересно на них посмотреть было бы. — У меня на самом деле есть вопрос, потому что тут есть два клевых специалиста по распределенным системам, а вопрос этот мне иногда не дает покоя. Я помню, что у Raft была какая-то проблема, что он не хэндлит случаи, когда у тебя как бы нет сплит, но однонаправленный. То есть у тебя одна часть сети может входить во вторую, а вторая в первую не может. Или какой-то такой странный случай, когда-то иногда Raft ломается. Кто-нибудь помнит, когда? — Ты правильный случай, если я правильно помню, описал. Но он не то, что ломается, там сейф не нарушается, он просто встает. — В смысле, не может выбрать лидера и все такое? — Ну да, да. — Скорее детали реализации, чем свойства алгоритма протокола. В смысле, там... То есть в пейпере там описывается, как бы, вот есть какой-то алгоритм, он работает так-то. Если у нас, не знаю, нижележащая система, может, они там сделали какие-то предположения о нижележащей системе сети, если эти предположения неверны, то и у них, собственно, доступность нарушается. Но я сейчас гадаю, но мне кажется, неверно утверждать, что любая система, которая основана на рафте, она подвержена вот такому поведению. — По-моему, я читал чуть ли не один этот Диего, что там, да, не проверялось, или потом отдельно была внесена спецификация. Честно говоря, я тоже не хочу врать, нужно гуглить вопрос. Но я помню, что там, даже если что-то нарушалось, нарушалось только lightness, не safety. Вот, это я хорошо помню. Да, я думаю, что можно переходить к другой большой теме. Вот тут как раз был вопрос про разные паксесы модные. Вот, собственно, у нас тут самый модный хипстерский паксес от, собственно, гостя. Правда ведь? Алло? — Напоминаю о необходимости снимать мьют. — У меня, возможно, были проблемы с сетей, какие-то. — Ого, надсплит! Надсплит в прямом эфире! Вот. Я тут пытался подвести, шутя, что у нас в гостях как раз автор самого моднейшего, хипстерейшего варианта пакс, которых просто сейчас бледенеешь. В смысле, эдж. Вот, я тебе предусловую таким образом. — А, окей. На самом деле у меня, наверное, проблемы с сетей продолжаются. Ладно, я попробую. В общем, раз мы тут говорили о паксесе и TLA+, у меня есть что добавить по этому поводу. Я недавно, ну, как давно, пару лет назад сильно заинтересовался этим алгоритмом, начал изучать, как он работает, и в итоге, по-моему, изобрёл свой собственный вариант паксеса. Основная идея мультипаксеса и рафта, если попытаться отойти чуть подальше, чтобы осмотреть всё разом, это у нас есть реплицированный лог, в который мы можем только добавлять записи. То есть append only replicated log, on linearizable, и на каждой машинке, которая поддерживает этот лог, у нас ещё стоит сбоку машина, которая читает, вычитывает все команды из этого лога и применяет их на себя. То есть получается, мультипаксес и рафт это такие протоколы, которые позволяют построить replicated state machine, реплицированную state machine через репликацию команд. Я смотрел, писал свою собственную реализацию мультипаксеса, пытался её оптимизировать где только мог, и потом опубликовал у себя в блоге типа вот смотрите, какую штуковину можно построить. Кто-то пришёл в комментарии и такой говорит, чувак, смотри, у тебя тут какая-то переменная, ты в неё только пишешь, но никогда не читаешь. У тебя вероятность здесь ошибка. Я такой начал думать, блин, чёрт, действительно так? С другой стороны, я абсолютно уверен, что всё работает. Я взял изначально мультипаксес и потом последовательностью небольших рефакторингов, очевидно правильных, по крайней мере очевидно мне, довёл это до состояния, которое было у меня в блоге. Потом мне говорят, чувак, что-то не используешь. Я задумался, думал-думал, а потом так, о, Evrica, блин, это же совсем другое. И оказалось, я придумал, то есть сделал реплицированную state machine, но где вместо command я реплицирую сам state. Получается, если мы строим что-то типа, допустим, k-value storage, где каждая value, оно небольшое по размеру, то мы можем просто взять и запустить гигантское количество state machine, на каждый ключ по state machine. И таким образом мы сможем построить, допустим, k-value storage, который у нас реплицирован и работает. — Секундочку, маленькое лирическое вступление, если я правильно понимаю, примерно так React Ensemble и Cassandra LWT делают, но у них там не CASPACS совсем. Но идея похожая. — React Ensemble, насколько я его понял, он работает на уровне бакетов, то есть они реплицируют не каждый отдельный ключ, а... — Ну там хитро! Там у тебя группы процессов на бакет, но... на preflist, на комбинацию репликов, служивающих одни и те же ключи. Но внутри них стейты на каждый ключ там вот так. То есть, грубо говоря, там очень хитро сделано. Такие вещи, как восстановление, перепереналивка ноды, или синхронизация ключей и всякое такое, она работает глобально на группу реплик, а tracking state именно с точки зрения паксоса, он происходит на каждый отдельный ключ. То есть, хитровато. — Окей. Я на самом деле смотрел немного на React Ensemble, и в отличии... Вот этот CASPACS, то есть я в какой-то момент его придумал, затем написал имплементацию на JavaScript, кстати говоря, о TLA+. Один из разработчиков CuckroachDB, он такой читает, читает, а он говорит, что это фигня, это абсолютно не работает. Вот у тебя здесь ошибка. Я такой, блин, ну на самом деле это не ошибка, я написал... То есть, не знаю, там на английском написал, наверное, некорректно, я неправильно понял. Он такой, блин, да, вроде работает. Ладно, я напишу TLA-спецификацию, а он говорит, что это значит, что это не работает. В итоге он пишет TLA-спецификацию, и она работает. Вот. Говоря, TLA-спецификация. После этого я, когда убедился, что это более-менее работает, я написал статью, я писал в ней, как менять, допустим, размеры кластера. То есть у нас есть три машинки, которые поддерживают вот эту вот CASPACS, то есть это рестейт-машину. В реальности у нас есть проблема о том, что, допустим, одна машинка умрет, у нас станет две машинки, и получается, мы не сможем пережить никакое падение. Нам нужна способность добавлять новые машинки в систему. То есть делать реаконфигурацию. И вот эта вот реаконфигурация, насколько я понял, она либо невозможна для реакансамбля, либо невозможно повышать количество машинок в сети. То есть, допустим, у нас три машинки, то есть гарантированно нельзя повышать количество машинок в сети. То есть у нас есть, допустим, три машинки. Мы можем пережить смерть одной из них. Мы туда пишем какие-то данные. И вдруг в какой-то момент критичность этих данных, она возросла. То есть мы начали писать что-то более-более важное туда. И мы хотим... О, отлично, давайте мы добавим еще две машинки, чтобы у нас тогда пять будет всего, значит, мы можем пережить падение двух из них. Так вот реакансамбль, он не позволяет изменять количество нот в системе? Я сейчас не хочу врать, потому что я очень давно его читал. Насколько я помню, там все было несколько хитрее. Там иерархия паксосов, там есть один, типа, верхневыровневый паксос, в котором по дефолту, если специально не конфигурировать, участвуют просто все машины-кластеры. И там, соответственно, нужно, чтобы реально вылетело мажорити. Но он используется для того, чтобы сконфигурировать дальше все остальные паксосы. Остальные паксосы, они работают на, так скажем, уровне виртуальных узлов, если я правильно помню. То есть грубо говоря, вылетевшая одна машина приведет к тому, что, скорее всего, процессы, которые на ней были, они будут переинстанцированы на другой машине и просто будут, как бы, перенальются из существующих реплик и будут притворяться до последнего вылетевшей машиной, если я правильно помню. Хотя я могу ошибаться сейчас. Вот этого я уже не супер достоверно помню. Но там совершенно точно внутри протокола именно отдельного воркера, там точно есть команды покидания и присоединения. Просто, возможно, именно с точки зрения операционной глобальной вот всей штуковины, очень может быть, что просто уляк такая имплементация, что вот вы, когда конфигурируете strict consistent bucket, он у вас, как бы, вот его сконфигурировали и уровень репликации внутри бакета вы потом уже не повысите. Если я правильно понимаю, это не значит, что вылетевшая машина в автоматическом счете означает, что у вас совсем все, что не было, будет недоступно. Я так понимаю, что просто оно перейдет куда-то еще. Да, я неправильно сказал. Я согласен. То есть у нас три машинки, уровень репликации, у нас всегда будет уровень репликации три, у нас машинки могут умирать и могут добавляться новые, ну, по крайней мере, я служу по документации, но ты не можешь изменить вот это вот три машинки. То есть это свойство называется nval, и я только что скинул ссылку на документацию в React, где они явно говорят, что если вы хотите повысить вот этот уровень репликации, вы должны создать новый бакет и туда мигрировать данные. Да-да, это так. То есть это ограничение не React Ensemble, на самом деле, это ограничение именно уже того, как он интегрирован в большой React. Потом... Да, я вот только смотрю на большой React, я не знаю. С другой стороны, React Ensemble, React... React, он не поддерживает удаление. То есть он поддерживает удаление только через TomStone и TomStone, но то есть это все равно тратится диск на это. То есть если у нас есть большая система, в которой часто добавляют данные, часто удаляют, то в конце концов мы израсходуем диск. Да, само собой, опять же, это ноги торчат из того, что это костыль поверх консистенции системы. То есть если у вас там есть дипломент React, который почти всегда говорит консистент, но у вас есть какие-то ключи, типа не знаю, вам нужно, чтобы было зарегистрировано, не знаю, двух пользователей с одинаковым мейлом, вот то единственное место, где у вас там нужна strict consistency, вот чтобы оно было через Cosmetics, а все остальное у вас уже eventual. То есть это там такой был use case примерно. Да. Другая особенность... Ну, секундочку, я хочу продолжить, что это опять же, если я правильно помню, это свойство, опять-таки, не React Ensemble, а интеграция в React Ensemble в React. То есть можно взять React Ensemble и использовать его отдельно, и возможно он будет лучше, чем интегрированный в React. Да, да, да. О, прикольно, я не знал. Вот, то есть я в статье писал, как удалять без tomstomps, как изменять размеры кластера, и так как это Paxos, который мы для каждого ключа используем отдельную, отдельный его instance, в случае, если у нас есть, допустим, есть лидер, то есть у этого Cospax у него есть два варианта работы, то есть мы можем работать с лидером, можем работать без лидера. Даже если есть лидер, у нас лидер на отдельный ключ, он свой, и если система падает, то у нас, допустим, если есть три ноды, и одна из них упала, то доступность будет, возможно, будет зафикшена только у одной трети машин. А в React я тестировал, то есть я изолировал всякие ноды, и весь кластер тормозился до 8, по-моему, секунд, когда какая-то особая нода удалялась из кластера. Да, там есть особые ноды, опять же, это скорее архитектура самого React, чем Ensemble. К сожалению, там есть особые ноды. Я тоже тестировал вот эту доступность, как ведут себя системы, когда мы удаляем какую-нибудь одну ноду, изолируем, как ведет себя доступность. Куча всяких разных систем, то есть etcd, Cockroach, TIDB, и Console, и etcd продемонстрировал себя лучше всех. Ну что, он активно все в продакшене используется. С React Ensemble там была такая история, что они же с 1.0, потом с 2.1, а потом пошел, кончился. И я так понимаю, что на Ensemble в итоге было не так много реальных клиентов, сидевших. И я подозреваю, что просто никто его в итоге никогда не допилил. И вот... Даже не Ensemble, а интеграция Ensemble в React. То есть Ensemble был в очень хорошем состоянии, его делал Джозеф Блум, что это его зовут, который потом ушел в Facebook, потом я не знаю, какая у него была дальнейшая судьба. Вот. И... Собственно... То есть он сделал React Ensemble, оставил его в хорошем состоянии, и потом уже интеграция занималась... Ну, частично он занимался, частично другие люди. Потом, когда Embash кончилось, сейчас, если кто-нибудь сейчас снова займется... Мы пропустили такую занятную новость позапрошлый еще раз. Случился первый релиз React на Community Driven. То есть React потихонечку куда-то поехал. Может, хотя бы начнет собираться на свежем Ирландии в какой-нибудь момент. Вот. И... Да, по поводу коспаксиса, у меня к нему была такая претензия. Переналивка узлов. То есть то, что ты описываешь в статье своей... Да, кстати, там есть реальная статья у Дениса, опубликованная, ее даже уже успели обсудить на Papers.gov. Да. И... Там ты это описываешь, если я правильно понимаю, ты предлагаешь просто сделать лист ключей и просто по каждому пройтись и у каждого ключа поменять мембершип. Правильно понимаю? Да, это главный минус. То есть сложно... Не сложно, а... Ресурсоемко делать реконфигурацию. Ну то есть там, типа, пример, который, не знаю, где бы я хотел коспаксис использовать, вот такая система, не знаю, одна из таких систем, которые я знаю, там, не знаю, фантаз原 bindsworth, одна из таких систем, которые я знаю, там примерно ну, даже из пары систем, которые я знаю какие-то interacts, которые могли бы чего такого получить преимущество в одной там вообще десятки миллиардов ключей, в другой там были, ну по меньшей мере, миллионы ключей. Но миллионы ключей, это уже довольно тяжело обойти. Десятки миллиардов, это просто нереально. Можно систему... то есть я согласен, это минус, и отчасти это происходит из-за того, что каждая отдельная стоит машина, она независима друг от друга. И, допустим, в Raft и в Multipaxis у нас мы реплицируем команды, и у нас есть лог, и каждая... мы можем сказать, что когда-нибудь каждая машинка, она как бы будет содержать лог, допустим, до текущей точки. Поэтому, когда мы делаем реконфигурацию в Raft и в Multipaxis, мы можем те же самые миллионы ключей скопировать, но мы их будем копировать с одной машины. Поэтому будет... то есть требуется меньше сообщений, меньше... требуется меньше трогать данные, чтобы сделать реконфигурацию. Можно взять Caspaxis и в теории его продолжать усложнять дальше, но у меня основная идея была в том, что, смотрите, можно вот так вот взять и просто сделать какой-нибудь аналог etcd, например. Но если усложнять дальше, можно сделать какой-нибудь background-процесс, который синхронизирует все ноды между собой, и тогда у нас получится такое же свойство, что... И вот если я помечу текущий момент времени, то через какой-то промежуток времени все ноды будут содержать данные до этого текущего момента. И если вот эту вот систему добавить, то тогда реконфигурация, она будет отчасти почти как в Raft и Multipaxis. Мы берем вот этот вот хвост, загружаем этот хвост с одной машины, а затем уже добиваем остаток через стандартный механизм и получаем вот этот вот хвост. Я как раз хотел подобное предложить, потому что у тебя же там была в твоем же пейпере такая интересная способная доказательность всякого через сетевую эквивалентность, как ты это называешь, то есть представим, что у нас есть какая-то функция, которая фильтрует трафик специальным образом. Собственно говоря, можно намертеть такую штуку, которая инжектирует в некоторые значения, ну, например, она, собственно говоря, процесс, который считает, например, Merkle дерево от узла, инжектирует, например, там, корень верхней листья вместе в какое-то значение, и, соответственно, вот все, что записано до этого значения должно как бы в это Merkle tree попадать. И, соответственно, при репликации можно при переналивке пустого узла можно, там, не знаю, находить последний такой записанный, наливать, чекать и одновременно использовать такой сетевой фильтр, который будет типа форвардить трафик. О, да, кстати, это прикольно. Но это уже больше как сделать настоящую систему поверх этого. Я был более заинтересован, собственно, в самом алгоритме, и дальше у меня нет никаких планов. На самом деле самая большая плюшка твоего алгоритма, извини, что перебиваю, с точки зрения практики, то, что у тебя, как и у эгалитарианского пактуса, нету... То есть лидер может быть, но необязателен. А сейчас все наконец перестали делать распределенную систему в одном дата-центре, у всех сейчас проблема сделать распределенную систему многодата-центровую. И если смотреть на тот же самый как Роуч, который Hraft, у них в итоге проблема решается тем, что просто вы некоторым ключам говорите, что у них дом вон в том регионе. Это клево, но требует ручных манипуляций. Гораздо круче было бы, если можно было бы просто не делать домашнего региона, никому, а иметь систему, которая симметрична. То есть откуда-то начали спрашивать, а там и становится быстро. Это было бы очень клево. Hraft так делать не может в принципе. То есть ему нужно реально физически ключ начинать другой стад машины управлять. Чтобы он начинал управляться другой стад машиной. Каспак, кстати, в этом плане гораздо проще. Иголитариан в принципе может, наверное, позволить сделать что-то типа лога, но типа для несвязанных ключей, и позволить их обрабатывать разными подсостояниями, но он при этом и сильно сложнее. И если просто речь о кейвэлью и транзакциях сверх кейвэля, то иголитариан получается сильно сложнее и так не нужно все равно. В смысле, нет необходимости так сложно делать. А если придумать какой-то механизм, ну и придумать, проверить, доделать какой-то механизм переналивки узла поверх каспакса, это может быть реально очень практичной штукой для многодатацентровых сетапов. Может кто-нибудь этим займется. Сейчас я знаю, что есть несколько имплементаций каспаксаса. Первое, это я написал систему на жаваскрипте, грядку. Грядку, потому что в качестве хранилища я использовал редис. Получается такая грядка редисок. — Да, я хотел представить тебе, когда гостя представлял, забыл представить тебя как главного специалиста по полке грядок. И высадке редисов. Но я забыл так сделать. — Вот, и эта грядка работает примерно так, как ты описал в плане лидера. То есть, если ты обращаешься к какому-то в терминологии к пропозеру, то после того, как ты с него что-то прочитал, то все обращения с этим ключом через этого пропозера становятся вдвойне быстрее. То есть, если в обычном цикле консенсуса у тебя два раунд-рипа при пэе на септ, то когда ты работаешь гарантированно... не гарантированно, когда ты работаешь с одним пропозером, он может делать пиги-бэкинг следующего пропозера на текущем асепте. Потому что мы делаем пропозер, мы не передаем никаких данных, которые характерны для запроса будущего. И тогда если мы знаем, что все клиенты будут ходить через этого пропозера, то все будет работать быстрее. Но если кто-то пойдет на другого пропозера, сейфти не нарушается. Это просто оптимизация по скорости. Если мы перед системой поставим что-нибудь типа consistent-хешинга, который будет перенаправлять трафик, который трогает один ключ на ту же самую машинку почти во всех случаях, система будет работать в два раза быстрее. Помимо грядки есть разработчик Microsoft Orleans Рубин Я точно не помню его имя. Он работает над имплементацией под Microsoft Orleans. Также разработчик Fastly Он до этого работал в SoundCloud над системой Roshi, которая серии ZT-бейста Питера Бургон, по-моему. Он пытался делать имплементацию на Go. И, собственно, он сделал доклад на Papers by Love. И для меня следующий шаг с этим коспаксисом я пытаюсь... Я подал заявку на конференцию научно-академичную. Посмотрю, получится. Я никогда в этом не участвовал, поэтому для меня это всё безумно интересно. Есть ли какие-нибудь ещё вопросы про коспаксису? Видимо, нет. Я, кстати, только сейчас понял, чтобы не замеченный стучал по клавиатуре. За это я извиняюсь. Не сильно вроде. Вот. Я так там... Я думаю, что можно перейти к другим темам. Мы, наверное, на сегодня свернём Distributed Zen. Он у нас сегодня получился очень распределённый. Тему против лендов будем обсуждать? Или... Свет отвалилась, поэтому... Без неё не будем. Окей. Тогда, собственно, время для Hardware Zen. Перед переходом к Hardware Zen я, наверное, расскажу про конференцию R2Con, которая пройдёт в сентябре. Сейчас скажу точно. С 5 по 8 сентября не вижу где. Но не в Москве. Не в России. В Барселоне. Поэтому... Да, собственно, про что конференция. Такой проект называется Radare2. Это open-source проект, представляющий собой фреймворк для реверс-инженеринга, анализа бинарных файлов и всякого такого. Я за ним начал следить некоторое время назад. И меня он очень порадовал. Не только своим функционалом, но и прикольным, дружелюбным сообществом. И вообще проект очень активно развивается. Я подписался, думал, ну там у них будет патч в неделю. Оказалось, нифига. Там прям активные обсуждения в Телеграме. Там постоянно какие-то полреквесты, обсуждения в бактрекере, всё такое. Поэтому интересно следить. Вообще я интересуюсь в настоящее время развитием разными open-source проектами, как они развиваются. И они очень сильно отличаются. Если посмотреть на Postgres, на Radar2 и какой-нибудь игрок, то это прям очень разные комьюнити с очень разными подходами. И это интересно. Но, наверное, я об этом как-нибудь в другой раз расскажу. Вообще, скажу, что это, не вдаваясь в подробности, что инструмент полезный в программировании и полезно держать его на вооружении. Я с его помощью отложил один неприятный бак в кастомном алгоритме с поджатием, который выбрасывает нули. У меня были данные, где очень много нулей, и мне нужно было их пожать именно нули. А все остальные данные были не сильно избыточны, поэтому их не было смысла сжимать. И там был бак. И вот некоторые инструменты из этого фреймворка мне в этом помогли. Там есть, в частности, Radiff2, который считает диффы от бинарных файлов. И он очень удобно, когда тебе нужно по смещению 3 мегабайта найти, что нолик на единичку заменился в таком стиле. Да, поэтому я хотел рассказать, что эта конференция будет в сентябре, и если вы чем-то таким интересуетесь, вот теперь вы про нее знаете, также на YouTube лежат видео с этой конференции за предыдущие годы. Она проходит с 2016 года, поэтому вы можете посмотреть, понять, насколько вам интересно, и ознакомиться с Radiff2, если вы никогда им не пользовались, попробуйте, он клевый. Есть ли здесь вопросы дополнения, что-то такое? Ну, окей. Да, тут я подписан на рассылку от SID Studio. Это интернет-магазин, который торгует всякими железками и сопутствующими товарами, и мое внимание привлек одноплатный компьютер на базе ARM, называется Hi-K970. И интересен он в ряде моментов. Вот, во-первых, он четырехядерный, и с частотой процентов, а, даже восьми, то есть четыре процессора Cortex A73 на 2.36 ГГц и четыре Cortex A53 на 1.8 ГГц. Честно говоря, не до конца понимаю, как это работает, то есть он прямо честно восьмиядерный, или он переключается в зависимости от режима, и в один момент времени является четырехядерным. Если кто-то этот момент понимает, буду благодарен за комментарий у нас на сайте или в чате. У него 6 ГБ памяти и 64 ГБ microSD, плюс можно через PCI-Express подключить более серьезный диск. Ну и тут разные другие интересные моменты. HDMI выход, все такое. Цена, вопрос, 300 долларов. И я подумал, что это достаточно небольшая цена для компьютера, который не стыдно себе поставить на полноценный десктоп. Мы-то тут, конечно, любим ноутбуки постоянно с собой таскать, но нормальные люди все еще продолжают пользоваться обычными стационарными компьютерами, и вот такая же леска, если вам чисто веб, почта, фильмы, всякое такое, прям очень интересно смотрится. А другой интересный момент, что у него на борту есть устройство под названием, сейчас скажу, NPU. Это прям железка специально для обучения нейронных сетей. И утверждается, что она интегрируется с в кавычках популярными фреймворками для обучения нейронных сетей, к сожалению, не уточняется с какими именно. Вообще, мне интересно, доводилось ли кому-то из присутствующих в этом выпуске начать с простого, обучать нейронные сети? Ну, кроме совсем игрушечных, нет. То есть там в универе что-то модельное, да, если я правильно помню, но так современные, особенно используя фреймворк типа TensorFlow или Torch, нет, и, к сожалению, у нас сегодня нет ни Светы, ни Вани, которые в этом гораздо более продвинуты. У нас еще есть периодически гость Слава, который тоже Вячеслав, в смысле, ой, сори, Ярослав, который сегодня не с нами, прости, как обычно. Вот. И... Да, в общем, я думаю, что если ты у них спросишь, они тебе ответят. Я баловался последние... В прошлом году много баловался с нейронными сетями. Использовал ли ты при этом NPU? Нет. Их нигде нет. А в облаках еще не занесли, разве? Не в курсе. Я все делал на, соответственно, куди. Мне в этом плане интересно, насколько оно сопоставимо с так называемой TPU, который TensorFlow, CSS, или как они, которые у Google, которые, возможно, когда-нибудь будут доступны в облаке. Ну, по сути, это одно и то же, насколько я понимаю, только более брендово названо. Ну это как отличие... Менее брендово. Ну, то есть это как отличие Intel NVMe от SSD. Это одно и то же. Ну нет, NVMe, там есть характерная отличие. Это просто SSD, который втыкается в PCI Express. PCI Express, именно. Ну и что? Ну это интерфейс. Ну да, но когда ты говоришь SSD, ты имеешь в виду.. . То есть, короче, это прям такое отличие по тому, куда оно втыкается, и чем оно является для... Ну то есть там нету больше никакого SATA и прочего говна. SSD это любой, по сути, твордотельный накопитель. Даже можно флешку, которую ты втыкаешь в USB, назвать SSD. Более того, она мало... Она мало отличается от диска, который вот SSD. Только наличием кэша. Ты согласен с тем, что не каждое SSD является NVMe? А тут надо почитать бренд-блок Intel. Понимаешь, вам не лень. Ну вот, на самом деле, не каждый. Это не потому что Intel маркетинг, от Intel маркетинга так хочется, потому что, когда ты говоришь SSD, ты не можешь по этому сказать, какая у него скорость. Если ты говоришь NVMe, ты уже догадываешься, что не стали бы на PCI-Express садить то, что там выдает меньше, там скажем, ну я подозреваю, гигабита. В любом случае, если у нас среди слушателей есть люди, понимающие, что вообще происходит, чем процессинг-юнит отличается от NPU, и вот это вот все, пожалуйста, оставляйте ваше экспертное мнение. Александр, скажи, вот смотри, я очень давно себе хочу купить компьютер на ARM. Так как я давно хочу слезть с Mac, примерно с того времени, когда я на него залез. 8 лет назад. Да, это будет подстава. Я думаю, надо купить себе замечательный, ну да, на Windows вот эти вот все проприетарные решения, тоже не хочется слезать. Хочется, чтобы было такое красивое, свободное все, и желательно вот такое, не такое, как у всех. Я вот думал, надо себе купить, короче, одноплатный компьютер на ARM, тем более там были какие-то рассказы про то, что теперь сервера на ARM есть, и все круто. Но каждый раз, когда я начал смотреть магазины, я видел вот что-то такое, что мы сейчас смотрим. Например, что меня отталкивает? 6 гигабайт памяти. А хотелось бы, чтобы можно было поставить 16, 20, там сколько, 32 гигабайта. Так, ну то есть твоя претензия здесь к объему памяти. Да, конечно, а что делать с 6 гигабайтами? То есть хочется, хочется, чтобы прям вот чтобы 32 было. Ну, потом тебе захочется в Skyrim поиграть, еще что-нибудь. Ну, тут не угодишь. Нет, я просто хочу Hello World на скале скомпилировать. Шутка. Так я... подожди, у меня есть ноутбук с 6 гигабайтами памяти, я успешно писал на нем на скале. Вот мне надо грязи. Скала, она не такая прожорливая даже. Тебя-то я не ожидал таких сирячек. Это автостебалово, мы внутри скала сообщества любим этот счет неронизировать. Я пока смотрю, есть ли тут куда воткнуть память, я ее вообще, честно говоря, не могу разглядеть. То есть, возможно, она чуть ли не... Вряд ли они ее сделали системой он-чип. То есть я тут что-то не могу догнать, где она вообще находится на этом компьютере. А, наверное, она спирячится... Радиатор тоже на память вроде не стоит. Короче... Может быть у них вот этот радиатор наклеен поверх нескольких чипов, то есть там вот, например, проц и рядом память. Не? Может быть такое? И сверху радиатор. Большой. Ну, радиатор... Скорее всего, он на этом самом... А-а-а... Все, я... Сейчас. Ну, короче, хз. Я не буду сейчас гадать. Память, однажды, куда-то спряталась. А-а-а... Александр? Я с... С... нейронными сетями никогда практически не работал. Мне интересно, вот этот модуль, про который ты говорил, NPU, он для обучения нейронной сети или он ее потом для выполнения, когда она уже построена? Отличный вопрос. Мое понимание такое, что для обучения, но я сам не эксперт, поэтому это не точно. Еще, кстати, из одноклассных компьютеров, которые я сам бы не отказался себе иметь, это BananaP, точнее, они бывают разные, это M2 Ultra, мне приглянулся. Стоит он в районе 100 долларов. Это в розницу и в российских магазинах. Вот. Что там по железу, я смутно помню. Я помню, что там есть Wi-Fi. Это для меня важно. А, ну с памятью тут еще хуже, 2 ГБ и 1,5 ГГц четырехъядерный процессор. Но это на случай, если кому-то 300 долларов кажется многовато, или не нужен такой мощный десктопный компьютер, также есть варианты и за... там, порядка 100 долларов, даже меньше. Вот. И я смотрю, у нас в темы скала 3 залетело, может я еще хотел про этот на платный компьютер спросить. А вот смотри, вот здесь указаны размеры, да? 100 на 85 на 10. Это, я так понимаю, не запихивается ни в какие микроатексы, ни во что, да? То есть это какой-то просто свой формат, и его нужно, я не знаю, прикручивать на доску. К стене. Если честно, не разбираюсь в форматах, вот, но ты можешь его, ну, что на AliExpress, что на eBay, много разных корпусов, ты можешь действительно подобрать алюминиевый или пластиковый по размеру и примотать к нему, либо напечатать. Это не самая большая проблема. Окей. Да, скала 3. Давай, расскажи нам. Да, я хотел рассказать, потому что ну, как бы, о скале новости теперь издевзенно не доносятся, потому что теперь все занимаются железом, бизнесом. На самом деле, потому что там просто ничего не происходит. Не, ну как в скале, происходит очень-очень много. Ну давай, расскажи нам все, что мы пропустили. Да, например, достаточно продолжительное время у команды Мартина Одерски развивалась такая вещь, как доти, вот, уже несколько лет, вот, и то есть, ну, это язык скалоподобный, который вот, весь ресерч был, как бы, унесен туда, а, как бы, весь такой интерпрайс был сосредоточен в скале 2, на которой все пишут, да, то есть все вот стабилизация фичей, улучшение, оно все было вот в скале 2, а весь ресерч был вот в этой доти. Но, как бы, скала 3 его никто не называл, его называли доти. Вот, и теперь вот официально Мартин объявил в блоге о том, что, в блоге скала, что доти, это теперь официально скала 3, и, соответственно, в 2019 году будет фича фриз, и в 2020 году скала 3, как бы, выйдет в свет. Ну, там, понятно, релиз кандидата и все остальное, и потом, соответственно, релиз, то есть ожидается в 2020. Вот. Это очень круто, потому что в доти это вообще замечательно, если кто-то пробовал запускать, там он мог увидеть массу улучшений, например, там, ну, улучшен тулинг, например, там улучшены сообщения об ошибках, улучшены сообщения об ошибках в имплиситах, в том числе, да, то есть теперь можно разобраться, что происходит. Вот. Что еще? Есть очень много новых языковых фич, которые позволяют лучше, удобнее, красивее писать код. Вот. И... Ну, в общем, это уже надо подробнее расписывать. Ну, в общем, скала 3 — это новое, прям, будущее, которое, прям, сияющее, доброе, красивое. Вот. Я хочу сначала набросить. Вот я всякий хочу согласиться с Сашей о том, что там ничего не происходит, потому что, на самом деле, почти весь Big Data Stack, который скала использует, там, Flink, Spark, это все, он все еще на скале 2.11, даже не на 2.12. Ну, 2.11 нормально, не надо. Она нормальная, просто прикол в том, что в 2.12 там была куча оптимизаций, если я правильно помню, самой, как бы, в компиляторе, в том, как оно утилизует виртуальные машины Java, тем не менее, оно почти совместимо по... по source compatible, однако из-за того, что нужно всю эту фигню, всю эту огромную гору артефактов перекомпилировать под еще одну версию скалы, я так понимаю, это главная причина, по которой у нас основные стэки все еще на 2.11. Даже те, где перформанс, в общем-то, не бесполезен. Ну, как бы это, собственно говоря, я не знаю, да, то есть я не пользуюсь Spark'ами, вот этим всем каждый день, и поэтому у меня 2.12 везде уже давно. И добавить, как бы, новый пакет, это просто, ну, как бы лень с их стороны, да, то есть на самом деле это очень просто, да, это отнастройка конфигурации. Я поддерживаю, там ничего не ломали. Это не так просто, потому что если у тебя есть, там, не знаю, типа сотни пакетов, все из которых нужно пересобрать и протестировать под новой версией, а также друг с другом, ну, это очень много работ по тестированию.",
    "result": {
      "query": "аналоги TLA+ с генерацией кода"
    }
  }
]
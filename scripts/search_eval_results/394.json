[
  {
    "segment_id": "13b08302-ae47-481a-b03a-afafd847fe2d",
    "episode_id": "f47045f8-9731-4d78-ab1d-8686115445ef",
    "episode_number": 394,
    "segment_number": 7,
    "text": "У нас, значит, есть облака. В облаках у нас есть два стула. Или у вас EBS, или похожая штуковина, то есть, какие-то диски, которые вы купили, это, по-моему, называется Persistent Volume, или как-то так, которые вам приезжают из облака. Это обычно какое-то распределенное реплицированное хранилище. Там обычно довольно все хорошо с bandwidth, но latency там, ну, в зависимости, конечно, от того, как с конфигурируешь, но он похуже, чем у топовых NVMe дисков. Ну, то есть, в данном случае, у дискорда под нагрузкой, под высокой latency прыгал до 2 мс. Чего им не очень хотелось, им хотелось latency, как у локального SSD, на чтение. Проблема с локального NVMe SSD. Проблема с локальным NVMe SSD в том, что он, вот он локальный, он прибит к машине, для него нет снапшотов, для него нет автоматической дорепликации, автоматических бэкапов, всякого такого. Когда машина умирает, оно умирает. И т.п. Ну, то есть, не самая дружелюбная вещь в облаке, потому что каждый раз, когда, не знаю, перезапускается машина, из-за флуктуации континума в облаке, не хочется терять данные и т.п. Чтобы это победить, они попробовали несколько разных штук и остановились на том, чтобы собрать софтверный MD-RAID из в общем, диска, который persistent volume и диска, который локальный. Чтобы чтение не часто, то есть, по умолчанию такой RAID, если вы сделаете RAID 1, он будет поровну балансировать нагрузку на чтение и на запись, точнее так, нагрузку на запись будет в обойти, нагрузка на чтение будет балансироваться. Чтобы не ходить лишний раз в диск, который будет долго отвечать, оказывается, есть опция у MD-RAID системы, можно сказать, что, можно так с конфигурировать, указав, что какой-то из дисков он долго отвечает и начинение его лучше не использовать. И это позволило скрутить то, что хочется, у них было еще одно ограничение, с которым пришлось поработать, что диски, локальные, в Google лоцируются фиксированным объемом, 300, чем-то гигабайт, а у них диски, которые молочные, у них по терабайту. Чтобы это войти, они сделали RAID-RAID, то есть они вначале сделали RAID 0 из локальных SSD-шек, чтобы добить до терабайта, а потом это объединили в RAID 1 с persistent folio. И таким образом скрутили то, что дает приемлемую перформанс. Они там, к сожалению, опустили кучу деталей и пообещали сделать вторую часть бут-поста с тем, как они этим всем управляют на масштабе и какие у них вылезли проблемы, но в целом довольно такой интересный подход, достаточно не rocket science, и в принципе понятная история, еще раз, чтобы проговорить, что если вам хочется пользоваться плюшками облачных дисков, но вы не хотите испытывать задержку на чтение от них, вы можете скрутить такую странную конструкцию RAID из удаленного диска и локального диска, и иметь как-то лучшее двух миров. Я уверен, что у них там что-то шло не так, я очень надеюсь, что они это в следующем блокпосте расскажут подробнее. Мне кажется, если я не свою ерунду, Google Cloud должен предоставлять такое прям, как готовый продукт. Ты согласен? Я скорее согласен, чем нет, но я думаю, что это не совсем тривиально в том плане, что им для этого нужно довольно хорошо контролировать хостовую систему, получается, то есть, наверное они могли бы это сделать на уровне гипревизора, и это было бы прикольно, или может быть на уровне драйвера своего",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 1761. Please try again in 3.522s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 1761. Please try again in 3.522s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
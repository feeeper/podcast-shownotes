[
  {
    "segment_id": "bf0f3477-e034-473d-abe3-b20beb85d88b",
    "episode_id": "001e620b-b59f-485a-9b9c-5710855324fb",
    "episode_number": 490,
    "segment_number": 5,
    "text": "да. Слушатель Иван Глушков спрашивает: Это плохо, что нержавейка? Свинец он потяжелее. Ну это да. Не знаю, надо посмотреть, есть где-то поблизости охотничьи магазины и просто можешь туда заглянуть тоже. На амазоне продается, просто он дороже и здесь шарики маленькие. Один килограмм шариков для полировки. Вот такие оказывается есть товары, удивительные. Поехали дальше что еще оказывается есть это уже не новое уже немножко с душком видео от с канала семью Database talks это я все еще через плейлист Database building box продираюсь потому что я их там почти все заложил и не смотрю теперь, как это обычно бывает. Хотя там уже сейчас выходит довольно интересная серия про оптимизацию, видимо потом будут догонять или не будут, посмотрим. В этот раз обсуждалась система под названием Spice AI. Это стартап так называется, и у них есть, не знаю, Тула. Я не готов это назвать роялями или чем-то еще, я называю это Тулой. Или даже какие-то сами говорят, они это называют Тулкит, который называется spice тоже. Есть на гитхабе под лицензией, здесь ничего не путаю, я патчу два там лицензия. И это меня прям очень зацепило, не потому что у меня есть какие-то интересные базаданные решения, а скорее просто потому что это дико похоже на то, чем я занимался две работы назад, только применительно к современным реалиям. В общем, что такое спайс как набор инструментов? Это штука, которая позволяет вам запустить какие-нибудь поближе к своему приложению такой серверочек, который принимает запросы на, я так понимаю, по зови совместимом диалекте он берёт Apache Data Fusion при помощи Apache Data Fusion разбирает этот запрос, строит планы. Вы этому серверу перед стартом можете рассказать какие у вас есть источники данных это называется Федерация, то есть вот как бы первое что они делают это Федерация SQL запросов. Скажем вы можете если у вас есть например какая-то таблица в Pasgress еще какая-то таблица это какое-то говно на файловой системе виде CSV а еще какая-то таблица это валяющийся на S3 паркет вы это все можете в конфигурационном YAM файле прописать и оно во время планирования поймет какие данные из какого источника нужно брать и возьмет оттуда. Больше того, если источник данных достаточно крошечный и понимает тоже SQL они возьмут и найдут максимально большое под дерево пламо которое можно пропихнуть в этот источник данных и пропихнуть всё под дерево каким образом? То есть мы берем под дерево логического плана и потом на основе этого под дерево обратно как бы депарсим его в новый SQL целевого диалекта это в принципе я не готов назначить что сейчас есть существующего что умеет федерацию данных открытого в общем насколько я понимаю, федерация так и делается и как раз таки на позапрошлой работе мы очень похожую штуку делали с патчей Кальсайд. Но они не просто федерируют, дальше они делают еще интереснее. Если вот так вот переписывать запрос кусок логического плана и отправлять его в PaskGres это в принципе неплохая идея. PaskGres если вы ставите совсем какие-то мега большие данные он довольно с разумной скоростью может отвечать. Вы там можете кэширование или материализацию по другим причинам хотеть. Но вот если у вас какая-то пипяка на s3 ну или даже не просто там какая-то нагруженная погрязка, которая обслуживает УЛТП нагрузку и вы не хотите постоянно его долбить какими-то запросами вы можете кроме того что рассказать их системе что есть такой источник данных вы можете сказать как его материализовывать То есть вы можете сделать какой-то select запросик Больше того, вы даже можете добавить информацию о том как это обновлять Вы можете сделать какой-то CDC поток вы можете сказать типа вот делай раз в от времени вот такой-то запросик вы можете насколько я понимаю даже какой то если у вас там временной ряд вы даже можете объяснить эти штуки как там догружать данные если в таблице временной ряд и оно будет просто периодически подсасывать данные и до материализовывать их и тогда у вас рядом с приложением окажется материализованный такой типа кэшик и материализует оно умеет материализовывать в памяти в Arrow оно умеет материализовывать в DAGDB, подозреваю, что они в паркете лежат оно умеет материализовывать в Osqulite и оно умеет материализовывать в PosgSql. Вот. Это вот просто уже два таких как бы кусочка. А еще что хочу по поводу, пока я говорю про материализацию и федерацию, еще хочу сказать, что вещь, которую для себя открыл, я про патчи DataFusion давно знаю, даже немножко им пользовался. Вот о чем я не знал, так это то, что по патчи DataFusion есть отдельный проект, который называется DataFusion Federate или Federation. То есть они в него сильно контрибьютели, но они не первые кто такую штуку использовал в DataFusion потому что в кольсайде федерация она как бы ну не то чтобы она встроена, но она как бы она более часть проекта, а здесь это как бы немножко соседний проект Они совсем сами Если вы просто импортнете Data Fusion, там некоторых вещей может не быть. То есть у них работа с S3 это немножко другая библиотека. Вот эта вот федерация это тоже немножко другая библиотека. Но круто, что оно есть, я не знал, что оно есть, я рад, что оно есть. Вот. И я больше всего рад, что я узнал вот про этот вот их тут кит, потому что если мне когда-нибудь в будущем придется решать задачу, которую я как бы уже в своей жизни решал, мне не нужно будет снова вспоминать, как мы это делали, переписывать с нуля, потому что вот есть опенсорсный проект еще и на Rust с DataFusion, который делает ровно то что нужно. У них там правда есть ограничения потому что процесс построения из логического плана обратно запроса на конкретную диалектик конкретного источника данных он имеет такую особенность, что во всяком случае внутри data Fusion, что если у вас есть какие-то udf и у вас её нет внутри data Fusion, то ну в общем добро пожаловать в ад, потому что вам чтобы что-то депарсить вам нужно вначале в логическом плане представить, а представить в логическом плане какую-то вещь, которой нету в вашем top lavel engine это проблема. Кстати у нас похожие проблемы были в кольсайде, но в кольсайде они как будто бы проще решаются. То есть в кольсайде там можно было внутри логического плана там еще кроме логического плана там есть еще такое такое представление как типа каталог хранилище данных с которым ты работаешь и соответственно в этом каталоге можно представить какую-то udf-ку которой может даже не быть имплементации и она позволит как-то худо-бетно в логическом плане это представить. У нас там были скорее приколы в том что вот если мы что-то не можем полностью пропихнуть в источник данных а там есть эта юдфка, которая как бы кто-то её, ну нашим, скажем, вы прикидываетесь посгресом, кто-то вызывает посгрес специфичную юдфку, а так получается, что эту юдфку не удается пропихнуть в какой-то реальный посгрес. И тогда начинается вопрос а как мы эту юдефку она должна быть на юдефку просто может как может быть это позы позы специфичная функция но в pazgres же все функции почти они юдефки или похожим образом сделаны вот и вот вы хотите вызвать какую-то позы специфичную функцию у вас ее вам её некуда пропихнуть, и вам нужно, чтобы у вас в вашем, вам в любом случае оказывается нужно, чтобы ваш top-level движок, понимал как это исполнить. Вот, в общем, для них это пока ограничение. Я не понял, будет они их решать или нет, но вот как будто бы сейчас не решают никак. Еще они конечно столкнулись с проблемой того, что когда вы делаете вот эту федерацию в другие движки, у вас во-первых начинается вы попадаете в локальный от типов данных, какие-то движки у вас будут маппиться один в один, какие-то вам предстоит принять некоторые решения, которые возможно будут иногда абсурдными или что-то где-то кому-то запретить делать.",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 3738. Please try again in 7.476s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 3738. Please try again in 7.476s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
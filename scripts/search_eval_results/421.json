[
  {
    "segment_id": "62fccbf3-b014-4fd6-9fd5-f13dc4dba006",
    "episode_id": "7c27517e-390f-4e1a-98fc-77028abd58cf",
    "episode_number": 421,
    "segment_number": 8,
    "text": "Потому что, получается, аутпут вот этого процесса, как мне кажется, который OpenAI собирается проводить, внутри себя как бы создавать свой увеличенный скоростью аламент с использованием вот этих первых EGI. Как бы общий аутпут этого процесса, это там, не знаю, скорее всего, сопоставимо с сотнями пейперов, скажем так. Это не попадает в один контекст одной модели, даже GPT-5. То есть она не может всё это обозреть и из-за этого всего вывести какой-то мега такой идущий план и стратегию. Это всё-таки не подвластно. Может быть, подвластно какому-то супер интеллигент в будущем, но не GPT-5. То есть это всё-таки EGI, но ограниченно относительно. GPT-5-то мы ещё не знаем, но вот, например, сейчас буквально две недели назад стало быстрейшим направлением использовать второстепенных субагетов для всяких разных целей, для произвольного файлика, для консультаций, и, в общем, оно стремительно разъезжается. У тебя не разъезжается понимание вот этой стратегической картинки. То есть, на самом деле, человек пока что очень сильно супер-EI, то есть прикольно, что есть термин superhuman, то есть superhuman capability, можно говорить, что человек super-EI пока что в вот этой стратегическом контексте. То есть всё-таки контекст даже самый последний GPT-4, 32 тысячи токенов, это сколько слов? Не знаю. Это довольно много, на самом деле. Но это один пейпер или несколько? Это сильно больше пейперов, но это, конечно, не весь архив. Но, опять же, если ты заспавнишь по агенту на каждый пейпер в архиве, или как ты их там группируешь, то, в общем, через делегацию вполне можно это расширять столько, сколько у тебя железа хватит. А железа у нас удваивается каждые два с половиной года. Всё-таки я не думаю, что вот из этого скалирования, между ними нет такой связи, которая есть в мозгу человека. То есть когда я сиквелик в компании, или там президент, у него всё-таки есть такой очень высокого уровня взгляд, который в некотором смысле интегрирует больше информации, мне кажется, всё-таки. И вот этого механизма интеграции в LLM, по крайней мере, в трансформерах нет. То есть мне кажется, чтобы у нейросетей появилась сопоставимая с человеком такая очень широкая способность к интеграции большого реально объёма информации, для этого нужен сильный онлайн-лёрнинг. Слушай, но где же пейперы, даже у того же OpenAI, которые говорят, что вот вам, короче, книжка, там на сто пятьсот тысяч контекстиков, сделай мне саммари. Вот она такая, ну окей, дай мне первую страницу. Окей, вот саммари первой страницы. И так по каждой странице. А потом дай мне саммари первой главы. По каждой главе саммари. Дай мне саммари все книжки из глав уже. Окей, вот тебе саммари все книжки. И по оценкам оно делает это довольно недурно. Да, но когда вот этот GPT-5, как я предполагаю, будет использоваться для генерации вот этого body of plans и body of research про alignment и про социологию, про всё-всё-всё, про стратегию и про международную политику, это будет просто больше как этот research будет примерно делаться так же, как сейчас делается просто обычный научный research людьми, то есть есть учёные, они концентрируются на одной проблеме, они генеруют решения, но каждой из этих сетей не будет, ей невозможно подать вот этот общий контекст, чтобы она попробовала каждый кусок этого research вот таким образом забайсить, чтобы в общем это всё складывалось в такую байс картинку. Это просто как это объяснить? Это понятно, то есть как бы ты говоришь про проблемы масштаба, но почему ты думаешь, что на GPT-5 они остановятся? Или какой-то другой агент, другая компания не сделает GPT-6? Нет, тут можно ещё с другой стороны посмотреть, а людям-то в голову это влезет? Не влезет. Отвечу Ване, мне кажется, их план такой, они сделают GPT-5, и если они увидят, что она достаточно для генерации вот этого body of research за год, скажем так, они попробуют такие за год даже не релизя этот GPT-5, попробуют сгенерировать это body of research, опубликовать его полностью, и, грубо говоря, скажу, и это body of research в том числе включит там объяснения по поводу стратегии, по поводу перехода на вот это число будущего, не только теорию вот как оно должно выглядеть, но и то, как к нему прийти из текущего, из текущей мировой ситуации. И потом, грубо говоря, скажут всем, вот смотрите, ребята, вот такой план, давайте всем миром его пытаться анализировать, с помощью людей, с помощью ученых, с помощью других AI, и люди как такие муравьи или как такие тараканы попробуют весь этот план покритиковать и развивать. Ну, я, естественно, рисую оптимистичную картину, то есть я согласен, что там есть очень много вещей, которые могут пойти не так. Начать с того, что GPT-5 может, или GPT-6 даже, может оказаться неспособным генерировать хорошие вот такие главным образом стратегии. С наукой еще скорее всего сможет, а вот стратегии не сделают. Ну, то есть, это только одна проблема, там много, на самом деле, естественно, там факторов риска и факторов того, как это может пойти не так. Естественно, как ты сказал, что да, могут оказаться какие-то open-source хакеры типа Stalint и API, или просто какие-то, которые за это же время, потому что сейчас после GPT-5 огромное же количество внимания хакеров и академиков привлечено в целом больше к AI, и сейчас очень многие люди, просто там, не знаю, тысячи людей смотрят, а как реально работает. То есть, мне кажется, объем академик-эффорта, который сейчас вкладывается в то, чтобы все-таки сделать онлайн-learning эффективный, или сделать там, не знаю, какой-нибудь супердальний вот этот контекст, или сделать реально работающую генерализацию или там создание новых концептов, вот все эти проблемы как бы технически как бы технического ML, ML capability, у них сейчас гораздо больше внимания академиков, и вполне возможно там за пару лет все эти вопросы будут создание вот такого AGI, который онлайн-learning и будет там просто bootstrapиться на любой GPU-шке, возможно это будет всем недоступно, естественно, тогда план OpenAI, он станет вряд ли актуальным, потому что наступит уже совсем хал. То есть, естественно, рисков много, и вариантов как это может пойти, не так много, но никак. Вот они хотят сделать, так и не делают. И поэтому, скорее всего, они хотят максимально быстро сделать вот этот AGI достаточно, чтобы сгенерировать этот research, и в том числе research по тому вопросу, как предотвратить вот эту очень быструю демократизацию этой технологии, потому что тоже надо решить, как предотвратить вот создание и доступ вот к такому очень низкоресурсному, грубо говоря, на одной GPU-шке AGI доступный как каждый дом, потому что это, естественно, пока что имеет очень большие риски при текущей конфигурации. Кто-то может создать вирус и просто его напечатать как-то в биолабе, закусить, там много других рисков. Как-то все равно все грустно. Я надеялся, что ты как-то более оптимистичную эту тему принесешь. Вот она, технологическая сингулярность. Вот это претензия к гостю. Ты тему нес, нес, нес, нес, нес. Неправильно донес. Ваня, ну ты так гостей распугаешь. Согласен, согласен. Прости, пожалуйста. Я вообще не понимаю, зачем в контексте этой темы скатывать эмоциональный отклик. Роботы detected. Что, мы хотим поговорить про билд-систему Сталина Карты или хватит на сегодня? Нет, я уже не хочу, если честно. Можешь как-то прокомментировать, ты читал статью Sparks of Artificial Journal Intelligence про JBT4? Я, честно говоря, ее не читал, но я представляю о том, что там написано. Потому что там многие из кусков про аналогику видений, про theory of mind и про решение дно задач. Но это все по отдельности другими ресерчерами выковалось на владельцах. Они как-то это... Можешь вкратце... Насколько я понял идею этой статьи, это в том, что приводится доказательство того, что текущий JBT4 у него уже есть зачатки разума. В смысле, в том понимании, что он делает такое, что теоретически он не должен уметь делать. И это приводится как доказательство для того, что мы очень близки к IGI. Мы должны быть очень аккуратны при создании следующих моделей. И, соответственно, вся статья посвящена показателям, доказательствам, примерам использования, когда вот эти вот зачатки показываются. Ну да, я с этим согласен. Мне кажется, вот главный такой бастион, который остался с точки зрения... Один мы сейчас обсуждали пять минут назад, это способность такой очень, скажем, long-range контексту.",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 3974. Please try again in 7.948s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 3974. Please try again in 7.948s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
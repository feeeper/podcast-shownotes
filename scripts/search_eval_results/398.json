[
  {
    "segment_id": "cd96220b-a17a-4682-9d7d-cb768b89a374",
    "episode_id": "79703b9a-ad66-486a-b947-1bba87d95fcf",
    "episode_number": 398,
    "segment_number": 6,
    "text": "Во-первых, поддержка синтексиса Merge. Merge — это в первом приближении как insert onConfig, insert onConflict doSomething, но на стероидах. То есть, например, вы можете вставить данные в таблицу, а если там конфликт, то удалить какие-то данные, или вставить что-то другое, там generate series, или вы можете сделать truncate таблицы. То есть это такая более универсальная и более декларативная штука. В блоге CrunchyData как раз чуть ли не сегодня, а может вчера, вышел блог-пост, который чуть больше эту мысль раскрывает. В целом, Merge — это прикольно, это удобно, хорошо, что его добавили. Отмечаются ускорения, связанные с алгоритмами сортировки, сортировка данных в памяти и на диске. Матчмарки показывают, что на определенных нагрузках можно наблюдать ускорение от 25 до 400%. Стало быстрее, очень хорошо. Также отмечается улучшение производительности в оконных функциях. Если вы используете в своих запросах rowNumber, rank, denseRank или count, именно с оконными функциями, тогда в Postgres 15 это будет работать быстрее. SelectDistinct теперь может исполняться… запрос может быть распараллелен. Postgres FWD — это, напомню, механизм, который позволяет вкладывать запросы в внешние VVD, не обязательно только в Postgres. Он теперь поддерживает асинхронные коммиты. Я не уверен на 100%, как это работает. То есть ты говоришь на своем аксесс-поинте «коммит», но не ждешь ответа от сервера. Я не уверен, что такое асинхронность коммит в этом контексте. Тебе, Валера, это о чем-то говорит? Нет, я, к сожалению, вообще очень плохо все представляю, как именно Postgres FWD сделал. Я бы подозревал, что это настройка, которая… Я для себя понимаю Postgres FWD как вещь с настройками. Я примерно представляю, какой у него интерфейс со стороны подключения к Postgres. Блин, нет, не так скажу. Со стороны расширения я знаю, какой интерфейс у Postgres QL и FDW. Которые к другому Postgres QL подключаются, я без понятия. Я, опять же, не эксперт, мне кажется, там липпи-кью банальный. Ну да, но опять же, если так, кстати, то ты же при липпи-кью контролируешь ли ты… Ну да, обычно это просто… Но, наверное, я гоню, потому что у тебя в FDW есть всякие пушдауны в планах. И я с трудом представляю, как это через липпи-кью делается. Я, к сожалению, вообще не работал с FDW, когда это касается реализации расширений. Поэтому я предлагаю перестать гнать и пойти дальше по свистку. Согласен. Но может быть и в липпи-кью там что-то проброшено, я не готов сказать. Если вы специалист по написанию FDW штука для Postgres, вы к нам приходите, будем очень рады пообщаться. Rite-A-Headlock теперь может сжиматься встроенными средствами. Поддерживаются два алгоритма LZ4 и ZSTD. Нужно брать конкретные нагрузки и мерить, но предположительно у вас будет меньше диска IEA, у вас будет меньше потребления, собственно, дискового пространства, у вас предположительно будет быстрее рекавери. Но опять же, нужно брать конкретный железо, конкретные нагрузки и проверять. Также алгоритмы ZZIP, LZ4 и ZSTD теперь поддерживаются в PGBaseBackup. Это штука, которая делает бинарные и по большому счету единственные правильные бэкапы в Postgres. Потому что альтернатива это вот эти текстовые бэкапы через PkgDump, и они не так хороши, потому что конвертируют данные в текстовый формат. При дампе, при восстановлении, соответственно, нужно текст парсить и понимать, что он означает. Нужно перестраивать все индексы для всех таблиц, это дорого. Поэтому если вы делаете бэкапы, вы должны их делать через BaseBackup. Или альтернативные тулы, которые, по сути, как правило, используют BaseBackup. В случае рекавери баз данных, про рекавери мы сегодня еще вернемся в этом выпуске. В случае рекавери с UBD будут пытаться префетчить страницы с диска, на который Write-a-Headlock ссылается, на тех платформах, где это поддерживается и реализовано в Postgres. В Release Notes не уточняется, что это за платформы, а мне было лень разбираться, я рискнул предположить, что на Linux это должно работать. Так что рекавери стал быстрее. Занесли новые функции для работы с регулярными выражениями. RegExpCount, RegExpInstr, Like и Substr. Я не уверен, что такое Instr, но это можно выяснить из документации, если вы активно используете регулярки в вашем SQL. Я, кстати, не могу сказать, что я активно пользовался регулярными выражениями в Postgres. Бывает необходимо, когда ты реализуешь какой-нибудь… Я неоднократно уже сталкивался с задачей, видимо, попадая в такие продукты. Аналитика. Не обязательно аналитика, просто когда у тебя есть какой-то конструктор запросов, который в пользу дается или даже язык запросов полноценный продукт, на котором я сейчас работаю, PromQL, я работаю на PromScale, но он в частности поддерживает язык PromQL. Ну, с основным PromQL нужно переписать в SQL. В PromQL могут быть регулярки. И не я, правда, над этим работал, но у нас есть некоторые специальные костыли для поддержки регулярок. Там, правда, есть особенности, потому что я думаю, что те регулярки, которые здесь довезли, скорее всего, не подходят нам, потому что у регулярки… У регулярки, конечно, есть разные диалекты, и в PromQL, по-моему, другой диалект регулярок, чем в Postgres, я не помню детали. Как бы то ни было, использовать регулярки обычно пригодится не потому, что вы… Во-первых, просто когда вы выбираете какую-то аналитическую штуку пытаетесь сделать, вы действительно можете просто в запросе регулярку написать. Но что более часто встречается, это вы транслируете какой-то конструктор запросов или какую-то другую штуку, которую задает пользователь, и вот там вот где-то есть регулярка, и самый простой способ эту регулярку реализовать, это напрямую отдать ее функции по работе с регулярками. Тут есть, нужно быть, конечно, осторожным, потому что если это прям совсем производитель, пользователь может делать, то так лучше не делать. Но если это какой-то коробочный продукт или там не знаю что-то, что не торчит каждому пользователю вашего сервиса, так что он потом может поддоступиться к всей базе, то в принципе так делать, наверное, ок, мне кажется. Я в начале своей карьеры имел некоторое дело с аналитикой, и там были задачи, когда у тебя есть прям сырые текстовые данные, либо логи, либо, ну в том проекте мы хуес выгружали, тоже тексты, и нужно было регулярно проходиться, но в том проекте мы это делали тупо перлом, а можно взять Postgres, взять файл pdv, pdv файл, не помню как он шире называется, ну то есть вы можете делать запросы к файлу, и вот из него выгрести логи, пройтись по ним регулярно и в один запрос все получить. То есть по моим представлениям это в аналитике может быть полезно. Отмечаются улучшения в логической репликации. Очень важные улучшения, хочу заметить. Да, да. Теперь на стороне паблишеров вы можете указать, вы можете сделать row filtering, то есть указать предикаты, по которым будет определяться строка, она уедет или не уедет, а также указать списки столбцов, которые публикуются. Это очень круто, если вы используете логическую репликацию. Да, то есть раньше, если вы хотели на основе логической репликации построить какую-нибудь инвалидацию кэше или подобную штуку, вам нужно было довольно аккуратно с ним работать, потому что вы получали, если не ошибаюсь, можно было подписаться на отдельную таблицу или группу таблиц, не совсем на всю кэшу. Всегда было. Но если эта таблица high volume, то, короче, привет. Здесь же получается так, что вы можете отобрать только те апдейты, которые реально вам интересны. И это очень сильно повышает полезность логической репликации для таких подкейсов, потому что часто, если вы хотите инвалидировать какие-то кэши, то вы, скорее всего, действительно, притом так, что вы хотите прям проактивно это делать, то, скорее всего, вы действительно имеете дело с какой-то high volume таблицей. Так что да, крайне полезная штука. И там, как, собственно, упомянутые выше по выпуску, раньше по выпуску SubAbase, они прям такие, вот твит с анонсом о том, что PostgreSQL 15 зарелизился, и там вот в реплаях SubAbase такие, логическая репликация, апдейты к ней. Скажи, пожалуйста, у тебя были проекты, где ты использовал логическую репликацию? Нет, как бы я очень много раз хотел ее притащить, и всегда начинается, что начинаешь смотреть, как с этим работать, и такой, блин, ну, в общем, что-то как-то, вот тут нужно подставить кастылик, здесь нужно кастылик подставить, а может по-другому сделано, не знаю, на Tifa, Elison, например. Ну, то есть, я говорю, что, к сожалению, было слишком много вот этих вот, как это, задач с звездочкой, чтобы просто для какого-то такого проекта, которому не нужны реально все изменения в таблице, ее использовать. По моим представлениям, основной use case здесь также аналитика, то есть, когда у вас есть больше одной базы данных на разных серверах, вы хотите слить нужные вам данные в какой-то один аналитический сервер, то вот вы делаете логическую репликацию, фильтруете, только нужные таблицы реплицируете, все это в один сервер фигачите, а потом уже на нем можно анализировать. Ну, кстати, когда у меня был проект похожего толка, у нас там было скорее так, что была изначальная кавка-источник, из которого потом собирались разные базы. Но с другой стороны, если у вас есть какая-то операционная база, на основе которой нужно что-то собрать, то она как раз может, как раз ее стрим-логическая репликация может быть хорошим источником для того, чтобы наполнять такую кавку, из которой потом собираются другие базы. Что еще? Теперь можно писать логи в формате JSON. Основная причина, я смутно припоминаю по треду, что, к сожалению, я не перечитывал его и не прилинковал, а в Postgres при определенных условиях у тебя в лог-месседжах могут быть, может быть, больше одной строки на записи. И это очень сложно парсить. Вот с JSON у вас такой проблемы не будет. У вас будет одна JSON-строчка, которую потом можно как JSON пропарсить, а в нем уже будут многострочные строки. Это одна из причин его добавления. Выкинута поддержка Python 2, в смысле которой PLPython, потому что он уже 2-3 года за деприкейшен или end of life, я не помню, как это называется. Поэтому самое время. Если у вас в Postgres хранимки на Python 2, самое время иммигрировать. Для вас это также блогер с переходом на Postgres 15. Статистика теперь собирается через разделяемую память в Postgres. Раньше это делалось через, по-моему, в пайлике и сигналы. По историческим причинам, насколько я знаю, была такая реализация. Теперь у вас статис-коллектор реализован более эффективно, что есть очень гуд. Также теперь добавлено новое расширение, называется pg-valinspect. И оно как pg-inspect, и на самом деле в Postgres много такого рода расширений, которые позволяют смотреть в кишки, дают андроспекцию. Вы можете теперь прямо из Postgres, прямо на SQL, изучать записи в Red Hat логи. Это удобно в разных задачах, как то обучение, просто понимание, как СОБД работает для отладки разных хитро-выдуманных проблем. Я смотрю, Валера комментировал в карточке, но комментировал про логическую репликацию. Ага. Не могу не похвастаться, что я пару раз засветился в Release Notes, это так. Ой, не скромничай. Притом засветился какой-то так себе исправлением, но тем не менее. На самом деле много людей с Timescale засветилось, я по долгу службы составлял список, по-моему человек 5 из Timescale отмечен в Release Notes. Вот, есть ли у нас еще что-то по... А, знаешь, что самое главное в Postgres 15? Вот, вот, самый большой фичерк, который мне нравится. У них известна ценовая политика, Валер. Да, просто нанимаешь консультанта по Postgres. Ну, кстати, было бы прикольно, если бы был еще спрос на консультанта по... Или кидаешь деньги в один рыженький ДБАС. Было бы прикольно, если бы были востребованы специалисты по всяким там FLIT, VS Code и так далее. Но, насколько мне известно, вот прям контрибьюторы в VS Code, они не пользуются большим спросом, к сожалению. Я думаю, мы можем переходить к следующим темам. Честно говоря, Валер, я бы предложил тебе начать с NoFlag. Не начать, ну ладно, как скажешь. Я просто немножечко устал говорить. Я надеюсь, там сирену не очень слышно за окном. Не очень громко, нет. Хорошо. В общем, тут есть еще с прошлого выпуска принесенная тема. Спасибо, что дождались и не стали обсуждать без меня. Кстати, отмечу, на этой неделе почему-то не было записи вот этого Databases. То ли докладчик не дошел, то ли записи еще в обработке непонятны. Ну да, расписание должно было быть 10-го числа, по-моему. Я думаю, если почитать твиттер Инди Павла, то может быть что-то прояснится, но я что-то забил. Окей. В общем, Snowflake. Почему меня это заинтересовало? Ну то есть, я просто открыл карточку, Саша такой, типа, это лайки, манифесты, паркеты, ну и все. Фигня какая-то, неинтересно. Ага, манифесты, паркеты. Звучит знакомо, пойду посмотрю. И действительно, они там рассказывают про три вещи, но про одну они нам на самом деле ничего толком не рассказывают.",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 5905. Please try again in 11.81s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 5905. Please try again in 11.81s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
[
  {
    "segment_id": "aa95bcb3-8102-4967-9f83-7d56b7426beb",
    "episode_id": "70c8ca74-0a84-48fa-b51b-cc76e04230e9",
    "episode_number": 180,
    "segment_number": 2,
    "text": "Ну да. Ну, либо ты обычно знаешь, где твои джарнички лежат, ну это обычно точка SBT в твоем домашнем каталоге там чего-то-чего-то, ну в принципе туда можно все что угодно прилинковать, небольшая проблема. Ну то есть весь мир так живет, я просто выпал из этого мира. Нет, надо все-таки на это, как это, микросервис разбивать это на более маленькие кусочки, чтобы не было таких больших взаимных зависимостей, интерфейсы по какому-нибудь gRPC и все, поехали, все работает. Нет, ну реально, вот у меня 10 тысяч строчек кода и у меня 7 гигабайт, мне нужно бинарей для того, не бинарей, а всего вместе, для того, чтобы эти 10 тысяч строчек кода скомпилять C++. Ну жесть какая-то. Так, все, я поплакал. И связанная тема, это как раз по поводу зависимостей, работы с зависимостями, версионирование. Аналогично есть боль в Go, я правильно понимаю, Алексей? Да, следующий плач от меня. Следующий плач Ярославный от меня. Итак, что случилось, ну я не знаю, если вы следите за Go миром, ну или просто где-то рядом проходили, вы знаете, что в Go есть тресны, но и проблемы. Это отсутствие дженериков, отсутствие исключений, отсутствие нормального управления зависимостями, примерно в таком порядке, плюс-минус. При этом управление зависимостями там на самом деле все было лучше, комьюнити вокруг этого все работало, и тут на прошлой неделе случилась бомба, или прежде на прошлой, в начале этой недели случилась бомба, когда Роскокс, один из авторов Go, один из core-тим Go, проложил свое собственное решение, на котором он по-тихому работал несколько месяцев, и конечно, сообщество взорвалось, потому что это решение пошло прямо в противоположную сторону от того, куда шло все сообщество с инструментом, который называется ДЕП. То есть тут три больших аспекта в этой истории, один исторический, второй технический, третий, не знаю, социально-моральный, я бы так его назвал. Вот, я не знаю, наверное, можно в таком порядке кратко пройтись, да, что было... Обязательно. Окей, значит, сначала с исторического перспективы, то есть Go, когда только-только появился, он собирался makefile, makefile эти писались руками, потом постепенно появились include, когда ты вначале делал include одной части, потом перечисал в применное окружение все свои файлы, в конце включал как бы, как бы, эпилог, да, makefile, и оно все собиралось. Потом чуть позже появился телеты Go Build, которые автоматизировали на сборку этих makefile. Через какое-то время они начали уделять у тебя эту гонь стал, которая выкачивала исходники на Go из интернета, там, с гитхаба, с гугл сортс кода и так далее, и клала их в GoPath в нужное место, да, когда с GoPath концепция GoPath, а это то, где лежат все исходники на Go, появилась примерно тогда же. При этом эта утилита, она была абсолютно тупая, она брала самую последнюю версию, если флажок не был указан, да, если флажок был указан, то еще брала последнюю версию, если флажка не было, она ничего не делала, если исходники уже были, а если их не было, выкачивала последнюю версию точно так же, как флажков. Соответственно, эта утилита Go Install была перелаботана в Go Get, в версии Go 1, и вот мы до сих пор в Go с ней живем. То есть, когда вы делаете Go Get в какой-то пакет, если его нет, он выкачивает последнюю версию, если нет, ничего, он, в смысле, если уже есть, то ничего не делает. Соответственно, комьюнити это не нравилось, многие люди приходили из других языков, вообще, нет, шаг назад, почему было сделано так, да, почему нету никакого версии в Go Get. Причем еще-то, потому что когда Go разрабатывался, он разрабатывался внутри Google, и они не знали, как делать по-другому. У них так принято, у них монорепозитория, у них, когда ты меняешь зависимость, ты меняешь весь код, который от этой зависимости зависит, да, переписываешь, и есть внутренний мир, либо делаешь другой путь, другую библиотеку. То есть, по сути, когда ты меняешь библиотеку несовместимым образом, ты делаешь либо новую версию с другим путем полностью, либо просто, не знаю, меняешь название библиотеки в конце концов. И они сделали ровно так, как у них, потому что они просто не знали, как сделать по-другому. Причем это не мои домыслы, это они прямым текстом где-то писали и говорили. Соответственно, сообществу это не особо понравилось, с самого начала еще с Go 1.0 появились какие-то альтернативные решения, которые похожи были на как сделано в других языках, когда вы ставите какие-то пакеты, есть какой-то централизованный репозиторий, не знаю, качаете zip-архивы, какие-то эти токели. Все это не прижилось. Ну, сообщество тогда было маленькое, оно было очень противоречивое. Кто-то говорил, что централизация — это ужас, не надо, не надо. Кто-то там сильно пришел за то, чтобы типа все делал централизованно и пир-то-пир. Были люди, которые, нет, давайте с GitHub оставить, как сейчас, это правильно. Но забегая вперед, могу сказать, что когда люди говорят, что централизованное не надо, конечно, это интересно на это слушать, потому что и так сейчас все централизованное, все лежит на GitHub. Дальше было несколько таких больших мейнстонов в этой истории. Был проект GoPkgin, который по сути является прокси для GitHub, но знает, какие там есть теги, какие есть ветки, и когда вы делаете go-gets-go-pggin, он выкачивает вам нужную версию, которая прям в руле указана, там v1 или v2, там мажорная версия только. Следующий большой шаг был, когда в сообществе сказали, что давайте использовать CMVR, и плюс-минус все с этим согласились, но не очень было понятно, что делать-то. Как идея, давать CMVR-то хорошо, но конкретных шагов тогда еще не было. И чуть позже, где-то летом 16-го года, после американской конференции GoFairCon, собралось сообщество людей, которое за это все ротовало, и решило, что с этим надо что-то делать, пора уже, так сказать, взять в свои руки, несколько лет прошло, ничего не изменилось. Началось все с того, что они обсудили, как эта утилита для управления зависимостью должна выглядеть глобально, то есть какое должно быть поведение. К этому моменту какое-то количество утилит уже было, был GoDebs, GoVendor, Glide и так далее, они все работали, как большинство других экосистем, которые там... Есть команда для установки пакета какой-то версии, есть команда для деустановки и так далее. Вот этот комитет, который собрался, комитет в кавычках, на самом деле, потому что это было несколько человек, которые довольно хорошо общались, не как обычно в комитетах, они решили, что никакой этот развернутый интерфейс не нужен, по сути должна быть одна команда Ensure, то есть типа убедись, что все хорошо. Если все не хорошо, сделай так, чтобы все было хорошо, если уже и так все хорошо, ничего делать не надо. А на более низком уровне там система в чем-то похожа на многие другие системы, похожа на Cargo, в Rust похожа на Bunder в Ruby и так далее. То есть если у вас один файл-манифест, который указывает минимальные версии, которые вы хотите, есть отдельный лог-файл, который указывает реальные версии, которые используются. Деп, ну и дальше этот комитет начал делать инструмент на основе этого описания интерфейса, как он должен обратно. Его назвали Деп, это был официальный эксперимент. Официальный, как мне теперь кажется, это было не очень удачное название, но тем не менее, его назвали официальным экспериментом, начали делать-делать, наплылось какое-то комьюнити, теперь этот инструмент есть и большая часть сообщества Go разработчиков им пользуется. А как он называется? Деп. Деп. Все понял. И репозитория у него, соответственно, там github.com.go.lang.dep, то есть он лежит под аккаунтом Go.lang, что как бы придает ему статус официальности и немного уменьшает статус эксперимента. И тут случилась бомба, вдруг откуда ни возьмись, Роскокс, который один из разработчиков Go из Core Team выкатил в свою версию инструмент, который называется Vigo. Vigo это полный форк команды Go, то есть есть утилита Go, которая там делает сборку, получает новые версии и так далее и тому подобное, он ее целиком форкнул и добавил туда версионирование. Попутно он сделал много-много чего другого, то есть если вот прям зачитать его пропозал, он предлагает оставить самые лучшие части, которые есть в GoGete, а это основная часть, это простота, то есть вы делаете просто GoGet и последняя версия остается. Добавляет повторяемые сборки, то есть это означает, что если вы делаете Vigo билд, например, спустя несколько лет, результат получится точно такой же, даже если там вышли новые версии, изменился компьютер, все-все поменялось, мир вокруг поменялся, результат получился на тот же самый. Добавляет семантическое версионирование, убирает вендеринг. Вендеринг это концепция, которая есть в Go, когда вы все свои зависимости кладете в папочку рядом и тоже кладете ее в реплисдории, то есть есть отдельный каталог вендеринга, который немножко специальным образом обрабатывается в Go, то есть если вы используете какую-то внешнюю зависимость и ее нет в глобальном GoPath, но она есть в каталоге вендер, берется она. На практике это означает, что все зависимости, все исходники лежат рядом с вашей программой, написанной на Go, это называется вендеринг. И, соответственно, его пропозал Vigo вендеринг убирает целиком. Убирает целиком концепцию GoPath, которая была в основе Go даже до версии 1.0, то есть от GoPath, это место, где лежат все ваши исходники на Go. И, соответственно, добавляет миграцию нормальную с Депа и предшественников. Технически все довольно интересно, я бы сказал. То есть Роскокс написал за вот эту неполную неделю, с вторника по субботу, написал 7 больших статей, я бы даже сказал кое-какие из них очень огромные, про то, как это все работает. Я очень надеюсь, что он их писал заранее, а не прям в день по статье, потому что если он писал в день по статье, то это как бы немного возникает вопросы по поводу нашего собственного перфоманса. Почему мы не можем столько делать, сколько он делает. И он написал все большие-большие статьи про то, как все это работает. Тут очень сложно делать TLDR, но из того, чтобы я отметил, что это очень сложно. Во-первых, в Go появятся концепции модулей, которых до этого не было глобально совсем. То есть были пакеты, были репозитории, которые содержат несколько пакетов, были импорт-пути, которые плюс-минус совпадали с путями к репозитории, и точно так же они лежали на диске. Теперь появляется новая концепция модулей, которая является версионированной коллекцией пакетов, и в отличие от тех самых пакетов, которые тянутся напрямую с GitHub и так далее, это по сути представляется ZIP-архив. Соответственно, он может качаться с любого места, и его можно эффективно прешировать, использовать какие-то прокси. По умолчанию, если, допустим, вы исходники ставите с GitHub, и они качаются с GitHub там гитом, то, соответственно, модуль качается как тег из автоматически создаваемых GitHub-релизов на каждый этап. Вот, я не знаю. Если есть вопросы, вы можете прям вставать, походу делать предмет. Да, есть вопросы. Я так понимаю, что этот раскокс, он не состоял в этом DEP-комьюнити? Состоял. Значит, смотри, раскокс — это разработчик в Гугле, он один из core team в ГО. Ну, вообще, в ГО нет такого термина, к сожалению. Я про экспериментальный DEP, который. Нет, он не состоял в этом, не знаю, комитете, я тоже не люблю это слово, комитет, я бы не сказал, что это комитет, но короче, он не был в этой группе единомысленников, но он точно про неё знал, он точно с ней переписывался. Причём вся эта переписка была в публичном пространстве, то есть он явно был в курсе. Ему, как я сейчас понимаю, ему не очень нравилось, куда это всё идёт. То есть глобально, вот DEP, который сейчас есть, он работает так же, как и другие инструменты. Если, например, ты ставишь новую версию, ну, немного забегай вперёд, но ладно. Короче, если ты ставишь какую-то зависимость, он по умолчанию берёт самую новую версию, какую тебе надо, и обновляет другие зависимости, которые от неё зависят. Это НП полная проблема. То есть, по большому счёту, если ты хочешь, ну, у тебя есть какие-то существующие зависимости, и ты хочешь добавить новые, тебе нужно, там, перебором это решать или, там, SAT-солвером использовать или какой-то ещё хитрый алгоритм. Вот он до этого, вот ещё до Vigo, до всего остального, он написал статью про то, как эта проблема работает, в чём проблема, как другие инструменты это решают, плюс-минус, все решают её одинаково, там, с какими-то техническими решениями и так далее. Что он предлагает радикально изменить, это изменить подход. То есть, по умолчанию используется не самая новая версия, а самая старая. Вообще, мне вот эта идея очень понравилась. Вот, она бомбит, многих бомбит конкретно от неё, да. Я правильно понимаю, что на самом деле бомбит от двух вещей, что первое, он, ну, как бы никого не ставил в курс про свою работу, и такой выходит сумрачный гений, типа, ребят, я сделал, там, смотрите, как здорово, а второе, что он предлагает всё сломать и начать делать правильно. Я вот предлагаю вот эту первую часть, да, которую, там, как я сказал, не знаю, социально-морально отложительно потом. Это очень интересная тема, но давайте сначала с технической разберёмся. Вот, что касается того, что он предлагает всё сломать, так далее, вот с точки зрения совместимости ГО, ГО-1 позволяет это делать, потому что гарантии ГО-1 распространяются только на язык и на стандартную библиотеку, но они не распространяются на тулинговых, как всегда. Вот сейчас какой-то формализм включаешь, меня же интересует то, что у реальных программистов на реальных проектах начнёт всё ломаться, и новички, которые приходят в ГО, они будут читать туториалы, там, как работает зависимость и будут находить старые, потому что они, там, в Гугле давно проиндексированы, и на них ссылок много, и учиться делать неправильно, а потом выяснить, что, о, оказывается, там, с ГО-1, я там не знаю, 25, все уже делают совсем по-другому. Понятно, если всё, как вам написано, будет работать, в целом всё будет сильно проще. То есть концепция го-пафа, это, знаешь, это долгое время, ну, это такая фигня, да, которая работает, на самом деле, плохо, то есть мы к ней уже все и привыкли уже более-менее, это наш, я не знаю, как сказать, стагонский синдром, да, го-паф это, там, кто-то, кто, там, не знаю, не любит новичков в комьюнити, говорит, что го-паф это фильтр, который отсеивает всяких там неудачников, которые не могут это осилить. Другие люди считают, что го-паф, ну, к сожалению, он есть, его надо понять и принять, да, эта штука его убирает целиком, это большой плюс сам по себе, даже если избавиться от всего нового, это уже огромный плюс. Концепция того, что у тебя есть модули, которые версионируемые, и то, что ты можешь склонировать себе репозиторий и начать с ним работать, и не пытаться куда-то правильно положить файл в системе, настраивать примерное окружение, тоже большой плюс. Большой плюс то, что у тебя, как бы, повторяемые билды возникают, то есть зависимости, при этом у тебя нет вендеринга в таком классическом смысле, то есть у тебя нет необходимости класть большое количество исходников в тот же репозиторий, но при этом есть повторяемые зависимости, которые до этого без вендеринга не нельзя было. То есть на таком уровне все большие плюсы. То, что ты говоришь, что все это сломается, что реально все туториалы будут устаревши, это все правда. Но это как бы... Подожди, подожди, подожди, сломается. Он же делает новую утилиту, то есть то, как ты раньше работал, там, GoGet, GoInstall, оно же будет продолжать работать. А вот смотри, InfoGo — это тоже эксперимент, так же, как и DEP, это тоже эксперимент. От того, что это сделал Роскокс, который в Core Team Go, это не делает его более официальным решением. Что, к сожалению, многие в комьюнити не понимают. То есть бомбит опять же у многих с того, что типа чувак из Core Team такой спустился к горы с крышами и говорит, я вам все знаю, как сейчас делать. Нет, это эксперимент, это тоже такой же эксперимент. От него, возможно, откажемся, возможно, все будет совсем не так. Но если все будет так, как сейчас предлагается, никаких радикальных изменений не произойдет, то Vigo полностью заменит утилиту Go, как она работает сейчас. То есть по сути Vigo переименует в Go. Соответственно, когда ты будешь делать GoGet, старое поведение сейчас какое-то время отключат. Понятно. Не, ну вот это я бы не делал. Я к тому, что надо делать, чтобы старые предыдущие версии какое-то время работали, предыдущие версии документации старых пакетов и так далее. То есть сделай ее пока там Go-версии 2. Ну что, какой-нибудь дополнительный флаг. И ворнинги обязательно должны быть ворнинги. Вот, ворнингов не будет, к сожалению, точно. То есть глобальная философия Go и сборки, это верно, что ворнингов нет. Либо болтча, либо ошибки. Что касается переходной природы, он точно будет. Сейчас агрессивный план такой, что самое начало разработки 1.11 и в 1.11 это включить как опт-ин эксперимент. То есть нужно будет переменное окружение какое-нибудь поставить, чтобы это работало. И если все будет хорошо, никаких новых косяков не выйдет, в 1.12 это будет помолчание. Через какое-то время, не знаю, через две версии, например, в 1.14 старое поведение отключат. То есть это два года, и это на самом деле довольно агрессивно для Go в целом. То есть возможно, оно будет и подальше. А через какое-то время это заменится. То есть вендоринг точно так же входил. В 1.12 это был эксперимент. Если ты хочешь использовать вендоринг, тебе нужно было криминальное окружение поставить. В 1.16 если ты не хочешь использовать вендоринг, хочешь старое поведение вести, ты тоже стоишь примерно окружение. В 1.17 у тебя вариантов уже не было. Ты должен был использовать вендоринг. Если у тебя есть папка... На самом деле это не то, что ты обязан использовать вендоринг. Просто если у тебя есть папка, которая в случае получился так называться вендоринг, но используется для чего-то другого, тебе нужно было за год ее криминаловать. Поэтому сейчас это вот. То есть это не будет ломающее изменение, потому что ломающее изменение в Go комьюнити постоянно. Нет. Это такой наброс. Нет, подожди. Но тот же самый вендоринг, его точно так же внедрили. Хотя он по сути тоже ломающее изменение. Потому что нельзя иметь папку вендоринг, потому что предполагается, что там то, предполагается, что все работает вот так. Я бы сказал, что никакого тощего особо нет. Но да, если у тебя был каталог вендор и с 1 в 7 по умолчанию без вариантов он стал работать по-другому, то да. Но это нужно было особо постараться. То есть для того, чтобы... Ну, как работает вендоринг. По большому счету, если ты импортируешь какую-то зависимость, там не знаю, github.com, slash foo, slash bar, slash baz, и у тебя есть ровно такая же структура каталогов под каталоги вендор, то будет браться она вместо вендора. Но это нужно особо постараться, чтобы у тебя в вендоре лежал точно такой же путь, но при этом это был не каталог вендора. Вот. Здесь я думаю то же самое. То есть механизм здесь optin в том смысле, что для того, чтобы использовать новый механизм модуля, во-первых, тебе какое-то время нужно будет временное окружение вставить, а во-вторых, тебе нужно будет создавать файлик с описанием, говорить о том, что вот эта репозитория или вот этот каталог под каталог у меня является модулем. И там, соответственно, у тебя указывается вся зависимость. То есть это все равно механизм optin даже после того, как временное окружение уйдет, он останется, потому что этот файл должен быть. Вот. Давайте я скажу все-таки пару слов о самых радикальных идеях. То есть первая радикальная идея это то, что использовать минимальную версию, которая есть, а не максимальную. Что, конечно, во-первых, почему так? Потому что это сильно-сильно упрощает задачу установки зависимости. Мы делаем ее из NP, полной задачи, которая очень сложная и тяжело решает стреля, делаем ее тривиальной. Почему? Потому что старая версия не релизится. То есть даже если мы как-то сделали так, что мы сделали старую версию пакета, поставили старый тег, все равно есть еще метка времени, и время бежит и не идет назад. И, соответственно, нельзя сделать старую версию, нельзя сломать этот механизм. Также за счет того, что указываешь минимальную версию, да, и минимальная версия означает, что со старой версией твой код просто не работает, потому что он там использует какие-то зависимости новой версии или там есть супер критичный баг, который поправлен в новую версию. Дальше, по сути, версия, которая ставится, это минимальное из всех минимально возможных. Ну, скажем так, да, то есть если у тебя есть разные пакеты, развитие от одного и того же пакета разных версий, то из них всех берется, из этих всех максимумов берется минимальное. Если это возможно. Если это возможно. Следующий шаг, который они делают, они делают так, что, ну точнее он, делают так, что это всегда возможно. Почему так? Это тоже интересный вопрос, он нас отправляет обратно немного к концепции GoPath и к импорт-путям. То есть импорт-путь — это некая строка, которая так получилась, что она выглядит как место расположения исходников и на диске, и то, где оно лежит. Ну то есть простой пример. Если у вас есть там github.com.fu.bar.baz, это что означает? Что на GitHub есть трипозиторий, пользователя Fu под названием бар, и в нем есть каталог баз, в котором лежат исходники на Go. На диске оно лежит точно так же. В GoPath у вас есть SRC и дальше точно такой же путь. И эта концепция предлагает в серединку, вот между названием репозитория и названием каталога вставить версию, мажорную версию, только мажорную версию. При этом если это v0, когда можно ломать все что угодно, или v1, когда у вас гарантирована первая версия стабильности, ее там как раз нет. Если у вас появляется v2, то, соответственно, v2 вставляется в середину. На практике это что означает? Что на практике ваш код может использовать одновременно и v1 и v2, ну и там, не знаю, v3, v4, если вдруг есть и надо, в одном и том же коде. Потому что формально, с точки зрения компилятора, как оно все лежит на диске, и с точки зрения пакетов и модулей, это разные библиотеки. Несмотря на то, что они там, не знаю, имеют некую общую историю и так далее, это разные библиотеки. В Go нету настолько глобального стейта, который бы шарился между разными пакетами. Соответственно, проблема классической ромбовидной зависимости, когда ваша библиотека зависит от нескольких версий одной и той же библиотеки, и оно в итоге все не сходится, решается ровно тем, что это по сути разная библиотека становится. Это то, что сейчас не решается DEP, например, с другими инструментами. Почему? Потому что они не настолько глубоко интегрированы в tooling, в классический Go. В компилятор, ну не в компилятор, точнее, в Go build и так далее. Слушай, ну вообще классно. Ну я имею в виду, это довольно сложная проблема, если он прям так оригинально и решает. Вообще классно. Ну то есть в Go появятся, наконец, нормальные управления пакетами. Слушай, такими темпами скоро появятся генерики. Может, еще исключения, наконец-то. Нет, исключения точно нет. Генерики, ну понимаешь, Go становится похож на нормальный язык, но как бы мир-то меняется. Подожди, а ты закончил с этими большими изменениями или там еще что-нибудь есть? Ой, я вообще их много. Тут понимаешь, такая тема, ее сложно говорить TLDR. Я уже сказал, тут 7 больших статей, краткая версия, ее очень тяжело сформулировать. Из самых больших я еще отметил, во-первых, концепция модулей глобально, то есть это новое, то, что в Go еще не было. И, соответственно, когда в модулях указывается зависимость, там нет такого, что у тебя есть два файла, один манифест, и один лог-файл, когда минимальные версии реально используем, это один файл, в котором указываются версии, и это ровно они есть. То есть это и минимальные, и текущие одновременно. То есть сама концепция, что мы используем минимальные, это довольно радикально. У многих, конечно, бомбануло из-за того, что как же так, мы теперь не будем патч-релизы, хотфиксы, хардблит и вот это все. Но тут идея в том, что повторяемость сборок важнее, чем все остальное. То есть если ты через какое-то время взял эти исходники и начал их собирать, ты получил ровно такой же результат. Если там был какой-то баг несколько лет назад, он будет у тебя в новой версии. Соответственно, если ты хочешь обновиться до последних патч-релизов, ты либо руками, либо каким-то другим турлингом, либо флешкой, если его убедят, что это важно, это сделаешь. Большое радикальное изменение в том, что теперь все эти модули это zip-архивы. То есть до сих пор ничего такого не было, это все бралось из репозиториев, то есть это должен быть ягид, или svn, или базар, или mercurial. Теперь это zip-архивы, что, конечно, открывает большие перспективы для людей, которые хотят сделать или прозрачное кэширование, или хостить у себя в артефакторе, или не дай бог, кто-нибудь попробует сделать чередой сенсоризованной репозитории. Я думаю, что GitHub должен заплатить ему за это. Ты имеешь в виду за то, что меньше с GitHub будут качать? Да, да. Ну, может быть, да. Может быть, но надо понимать, что если у вас пакет на GitHub, то по умолчанию эти все релизы будут качаться zip-архиву из релизов. То есть на самом деле нагрузка же будет на GitHub, но да, она будет статическая. Самое главное, что она идеально кэширована, то есть релизные версии не меняются, кэш их всегда может положить навечно. Я не знаю, что еще такого большого-большого технического отметить, ну, наверное, вкратце-вкратце, наверное, все. И плавно можно перейти как раз к последней части, к социально-моральной, я бы так ее назвал. Проблема в том, что действительно Роскокс, когда это все делал, он не особо коммуницировал с внешним миром, то есть как потом уже выяснилось, он коммуницировал с Сэмом Бойером, который писал деп. И я тут смотрел видео, тут недавно вышло видео, где он, как раз Роскокс, Сэм Бойер и модератор, ну и Джесси Фрозелл тоже за компанией, они обсуждали как раз этот подход, там было видно, что Сэм, автор депа, он довольно, как сказать, расстроен, если это мягко говорить. Причем еще тут, конечно, очень многие это увидели, как такой чувак сидел на горе, что-то все придумал, пустил с ней вот вам знание, делайте вот так. То, что как бы он это говорит официально, вот почему я вначале говорил, что это официальный эксперимент, почему это плохо. Это люди по-разному воспринимали, что это значит. Один из них, например, акцентировался на слово эксперимент, как, например, сам Роскокс. Он это там несколько раз в рассылке писал, где-то у себя в блоге писал, он говорил о том, что типа, для меня эксперимент вот что такое, это как бы взяли, попробовали, восприняли опыт, все разломали. Сделали заново, попробовали, получили опыт, еще раз разломали. И так несколько раз. Другие, в том числе Сэм Бойер, автор депа, они акцентировались на слово официальный. То есть в их мнении это было так, что вот мы сейчас сделаем инструмент, не знаю, пофиксим баги, зафиксируем формат лог манифест файла и так далее. И после этого в команду go внесем как есть, ну там, не знаю, com.interface, то есть вместо там dep.insure будет go.insure, например. Вот, это две принципиально разные позиции, соответственно, люди из-за того, что это называлось официальным экспериментом, кто-то, не знаю, ожидал то, что это по первому подходу, кто-то по второму. Соответственно, те, кто думал, что это эксперимент, они все возрадовались, потому что это отлично, еще один эксперимент, радикально другой, минимальная версия, нет goPath, нет вендеринга, отлично, давайте попробуем. Те, которые думали о том, что типа это официальный, вот все, деп, это скоро будет вот-вот, они, конечно, такие, то есть типа окей, мы полтора года работали, там, контрибьютили, писали документацию, были там тесты, пробовали, и теперь это все как бы выкинуто будет. Вот, и при этом надо понимать, что, например, Сэм Бойер, с ним заключили контракт на то, чтобы он, типа, расскок с этой тулзой помогал, что как бы хорошо, окей, там, ему дадут денег, дадут работу, чтобы не очень расстрелывался. Но дальше там так написано, что типа он будет помогать, там, с импортом из депа, из других существующих систем. То есть, ну, на это тоже по-разному можно посмотреть, да, радикалы на это посмотрели как-то, типа, ему дают денег за то, чтобы своими руками свою работу уничтожал. Не очень понятно, как оно все как бы было на самом деле, за кулисами и так далее, но с точки зрения на это радикально разно. И, конечно, никто не радуется от того, что это случилось так все неожиданно, настолько, как бы, раз было чисто небо, и тут на тебя. И только-только там кто-то писал, что вот только я мигрировал на деп, да, или там кто-то писал, что только я убедил своих коллег, давайте мигрируем на деп, и тут на тебя новый инструмент, там, через, не знаю, через год, через полтора будет официально новый. Ну, то есть все было бы гораздо проще, если бы он коммуницировал и каким-то образом плавно подводил всех людей к этой идее? С одной стороны, да. То есть лично я считаю, что да, если бы это была более четкая коммуникация, более открытая и так далее, было бы лучше. Есть люди, которые придерживаются другой точки зрения, их документация тоже простая. Вот смотрите, если бы он так коммуницировался, так я смог бы ли он написать за 6 дней 7 таких больших статей, которые отвечают на все вопросы? Скорее всего, нет. Он бы все это время потратил на чатики, на комментарии, на почту и так далее. То есть то, что он там сидел 3 месяца на горе и придумывал, да, и пришел к нам в Скайджале, возможно, это плюс. То есть одни говорят там, что не фиксируйтесь на том, как он это сделал, важен как бы результат. Ну, тоже отчасти этих людей можно понять, но так себе я бы сказал. Это очень хороший вопрос, именно вот с точки зрения коммуникации внутреннего поведения в любой компании. Мне вот это напомнило то, что как-то раз мы пытались переводить людей со Скайпа на какую-то другую систему, я сейчас даже уже не помню какую. И всем не понравилось именно то, что вот внезапно пришли и сказали, а давайте попробуем перейти. То есть если бы всех предупреждали заранее, подготавливали к этой идее, все бы, может быть, и перешли. А так все настолько в штыки восприняли, что было очень сильно. Не знаю, мне нравится, когда кто-то приходит с каким-то готовым предложением. Это было бы лучше, чем если бы он пытался это сперва доказать, а вот у меня это может быть заработает, а может вот так вот будет. А тут у него все это готово, ты можешь потрогать руками и посмотреть. Ну смотри, я здесь могу добавить, если, например, мы берем компанию. У нас в компании есть программистов. И вот один программист что-то себе придумал и решил, что нужно это сделать, только потом говорит, что потом только представил свой результат команде. И вот смотри, у нас получается человек потратил время, а возможно, как это в системе ценностей этого программиста, это очень важная была задача, хотя с точки зрения компании, проекта и целей это вообще что-то неизначимое. И человек, получается, потратил время. И получается, что, в принципе, это полезная штука, но она совсем не приоритетная, и человек потратил, не знаю, неделю или пять дней, семь дней. И как бы, скажешь, что вот зачем ты это делал, либо делала. И такие ситуации просто у меня были в опыте. Я тогда была еще одним программистом в команде. И очень такие моменты были, когда человек куда-то в себя, и потом какой-то результат выдает, и почему ты этим занимаешься, а ты сделал. Вот у вас такие были примеры? И вопрос, Алексей, а сколько времени он потратил, Рескокс? Ну, из того, что я читал, я так понял, что он там... Ну, вообще, он в начале прошлого года, год назад, написал статьи типа «Мои решения», типа ну что... New Year's Resolution, короче, то, что я хочу в течение этого года сделать. Одна из вещей у него была, хорошо, про длительность зависимости. Я так понял, что к концу года он об этом вспомнил. Где-то с начала декабря начал этим заниматься, то есть я бы вот сказал, ну три месяца он этим занимался. Два с половиной, да. Да, то есть отвечая на вопрос Светы, тут понимаешь, в чем дело. То, что, по сути, Рескокс — это один из дизайнеров языка. Я бы сказал, что сейчас, в текущий момент, это, наверное, один из главных дизайнеров языка, может быть, самый главный дизайнер языка. Поэтому ему никто толком, так сказать, не может. Чувак, ты занимаешься фигней, давай лучше три месяца подумай, как Джеймеки сделает, а? Тем более, что я думаю, что на это время в суммарном же гораздо больше ушло. Ну да, есть смешные картинки на то, что типа вот почему я все время говорю «спускается с горы», «спускается с горы», потому что есть картинка, которая описывает, как Рескокс со скрижалями пришел, да, такой, типа к людям снизу там деб, там все что-то пишут, реально пришел с двумя скрижалями, скрижаль Джеймеки бросил, разбил, достал скрижаль, вот Виго теперь, нашей главной религии. Вот, то есть сказать ему, что типа не занимайся этим, ценности никакой нельзя. И он как бы и один из главных лексикторов ГО, и ценность большая есть, и проблемы важные, и решения хорошие. Но коммуникация, конечно, могла бы сильно быть лучше. Вот это боль, вот это я понимаю проблема. Не то, что у тебя с Бейзелем. На самом деле. О, слушай, я придумал, а давай всех гоферов на Бейзеля переведем. Ну, а зачем ГО два пакетных макетов, вот эти вот, и все внутри гуглажа. Ну, а в Бейзеле есть генерики, простите. Могу, кстати, смеяться, но на самом деле поддержка ГО в Бейзеле есть, но я просто не уверен, кто ей пользуется. То есть, если у вас проект собирается уже Бейзелом, и там есть какие-то куски на ГО, то да. А если у вас все на ГО, то точно смысла нет никакого. Надо сказать, что, кстати, вот несколько дней назад, там 16 июля, вышел релиз ГО 1.10. Я как раз сейчас вернулся только с релиз-пати ГО 1.10. И там большая вещь, которую завезли, это очень агрессивное кеширование результатов сборок. То есть, оно теперь зависит от контента файлов, а не от времени модификации, зависит, не знаю, в случае тестов, зависит от кода тестов, зависит от зависимости тестов, ну типа тестов файлов, то есть, реально. Но в целом глобально кеширование результатов очень агрессивно, и это очень сильно экономит время. То есть, это одна из тех фиш Базла, которая была. Как она, иммутабельность и кеширование. Вот теперь у нас в ГО тоже есть то же самое. Вообще в целом ГО прям реально развивается. Сейчас они ушли от ГО ПАТ, добавили вот это вот кеширование всех артефактов. Прям превращается в нормальный язык. У меня конспирологическая теория, а может быть такое, что, не знаю, Гугл, большая страшная корпорация, посмотрела на все это дело, такое, что там мои гоферы собираются там в комитеты, пишут какие-то тулы, как им вздумается, не бывать этому. Мы сделаем наш Гугловый расово верный менеджер зависимости, который мы решили, как нужно сделать, и сами будем его контролировать, чтобы там никакие комитеты не определяли судьбу нашего языка. Или не могло такого быть? Слушай, это отличная тема. То есть, я думаю, что корень проблемы примерно в этом. То есть, ГО был сделан Гуглом, и во многом это был язык, который на ранних этапах контролировался Гуглом. Сейчас влияние Гугла сильно-сильно меньше. Интересно, что изначально он был сделан просто чуваком в Гугле для себя. Ну, не совсем. Нет, я бы так и сказал. История возникновения ГО такая, то есть, эта байка, она как бы типа как притча и анекдот, но на самом деле так все и было. То есть, история была такая, что Кен Томпсон, который создатель языка Би и создатель Юникса, такой бродатый чувак уже, очень пожилой. Роб Пайк тоже, который там известен как создатель План 9, например. И Роберт Грейсмайер известен во мной, там не знаю. Одни из его заслуг — это то, что он был принципиальным автором и архитектором Java-ход споты. Вот они втроем работали в Гугле, они сходили на митап, посвященный новому смерти C++. Я не знаю, какой это год был, но я думаю, там 03, наверное, версия, что-то такое. Послушали про это все, вернулись к себе, и их одолела грусть и печаль, что как же так мы делали такие простые языки, типа Би, Си, Юникс сделали, все такое, а почему все так сложно?",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 20193, Requested 16194. Please try again in 12.774s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 20193, Requested 16194. Please try again in 12.774s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
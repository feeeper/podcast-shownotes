[
  {
    "segment_id": "718374bb-38b0-45b5-9951-7126c1e9f94b",
    "episode_id": "d672741e-0105-4c3e-aabe-30e003a0bf2c",
    "episode_number": 222,
    "segment_number": 14,
    "text": "вот просят вас бизнес и вот есть два варианта и короче, или, обычно раньше было два варианта можно начать писать на JavaScript возможно вы этого не хотите или нанять JavaScript разработчика возможно у вас нет на это денег и наконец вы можете теперь взять, просто включить немножко магии и когда у вас случается в JavaScript стороне какое-то событие, вам в актор прилетает записочка вы эту записочку обрабатываете берете кусочек HTML, генерируете и говорите, а вот этим кусочком HTML заменяется вот тот кусочек HTML он отправляется на фронтенд и заменяет кусочек HTML и все красиво, прекрасно вся логика живет только на написано только в одном месте на back-end, ваши страницы прекрасно индексируются я поясню, чтобы было понятно у вас получается соединение stateful с сервером то есть вместо того, чтобы соединение было stateless, когда приходит запрос вы делаете ответ, у вас получается на каждое соединение есть какой-то стейт внутри сервиса и этот стейт может на лету изменять логику, ну то есть как бы вам пришел запрос вот мне здесь увеличено единичку вот этот параметр, он выплевывает в HTML, где он увеличен на единичку по сравнению с предыдущими данными, которые были сохранены в стейте то есть это не просто глупо тупо запрос, который по WebSocket приходит это запрос, который имеет поддержку в фениксе на уровне получается фреймворка и это удобно, из-за этого становится очень писать это не просто слова, это на самом деле удобно, есть примеры вот прямо на страничке, когда у вас запрос выглядит в три строчки для того, чтобы там изменить реальные данные на странице но проблема-то такая мне кажется, что они здесь это очень пафосно написали но по сути область применения очень маленькая, ну почему? красная марка очень большая, потому что мне кажется, что несмотря на то, что там чисто технологически можно хот-треллу сделать, просто это уже довольно бессмысленно если вы не пишете прям вообще полностью вебап а мне кажется, большинство современного веба, несмотря на то, что нынче стало модно реакцию куда ни попали он на самом деле не нуждается в таком количестве адского джеба скрипта который выполнялся бы прямо на клиенте то есть там, за исключением Google Docs, Gmail, треллы вот таких вот проектов а для того, чтобы досту-ю от джеба скрипта нужно небольшое окно чатика ну ладно, окно чатика можно сделать просто мимо основного приложения просто строить какой-нибудь джеба скрипт код, который будет просто сам всплывать ну опять же джеба скрипт ну как бы неважно, я пытаюсь привести пример сейчас основное количество веба это новостные ресурсы ну такая весьма то, что я лично посещаю новостные ресурсы какие-то интернет-магазины какие-то площадки с курсами какие-то поисковики ресурсы по языкам программирования и так далее, то есть там везде есть максимум поля для поиска или какой-нибудь превью или там не знаю какой-нибудь интерактив с элементом с которым ты сейчас взаимодействуешь, что не знаю, нажимаешь на курс там выплывает рядом с этим какие-нибудь рекомендации что-то еще такое, то есть такой легкий уровень динамизма, который или тащить сразу много джава скрипта и там, чтобы он начинал делать запросы в разные места, все красивенько подтягивал или черт возьми, просто если пользователь начал взаимодействовать с каким-то элементом, ему нужно что-то интерактивное вот как бы ему показать, чтобы было клево и модно и веб-двонольно это просто делается добавлением небольшого количества логики на сервер, основное количество бизнес-логики будет сохраняться, оно у вас будет переиспользоваться и вот если вы опять же, вы не делаете большой специальный проект, который про приложение то, чтобы быть приложением в браузере у вас, наоборот, уменьшается количество работы Возможно, возможно, но здесь же получается, что у тебя все будет на взаимодействии с сервером Почему все? У тебя все еще, как бы, смотри для начала, если ты не открываешь свой веб-сокет то у тебя все еще прекрасно рендерится статическая страница Ну вот, пожалуйста, если у тебя Но я имею в виду, если тебе надо что-то динамически делать любое динамическое изменение, то у тебя взаимодействие с сервером, насколько у тебя большая а раньше Ну, то есть, как бы, JavaScript генерится на client-сайте, у тебя не надо ничего делать Я понимаю, о чем ты, но давай так, если вам нужно Более того, подожди, да, я до конца скажу Большинство крупных теперь текущих страниц типа того же Gmail'а, который мы уже не раз ругали который стал очень громоздким, большим но за счет этого он делает большую предпокачку и большую работу как бы для ускорения работы на client-сайте я нажимаю на кнопку и там реально сразу появляется что-то. Он долго загружается зараза иногда слишком долго, но когда ты реально работаешь с ним, он у тебя минимальную информацию для отображения сразу тебе отображает без того, чтобы что-то обратиться к серверу А здесь получается тебе для каждого взаимодействия, для любого изменения у тебя поменяется, кто-то что-то печатает да тут же самую строчку поиска Ты вбил две буквы, тебе как долго придет запрос? Ну, то есть, ну, скажем, у тебя 100 миллисекунд обработка, да, пошла туда-обратно Ты можешь, ты в любом случае вбил две буквы, ты в любом случае это не сделаешь без взаимодействия с сервером просто никак, тебе нужно это completion с сервера подтянуть Ну, здесь согласен, здесь я пример не тот привел И почти любой интерактив, за исключением анимации, которая просто анимация оно все будет требовать какого-то взаимодействия с сервером, большинство ребята на самом деле, в принципе, делали даже там типа змейку на этом Вот этот пример, это самый страшный пример, который они могли привести Ты представляешь себе змейку на этом сделать? Это именно, что пример в том плане, что он показывает Что во всяком случае, чистого слово фреймворка проблем с тем, чтобы был в меняемой ленте нет Да, если ты будешь сидеть там, типа если у тебя сервер в Европе, а ты будешь пытаться изыграть змейку из Америки, тебе будет неприятно Но это знаешь, это единственное ограничение этого подхода Вы просто вы вот не делаете змейку на этом Но опять же, это того же, что говорил Да даже если змейка будет в Европе, и ты в Европе ты все равно не сможешь в нее играть Да смогу я в нее играть Да ладно тебе Ну давай же Мы в прошлый раз Рассуждали, что или в позапрошлое, когда мы говорили что лейтенси после того, как ты нажал на клавиатуре может быть до сотен миллисекунд для отображения на экране на твоем же компьютере без обращения к серверу Слушай, у тебя до сотен миллисекунд У тебя пинг внутри континента, он будет он зачастую 25-30 миллисекунд допустим, самый оптимальный случай То есть получается, что тебе 20 миллисекунд у тебя ушел туда запрос 20 миллисекунд он придет обратно непонятно, ну 30 ладно, сколько он там обрабатывается плюс для отображения этой информации да блин, в эту змейку я замучаюсь играть Это даже не важно Да нормально До 200 миллисекунд нормально А, началось, мы это в прошлый раз обсуждали Это нормально, еще раз, вот в шутер ты играть не сможешь Я просто играл Я в Лаллиц играл при таком лейтенсе когда в Корее был на европейских серверах там 300, но пинг был Ну и как бы играбельно в принципе Ну то есть в шутер играть не сможешь Но нажимать кнопку вовремя сможешь А я не согласен Я считаю, что змейка с 200 миллисекундами это уже нереально С тобой разговаривают два человека, которые регулярно играют в игры Я вообще не знаю Моя актуализация Кто-нибудь может сказать самое главное Ключевое, что подкупает в этой штуке То, что оно стоит, хранит или что Или то, что легко написать Самое главное, да, что тебе не нужно быть одновременно То есть тебе во-первых вообще не нужна никакая дополнительная фронт-энтент разработка Кроме того, что у тебя уже и так есть две статики Во-вторых, поскольку у тебя логика шарится ты тупо быстрее будешь фичи пилить То есть это знаешь, как в свое время рельсы было очень клево Я вот смотрел Говори, говори В отличии от Node.js, например, не особо большая разница То есть я бы на Node. js не больше кода бы написал для для такой работы, думаю Ну в смысле, тебе же нужно оно будет подменять кусочки дома сразу То есть это же не просто работа с WebSocket Это же работа сразу с обновлением UI-элементов на основе UI-событий Это все уже за тебя сделано Я как-нибудь по-моему с React. js что-нибудь бы намутил, он бы тоже и дома и все это делал Правда, оно громоздким бы, конечно, было Ну вот начнем с того, что оно минималистичное Во-вторых, оно Ну, кстати, я не уверен, что оно на клиенте используют Во-вторых, за тебя сделана вся работа За тебя остается только бизнес-логику закодить И как бы отдавать Фактически те же самые аргументы, что для Node.js Нет, в смысле, подожди Node. js сама по себе, я не знаю, там наверняка тоже может быть есть какой-нибудь такой фреймворк, который рендерит и там и там Но Да есть, есть, который на серваке рендерит Ну просто к тому, что нужно же здесь, чтобы и на серваке рендерил и отдавал И на клиенте обновлял Да, и на клиенте обновлял Ну то есть, я не знаю, наверняка есть Но просто фишка с JavaScript в том, что Да давай, говори ты потом, я В общем, как бы для меня здесь Плюшка в том, что у тебя логика вообще одна Она задеплойна в одном месте, обновляется в одном",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 4414. Please try again in 8.828s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 4414. Please try again in 8.828s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
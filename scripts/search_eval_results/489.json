[
  {
    "segment_id": "1d1d1b7d-659a-4b22-b5bd-5409cba3a898",
    "episode_id": "a7c18da9-e693-479b-bf8c-02f9a870b6ab",
    "episode_number": 489,
    "segment_number": 6,
    "text": "Ходыщь. Сейчас появится, появится. Да что ж такое долго не появляется. Мда. Я пока отойду за мрамором, а то потом забуду. Давай, отходи пока за мраморным, а я пойду по темам. А первая тема опять требует, наверное, комментарии либо Саши, либо Валера с теми из блога Namescale о том, что остальные делают векторные базы неправильно, и их предложение правильного подхода это PG AI векторайзер. Сейчас спросим у Саши. Пока перейдём к следующей теме. А следующая тема мне показалась прямо интересной. Я думал даже покупать винчестер новый для NASA, а тут как раз свежие данные по отказам дисков от Backblaze. И это прямо интересно они накопили много статистики по тому какие диски, сколько у них они работали, сколько было отказов. Коэффициент отказов, и, соответственно, несколько графиков. Мне очень понравилось всё это читать и наблюдать. Единственное, что я не очень понял, я не сталкивался до этого с изготовителем HGST. Алекс, ты сталкивался? Звучит знакомо, но я им не пользовался. Мне кажется, я видел его как встроенные диски в одном из ноутбуков, которые у меня были. На самом не покупал никогда. Потому что остальные выглядят знакомо. Вот. И этот GSC, почему он меня заинтересовал, тем, что у него коэффициент отказов был самым низким в 22 году и стал самым высоким в 2024. Но внезапно теперь я уже даже не хочу покупать, хотя изначально думал. Вот. И по коэффициентам отказа получается удобнее всего пользоваться WDC, WDC или Toshiba. Вот один из этих двух производителей. Причём у них тоже по разным, видимо, от серии зависит разного размера, а диски с разной скоростью отказывают интересно что мне интересно в этом графике это почему-то абсолютно у всех производителей повышенная доля отказов в третьем квартале 2024 года что произошло в третьем квартале Кто-то громко кричал в дата-центре или что в общем? На самом деле шутки шутками, но интересно насколько это может влиять такие вещи как допустим отказ питания в дата-центре. Если у них был квартал где у них там не знаю много аутеджи было физической инфраструктуры возможно это как-то повлияло на статистику. А ещё может быть завязано на то, кто когда покупает диски. То есть у тебя идёт покупка дисков привязанная к какому-нибудь финансовому году и у тебя это может быть ну то есть грубо говоря у блэк блейза. Может быть они покупают прошлогодние там и так далее поэтому большинство отказов получается тоже в одно время. Ну вот если посмотреть на третий квартал 23 года который тоже на графике присутствует там как раз наоборот на понижение шло. Зато гляди второй квартал 2023 тоже подъем у всех. Возможно, это как раз связано с тем, что они покупают их по теме и в какой-то момент эта партия начинает вся группой ложится, изнашиваться. Да. Ну общий, чтобы вы понимали, общий коэффициент отказов в районе 1-2-3 процентов это как считается этот IFR anyolized failure rates то есть вероятность что в одном в какой-то год сломается какой-то диск да то есть процент от оказывать за год вот если у тебя один 1-2-3 процента за год, это в принципе нормально. Имей несколько дисков, и вот у тебя получается вероятность того, что информация выживет, довольно большая. Спасибо большое за ссылку. Прям интересно поглядеть это круто хотелось бы чтобы они такую же статистику еще по SSD опубликовали потому что это у меня например сейчас практически все мои дома компьютеры не жесткие диски используют ssd даже вот нас я собираюсь собирать но я думаю что скорее всего напихаю в него ssd. Да ладно прям по-настоящему ssd засунешь? А у них в цикле? Скорее да чем нет. Ну по надёжности они вроде как сопоставимы с жесткими дисками мне больше скорость у них потребление энергии теоретически это на самом деле такое я глупостями балуюсь но вот короче сижу и думаю что они тихие в них ничего не двигается никаких механических деталей если их хорошо охлаждать то они наверное даже и жить будут лучше но не знаю вот если бы кто-то опубликовал исследование то было бы очень здорово ты просиузывай и все время жизни Да. Ну вообще у Nandflash ограниченное количество циклов перезаписи. Так что там все должно. С другой стороны на нас я скорее всего буду писать в среднем меньше чем например на мой обычный компьютер. А на моём обычном компьютере они как-то даже не знаю, когда у меня последний раз SSD сдох давно. Редкое событие, в общем. Пишут, что вот этот вот H, как я уже забыл произноситься, что это Hitachi. В чате пишет lexeee. Может быть, на самом деле Hitachi, а я что-то даже Как там он назывался? Я уже закрыл эту вкладку. Ну и ладно. Hitachi так Hitachi. Саша, мы до тебя ждали, потому что первая тема, наверное, для тебя. А может, подойдём Валеру? Статья из блога Timescale о том, что остальные делают векторные базы неправильно, и правильно надо делать через PG AI векторайзер. Понятия не имею, что это значит, но вот ссылка на блог и на GitHub. Ну, я не читал. А что, хорошая статья? Ну или предполагается, что я читаю все статьи из блога TimeScale. Их там довольно много. VectorAiser, тем более на гитхабе выложено. Но я PG Vector пробовал, то есть конкретно PG AI я не пробовал. PG Vector хорошее решение. Если вам нужно рекомендовать похожие некие сущности, то есть у вас там интернет-магазин и вам нужно на главной пользователю порекомендовать нечто похожее на то, что он смотрел недавно. Например, как бы Purevector хорошая тема. EPGAAI, я так понимаю, то же самое, но немножко другое. В чем отличие? Надо изучать. Подожди, там в названии прямо AI. Всё, где в названии AI намного лучше. Ну так-то да. Но мы с тобой не инвесторы, поэтому не работает, мне кажется. Согласен. Наоборот работает. Следующая статья это Antires написал короткий пост про то, как мы разрушаем софт. Если честно, мне прямо понравилось. Я не согласен вообще ни с чем, но мне прямо понравилось. Antires молодец, красавчик. Я не читал, расскажи. У него статья, большая статья на полторы страницы формата 4, написана огромным шрифтом, не знаю, 17-м, 20-м. Фактически 20 предложений. Каждое предложение начинается с того, что мы уничтожаем Software, а дальше объяснение, как мы уничтожаем Software. То есть как бы первое предложение мы уничтожаем его, потому что мы не принимаем сложность complexity во внимание, когда мы добавляем новые фичи. Второе приложение мы уничтожаем software сложными build системами. Третье мы уничтожаем сумасшедшими зависимостями, цепочками зависимостей, делая это всё очень ненадежным и быстро ломающимся. Вот. И в целом как бы тут много чего хорошего, с этими сферами я частично согласен. Но есть там куча всего, где говорится, что мы не думаем про сложность, мы не делаем, мы не продумываем дизайн, мы делаем тяп-ляп, лишь бы быстрее в продакшн. Ну, я не знаю, это всё сильно зависит от того, где ты работаешь и чем ты занят. То есть я работаю в инфраструктуре и за последние кучу лет постоянно с тебя требует скорость, но везде культура такая, что с тебя требуют очень хорошо продумать про дизайн, очень сильно подумать про совместимость по API, очень сильно подумать о том, как правильно расширяемость сделать поддержку расширяемости или нагрузочное тестирование и поддержка нагрузки в дизайне и так далее. То есть как бы масштабируемость вот это всё на моей работе. Это требуется постоянно, и я с половиной пункта из-за этого в его статье вообще не согласен. Мне кажется, что сравнивать твою работу со среднестатистической софтовой компанией не очень корректно, да? Согласен. Но как пользователь софта я могу сказать что хуяк хуяк и в продакшен он абсолютно имеет место быть и кубер затаскивают туда он не нужен. И API, модный фреймворк используют, потому что он модный. И все побежали, и я побежал. Что? Так нет, Олег же говорит только про случай, когда он не нужен. Когда он нужен, то конечно. Что примерно никогда. На самом деле я тут недавно пересел просто по интересу на VSCode. Я в свое время его и забросил, потому что он тормозное, ужасное м-м м-м м-м м-м м-м м-м м-м м-м м-м м-м м-м м-м м-м м-м И оказалось VS Code быстрый такой, отзывчивый редактор, мало чем по скорости уступает Sublime. Я отлично помню время, когда я на Sublime просто молился, потому что он быстро работает и мгновенно отвечает, в отличие от VS Code. И я поэтому как бы да, на самом деле, как пользователь, я уже вижу, да, что я готов сесть на VSCoda, хотя я понимаю, что в VSCoda количество уровней абстракции, наверное, ушло давно за несколько миллионов, там нули замучаешься считать. Про VS Code я бы сказал, что тут он выиграл из-за того, что он опенсорс. Sublime был хороший с самого начала, но закрытый, а VS Code он был опенсорс и многие компании начали в него инвестировать ресурсы инженерные. Поэтому странный электронный пилкин превратился в на самом деле довольно сносный кусок софта. Одна небольшая компания вложила довольно много ресурсов в пиар этого опенсорс редактора. А это в свою очередь привлекло дополнительных атрибуторов. Я не могу об этом говорить, но я знаю, что больше одной большой компании существенно заинтересованы в успехе и хорошем качестве ВС кода. Вот. Короче, читайте интерес, у него всегда интересные Вообще по поводу статьи я бы сказал, что в целом он по факту прав, но дело просто в том, что большая часть программирования она происходит не ради искусства программирования, а ради того, чтобы заработать деньги как можно быстрее. Ты о чём сейчас? Я говорю о наболевшем. Закрой уши, если тебе больно. Нет, я согласен. То есть, во-первых, я согласен с интересом, особенно про пункт, что часто не принимается во внимание сложность того или иного решения она все равно тащится вот это я о наболевшем очень много то есть как по-хорошему в моей идеальной картине мира выглядят программирование? У тебя перед тобой сложная задача и очень сложное железо, какой-то физический мир, с которым ты взаимодействуешь, бизнес логика. Ты строишь некие примитивы, которые решают маленькие задачки. Потом ты собирая эти примитивы, решаешь более сложную задачу. Всё это хорошо документировано, протестировано. И так ты из маленьких кубиков собираешь большую систему, но каждый отдельный её элемент логичен, понятен, правильно устроен. Реальные большие сложные системы, особенно которые лет 30 разрабатываются, они нифига не так устроены, у тебя всё взаимодействует совсем у тебя здесь в этой системе предполагается что там в другой части системы там что-то каким-то определенным образом работает и как бы не дай бог кто-то случайно это поведение нарушит тогда вот в той части системы ты это меняешь, а в той и в другой части системы это ломается. И у тебя энное количество фич, которые когда-то были добавлены, которые уже, скорее всего, нафиг никому не нужны в 25-м году, но выбросить ты их не можешь, потому что ну ты сломаешь обратно совместимость понимаете вот то есть это первое да про сложность я это вот прям вот в сердечко прям самое вот во вторых я согласен с Алексом что у тебя есть программирование которое вот как бы для себя для души а есть там заработать денег ну чтобы чтобы тебе было на что жить еще неплохо бы там как-то откладывать накапливать да понимаете вот и это две совершенно несовместимые вещи вообще. Поэтому желательно вот на работе мы зарабатываем деньги, а для души это уже потом в свободное время. Потому что когда ты пытаешься совмещать, по моему скромному опыту это ничем хорошим не заканчивается. Заканчивается какими-то волнениями, переживаниями, которые ну зачем тебе они нужны? Всё так, пошли дальше. Следующая тема. Microsoft закручивает гайки. Будем про Microsoft? Ну ладно, давайте. При выходе Win11 в 2021 году они опубликовали способ обойти проверку наличия TPM Trusted Platform Module, чтобы можно было обновиться с 10 на 11. Теперь, три года спустя, они убрали описание этого способа и просят тех, кто это сделает, катиться обратно на Win10. Я ощущение специалиста. Катиться обратно это звучит чрезвычайно странно, потому что если бы я был Майкрософтом, я, конечно, не хочу поддерживать пользователей со старым железом, нужного мне TPM, но я еще меньше хочу пользователей переходить на старую версию продукта, которую я совсем не хочу поддерживать. Я не понимаю, как это может работать. Ну и что, большая толпа людей прямо побежит выполнить инструкции и перейдет обратно на Windows 10 или что? Может им в какой-то момент придёт патч и он автоматически всё продаунгредит. Автоматически это ещё может быть. Но вот так, чтобы попросить людей а давайте вы придёте и обновите себе на предыдущую версию. Я не знаю, это звучит странно. Возможно нужно копаться в деталях, но опять же я там же в канале жаловался, что у меня вот компьютер, с которого я сейчас вещаю отлично работает, но в нём нет TPM 2.0. Но у него с производительностью всё нормально, игры на нём идут, мои компиляторы летают, вес код работает без проблем. Даже хром не может съесть всю память, потому что я напихал туда памяти сколько мог. Я не хочу менять всё своё железо просто потому что там не хватает какого-то глупого типиэма. Но в какой-то момент Майкрософт перестанет поддерживать десятую Винду и у меня будет выбор либо менять всё железо, либо переходить на какую-нибудь другую операционную систему. Не вполне уверен каким путем я пойду, но пока что менять все железо кажется непривлекательной задачей. У тебя есть третий вариант это в какой-то момент перестать обновляться? Это быстро перестает быть приемлемым вариантом, потому что как только zero-dea перестают закрываться, они перестают быть zero-dea и у тебя начинают появляться жильцы на твоём компьютере, которые тебе аренду не платят. Твоё железо используют. То есть с антивирусами всё так же плохо, как лет назад. Мне казалось, там есть определённый прогресс. В принципе, там zeroday, не zeroday, но если у тебя антивирусные базы обновляются и продукт нормально сделанный, то они вроде срабатывают. Жрут ресурсы какое-то количество, но тем не менее работают. Это всё становится сразу сильно сложнее, менее приятно. Если уж не заниматься какой-то акробатикой, то я лучше уж ей буду на Linux заниматься. Но там же нет игр. К тому же, как мы установили, благодаря Валву теперь все игры идут на Линуксе, так что зачем вообще Винда нужна? А как вообще все игры идут на Линуксе? Ну конечно не все, но многие, потому что протон вроде как хорош. Окей, пошли к следующей теме. Следующая тема промежуточные практически результаты использования Rust в Linux. Пока получается не очень, скорее даже совсем не получается. Смесь Rust и C и две ссылки на net про кризис продвижения Rust в ядро из-за опасений и так далее. Я не читал ссылки, я не слежу за Rust в Linux. Кто-нибудь знает? Читал? Я не читал статью на Opennet, но я смотрел какие-то другие ссылки, которые потом в канале постились и кажется, что в общем-то типичная ситуация, когда есть группа разработчиков, которые считают, что не надо нам ваше все это новомоднее дерьмо, нам их сложно, не хватает нам еще ваших этих странных новых языков. А есть другая группа разработчиков, которые сидят смотрят на всё это и думают, что Господи Боже мой, да сколько можно вот эти старые опасные инструменты использовать, Нельзя так жить, надо как-то переставать заниматься мазохизмом. И разработчики договориться не могут в данный момент. Там одни контейнеры ядра считают, что раз это в общей сложности добро, другие считают, что это того не стоит. Это дополнительная нагрузка, сложности, дополнительные зависимости, компиляторы и ещё бог знает что. Ну и видимо до тех пор пока они не придут к какому-то консенсусу вот эта драма будет идти там. Я так понимаю последняя итерация этой драмы была спровоцирована тем что Гектор Мартин который работал над Асахи Линуксом и в том числе контрибьютил растовый код в ядро сказал что я устал я муха жук и в том числе потому, что так тяжело коммитить раст в ядро, потому что в ядре его не хотят принимать. Я ему сочувствую, в целом я скорее одобряю раст, чем осуждаю. Но в общем, мне кажется, что это меньше инженерная проблема и больше проблема поиска консенсуса между людьми с разными приоритетами. Вот я как раз хотел спросить. То есть я знаю, как это в образцовом сообществе работает и для меня не очевидно почему эта проблема в других проектах. В общих чертах идея такая, что у тебя по умолчанию патчи или какие-то идеи отвергаются. Когда они отвергаются? Кто-то приходит в сообщество и говорит: А давайте начнем в прогрессе использовать раст или си плюс плюс или ди ну там как каждый раз какой-то какая-то новая модная технология появляется вот завязывается тред и в треде люди высказываются да что там я считаю это будет хорошая идея я считаю что это будет плохая идея И по результатам тренда на 100+ сообщений как бы вырисовывается вердикт, что это предложение controverial. Поэтому оно отклоняется. И когда в следующий раз кто-то приходит в тред, что а давайте там podgress перепишем на раз, ему говорят, что, пожалуйста, не открывай эту Can of Warms, потому что вот смотри, треды 1-2-3, мы это уже много раз обсуждали. Можешь их почитать и понять какому вердикту мы пришли. Мы в смысле в целом позгорцовое сообщество. То есть если идея контровершал, то она отклоняется и больше мы к ней не возвращаемся. Все И ни у кого нет особых переживаний на этот счет. Почему это в Ленуксе драма? Потому что нет такого механизма, что мы уже отклонили эту идею. Она вот так и продолжает сообщество к ней возвращаться снова и снова? Тут дело в том, что её не то что не отклонили. В ядре уже есть код на Rust. Это в чём проблема? Я так понимаю особенность проекта Linux в том, что у них есть некоторая иерархия майнтейнеров, в которой каждый отвечает за свою часть дерева исходников. И некоторые из этих майнтейнеров считают, что наоборот раст нужно тянуть и они принимают патчи, но другая часть мейнтейнеров они считают, что раст это зло, рак и убьёт ядро. И поэтому в свою часть исходников они отклоняют патчи. И в итоге, когда ты хочешь заимплементировать что-то, что трогает два вот этих лагеря, у тебя оказывается проблема. Потому что там один мейнтейнер и не против замерить твой растовый патч, а другой мейнтейнер считает, что нефиг заниматься всякой ерундой и пишите на С. И ты оказываешься в неловкой ситуации, когда в общем как бы разработчики и майнтейнер одного и того же проекта не могут между собой договориться, а ты как третьесторонний контрибьютер вообще не знаешь что с ним делать. Ну возможно, я не всю специфику знаю. У Linux, как нам известно, есть некоторое количество своей специфики. Но для меня как стороннего наблюдателя это звучит как какая-то не очень здоровая ситуация. То есть, вроде как уже есть консенсус, что в проекте используется язык Rust, а потом у тебя в проекте появляются люди, которые как бы это саботируют. И у меня тогда вопрос вот к этим людям. Но в то же время у тебя возникает неудобная политическая ситуация, потому что а что ты с ними сделаешь? Ты их никем толком не заменишь. Странная, нездоровая ситуация, непонятная мне. Я рад, что не работаю над ядром Linux, если честно. Ну так, я сказал, это не техническая проблема. Сейчас это уже проблема просто людям договориться. И у людей есть разные предпочтения, технические мнения и обидки на ту или иную часть сообщества. Поэтому не знаю, мне кажется, рано или поздно либо они договорятся, либо Линус выйдет и стукнет тапком по столу и скажет, что будет, как будет и всё. С практической точки зрения, как бы если вот новые. Если бы передо мной стояла задача поправить код, я знаю про эту специфику, потому что мне предстоит править больше одного места. Получается мне предстоит писать код на Си. Но если я хочу, чтобы мой патч был принят или я потрачу время впустую. Получается так. А если ты хочешь написать большой и сложный графический драйвер, который ты не хочешь писать на сип, потому что ты заколебёшься всякие там небезопасное использование памяти на нём отлавливать, тебе нужно потрогать два API, для которых нет растовых бандингов. Смотри, есть два варианта. Если я это делаю по фану, то у меня есть вариант завести себе другие хобби. Если я это делаю по работе, то выбор стоит между мой код не будет принят и я заклябусь это отлаживать, но мой код будет принят. Ну как будто бы из двух зол выбирают меньшее. Не знаю, мне кажется мы немножко по кругу ходим. Будет ли код принят в этом и проблема. Нет консенсуса. Может будет принят, может нет. Если тебе повезет с тем, какой майнтрейнер отвечает за твою часть проекта, тогда тебе повезет и код примут. Если не повезет, то привет. Но ты узнаешь об этом скорее всего в последний момент. В подкасте очень хотелось бы поговорить с кем-то, кто реально занимается подобного рода разработкой. Я знаю, что в Linux-сообществе сильно больше одного русскоговорящего контрибьютора. И насколько меня не подводит склероз, в этом подкасте у нас таких гостей не было. Поправьте, если я ошибаюсь. Может быть были, но мы просто больше 10 лет записываем подкаст, я мог и забыть. Но, по-моему, не было никого из Linux сообщества. Мне кажется, кто-то приходил про OpenVizz рассказывать. OpenVizzi был, это правда. Но там, насколько я помню, Open Vision прямо в ядре или он немножко сбоку? Мне кажется, он изначально был сбоку, но некоторая часть из них потом была замежена. И в итоге получились Си Групс или что-то такое. В общем приходите к нам в гости, на сайте есть инструкция как это сделать. А ну это мы будем заканчивать? Это все тема? Так мало? А нет! Про глубину кроличьей норы и про то, как Ханс Джи Боем писал калькулятор. Я почитал, мне очень понравилась интересная статья про то, насколько глубоко можно идти, когда пишешь калькулятор. Казалось бы, простая вещь. Я не читал. Расскажи мне. Там получается довольно любопытно. То есть статья говорит, что вот Google нанял чувака, который должен был написать калькулятор. И пойдём с простого. И простое в калькуляторе он показывает два скриншота калькулятора Android и iOS, в котором делается простое 10 в сотой степени плюс один, ну в смысле 10 в сотой степени, это в скобочках плюс один минус и в скобочках 10 в сотой степени. Из-за того, что числа большие, но они как бы равны между собой, ты понимаешь, между собой равны получается единичка в ответе. Но если их делать по очереди сложения, то 10 сотый мало чем отличается от 10 сотой плюс единичка. Поэтому один калькулятор выдает 0, а второй выдает единичку. И с этого начинается объявление, с этого начинается статья, в которой дальше рассказывается, как правильно делать калькуляторы, как надо представлять правильные числа, как что надо любое число представлять в виде Биг. Нума это последовательности цифр, вместо того чтобы представлять их в фиксированном размере. И по этому поводу, кстати, я вспоминаю, я давным-давно собеседовался в Google, лет так 15 назад, может 10, я не помню давно. Вот, 15. И ездил даже, по-моему, в Лондон. Меня они возили на собеседования. И меня там просили на любом языке программирования сделать как раз вот этот вот большое число произвольного размера. И я это делал на двух языках: на Python и на Orlana. И вот сейчас я гляжу, как они фактически ту же самую реализацию делают. Тоже интересно поглядеть. А какие операции ты реализовывал? Сложение, вычитание, умножение, деление. По-моему, всё. С делением Ты сделал деление в столбик, я полагаю, да? Да. Я решал эту задачу в своё время. Мне для себя было интересно разобраться в криптографии на эллиптических кривых там работы используются большие числа вот я реализовывал все эти операции и читал книжки о том как это делается там вот вот сесть и на собеседование реализовать деление это далеко не тривиальная задача потому что там есть хитро выдуманный сценарий ивчик который срабатывает при очень редком стечении обстоятельств. Нужно специальный тестовый сценарий, который выстрелит тебе этот ивчик. Я не помню деталей за давностью лет, но кому-то интересно, у меня в блоге была на эту тему статья, и я ее найду и прилинкую, если вы кому-то интересно именно про операцию деления и где там интересный граничный случай. Линкуй. Я ещё добавлю, что конкретно в контексте скриптографии правильная реализация длины математики она должна быть за константное время. То есть там важно, чтобы независимо от того, там умножаешь ты на ноль или на какое-то большое число, время, которое тебе нужно, чтобы выполнить это умножение было константным, потому что если оно не константное, то можно, то сторонний наблюдатель может начать выводить о том начать делать наблюдение и понять какой у тебя например ключ используется для шифрования и со временем его извлечь из твоей системы вот Это упростить подбор. Вместо того чтобы подбирать по всему множеству чисел можно будет убрать те множества в которых уже на этом месте стоит ноль и так далее. Таким образом оказывается что реализация длинных чисел для криптографии она не самая производительная и не оптимальная если ты хочешь именно вычисления производить там не знаю с научными целями такой интересный факт вот значит следующие вопросы это типа как должно представлять как должен правильно представляться ответ и там если вы прибавляете 0.2 плюс 0.1 вы хотите получить 0.3 а не 0.3 и 0.0 и в конце там еще какое-нибудь маленькое число вот и соответственно когда вы хотите делать синус нуля вы в то же время хотите ноль потому что синус нуля это ноль вот и как бы прочие подобные вещи здесь очень сильно углубляются в математику, в то, какие числа бывают от натуральных к рациональным, к алгебраическим и так далее. Вот, и, в общем, прямо очень интересно. Я всю статью не читал. Я прочитал половину, а потом пошёл просто листать, но выглядит очень интересно. Пишу теперь её как я очень люблю. Я нашёл статью, я её прилинковал, и я понял, что писал её в 2010 году. Этот неловкий момент, когда ты можешь сказать, что 15 лет назад я написал статью про эллиптическую криптографию и алгоритм работы с большими числами. Вот тогда-то мозг работал, не то что сейчас. Не то что сейчас мы про эти принтера в основном разговариваем. Ссылка, которую принесли, о том, что автора Торнадо Кэш, которого какое-то время назад упекли за решётку, его освободили, чтобы он мог податься на апелляцию. В общем, я саму статью не читал, я слежу за этой областью. Но это хорошо, мне так кажется. А следующее, Саша, тебе будет Проект пассивного Wi-Fi радара на основе 6 ESP32, сцепленных по задающей частоте. Позволяет локализовать Wi-Fi излучатель в 2D или даже в объёме. Ссылка на сайт проекта и видеопрезентации.",
    "result": {
      "query": "пассивный Wi-Fi радар ESP32"
    }
  }
]
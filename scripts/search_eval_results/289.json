[
  {
    "segment_id": "3fbd532e-8090-4143-82ef-ae1214907ff9",
    "episode_id": "d6b2d7c3-9191-4e63-87ee-d2c882b4c2a8",
    "episode_number": 289,
    "segment_number": 6,
    "text": "И то есть там был подробный разбор как бы, в принципе, вы можете послушать один из предыдущих выпусков. А потом у них прям следом за этим же, за той статьей, которую мы так разбирали, была статья про то, как они это тестировали. И я ее заметил уже после того, как мы ее разобрали, потому что, наверное, я бы их объединил в одну, но с другой стороны, хорошо, потому что не получилось слишком длинно. Мы в подкасте DevZen очень любим говорить о том, как вы все ненадежные, а также в лице меня очень любим говорить о том, как клево все рандомизировано тестировать, QuickCheck и вот тут все, все, все эти прекрасные штуки. Также у нас были русские профайзеры и прочие такие потрясающие рендеры. Мы периодически упадем Harbid.UFS, которые сделали бочки с Целодб. Это все клево. И вот как бы, видимо, также считают инженеры в дропбоксе. Они подошли к этому переписыванию во многом с позиции а давайте сделаем так, чтобы то, что мы подопишем, было очень легко и здорово тестировать. И поскольку у нас ну такая светотеплоя миллиона компьютеров пользователей, которые, во-первых, сложно пропатчить, во-вторых, оно критично к ошибкам, то есть если вы удалили пользователю файл, который он, возможно, не хотел, чтобы вы удаляли, он будет очень недоволен. И, наконец, просто из-за количества пользователей они найдут все h-кейсы, которые могут быть. То есть у нас много пользователей, у них разные операционные системы, и все на разных коннекшнах сидят, все в разные файловые системы. В общем, просто полный праздник. Одна из причин, почему они переписывали, была то, что в старой системе у них все было довольно сложно с тем, как это тестировать. Не в последнюю очередь потому, что система развивалась, ну то есть они начинали просто с такой магической коробки, которая была для магического кармашка, который был у каждого пользователя свой, потом появились общие папки, потом появился SmartSync, появились файлы, которым доступ есть у всех. И в итоге так получилось, что там образовались такие годовые кольца с такими кастелями, что просто у всей этой конструкции были состояния, которые как бы неконсистентны, но это нормально, а потом разрезовывается, ну, наверное, и должно было быть, ну, и все было положено. Поэтому новая система дизайновала, чтобы такой фигни не было вообще. И краеугольный камень нового дизайна он в том, что вместо того, чтобы хранить последовательность действий, которые нужно произвести, хранятся три дерева. Серыйное дерево, ну, дерево имеется в виду предполагаемое состояние файловой системы. Серыйное дерево, локальное дерево, то есть то, что у нас сейчас на диске, и дерево, которое было, когда мы lending раз, успело обучить синхронизацию. Вот это дерево нужно для того, чтобы мы могли на него посмотреть и найти отличия между серверным деревом и последним синхронизированным деревом, и локальным деревом и последним синхронизированным деревом. Это позволяет отличать такие случаи, как, например, если у нас файла нет на сервере, но есть локально, значит ли это, что его удалили на сервере и еще не удалили локально? Или это, может быть, мы новый файл завели, а на сервере его еще не отправили? И тому подобные кейсы. Также они всему присылали уникальные дефикаторы, и поэтому перемещение теперь является перемещением, а не удалением, добавлением и прочей такой, прочей такой истории. Вот. И у них, чтобы всю эту конструкцию тестировать сложно, они приняли несколько таких вот фундаментально важных решений для всей системы. Во-первых, у них есть отдельная такая штука-планировщик, который смотрит на эти деревья и планирует, что с этим делать. Эта штука, она всегда работает в одном потоке. Она, типа, ну, не скажешь, что она чистая, но можно сказать, что она детерминированная. И плюс у них IEOS кедулится на как бы отдельные тракулы, и у них есть как бы два уровня тестирования. Ну, даже, так сказать, два с половиной. Первый уровень тестирования на сути QuickCheck, на этот планировщик. То есть мы напомним для слушателей, которые, возможно, недолго с нами, не знаю, еще ни разу не слышали моей потрясающей лекции про QuickCheck и про property-based тестирование, мы берем как бы какую-то структуру данных, описываем ее как это, описываем ее форму, ну, скажем так, и описываем, как ее как бы увеличивать или уменьшать. Ну, то есть, например, список это, не знаю, список, он может быть список чего-то. То есть, скажем, у нас список пар, и в паре у нас первый элемент это, скажем, строка, второй элемент это, скажем, интеджер. И как бы мы, соответственно, можем сам простейший вариант, эта структура, это просто пустой список, там, не знаю, мы можем инкрементировать как бы размер на один, у нас получится список из одного элемента пары. Опять же, внутри пары мы можем делать простые элементы или сложные элементы, мы можем например, сделать пустую строку, а в качестве интеджера 0 поставить, можем сделать строку там, не знаю, размером на тысячу символов, или даже десять тысяч символов, и инт у нас какой-нибудь там, не знаю, на границе переполнения. Вот. Ну и, соответственно, есть правило, по которому структура данных растет и на воротскую коживается. Потом мы берем нашу систему, которую мы планируем тестировать, мы генерируем разные конструкции этой вот, этих входных данных, форму которых мы описали, скармливаем, а потом проверяем какой-то вариант. И важная фишка всех property-based, то есть как бы фреймворков, в том, что они, после того, как они нашли какой-то способ вашу систему разломать, они потом могут минимизировать примеры, на котором оно сломалось, именно благодаря тому, что у нас были правила наращивания структуры и уменьшения структуры. И найти вам минимальный пример, который ломает ваш код, и вы потом сможете, просто как бы прогнав ваш код на этих же входных данных, получить такой же результат. Это очень клево вообще, в принципе, прям, как вот я описал, работать для всяких сервизаторов, для таких систем, типа планировщик. В случае систем, у которых есть какой-то стейт, там сложнее, там появляются еще абстракции, но для обсуждения этой статьи нам будет достаточно просто простого варианта работы с такими системами. Так вот, собственно, извини, Свет, но у тебя на фоне машины ездит. Так вот, у нас есть планировщик, ему генерируется какое-то базовое дерево, потом генерируется пермутации от этого базового дерева, чтобы сгенировать другие два дерева, там серверные, локальные. Это делается именно пермутациями, случайными, потому что если сгенировать просто три совсем случайных дерева, то не факт, что найдутся какие-то интересные случаи с перемещением файлов или с удалением, добавлением, конкурентным, потому что они будут просто три несвязанных дерева, поэтому инженеры Dropbox утверждают, что они так больше интересных сложных случаев находят. Ну и во-вторых, они, конечно же, везде, где у них используется рандомизация, там интересный пример, например, в хэшмаппе Rust используют рандомизация, чтобы нельзя было построить DOS атаку на какой-то сервер, который эти хэшмаппы используют. Вот у них просто везде используемые генераторы исключительных чисел, они везде заткнуты сидом, который генерируется в рамках как бы property-based прогона, чтобы прям гарантированно, детерминированно проходить по тому же пути исполнения. И собственно, да, они генерируют структуру, прогоняют планировщик, и они выплевывают какие-то шаги, они шаги как бы выполняют в таком виртуальном выполняторе, и так вот делают, пока планировщик не скажет, что все в состоянии сошлось, и потом проверяют на нем какие-то инварианты, то есть, во-первых, есть базовый инвариант, что в итоге все деревья выглядят одинаково, плюс потом они генерируют инварианты на основе того, что там происходило с деревьями, то есть, скажем, если они знают, что там в результате, что как бы одна из перемутаций была вовление файла, то, типа, файл не должен потом исчезнуть, потому что иначе возможно был бы тривиальный случай имплементации, когда просто все три дерева сходились бы к пустому дереву, мы просто берем и все удаляем. Потрясающий планировщик. Вот. Ну, я думаю, что за совсем подробностью я по статью я перейду к другому уровню тестирования, поскольку вот эта вот а-ля-квикчей-штука, она тестирует только планировщик, им нужно было как-то тестировать собственно более крупный средство системы, и там они делают следующую штуку, они как бы они весь планировщик и вообще всю эту штуку написали на расторских фьючерах, и по сути они взяли и замокали, во-первых, файловую систему, IO и там таймеры, и кроме этого они еще как бы не то что замокали, они сделали кастомный как это называется, в общем, экзекютер фьючей, который, помимо того, чтобы экзекьють фьючи, которые положено экзекьють, он может в нужные моменты, когда вот этот планировщик как бы пока приостановился, ну, то есть он заблокировался, чего-то ждет, они берут, могут вызову файловой системы добавить проблем, вызову сети добавить проблем, переставить что-то местами, ну и так далее. Вот, таким образом они такой фейлор инжекция изводят в тест, тоже опять же все детерминировано, и все как бы седы для рандомайзера запоминаются и воспроизводимы, и таким образом они покрывают еще и как бы срез по как бы более интеграционной. И наконец, последний, второй с половинкой способ, который они тестируют, они еще вынуждены проверять на как бы на нативных файлах системах, но это гораздо медленнее, чем на замоканных, потому что приходится не с памятью работать, а с диском, и у них там получается более ограниченный набор тестов, и они вынуждены там реализовать вызовы, то есть они на рандомизированные, переставленные местами вызовы, потом синхронизируют, чтобы оно через реальную файловую систему прошло один за одним, а как бы операционная система ничего там не переставляла лишнего, чтобы тест был повторяемым, в случае чего. Ну и там плюс некоторые ситуации, они не до конца могут из этого не до конца могут инвалидировать. Типа, например, они на реальную файловую систему не могут устроить искусственный ребут с недоделанным их синком, они-то полагаются на то, что такой случай более-менее покроется предыдущим вариантом тестирования, когда они просто все мокали в памяти. И также у них есть проблемы с тем, что им приходится мокать сервера, и в итоге у них там тоже есть как бы особенности с тем, как с этим работать.",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 4906. Please try again in 9.812s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 4906. Please try again in 9.812s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
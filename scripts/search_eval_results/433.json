[
  {
    "segment_id": "e6f902aa-db62-4224-bbf2-22ecf48ec81f",
    "episode_id": "7ca4c918-6d3c-4df6-96aa-b9d7d2474cae",
    "episode_number": 433,
    "segment_number": 5,
    "text": "То есть это его плюс, что он очень хорошо сжимает данные, но проблема в том, что вот он потом аппаратных разжимает не так быстро, как хотелось бы. Это, если ты там лепаешь за большой период времени, вот это тоже будет неудобно, не очень практично. Я не знаю, может они уже сейчас поправили, я вот буду как-нибудь проводить дополнительные бенчмарки, может это уже все сейчас нормально, но вот при мне это было так. Окей. Так, кроме Локи и Elasticsearch'а еще упоминаются векторы Clickhouse. Я подозреваю, Clickhouse, я думаю, было нечисто, видимо, с чем-то вроде Loghouse'а. Не-не-не, я использую Loghouse как чисто. Вот это вот дело в том, что вот если у вас это такая эволюция логов, я бы так сказал, что вот у нас есть простые строки, как у Nginx Logo, да, вот у нас там есть дата, у нас там есть название, то есть режим лога, то есть сам ошибка или warning и так далее. А вот название, там, не знаю, запрос и так далее, и там объем ответа, скажем. Это такая достаточно чистая структура, ее можно хоть в JSON положить и ничего не потеряет, ну то есть потеряет читаемость, но сам смысл того, что вот эта вот структура, здесь все четко определено, нет какого-то такого вольно написанного сообщения, где вот, не знаю, там написано просто в пользователе email такой там log.com зарегистрирован с таким-то паролем. То есть это вот одно, один тип лога, а есть другой тип лога, более такой парсируемый, такой более passable, когда написано пользователь зарегистрирован и потом идет там, например, ключ значения какой-нибудь, то есть email такой-то, пароль такой-то, ну, грубо говоря, хеш пароля. И это вот уже какое-то движение дальше. Когда потом вот у вас начинается уже структурированные логи, там JSON и так далее, вот уже появляется мысль, а что если использовать, ну это такая упоротая мысль, но и что если все-таки использовать какие-то базы данных SQL ориентированные. И тут интересный способ, так вот можно использовать Clickhouse. И у меня тоже есть опыт использования Clickhouse на продакшене для хранения просто чисто логов Nginx, чтобы строить по ним какую-то аналитику. Когда вот мне тут под рукой какой-нибудь Google BigQuery или помню с Amazon'овского аналогичного сервиса для какого-то Big Data, то можно использовать просто Clickhouse. То есть запихиваешь его через вектор логи этих же, которые там могут друг к другу нативно погружиться, вектор Clickhouse. И все будет довольно достаточно элегантно. То есть вот тебе столбец с временем ответа, вот тебе столбец со статусом, ну и достаточно много столбцов, но это же для колоночной базы или кауз, это как раз очень даже плюс. И что еще могу добавить? Да, про вектор, кстати, там я тоже, вот у меня недавно была задача интересная про вектор, тут уже достаточно актуальная информация. Когда надо было достаточно сложный паттерн разбора данных сделать, это у меня был такой проект, когда есть такая игра Elite Dangerous, и от нее какое-то сообщество делает дамп-базу всей млечного пути в игре всех звезд и так далее, всех планет, станций. Этот дамп занимает где-то около 400 гигабайт в ZIP, это JSON логер. И я пробовал его запихнуть через вектор, распарсить, запихнуть по разным индексам, например, эластика. Вектор, он показал очень интересный результат, потому что сначала он вроде бы работал, распихивал данные, куда он надо, но потом все больше и больше, почему-то набирались какие-то такие спайки по производительности. Когда вот он ничего просто не делал, только потреблял одно ядро. Стабильно одно ядро на 100%. Что он там делал, я пробовал дамп-базу через PerfTop в Linux, и там понял просто, что он зачем-то выделяет новые какие-то объемы памяти. Я пробовал искать по GitHub, ничего не понял, очень интересно. Вот. Но вектор это вот тоже нормальная на самом деле штука. Вот если его использовать просто, например, для парсинга логов и от присылки в ClickHouse, скажем, тот же, и с кубернетики в ClickHouse использовать, или там хранить в S3-шке, то это тоже хорошая штука. Но вот если его использовать тоже как-то вот экспериментальные какие-то штуки, типа вот его, ну для меня экспериментальные, типа вот его собственного языка парсинга VectorMapLanguage, то вот начинаются тоже какие-то такие странности с ним. Которые, даже не знаю, вот сами раскрутили они, сами разработчики. Так, я тем временем читаю читать. Я так понимаю, от Антона вопрос еще про локи. Что будет, если терабайт логов в час, видимо не сжатых имеется в виду, во сколько оно превратится в данных после сжатия. И... Да, давай с этого начнем. Я здесь не могу сказать, это надо обязательно делать все рендишки людям. То есть, если использовать терабайт логов в час, я не знаю, я могу пытаться у себя локально это развиваться, но вряд ли получится. У меня там всего 2 терабайта на диске. На SSD. Ну понятно, да, что это не так-то просто такую нагрузку получить, просто может у тебя есть данные, чтобы их экстраполировать. А вот кластеров, не знаю, там, которые... Дело-то, кстати, еще в том, что я когда пробовал еще переничмаркать в плане получения логов, например, приходится еще выгрузить логи за несколько дней, там, или за несколько часов, в которых там, ну, мегабайт, не знаю, там, 200 логов за 1 час или за 10 минут, то это тоже становится проблемой, потому что вот на отдачу, то есть не только на внутреннюю обработку логов, но еще и на отдачу, логи тоже медленные. Вот при мне был, по крайней мере, то есть года 2 назад, когда надо было ему, то есть можно сказать, да, вот отдай мне вот по такому-то времени, по такое-то время, просто вот ничего, там, никакой запрос не надо сделать, только вот по фильтру по времени. И он может не задумываться, он может отдавать логи, но он может это делать медленно, то есть просто там 100 килобайт, ну, несколько сотен килобайт в секунду, когда ты ожидаешь какой-то отразительности. Это прямо очень печально звучит. Да. Другой вопрос от пользователя без имени. Иметь маленького шу... ну, даже не вопрос, а просто предложение, что можно иметь маленького шустрого демона, который быстро фильтрует мусор на раннем этапе пайплайна, дальше это кормить в analog vector или в fluend. 2 года назад fluend работал быстрее, чем вектор. Я по этому поводу имею сказать, что это хорошо работает, если вы прямо вот, не знаю, какие-то определенные вещи из этих логов хотите получить, то есть вы алертить на них хотите, то это работает. А если вы хотите все логи, и вы не знаете, что вам понадобится, это может быть... такая задача возникает по разным причинам. Во-первых, у вас может быть прекрасно сработали алерты, теперь вы хотите разобраться, что же произошло. Произошло оно вчера. Ну, начало происходить оно вчера. То есть система начала деградировать вчера. И вы взяли, уже все логи выкинули. Ну, не очень здорово. Вторая вещь, которая еще более интересный кейс, это логи... это audit логов. Когда у вас есть клиент, у которого что-то случилось, вы SaaS компания, например, и вам нужно понять, что, черт возьми, происходило, и варианта сказать, извините, мы уже все логи отбросили на раннем этапе, у вас просто нет. Ну, и даже если на самом деле надо как-то подбрасывать логи, то этого не надо писать отдельно на демон. Это, собственно, есть сам вектор. Потом, может, или FluentBit, FluentD, и так далее, и FriendFriends. Потому что эта система прекрасно заточена под pipeline логов. Зачем грозить дополнительной сущности? Это вопрос. Потому что логов очень много. Ну, а логов много, но просто для обработки много логов, это подходит тот же вектор сам по себе. То есть они это тоже умеют делать, и они для этого как раз и заточены под high throughput, под большую пропускную способность. FluentBit, кстати, вот очень хорошая штука. Достаточно стабильная, там, конфигурация у него с приколами, ну, в плане синтаксиса конфигурации. Но в целом же вот FluentBit прикольная штука, мне она понравилась. По производительности, в плане потребления памяти. Мне казалось, что FluentD не занимается, собственно, флэнгом логов, мне кажется. Мне казалось, что просто какая-то промежуточная штука. FluentD? Нет, я про FluentBit говорю. FluentD похожая штука. Просто переписанная на C. И я работал, да. Просто насколько я понимаю, FluentD, он сам по себе не занимается, как я уже начал говорить, отдачей. Он про то, чтобы собрать это всюду и положить куда нужно. В частности, в Elastic или вообще, прости господи, Hadoop. Или S3. А как вы оттуда выгребать будете, это уже ваша проблема. А, ну, не знаю. Там нельзя, конечно, выставить очень сложный pipeline, но можно просто фильтровывать и что-то переслать в одно место, а что-то переслать в другое. То есть, одновременно, спокойно можно что в FluentD, что в FluentBit, и так далее, в Vectre, и в других системах. То есть, можно настроить пересылку в другой FluentD, там, в другом хосте, какой-то централизованный. Или можно настроить, наоборот, там, рассылку по детским FluentD, который каждый из них там будет рассылать один раз, если хранится, то другой хранится на, не знаю, там же, эластике. Слушай, я как раз-таки, меня всегда как раз-таки заинтересовало не сложить логи очень быстро куда-то, потому что девнул-то все могут написать. Или даже, может быть, не девнул, но огромную помойку, ну, файловую, ну, в принципе, там, тоже самое, HDFS3, они давно существовали, как-то зараутить логи и положить, наверное, можно. А вот как мы из всего обсуждения пока получается, что достать логи, если они особенно не структурированные, из этой большой кучи логов потом сложно. И я видел, наверное, мало. Пипом 1, ровно, SaaS видел, я забыл уже, как называется, который прям хорошо и быстро выгребал логи, даже если их было много. Он был прям пипец дорогой. В большинстве случаев, если у вас нетривиальное количество логов, и вам нужно иметь возможность их все сохранить, я каких только приседаний со штангой не видел. Наверное, самое рабочее это вот, да, какая-то фильтрация по времени и индексирование определенных, там, типа, мы знаем, каких полей, чтобы там однозначно можно было идентифицировать номер кастомера, и потом уже, там, не знаю, в параллель со многих машин выгребать эти логи, для потом уже анализа, после того, как они были выгребены. Вот это самое, производительное, что я видел. И это работало, это было построено, система построена была для конкретного юзкейса, для аудита по каждому кастомеру. Как такое сделать для общего случая, мне сложно представить, и вот эта история про то, что из локи данные, логи выгружаются по, там, не знаю, килобиты жалкие, это прям как-то пугает, потому что, может быть, нужно выгрузить гигабайт логов, потом по ним анализы делать. То есть, в общем, от тебя пока какие-то неутешительные вести по этому плану, по этой части. Ну да, то есть, получается, в таких случаях, когда нужно потом достать автоматизированно из того же, не знаю, там, из того же S3, то есть какой-то артбекап логов, грубо говоря, и потом его отобразить, это надо вот писать или какие-то дополнительные скрипты, там, вираски какие-то, не знаю, pipeline gitlab, чем-то такое. В общем, короче, нужно еще с log house будет поэкспериментировать, потому что есть у меня подозрение, что оно, наверное, лучше, чем многое. То есть, интуитивно хранить логи в колоночной базе данных, даже просто, как бы, основная часть всего, просто как строки с парой полей, которые заполнены как колонки, уже будет сильно лучше, чем многие другие решения. Безусловно. И, да, у меня просто было такое кейс, когда я рассказывал про дамп из игры, когда я пытался запихнуть через вектор обработать. Я его просто запихнул через клиент консольный, я просто скрасил его, вот тебе файл с чесонами, пожалуйста, разархивируй его, сам вот здесь там распаркси и так далее, разложи по колоночкам. И он это, черт возьми, сделал. Я не знаю как, но вот хвала Александру Миловидову, так, конечно, это завод главного разработчика, там у них все с этим, по крайней мере, очень даже производительно и красиво сделано. Если надо, например, загрузить просто огромный дамп логов. Я, в общем, клеихаун с этим отлично справляется, в части вот поиска, например, кого-то запросов и так далее. Там можно даже настроить ограничения по памяти, чтобы он потом свопил на диск. Вообще замечательная штука. Это, кстати, я зашел на страничку логхауза и там обдейли 20-го года, возможно, мы даже обсуждали и я сейчас забыл, что логхауз больше не поддерживается. Идите используйте логи, говорят нам. Что ж. Возможно, тебе нужно сделать еще один подход к логе, возможно, стало лучше. Возможно. С тех пор, я думаю, многое изменилось. У графана много ресурсов на то, чтобы развивать свои системы. Там у них еще, например, есть, ну, спойлер, у них еще есть алертинг. Очень интересный такой графан онкол, который я, кстати, пробовал, ну, я еще его не пробовал, потом-то сделал. Я очень хочу попробовать знакомиться с проектом. По сроку никак не дойдут еще. Потому что графан у него вообще, на самом деле, графан у него и, собственно, не алертинг. Он может сама себе отправлять там, например, какие-то алерты, ну, настройки алерти по графикам и отправлять даже по алертам, по дашбардам, по какому-нибудь Slack, Telegram и так далее. Под дискорд. Но там же нет какого-то расписания инженеров, там нет ничего такого. Вот этим занимается как раз графан онкол. Который, вроде, должен это все делать. Я не знаю, насколько там он все интерпайзер в плане инцидент менеджмента там и так далее. Потому что я как-то работал вот в компании, где много было всего самописного, спойлер, не Яндекс. И там была в том числе одна такая очень крутая система по инцидент менеджменту, где можно было даже по сморту написать, там, заревьюить его там с менеджментом и так далее. Очень классно. И там еще была такая централизованная, объединенная и так далее. Так вот. Говоря еще про эволюцию каких-то логов, вот, есть что-то более оптимальное, чем укорениться в логе сами по себе. Потому что есть какие-то диагностические данные, просто какие-то маркеры, что что-то у нас не так. Например, какой-то запрос занимает очень много времени. Такое можно запихивать в метрики, казалось бы. Но там тоже очень много подводных камней. Потому что, вот, скажем, давайте какой-нибудь разработчик подумает, окей, давайте просто будем логировать каждый запрос по метрике делать. Там в качестве лейбла применится просто уровень целый. С полной системой, там, Urid'ом каким-нибудь, там, UserID и так далее. А потом... OpenTelemetry так выглядит. OpenTelemetry Traces. Traces — это только отдельная история. Traces — это вообще манны небесные. Не, ну, к сожалению, в плане кардиналити они у меня так и выглядят. В Traces в KeyValue к Traces можно прилепить любую херню и фреймворки прикрепляются в KeyValue к Traces. Зачастую, например, прям вот тебе трассу ошибки, например. Я имею в виду, в смысле, это индексируется в памяти тоже? Ну, в нашем решении это не в памяти индексировалось, у нас было все немножко хитрее. Если я ничего не путаю, Pyramidius строил GIN-индекс по всяким возможным уникальным... Или не GIN, сейчас... По-моему, мы строили... Я не хочу соврать. У нас, по-моему, был GIN по индексам в уникальные хранилища вот этих вот уникальных значений для... Как это объяснить-то? Короче, мы для каждого встречаем ключ... Каждый встречаем пару ключ-значений, какой бы он, в частности, уникальный. Мы хранили отдельную, как бы, нормализованно хранили вот это вот оно. И потом для всех вхождений все вхождения мы по всем вхождениям в основной таблице мы строили GIN-индекс. Если я правильно помню. Слушай, пока мы здесь не ушли, ты в курсе, как устроен этот Honeycomb? Туда ушел этот Ferg. Помнишь Ferg? Помню, но для фиолетика устроен. Да, Ferg.k. Он ушел как раз в Honeycomb. И Honeycomb, они себя рекламируют как high-coordinality решение. И ты можешь запихивать любые ключи, значения туда, и там поиск мгновенный. Ну, то есть, как бы, посмотри демку, это просто снос башки. Я не знаю, как они работают. Ну, слушай, везде поиск мгновенный, пока у тебя данных мало. Не, ну там, в смысле, там как раз, там, эти, как его, там график они строят. Ты говоришь, я хочу найти все события, которые пришли, в которых поле A равняется B2235, и он строит графики, там, тысячи событий в секунду на графике показывают мгновенно. Ну, то есть, как бы, я не знаю, как это работает, и мне сложно себе представить, насколько можно быстро делать вот по high-coordinality поиск, а потом ты делаешь, смотришь, там есть какие-то всплески по, скажем, это latency какая-нибудь, или это, знаешь, значение слишком большое, и ты выделяешь область, и он тебе говорит, вот эти вот, те, как это, все точки, которые попали в эту область, отличаются от всех остальных точек, вот по вот этим вот ключам, по вот этим ключам, по вот этим ключам, там вот такие, такие, такие значения. Я не знаю, ответ на этот вопрос, наверное, иначе бы я... Ты бы работал уже в хронику. Но я могу сделать пару таких предположений, что, во-первых, обычно эти все очень сильно high-coordinality данные имеют такое специфичное распределение, что у тебя есть очень много ... очень такой плотный кластер ключей, которые, типа, вот, например, hostname, да, у тебя hostname часто встречается, и у него значения такие, как бы, похожие, ограниченные, предсказуемые. Есть какие-то такие, знаешь, one-off хреновины, типа, вот тут, короче, фреймворк вот по этому ключу иногда пишет stack trace. И вот у тебя вот такое вхождение, оно будет, типа, один раз или, может быть, два раза. И, наверное, они что-то умеют делать и как-то хорошо работают с тем, как оно распределено, и они знают, какие ключи как распределены, и за счет этого, скорее всего, могут очень хорошо и быстро, эффективно отсеивать или там даже как-то, ну, короче, применять только эти фильтры, которые реально эффективно отфильтруют. Интересно. Я, кстати, не слышу, где тут про Honeycomb. Это SASS. А, SASS. Вот, если честно, интересно было бы поглядеть на open-source решение, которое будет соревноваться с Honeycomb. Потому что, ну, когда смотришь их демочку, это прям, это реально снос башки. Я бы хотел вот такое установить себе локально у себя в Synology и собирать метрики с высокой кардинальностью для партнеров. Та же была бы. Кто там у нас вот ищет идеи для новых стартапов? Вот open-source стартап прям ждет вас. Ну, если хотите просто, на самом деле, нормально, ну, если хотите, например, работать с high-cardinality данными, то или просто добро пожаловать в базу данных, или просто не использовать high-cardinality, то есть не индексировать такие данные, пожалуйста. Не, ну, слушай, база данных тоже автоматически с high-cardinality сами все они работают. High-cardinality это сложно даже, там, в том же классическом PostgreSQL у тебя классически есть B-дерево. Как... Ну, и просто уж в PostgreSQL есть как бы таких более популярных фичей PostgreSQL, но все еще сравнительно эзотерических вещей есть GIN и GSTED индексы. Но, опять же, с теми же самыми GIN индексами нужно быть аккуратными, потому что их... С ними можно в очень интересную ситуацию попасть в плане производительности. Я, к сожалению, вот у меня нет какого-то PhD в индексации данных, я больше такой по... в прямой плане практик, если честно. Поэтому я не могу тут ничего сказать. У меня это все впереди, изучение индексов и шминдексов и так далее. Что вот у меня есть какой-то опыт, это как раз в OpenTelemetry, потому что у меня вот был один какой-то проект, где надо было... Где я по своей инициативе понял, что вот я не могу понять, почему запрос так медленно отрабатывает, почему этот endpoint так медленно отрабатывает, я вроде посмотрел, там нет никаких N плюс 1 запросов, все нормально вроде бы, но вот на Proddy медленно работают. И дебаги же на Proddy не включаются, как правило, потому что это был такой mature проект, ответственный к там компании и так далее. Поэтому я подумал, окей, и у заказчика есть OpenTelemetry, свойства там развеланных стек и так далее, там они его где-то себя используют, коммунальную систему, и я подумал, окей, давайте промоу-внедрить у нас. Это была очень веселая история, потому что там был язык программирования такой свой, ну, это был собственно конечно Ruby, но дело в том, что OpenTelemetry под Ruby там он такой вроде как community-based, он не очень так активно разрабатывается, но разрабатывается, но не сильно. И в общем, история получилась такая, что такое ощущение, что OpenTelemetry был нужен только вот таким вот сумасшедшим людям вроде меня. То есть только мне там в команде, чтобы просто добавить одну проблему. Я надеюсь в итоге, что там сейчас они очень радуются этому символу, если так и мониторингу, потому что на самом деле OpenTelemetry это просто касса эволюции, логов, метрик, все такое объединено. Когда вот ты можешь и у тебя есть не просто событие, как лог, ты можешь посмотреть и через у тебя какой-то такой x3cd, можно сказать, звуковой, который прорабатывается через через те или иные хас там микросервисы, OpenTelemetry, OpenTracing, частный случай OpenTelemetry, он разработан именно для вот таких распределенных систем, где много сервисов, где они друг с другом коммуницируют, и там OpenTracing как раз вот проброс данных о запросе, такой вот один цельный лог с информацией о том, как приходил запрос, сколько он занял, как долго он здесь, в этом сервисе провел, как долго тут провел, какие-то еще дополнительные поля есть и так далее. То есть это такой как флейм граф производительности, только вот с наворотами. Беда в том, что он только никому не нужен. Точнее нужен, но только вот им мало кто заинтересован, я бы так сказал. Почему? Ну вот я, например, не встречал много команд, которые бы вот так, с таким же энтузиазмом, как я, были заинтересованы в этом деле. Я вот пытался вот, это интересная история, потому что еще вот здесь следующий пункт, где здесь во всем этом логах, метриках и так далее разработчик сам, но что, вроде как он должен сам быть заинтересован, но это отдельная история. Можем потом еще про это поделиться, если будет время. То есть вот дело в том, что вот мне этот трейсер, разработчику надо еще убедить, что это ему интересно. Это правда, потому что люди почему-то, вот одна из проблем, с которой мы столкнулись, как продукт, я не знаю, сколько я могу на самом деле потом разговаривать, поэтому я буду аккуратен здесь. И опять же, я не занимался продуктами, как бы, все, что я скажу, это не официальная позиция компании, это мои наблюдения как бы человека, который просто занимался разработкой непосредственно продукта. Я к как это, outreach не имел никакого отношения, но вот ты приходишь на конференцию, разговариваешь с кем-то, такой, типа, да-да, клево, телеметрия, тассировка, и как бы, по факту, у людей на самом деле проблемы просто нормально вообще Prometheus интегрировать. А трассировку в свое приложение встраивать далеко не все готовы. Я, в принципе, работал в одном месте, где у нас была трассировка практически с самого начала, но это было связано с тем, что у нас дистрибутив был. Это такой кластер, куберкласс, где было много разных компонентов, и разбираться, что у клиента произошло на системе, если бы в этом не было встроенного ягер-трассировки какой-то, было бы просто невозможно. Поэтому мы это сделали. Какая мотивация вот у людей, у которых там, не знаю, скажем, монолит на Ruby, непонятно. Если там, конечно, куча микросервисов, то постепенно мотивация появляется. Но, опять же, заставить всех между всеми микросервисами правильно пробрасывать, все эти ID-шники, это задача для хорошей платформенной команды, задача для, даже не знаю, какого-то такого, чтобы инженерный менеджер между собой договорился, что это для всех важно. Сложно. Мало кто реально это делает. К сожалению. Вот, короче, кто-то решит задачу построить какую-то полезную информацию на основе логов, чтобы не нужно было... Есть такие две офигенные задачи. Строить метрики по трассам, чтобы достаточно было что-то одно сделать, и не нужно было второе еще руками прописывать, потому что одно, очевидно, делевать и в другого. Второе — трассы по логам неструктурированным. Те вот, мне кажется, соберут кассу. LogGPT. LogGPT. Midjourney. LogMidjourney. Рисует это. Помните, у нас в каком-то выпуске были эти лица, как они назывались, по которым можно определять много что-то в многомерных данных. Вань, помнишь такое? Мы еще DoomGate на обложку присобачили. Нет. Я все забыл. Это, мне кажется, год назад. Нет, больше уже года назад. Наверное, два года назад уже было. Я рыбка-пони, это еще я... Понятно. Я так долго не помню. Понятно. В общем, да. Midjourney просто смотрит на ваши логи и рисует вам вот это вот лицо, можно определить, как ваша система себя чувствует. А, да-да-да-да-да-да-да-да-да-да. Да-да-да, я вспомнил. Мы еще книжку вспоминали, как там она называется-то, с этим... Там вампир смотрел на лица, потому что лица хорошо отображают... Это совсем не ложная слепота. Да-да, ложная слепота. Моя любимая книга. Да, моя тоже. Ладно, вернемся к нашим приземленным темам. Что у нас там дальше? Мы к телеметрии подошли, да, и остановились на том, что никто не хочет интегрировать, Ваня. Мяч обратно в твой огород. Почему ты так оптимистичен? Почему ты так оптимистичен? Оптимистичен относительно чего? Или вообще оптимистичен? Ну, ты такой вот прям про трассу начал радостно задвигать. Я не понимаю вопроса. Ну, то есть они же помогают. Все это помогает. Да, но тут так типа... Не знаю, ну то есть... Я же как бы привел контраргумент, что вот мне не кажется, что люди реально этим пользуются. Так вопрос не в людях, вопрос в тебе. Если ты этим пользуешься, ты это добавляешь и пользуешься. Без этого некоторые вещи сделать невозможно никак. То есть как бы, когда начинаешь об этом думать, как это правильно сделать систему, у тебя начинается система, состоящая... Я недавно писал этот, как его... Для себя... Как это... Мысли типа, что я хочу видеть в нормальной системе. И как бы нормальный трейсинг это одна из основных вещей. А если вообще идеально будет, если он будет еще distributed tracing, а еще идеально будет, если он будет... Как это называется-то? В общем, чтобы он был случайный, но consistency... Как-то... Как-то у него специальное название, чтобы, в общем, консистентно он его сэмплировал. То есть как бы, если у тебя приходят запросы с одинаковым trace ID, то он с одинаковой... В смысле, обе системы будут его либо сэмплировать, либо не сэмплировать, если ты им даешь какой-то... А, я понял, что это даже типа, чтобы оно сэмплировало не вообще все, чтобы не перегружать систему. Да. Но если сэмплируется что-то одно на пути, то и сэмплируется и второе, чтобы не было так, что полтрассы отсутствуют. Да, да. Это называется консистентный вероятностный head sample tracing. Head trace sample. В общем, вот эти пять слов перемешайте в нужной последовательности, поставьте. Вот. И получается, это вот это самое правильное, что ты можешь сделать. И это на больших, на смысле, на больших, на большом потоке событий единственная вещь, которая тебе поможет. Ну, помимо тулинга дополнительного, когда ты можешь там отдельных пользователей включить, трассирование и сэмплирование, или ты можешь отдельные запросы по какому-нибудь я не знаю, хедеру дополнительно включать сэмплирование. И при этом это должно быть сквозное сэмплирование, чтобы у тебя, если ты флаг поставил, то у тебя все подсистемы и все подзапросы тоже получали этот флаг и тоже, соответственно, влоги куда-то сыпали. И чтобы ты мог потом это все анализировать и вот это вот графики выводить, сколько где потратилось, кто откуда вызвался. Блин, ну вот без этого вообще как можно сложную систему, которая по-настоящему сложная, каким-то образом разбирать? Никак ты это не сделаешь. И поэтому добавляешь. И поэтому я оптимистичен, потому что сейчас появляются куча инструментов. Я помню, что я 20 лет назад мы что-то самостоятельно писали на Erlang, придумывали какие процессы к удаче будут получать, посылать и так далее. А сейчас вон у тебя есть OpenTracing, и пошел, поставил несколько контейнеров, поставил несколько этих сайткаров, агрегаторов и все, и все работает автоматически. Пыньк! Классно же! Вообще же четко же! 10 лет назад мечтать о таком не мог, а сейчас работаю из коробки. Возможно, мы просто не встречались, только вот такие консервативно настроенные команды, которые думают, а это... Они даже не то, что консервативно настроенные, у них просто нет времени, это одна проблема. Вторая, они не могут договориться, как это все как это... вываливать, чтобы не только одна какая-то команда вываливала, а чтобы они все это вываливали. Чтобы он друг с другом работал. Потому что Distributed Tracing, он же бессмысленный, если у тебя только один сервис его вываливает. Нужно, чтобы на всем пути запроса оно было выгружено. Согласен. То есть получается, что это работа только в больших командах, где уже назрела настолько большая необходимость, что никто уже с этим не спорит и все делают. Кстати, да. Наверное, да. Потому что если у тебя, я не знаю, еще деньги не зарабатываются, то никто про трейсинг думать не будет. Или вот да, та ситуация, когда вот то, где я работал, где вне зависимости от денег ты это вываливаешь внешнему клиенту, и ты просто не сам не сможешь даже своей командой из трех человек не сможешь в этом разобраться без Distributed Tracing. Потому что ты не можешь просто, не знаю, пойти, не к каждому клиенту можно пойти на кластер и начать там своими грязными ручками что-то делать. Ладно. Ну говори, говори. Это вообще интересная история, потому что если же ты сейчас подошел к этому, а что вот в итоге просто чтобы были хорошие логи, чтобы были хорошие менторки, были хорошие VTC Trace и так далее, это вот надо получать что-либо и я понимаю, это должны вот те самые вот какие-то странные чудики GenDrops инженеры взаимодействовать с разработчиками. То есть быть заодно с ними, чтобы объяснить им, чтобы разработчики объяснили свои хотелки, чтобы вместе как-то родить такое решение по мониторингу. Ну тут смотри, обычно наверное из того, что я видел, нормальные метрики возникают довольно быстро, когда есть какая-то эскалация разработчиков. Потому что, когда что-то сломалось, если... Ну то есть я бывал и on-call, я не очень люблю быть прям первым как-то первым уровнем обороны на on-call, но вот когда я был первым уровнем обороны на on-call, у тебя прям очень-очень естественным образом настроены приоритеты в жизни и на работе, что типа ты не шипишь код без того, чтобы не обманывая его хорошо хотя бы метриками и логами. Ну, трассы, допустим, там, где я работал, у меня не было. Да и, в общем-то, это был монолит на рубе. Одно из самых нагруженных, это было монолит на рубе. Не было смысла внести беду в трейсинг. Да и open-telemetry просто не было тогда. Да и open-telemetry просто не было тогда. Когда есть хотя бы какая-то эскалация разработчика, если его, ну если уж не разбудит, то хотя бы ему придет issue, в котором будет, а что же там такое, очень быстро появляется правильное представление о том, какие метрики нужны, чтобы отвечать на такие вопросы. Это очень хороший point. Выходит, что так, да, что получается или должны быть подниматься по там онколу в 20 часа ночи и да вовсе там какой-нибудь, грубо говоря, и там, ну какой-то срежник и разработчик оба или прямо только разработчик, чтобы вот ну или там да вовсе кто-то участвует в разработке, чтобы оба могли там разрабатываться, чтобы оба были заинтересованы в том, чтобы тема была наблюдаемой. Это важное слово. Я не уверен, что разработчиков нужно прям поднимать, разработчиков просто должны issues прилетать. Ну то есть смотри как у тебя команда обычно приоритизирует какие-то задачи над которыми работать. Если у тебя среди задач над которыми работать нужно отвечать на вопросики неудобные, даже если ты при этом не поднимаешься ночью по звонку. Если эти issues прилетают часто от всего, что ты можешь неудобно помучать, метрики обычно появляются. Ну медленнее, чем если ты поднимаешься по звонку, но тем не менее появляются. Главное, что вот этот фидбэк в виде тикетов, он именно был какой-то такой, который наблюдаем менеджменту, а не так, что к тебе кто-то прилетает сбоку, что-то спрашивает и убегает, получив твое неуверенное хз. Потому что вот в этой ситуации, когда кто-то прибегает, спрашивает и убегает, это все проходит мимо менеджмента и это ни в какой момент не становится видимо как вот нагрузка, которой занимается команда. Ты имеешь в виду, что это не отражается как-то в постмортеме или типа того? Даже не то, что в постмортеме, я повторюсь, у тебя есть какой-то план на неделю, например. Как часто вы делаете ваши танцы с бэклогом и задачами и планированием на неделю, вот это все. Как ни назови, бэклог грувинг, скран, канбан, вот-вот-вот, абсолютно любой процесс, у которого есть входящий поток задач, если в входящем потоке задач нет задач ой, вот там что-то сломалось, пожалуйста, помогите нам разобраться срочно и нет задач уровня разработчиков поднимают ночью, то понятно, что для команды разработчиков, особенно для менеджмента команды разработчиков, это будет казаться какой-то, ну, типа, а зачем это делать? Ну, типа, нам за это не платят, нас за это не спрашивают. Если есть какой-то процесс эскалации в течение дня, таких задач в команду, то есть, я повторюсь, не в отдельного разработчика команды, а вот именно в команду, то метрики появляются. Я не думал об этом. Ну, то есть, я не знаю, приведу пример так, что есть, короче, разработчик, пусть будет Антон, у нас нет, вроде, Антона в гостях никакого, Антон очень любит метрики, он очень по ним упарывается, вот он берет просто и 30% своего рабочего времени тратит, чтобы все обмазать метриками. К нему приходит, начальник говорит, Антон, я тебя сейчас нахер уволю, ты 30% нашего бюджета просрал, ну, то что, какие-то дурацкие метрики, как это еще нужно? Потому что, вот, менеджеру Антона, пусть будет Петр, Петру непонятно, почему Антон вот так вот этими метриками упарывается. Ну, да, что-то где-то слышал на конференции, что, да, полезное дело, ну, прям уж увольнять не будем Антона, но это не то, чем мы его просили заниматься. Тогда как, если у тебя Петр, глядя каждый день на то, чем занимается команда, видит, что, значит, они вот сегодня прилетел срочный ИШ его там от эксплуатации, и нужно отвечать, завтра прилетел срочный ИШ от эксплуатации, нужно отвечать, послезавтра вообще, короче, разработчика подняли ночью, потому что вообще не смогли разрабатываться без него, не смогли починить. Вот, когда такое начинает накапливаться, метрики-не метрики, возникает какое-то естественное не знаю, понимание у всей команды и у менеджмента команды, и объяснимая необходимость в том, чтобы инвестировать в лучшую видимость того, что происходит в системе. Ну, то есть, да, появляется такой запрос на это. Ну, да, у тебя, как бы, эксплуатация-то, скорее всего, один из держателей стейка. Понимаю о чем ты, да. Да, но мысль была о чем? О том, что не обязательно разработчики должны быть прям on call. Они просто должны быть вовлечены как команда. Да, именно. Так, мы уже наговорили, наверное, час. О чем мы не поговорили? Как я говорил, как нам говорил этот чел из Мандалорца. I have spoken. Я все сказал. Хорошо. Тогда я произволом ведущего. Ваня, Саша, есть еще какие-то дополнения, пока я не убежал к следующей теме? Давай быстрее. Хорошо. Буквально одной строкой, потому что я уже все забыл, я тему притащил к прошлой неделе, я пропустил прошлую неделю и все забыл. Но, в общем, там компания ByteDance, которая стоит за социальной сетью TikTok, с вашими любимыми 15-ти секундными поющими видео и танцующими видео и всяким таким, open sourced свое нечто, что архитектурно напоминает такой домороченный Кликхауз, ой, не Кликхауз, домороченный Сноу Флейк. Они даже, что характерно, используются, если я правильно помню, в FoundationDB где-то у себя для хранения метаданных.",
    "result": {
      "query": "логи high cardinality хранение"
    }
  }
]
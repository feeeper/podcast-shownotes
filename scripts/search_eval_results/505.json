[
  {
    "segment_id": "b7c1e6d5-e57b-4465-ae9a-c64c535305d8",
    "episode_id": "2e59e9bd-276e-43d3-94dc-30d51c8dff71",
    "episode_number": 505,
    "segment_number": 15,
    "text": "Любопытненько. Тогда ушли к следующей теме. Пойдемте дальше по темам. Следующая тема моя и я тоже про ЛМ. Мы в принципе с Сашей её немножко начали, когда Саша начал говорить про агентов. Это статья от как же его правильно зовут? Дэвид, кажется, Крошал. Он мне кажется много в чем засветился. Это человек который делал он в гошном комьюнити. Он компаундер тайл скейла и в принципе довольно много в гошном комьюнити делал всего. Сейчас он работает с каким-то еще и тоже кодинг agent штукой какой-то. Называется скетч. И статья собственно про то, как он от скептицизма перешел к такому активному использованию агентов. На самом деле буквально сегодня у, как же его зовут-то, то Pragmatic Software Engineer кажется блог называется я закину потом ссылку Да, просто The promatic engineer. Сегодня тоже был выпуск, где он прям много людей проинпровировал в общем-то с похожей историей. Мы уже в общем-то обсудили в начале выпуска, что лумка будучи, если ее научить делать Тул Коллинг и если ее поставить в такой типа цикл, это конечно очень упрощенное видение того, как это работает, особенно учитывая, что если вы хотите конкретно агент использовать для разработки, то чтобы не налетать на такие проблемы, на которые например налетел Саша, было бы прикольно например уметь определять tool, просто что типа ты просто агент, говоришь build, а вот как именно этот build tool, типа какой у него синтаксис, ты просто его один раз задаешь где-нибудь, и там подобные вещи, типа какие тулы звать в какой ситуации, то есть какими промптами это все обвешать, как это все интегрируется DEшкой. Это все важные юзабилити вопросы, которые нужно решать. Но вот в базовом таком, просто вид с высоты птичьего полета, это значит есть человек, который берет промт сует его в аламку, и аламка вызывает тулы и смотрит на ответ пока у него не закончится что делать. И потом он вам там или кулл реквест присылает или еще как-то вот она вам потом отвечает. И опять же, как мы это уже обсудили, фундаментальная разница между тем, что просто какой-то рандомной галлюцинацией от одного прохода lam по промту, в том, что оно докручивает ответ зачастую до гораздо более применимого состояния и благодаря этому способно выполнять гораздо большие задачи не налетая на тупые ошибки. Ну то есть она на них налетает, но просто где-то вдали от вас. Почему это работает? Потому что, отчасти потому что в принципе программирование так во многом работает. То есть типа когда мы что-то делаем, мы же не просто какой-то код пишем, мы зачастую там не знаю можем какую-то документацию посмотреть, мы можем там ваши скрипты запустить и так далее. И вот эта вот структура с тоуколами она в общем-то больше похожа на workflow, который у нас есть просто у самих людей есть как при нашей инженерной работе, если вот ну опять же мы исключаем какие-то по-настоящему сложные абстрактные задачи, а именно вот если мы говорим про что мы механически делаем когда мы пытаемся программировать. И вот он сравнивает попытку добиться от LM в один проход, просто по фронту привести к хорошему результату, а так как не знаю, попросить человека разбудить его утром и заставить его делать какой-то такой, не знаю, вайтбот-кодинг, притом на Си. Вот мы все это очень не любим, потому что мы привыкли собственно запустить Тулу и посмотреть на отряд. Почему заставляем ламку решать такую задачу? Тот факт, что ламка способна даже перфомить так, как на перфомит от одного запроса, это уже чудо чудное на самом-то деле, потому что люди так обычно не делают. Минус агентов в том, что это время и деньги, типа вам нужно этого агента где-то запустить, он должен где-то бежать, он это может делать довольно долго, потому что он может делать много тупых ошибок и в этом цикле может довольно долго крутиться. И в принципе, если вы не осторожны, вы можете довольно много потратить денег на один pull request. Не то что не осторожно, тут может быть так, что агент может зациклиться, то есть он может пойти во-первых, ты никак не ограничиваешь его, ты не можешь его ограничить. Нет, в принципе, ты можешь жесткий лимит по кредитам поставить. Нет, вообще-то он ограничен по количеству токенов. Ну да, да, я имею ввиду с точки зрения логики, он может уйти, то есть ты ему дашь миллион токенов, он может уйти в какую-то глубину и этот миллион использовать. Но ты же не будешь каждый раз говорить: Кстати, сделай этот запрос за 10 токенов. Нет, я имею ввиду, что вот если мы берем квот для примера, он в принципе не способен держать больше 100 тысяч токенов контекста. А когда он работает с внешними тулами, он копит контекст. Чаще всего у них есть вот этот rolling window, во-первых. Во-вторых, у них есть возможность суммировать перед тем, как он полностью очищает контекст. То есть есть куча механизмов, как это выйдет. Но он перед этим остановится. Ты вроде как, насколько я не уверен, доходил ли я до такого количества токенов. Мне кажется, что его нужно прямо попросить. Он остановится, его нужно попросить сделать саммари и запустить заново. Но я к тому, что самом деле это становится отдельной задачей. Это понятно, что у них есть решение, есть несколько способов, как это всё сделать, но просто само по себе это так не очевидно, когда ты начинаешь этим пользоваться. Я вот к чему. На самом деле эту интересную особенность вспомнили, что по дефолту агент будет пытаться все команды, которые он выполняет, и всё, что они выводят, себе загрузить в контекст, что во многих случаях вы не хотите. И нужно прямо уточнять промпт, что выполняй эту команду, но что она выводит тебе не интересно. Тебе интересен только код возврата. Я, наверное, не буду прям совсем всю статью пересекать, но он приводит пару примеров. В одном случае он, грубо говоря, запромтил агента и сделать авторизацию для гитхаба, и условно ушел с ребенком гулять. И вот с этой задачей оно справилась почти, то есть оно сделало фигню, но даже не столько потому, что это была какая-то невероятная фигня, а скорее потому, что получившееся решение оказалось самым оптимальным, потому что причины. Там сейчас, как в гитаве работает афишка, то есть он попросил сделать так, чтобы она работала с одним токеном на все. Казалось, что не так-то просто там какую-то другую штуку сделать, и она написала в итоге цикл, который очень дорогущий, и он в итоге это распутывая решил в итоге сделать, ну в общем, перепромтить просто по-другому, но в целом тот факт, что оно пришлось, справилось с проблемой, оно, как это, как это, в общем появилось себя как энергичный Джун, который все сделал. Вообще оставлять агенты без присмотра так себе затея, особенно вариация sinking агентов, потому что они могут в ходе работы над задачей завернуть вообще куда-то не туда и лучше смотреть за ними и прерывать, если мысль пошла не в ту сторону. Ну да, но с другой стороны ведь можно и нет. Ну типа ну не пошла в ту сторону. Нет, если по приколу, то конечно можно все что угодно, но если задача как бы сделать, решить задачу с помощью агента, то лучше С другой стороны, понимаешь, если ты прямо сидеть и нужно постоянно сесть и бебиситить, то это тоже бесполезной фигней становится, потому что если ты постоянно на него смотришь, вместо того чтобы делать другую задачу, то зачем тебе этот агент проще самому ее сделать. Это очень дискуссионно. В общем, он тут говорит о том, что вот такие тупые задачи типа интеграции с гитхабом, это было бы идеально бы спихнуть на онлайн, потому что ну не то чтобы кому-то очень нравилось этим заниматься, а с другой стороны отрегулировать потом пару фигней, которые оно сделало, и может быть где-то что-то прописать, дописать, до поправить и закомитить, это, как это, короче, что я хотел сказать, что весь point, который вообще в этом куске статьи делаешь, что у него заняло меньше времени и слов промпта, агента заставили сделать что он хочет, несмотря на то что он с первого раза сделал не совсем то, что в итоге было бы хорошо, несмотря на то что он точно следовал промту. Да, в общем, все равно заняло меньше слов и энергии, чем написать, собственно, кусок блокпоста об этом. И именно же в этом и прелесть агента, что ты меняешь время машин на то, чтобы оно за тебя что-то сделалось. Если оно с вами пошло не ту сторону, то ты через полчаса или может быть через час заметишь, ну просто перепромтишь. Если ты будешь этим беситить, вместо того чтобы делать свою работу, ну как бы не проще или сам код написать тогда просто с автодополнением. На мой взгляд, в чем прелесть лолм? Не в том, что они за тебя решают задачи, а ты в это время занимаешься чем-то другим. А в том, что когда ты сталкиваешься с задачей, которую ты воспринимаешь как неинтересное, вместо того, чтобы прокрастинировать над этим, что блин, это уже 20 раз в жизни делал, опять. Я согласен. Зачем тебе бесить неинтересную задачу? Я отвечаю на твой вопрос. То, что наблюдать за тем, как её решает LLM, и в случае чего его прервать, и в случае чего его поправить, чтобы он всё-таки решил эту задачу, это более продуктивно, чем не решить её вообще. Потому что ты будешь сидеть и такой: Блин, опять прокрастинируй вот это вот всё. То есть, понимаешь, выбор с моей перспективы, я не утверждаю, что у всех людей так, выбор не между тем, чтобы решить самому иили сидеть и побесетить ЛЛМ, а между тем, чтобы сидеть и побесетить ЛЛМ и не решить вообще, потому что ты будешь прокрастинировать. Я с тобой согласен. С другой стороны, я думаю, что рано или поздно тебе надоест сидеть и побеситить. Ты будешь просто больше ему доверять. Валера, за этим можно наблюдать вечно. Это как работа пожарного, потому что горит огонь, льется вода и человек работает. За этим можно наблюдать вечно. Ладно, вернемся к статье. Следующий пример, когда если это обобщить, то иногда люди делают в своих кодовых базах странненькое с точки зрения, не знаю, того, что типично встречается на форумах и того, на чем тренировали лмку. Тут, например, приводится пример, как они в tailscale часто имеют просто колонку с, не знаю, айдишником и jsnb, вторая колонка jsnb, а все другие остальные колонки получают просто как по большому счету алясы на куски jsnb-колонки. Это странненько, но с другой стороны для небольшого количества данных и для неструктурированных данных и для стиля не управляет схемой, когда заморочено, прикольный вариант. Я в принципе одобряю для особенно каких-то не очень нагруженных систем. Вот. И очевидно, если я лепке просто без контекста, что однопроходную, что агентную попросить что-то такое сделать, может получиться странненькое, но скорее всего будет делать фигню, или даже пытаться это все убрать. Вот, но можно как вот хак, который он придумал, просто прямо вот в файле писать комментарии, которые дают контекст от отсутствия того, что здесь происходит. И внезапно у него ломка смогла даже с такими схемами справиться и писать полезный код, полезные и правильные инсерты. Иногда я помогаю даже просто в паре месту написать комментарий todo и в промте указать, что вот там, где я написал todo, там сделай то-то и то-то. Иногда даже такой контекст уже полезен. И в общем-то из этого всего мы приходим к набору размышлений, что например LLM позволяет производить код, притом довольно рутинный. Это не всегда то что мы хотим. Есть просто проекты где в принципе ну считается что лучше меньше кода потому что это какая-то не знаю критичная безопасность и библиотека на Си. Есть проекты где проблема где кода уже дохера, и проблема в нем разобраться. И в принципе тут AI и LM тоже полезны, но скорее всего не генерация кода агентами. Тут вот как раз таки скорее всего нужно того же самого, я уже не помню, боюсь врать, мне кажется, у курсора и у Z тоже есть варианты спрашивать. По-моему Саша рассказывал про то, что у Z есть варианты, спрашивать про то, а что вообще кот, как он что делает. Не понял. Ты кажется рассказывал, спросил у какого-то L-m-ки, у тебя внутри зеда, как вот типа какая-то штука в мозге работает и он тебе даже более-менее вменяемо объяснил. Да, он может посмотреть на код, изучить его и дать саммари, здесь в общих чертах происходит. То есть типа в таких кодовых базах ЛМ все еще полезны, но агентов нужно очень, не знаю, пристрастно промтить, чтобы они правильные изменения делали, а не просто какое-то, которое они сочтут. То есть как это я бы это обобщил для себя и это уже не мысли статьи, это просто мое моё текущее представление, что даже самые примитивные не агентные сети, даже вот просто один проход, потрясающе перформят на задаче сделать из ничего что-то. Чем больше мы идем в сторону внести вменяемые изменения на существующем проекте, вот в один проход у нас довольно быстро перестает хорошо справляться, агенты у них сильно дольше продолжительность континуума полезности, но рано или поздно тебе просто как человеку должно быть понятно что ты вообще промтишь, потому что может быть реально нетривиальное изменение в большой сложной какой-то базе с неочевидными для тебя последствиями когда ты будешь кудревировать. И собственно тут встает такой вопрос, что возможно если бы ты это писал сам, ты бы налетел на какие-то интересные грабли, которые ты можешь себе не представлять, если ты просто делаешь кудревью. Так что у всего этого есть границы применимости и в чудесном будущем они все еще останутся, даже если он станет сильно умнее. Потому что все равно code so far review это принимает человек и как бы LM агент это способ ускорить написание кода, а нужно ли вам ускорять написание и нужно ли вам вообще больше кода это уже вам решать. Почему это полетело сейчас? Ну тут делается такой момент, что в принципе любому человеку, который изучал область машинного обучения в последние 50 лет, в принципе знаком с теменом Reinforchment Learning. Но LM-ки из образца 2023 были довольно так себе применимы к вот этому вот агентному циклу, тогда как LM-ки из 2025 сейчас прям под это оптимизируют. И я не уверен, да, он прямо об этом пишет, что как раз таки ключевой момент, что они довольно стабильно теперь могут делать пуллколлинг. И дальше в общем-то рассуждения о будущем, как бы что будет с IDEшками, что будет с вообще со всеми нами. Тут нет каких-то интересных прям ответов, но в принципе да вопрос в том, что какой правильный для этого UI все еще не до конца понятно, потому что они все-таки все еще делают какую-то такую знаешь типа не то что совсем фигню, а 95 процентов того что нужно, но местами нужно поправить и придумать к этому хороший UI это ну не то что прям супер тривиально, то есть например если ты делаешь просто процесс с play request и ты там потом, оно что-то сделало, ты даешь комментарий в play request, и оно взяло и переделало, и вот было бы проще саму эту строчку поправить. Соответственно, наверное, удобнее, когда оно дает тебе просто див, ты его например принимаешь по большей части и там не знаю где-то имеешь возможность руками подредактировать.",
    "result": {
      "query": "LLM agents code development workflow"
    }
  }
]
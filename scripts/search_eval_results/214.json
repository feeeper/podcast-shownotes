[
  {
    "segment_id": "5517f66b-8927-4fee-a700-3505a8a495fb",
    "episode_id": "1845796a-b6cb-4603-8d11-332be014f066",
    "episode_number": 214,
    "segment_number": 8,
    "text": "Конкретно в случае LLVM-а там, мне кажется, имеет немалое значение типа архитектурное различие систем, что у тебя ну то есть Apple сейчас явно педалирует в сторону того, чтобы иметь какой-то вот такой если я правильно помню, у них что-то такое уже есть для iOS, они как раз педалируют в сторону того, что у тебя программа должна компилироваться в intermediate representation какой-то, который потом как бы доделывается под специфичные платформы, то есть LLVM это у него заложено сразу в архитектуре, что у них есть этот промежуточный LLVM-овский white-code, из которого компилируется в конкретные процессоры. Им это очень нужно, потому что у них есть очень большая кодовая база, которую им хочется как-то так или иначе шерить между iOS-девайсами, которые на ARM-е и Mac-ом, который на Intel-овских процессорах, плюс у них на iOS им хочется, у них же там очень свой собственный ARM, им хочется его побыстрее развивать, побыстрее фичи впиливать и так далее, больше всего хочется, чтобы старый софт, который залит в App Store уже, мог в какой-нибудь момент эти новых фичи процессоров подхватывать, поэтому они очень сильно педалируют в сторону того, чтобы декомпилировать под конкретные девайсы. И мне кажется GCC просто в силу своего внутреннего устройства не способен делать те же самые вещи, которые делает LLVM, то есть тут еще это, наверное, немаловажно. Ну, возможно. Насчет того, что проекты используют и GCC, и Clang, ну и LLVM, мы используем, например, мы компилируем наше криптоядро и там, и там, и действительно отхватываем разные баги, и это всегда дико весело, я бы сказала, но лучше подобрать слово сложно. А санитайзеры? Санитайзеры вы используете? Мы используем статические анализаторы кода, мы используем штуки для анализа количества памяти, которое она пожирает. Вот, как-то так. Ну, норм. Мне кажется, я рассказал все, что хотел, если только у вас не остались вопросы, и возможно в чате есть вопросы. Вроде на все вопросы, что были в чате, были даны ответы. Если вопросов нет, я предлагаю передать слово похоже, что Валерию. Да, тут на самом деле очень короткое слово, как я уже сказал, буквально одной строкой, про то, что у нас... Мы это обсуждали в выпуске 211, то, что там Postgres 11 с всякими классными штуками, в общем, он вышел. Вот там вся новость. То есть можно для адаптера ставить его себе куда-нибудь в продакшн. Ура, ура, вышла новая подгря, мы уже попробовали, работает. Что, правда? Вы не спешите с выводами. Да, у нас уже крутятся автоматические тесты, мы использовали что-то благодаря этому, я сейчас какую-то посмотрю. Я знаю точно, что стабильно, долго у нас крутилось 9.6. Но вот вышло 11-е, мы на этой неделе увидели и начали обновлять докер образы, чтобы использовать новый. Клево, клево, клево. Окей, вы быстро. Ну, нам очень важно, чтобы все наши криптографические штуки крутились всегда и везде, или как минимум, чтобы мы знали заранее, где они не работают. Да, потому что очень часто, если он не работает, то править приходится довольно долго. И плюс это клевый повод обновить документацию и сказать, а вы уже готовы? Пока не забыл про GPL и криптографию и узнать все, что скрыто, если так можно. Есть интересная особенность у GPL, что производители большинства embedded устройств, всяких там роутеров и так далее, они часто строят свой бизнес на Linux, на кучу-кучу разных GPL проектов, там типа squashfs, типа busybox, вот этого всего. И интересная особенность заключается в том, когда кто-то хочет посмотреть, а что у этого роутера внутри, немножко его переверсить, он берет дамп флеш-памяти и там смотрит, что там какая-то модифицированная файловая система. И он берет, ну вместо того, чтобы это дико реверсить, он берет и пишет письмо производителю, что типа вы знаете, я тут решил поревьюить ваш derivate от GPL код, и обнаружил, что вы нигде не выложили вашу модификацию файловой системы. А знаете ли вы, что лицензия GPL вас обязывает и тролливали. И это занимает какое-то время, но большинство производителей, они предпочитают все-таки выложить эти 3-4 сиршных файла, чтобы там 2-3 задрота могли посмотреть их файловую систему, чтобы просто не рисковать. Бизнесу это не нужно. Это достаточно полезное свойство GPL, я о нем почему-то раньше сильно не задумывался. Настя, а у вас под какой лицензией проект? Вот ты меня сейчас предлагаешь пойти в GitHub. Я пойду посмотрю. У нас на самом деле разные для веществ проектов. Сейчас я гляну, на чем у нас основные. Дай мне секундочку. Apache 2. Apache 2 у нас большая часть наших проектов, и есть те, которые на HGPL 3.0. А следующую тему добавил я, и немножко опрометчиво скипнули в прошлом выпуске, потому что она на самом деле короткая и была очень в тему. Почему она была в тему, я уже помню, немножко смутно, но там как раз разговор шел про социальные сети и про то, что ну, как бы создаем некие разные под разную активность. И новость заключается в том, что компания Google закрывает Google+, ну, у нас Slowpoke Zen, простите, как раз в числе прочего из-за утечки большого количества данных пользователей. Они, конечно, пишут в своем блокпосте slash пресс-релизе, что у них нету достоверной информации о том, что много данных утекло, у них был баг, который позволял этим данным утекать, но вроде как никто не успел им воспользоваться, но они об этом точно не знают, потому что якобы из соображений безопасности они хранят логи всего 2 недели. Потому что хранить логи 3 недели — это совершенно небезопасно. Абсолютно, абсолютно небезопасно. Видите, как компания вас позаботилась? В любом случае, плюс официально хана, он просуществует еще где-то до следующего августа в таком предсмертном состоянии. И после чего он будет существовать только в виде... Он будет существовать только для компании, которая использует его как корпоратив... У него, короче, есть возможность быть использованным как корпоративная соцсеть за деньги. То есть если вы к Гуглу несете бабло, у вас может быть такой маленький уютненький LinkedIn слэш-интронет, слэш-как вы это называете. С точки зрения бизнеса, опять же, понятно, если люди несут бабки, зачем запрещать им нести бабки. Не могу сказать, что я очень сильно расстроен. Мне казалось, что Гугл плюс не то, чтобы прям активной жизнью живет. По-моему, они так прямо в пресс-релизе написали, что особо никто не пользовался. И мы вроде как думаем, что никто этим API, которое Reveal, которое показывало данные пользователей, не нужны. Что вроде как никто этим API не воспользовался. Но возникают паранодальные сомнения. Закопали и закопали. Мне кажется, пошли дальше уже. Я случайно обнаружил, кстати, что Гугл-код его вроде как закопали, но он немножко торчит с этим велькими стами. Работает еще, да. Валера, расскажи нам уже, почему ЭКТО-3 сломает обратную совместимость. Ну хоть что-то серьезное давай. Ну, кстати, не то, что там серьезное изменение совместимости было. Там дело такое. Для начала вводная небольшая. Для тех наших слушателей, которые не знают, что такое ЭКТО, в общем, есть такой язык-эликсир, который поверх реланга нахлобучен. Точнее виртуальный, машина-реланга. У него есть довольно моднейший веб-фреймворк ФЕНИКС. И у моднейшего, точнее так даже, моднейший веб-фреймворк ФЕНИКС в свою очередь строится на моднейшем способе доступа к базе данных ЭКТО, который я, например, очень сильно одобряю, потому что он, в отличие от многих похожих проектов, скажем так, не пытается быть слишком умным, не пытается очень сильно абстрагировать базу данных от программиста и по сути оперирует такими вещами, как схема данных, запрос, какая-то валидация, то есть как она там называется change set, и так называемая репозитория, что по сути является интерфейсом к подключению к базе данных. И в отличие от какого-нибудь рубёвого актив рекорда, где модель сразу слишком умная, сама сходит в базу за тебя, нечаянно сделает плюс один запрос и всякие такие проблемы, в ЭКТО не существует, больше того механизм конструирования запросов в ЭКТО довольно удобный, но вот оказалось, что механизм схем и валидация, точнее, change set тоже очень удобный, люди начали использовать даже в некоторых местах, которые непосредственно с SQL базами данных не имеют ничего общего или вообще даже с базами данных имеют мало общего, то есть в принципе их схема, change set просто удобна для того, чтобы принять какие-то данные из сокета и",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 3974. Please try again in 7.948s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 3974. Please try again in 7.948s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
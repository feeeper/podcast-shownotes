[
  {
    "segment_id": "ced0416f-e5b0-44db-9102-079630d76f7a",
    "episode_id": "0f45aa15-d9ae-4ec2-86fa-bc610d3f077e",
    "episode_number": 365,
    "segment_number": 11,
    "text": "А, ну, я тут как бы… Может быть, мы к этому перейдем. Да, да, давай, вы там чуть-чуть просто рассказать, то есть, в принципе, как я уже говорил вначале, у нас, на самом деле, очень много работы с данными. Ну, просто потому, что, как бы, перед тем, как любую проверку сделать, надо данные собрать. А данные, как бы, нужны из, в общем-то, большого количества источников. То есть, это не просто какой-то условный какой-то там, не знаю, банально там, MySQL, где-то там, по пользователю, допустим, поедешь что-нибудь там, типа, заберешь какую-то информацию и, допустим, что-то с ней сделаешь. Тут приходится, как бы, дать на большое количество данных. И поэтому, по факту, я, на самом деле, уже последний, где-то, наверное, даже чуть-чуть не год, просто работаю, как датинженер. То есть, в основном, занимаюсь, там, типа, каким образом можно там все вот эти вот, там, данные собрать и их предоставить. Я, в общем, как-то начал немножко копать в углу с датной инженерией и понял, что, как бы, количество технологий и вообще различных решений, их, как бы, такое огромное количество, что я вообще, как бы, ничего об этом не знаю, какие только может быть самые базовые вещи. Вот. Ну, с другой стороны, как бы, пообщавшись с другими датинженерами, понял, что примерно все, как бы, находятся в похожей ситуации, потому что, ну, к примеру, там, там, сколько у нас там, типа, разных, типа, типа, в хранилище есть, допустим, графовые базы данных, у нас там есть какие-то колоночные базы данных, у нас есть релационные базы данных, то есть, там, тоже самое, Massicle, там, не знаю, Oracle, там, Microsoft SQL Server, там, вот эти вот колоночные базы данных, там, какой-нибудь, там, ну, есть, Redshift, как бы, амазоновский, как бы, который больше, как бы, подходит для агрегации данных, там, вот это вот, графовые базы данных, там, там, штуку 8 я как-то нашел, когда, собственно, искал решение, которое можно, допустим, граф хранить, там, типа, Neo4j, там, OrientDB, потом, там, амазоновская, конечно, не совсем дурацкая, как бы, этот, непту называю, не, не, да, по-моему, амазон непту называется, как бы. На Позгрессе, на Позгрессе графовая база? Да, там, на Позгрессе какая-то базовая данных, база данных есть, есть какое-то, в общем, еще хранилище, там, типа, триплета, где, по сути, там, типа, как релационная база данных, но она хранит, там, типа, условно говоря, такие треугольнички, как бы, и потом они может как-то агрегировать, допустим, сгенерировать граф, то есть, там, тучи, там, разных стриминговых салюшинов, то есть, там, есть какой-нибудь там Spark, который там бачпроцессинг занимается, есть, допустим, условно, там, какой-то Apache Link, например, который тоже, там, типа, вот этот, вент в процессе там обрабатывает, а, кстати, в этой, в Alibaba, ну, то есть, в этом, в Aliexpress они, как бы, очень сильно используют как раз основные там… Именно, амбексе. Да, вот, то есть, и ты понимаешь, что есть такой огромнейший зоопарк разных салюшинов, и, на самом деле, причина этого заключается в том, что, когда, когда у тебя реально big data, просто, конечно, как определить big data, мне понравилось одно определение, что big data – это когда она в R не влезает, тогда это big data. Вот, ну, то есть, вы не можете, как бы, каким-то одним решением сделать так, что… Да, в принципе, язык аналитики, который… Ну, типа, условно, если ты не можешь в R запихать свои данные, как бы, вот, чисто вот эта вот консоль, которая у себя на компьютере ранее, то это уже, типа, big data. И от кого-то из датегенереров такое определение слышал, слышал big data, и мне оно понравилось. Вот. Довольно вольное определение, но, но, но, но, допустим. Ну, как бы, да, то есть, я сейчас не готов сейчас определять big data, потому что я на самом деле такой, знаете, я еще не настоящий сварщик, я просто как бы решаю текущие проблемы, как бы, связанные с данными. Вот. И да, у меня какое-то время было определенное ощущение, что что-то как-то слишком много всего, и я что-то как-то плохо разбираюсь, но, в общем, говорю, что пообщался с датегенерами, в общем, понял, что, в принципе, примерно все находятся в такой же ситуации, и скорее тут более, более ценится умение как бы быстро разобраться в какой-то там, допустим, системе, понять вообще как ее можно, нужно там использовать и так далее, и, допустим, заимплементить какой-то MVP, допустим, на этой системе, нежели чем ты будешь пытаться, как бы пытаться, ну, как бы охватить невозможно, и примерно понять, как все системы работают, и, типа, стать каким-то универсальным аракулом по всем вопросам как бы этого датегенеринга. Вот. А вот, собственно, как раз все закончится в Я, кстати, наверное, в чатик чуть позже там скину блок одного дата-инженера, который мне очень, в общем-то, понравился, который как раз писал на тему сравнения вот архитектуры как бы дейта архитектуры с классической архитектурой, как бы программной обеспечения. Ну, и, в общем, там такое основное тезисы было, что если вам, как бы, условно говоря, лейтензии, ну, как бы вы можете позволить какую-то лейтензию, там, типа, я не знаю, несколько минут, допустим, полдня, то, в общем, решение на основе как бы данных иногда бывает, можно диливерить там гораздо, словно говоря, быстрее, чем, допустим, решение на основе, в общем, тех же самых, ну, классических паттернов там разработки обеспечения там, религиозной базы данных, какие-то запросы там, какие-то индексы там, типа, серверы друг друга колят. Вот. Ну, в частности, она тоже... Я вот сейчас не очень понял идею, если честно. Ну, к тому, что, ну, например, просто пример приведу. Вот, допустим, условно, как бы, допустим, вы своей, как бы, компании делаете чарльбек-дефенс. Ну, то есть защиту чарльбека, то, что я вот говорил. Вам, по сути, нужно сагрегировать очень большое количество данных о пользователе. В чем из разных доменов. Ну, то есть, типа, из разряда, сколько он где, чем пользовался, там, сколько у него там этот, его время там, нахождения в системе, плюс еще, как бы, для того, чтобы смачить какую-то там, этот платеж, который вам приходит, допустим, от условной компании, которая вам какой-то лерсинг предоставляет, то есть, типа, с каким-то, допустим, с тем, что, допустим, у вас есть как у каком-то банке там произошел чарльбек, например. У них же нету, как бы, ID вашей, как бы, системы. Вам приходится каким-то образом, каким-то параметром сравнить то, что вот они вам прислали информацию, как бы, с тем, что у вас база данных. А это, допустим, где-нибудь у вас лежит какой-нибудь merchant ID, например. Это вот та информация, знаете, строчка, которую вы в банке транзакции своей смотрите. То есть, там рядом строчка бывает странная, типа, что-нибудь какая-нибудь там компания, там slash что-то, slash что-то, какая-то, в общем, arbitrary information. Вот. И, например, вот по всему этому, как бы, вам надо, типа, юзера вот свести со всем платежом, со всеми данными и отправить, допустим, вот эту вот информацию, как бы, в payment provider. Вот. Если вы это будете делать, условно говоря, там, на, как бы, имея какую-то, допустим, микросервисную архитектуру, то есть, вам придется сделать там экосистемы, там несколько разных эндпоинтов, которые вы будете вызывать. Там, возможно, у них, допустим, не будет каких-нибудь индексов на базе данных. То есть, вам надо будет идти в эти команды, и говорить, ребята, давайте как-нибудь индекс повесим или еще чего-нибудь. То есть, вы реально можете там потратить, словно, месяц на разработку такого solution. Но так как в данном случае, как бы, словно chargeback defense, он не требует от вас моментального реагирования, вы можете там, типа, оспорить это chargeback в течение, там, по общению месяца. Вот. То вы просто можете, там, я не знаю, через какую-нибудь там защинка этих данных в какой-нибудь аналитическую базу данных, и потом погонять просто query по аналитической базе данных, как бы, собрать все эти данные, допустим, попозже. Окей, я понял, наверное, мысль. Ну, надеюсь, я ее правильно понял, но такой, не знаю, в противовес, наверное, этой мысли, я дальше, у нас есть непереносимая как лактоза тема. И вот там высказывается другая мысль. Ну, я, в принципе, это наблюдаю, я в этой контексте много собеседовал среди полтора месяца. А давай мы плавно перейдем к непереносимой теме уже и в контексте вот… В контексте этих родов. Ну, я, наверное, все-таки, вначале я надвечу здесь, ну, то есть, я скорее против переходить плавно, потому что там эта мысль размоется, а я хочу ее высказать именно как самостоятельную мысль. Я, плюс, собеседовал с несколькими компаниями в этой области, и есть очень сильный тренд на как раз-таки лолэд-нс-обработку данных. И очень многие дейтовеер хаус продукты или даже просто какие-то более специализированные продукты сейчас очень сильно озаботились тем, чтобы отвечать на запросы с низкой задержкой и чтобы это делать быстро и немедленно. То есть, я не знаю, может, конечно, кейс антифрода такой особенный, но очень часто в дейты инжиниринги есть задачи, которые требуют даже, наверное, большего приседания со штангой и, короче, тяжелых операционных сложностей, татология получилась, которые вытекают из того, что данные должны быть достаточно свежими. То есть, мне кажется, не кажется ли тебе, что кейс, который ты вот приводишь и пытаешься, типа как-то происпроектировать на более какой-то общий случай, что он на самом деле специфичен для антифрода? Ну, смотри, ты сам понимаешь, что, например, если надо с об этом данные, допустим, по... Сагрегировать какие-то данные, допустим, за последние три месяца. Ну, такая у тебя задача есть. И тебе надо сделать это как бы быстро, условно. И ты, например, будешь пытаться гонять эти квири, допустим, на релизационной базе данных, причем эти квири будут достаточно тяжелыми. То есть, столкнуться с ситуацией, что когда время обработки твоего реквеста, оно будет достаточно большим. Ну, то есть, какие-то, допустим, секунды, что в этом случае будет не очень позволительно. То есть, тебе бизнес скажет, что тебе, ребят, не надо быстрее. Ну, дальше уже как бы начинаешь придумывать, типа что тебе сделать? То есть, например, если у тебя, допустим, данные, как бы спустя какое-то время, там я не знаю, день, неделя, они становятся уже имутабельными, то есть они не изменяются. Как бы просто какую-то ситуацию рисую. То есть, ты, в принципе, можешь их на предпрощет какой-то сделать. И, допустим, в момент обработки запроса ты можешь скрестить, условно говоря, какой-то там предпрощет, плюс как бы за какое-то последнее время из какого-то там, не знаю, из MySQL, вытащить какие-то там данные, которые там более свежие есть, которые еще не успели через все дайты попально пройти и попасть, допустим, в аналитическое хранилище. Ну, примерно, как-то так вот можно что-то сделать. Ну, то есть, чисто как, ну, вот идея. То есть, да, я согласен, что, типа, очень часто нужно, чтобы, очень хочется как бы иметь какие-то сложные запросы, вот как бы вот в рел тайнере делать. Ну, в общем, да, это, на самом деле, не так просто, как я тут сам с этим столкнулся. Тоже как бы с этой проблемой, как бы в тючле сейчас, ну, немножечко воюю. Есть ли... Ну, просто, смотри, я, наверное, дополню мысли, чего я, наверное, хотел еще допоспорить. Получается, ну, что, если правильно понимать, твой посыл был, что очень часто сделать решение на основе как бы команды данных быстрее, чем на основе команды сервисов. Но как только появляется вопрос короткой задержки, там, команда данных начинает строить сервис, который будет собирать данные, собирать нужные ответы с кучей всяких мест, где быстро, где медленно, и оно получается ни фига ни проще, ни сложнее, еще и кто-то должен оперировать. Ну, это, наверное, возвращаясь к той ситуации, типа вот этого копья из щита какого-то, ну, то есть, ну да, понятно, что вот... Так, что-то я уже немножечко сейчас это как бы попыл чуть-чуть, впрочем, сейчас попытаюсь закончить мысленно, но просто, что... Как бы... Данные... Ну то есть опять-таки, как бы вы идёте от бизнес-рекварментов, то есть, понимаете, что всегда в принципе есть какие-то там, возможно, с關лины, которые можно делать каким-то лейтен menoć, ну, что-то придумываете. Понятно, что иногда, допустим, у вас может быть сильная задача, что, допустим, из 5 минут сделать какой-то 10-секундное, допустим, лейтенublikо. То есть из 10 upgrade сделает какой-то real-time,uri, это меньше секунды, и как бы общего решения для каждого из этих кейсов как бы нету. И что отчасти приводит к тому, что у нас вот именно в связи с обработкой и процессингом данных есть в общем-то достаточно большое количество наобразных технологий и рейтеней, которые, в общем, вы как-то скомпоновываете во что-то одно, чтобы, в общем, для этого реала требовать бизнеса. Так, надеюсь, что это хоть какой-то смысл был в том, что я сказал. Так, я предлагаю плавно переходить к прочим нашим темам, если у тебя нет… Ну, если что-то, что мы упустили, что-то, что было важно озвучить, но мы не озвучили. Слушайте, да вроде все на самом деле озвучили, как бы, не знаю, у вас какие-то еще вопросы остались. На что-то еще могу попытаться ответить. Слушай, мы полтора часа тебя интервьюировали, я думаю, этого было вполне достаточно.",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 6066. Please try again in 12.132s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 6066. Please try again in 12.132s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
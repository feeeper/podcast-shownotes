[
  {
    "segment_id": "791041a7-7db7-4dce-b554-049977942f6b",
    "episode_id": "7f43af95-7803-4bf0-986c-4a5e278e0bbe",
    "episode_number": 46,
    "segment_number": 3,
    "text": "Как думаете? У кого-нибудь есть какая-нибудь любимая тема? А то я начну. Там осталась тема про секьюрити. Можно с нее начать. Давай. Ну мне пока нечего сказать. Все понятно. Я хотел, если честно, начать с другой. Я хотел начать с пользователя Sodian. Пользователь-слушатель Sodian написал про measuring microservices. Там статья по конференции CodeMotion 2015, которая время проходила. И в целом интересно с точки зрения, что с разных сторон рассматриваются майкросервисы. Не только с точки зрения, как это круто и хорошо, но и какие проблемы возникают с их тестированием. Там один человек, я, к сожалению, не знаю автора. Я имею в виду, не читал его блогов до этого. Поэтому я не знаю, что он до этого писал. Может, у него есть какие-то более развернутые мысли по этому поводу. Он комментировал проблемы тестирования микросервисов. Он предлагал делать это тестированием не юнит-тестов, каких-то маленьких внутренних функций, а тестированием фич-тестов. То есть, фич-тестинг. Когда у вас есть, скажем, какие-то инварианты в вашей системе и какие-то определенные фичи, которые должны соблюдаться всегда без разницы, что происходит снаружи. И вот эти вещи можно тестировать даже в реал-тайме. Для примера он приводил какой-то магазин, в котором, если вы, насколько я понял, магазин, что если вы идете по одной, то должны обязательно пойти по другой ссылке. Они поэтому должны быть обязательно один к одному. В API-вызовы этих двух вещей. И поэтому, если у вас совпадает один к одному, значит, все нормально на вашей системе. И это ваше знание этого инварианта помогает вам контролировать процесс, что у вас там ничего не поломалось. Если вы таких вещей накопите достаточно много, вы сможете хорошо проверять. Довольно оригинальная идея, она не сложна в реализации, сложна только в концептуальном понимании, какие у вас есть инварианты в вашей системе. Я бы, на самом деле, даже распространил себя немножко по поводу Infero, потому что там не просто интересная идея, но довольно свежая идея. Там был какой-то стартапчик, не помню название, который занимался, собственно, разработкой этих свежих идей и потом их купил Facebook. Потому что Facebook поверил в то, что им пригодится подобная штука в их... в анализе их кода для разных нативных платформ. Разного нативного кода для разных мобильных платформ. И, собственно, там две основных идеи. Подожди, Валер, ты переключился на Infero уже, да? А ты про что-то другое говорил? Да. Серьезно? Кто-то говорил, как будто я понял, что ты про Infero говоришь. Нет, Валер, я как бы поясню другими словами. Речь идет о ссылке истем слушателей про то, что микросервисы можно мониторить не как обычно по метрикам, типа число неудачных запросов, например, а о том, что можно их мониторить по принципу property-based-tests. Как меня поглючило, почему ты решил, что Ваня про Infero говорит? Sorry, guys. Честно говоря, лично мне идея кажется... Она действительно свежая, как Валер отметил. Но я с трудом представляю, честно говоря, как ее прикрутить. Ребята предлагают проверять инварианты серии, что если чувак что-то делает, то он, например, сначала авторизовался. Если он что-то делает, не авторизовавшись, то должен сработать алерт, как вариант. Что-то мне слабо представляется. Вот цвет. Ты как считаешь? Есть какие-нибудь... Это вообще в виде паперов статьи? Либо есть какая-то библиотека? Что это? Видео было на конференции, там дается ссылочка на само видео, оно не на YouTube, а где-то на каком-то внутреннем у них ресурсе. Можно посмотреть видео, и плюс эта статья – это просто мысли слушателей. Это просто мысли? Да. Я уловила идею, но хочу посмотреть, как это реализовано, хотя бы как вообще этим пользоваться. Потому что пока что из описания совершенно непонятно. Я могу поподробнее сказать. Самые простые примеры. Смотрите, мы не авторизовались, мы получили алерт. Дайте какой-нибудь такой простой примерчик, чтобы понять. Пока что у меня этого нет, и мне сложно судить. Но идея хорошая. Вообще он начинал свое видео, я только начал смотреть, дальше читал уже, не смотрел видео, читал только заметки. Начинал свое видео с того, что большая система, состоящая из большого числа микросервисов, она очень сложна. В том плане, что большое количество взаимодействий идет, и если какой-то из модулей сломается, это может привести к не тем последствиям, которые вы можете в голове своей иметь. И он в качестве примера брал наше человеческое тело. Говорит, вы же не считаете, там, ЦПУ отдельной взятой клетки, к примеру, или я не знаю, какого-то кусковена. Вы смотрите в целом на систему. То есть температура тела – это штука, которая комплексная, которая меряет вообще все ваши… какой-то инвариант, который объединяет все ваши внутренние маленькие системы. И с этой точки зрения он говорил, что такие инварианты для большой системы можно тоже придумывать. Они у вас есть в системе, просто вы чаще всего не задумываетесь, когда смотрите снаружи на эту большую систему. И он предлагал как раз пытаться это мониторить. В качестве примера он в том числе приводил способы взаимодействия системы, то есть модель акторов, как распространяются сообщения между акторами. Если, к примеру, у вас есть цепочка, и вы точно знаете, что в этой цепочке пришедшее сообщение первому актору, оно потом переходит второму, потом третьему, пятому и так далее, и доходит до десятого, вы можете просто сверять количество сообщений, которое попало первому и десятому, и оно должно совпадать. А если у вас там есть что-то вроде дерева, когда от одного акта идет двум, от каждого, то вы понимаете, что в конце концов количество вошедших в это дерево сообщений, оно там должно увеличиваться экспоненциально к веткам, в смысле, к листьям этого дерева. То есть это тоже можно как-то считать и учитывать плюс-минус. В общем, какие-то подобные вещи можно пытаться придумать. Как-то так. Давайте тогда к следующей теме пойдем. Поддерживаю. Следующей темой... Я что-то про секьюрити не вижу. Свет, ты какое имела про секьюрити в виду? Алексея было про секьюрити. В комментариях ссылка есть. Да, мы в конце как раз-таки начинали говорить про это, но решили, что мы уже перебрали по объему. Алексей, Литиум. Хотелось бы обсудить тему секьюрити в приложениях. Что сейчас на острие прогресса в Java мире в качестве секьюрити? Что использовать у себя, как сервлевл, особенно коллумлевл секьюрити? Я, честно говоря, не знаю, что это. Сложная, запутанная логика определения прав доступа к определенным данным. Я могу немного рассказать совсем чуть-чуть про секьюрити в нашем проекте, потому что у нас очень много секьюрити, между прочим. У нас база целиком зашифрована. Для этого используется самописанный DSL для работы с ним, потому что готовые нам не подходят, а шифровать руками перед хождением в базу данных сложно. Еще, еще, ну там, всякая криптография с асимметричным шифрованием и так далее. Но, честно говоря, я не могу слишком сильно раскрывать подробности, потому что NDA и вот это все. То есть, в основном, это такая криптографическая безопасность. SSL повсюду прикручен. Нужно следить за багами, потому что у нас нет админов, у нас все DevOps. И ты должен знать, когда там выходит какой-то когда есть какой-то 0d-exploit для Linux, тебе нужно апдейты повсюду раскатить и так далее и тому подобное. И, притом, узнать это должен не из русскоязычных сайтов, а как бы потому что там задержка типа два дня. Вот такого рода примерно проблемы. Ну и пишем мы это все под JVM на скале, поэтому у нас довольно, я с трудом представляю себе безопасные проекты на C. Но вот, вкратце, я надеюсь, ответил на эту тему. При этом OpenSSL-то на C написан. При этом он дырявый, как дуршлаг. Да, я как-то раз по работе был вынужден разбираться в коде, который там, внутри OpenSSL, и это очень страшно. И непонятно, не станет. Говорят, что есть ребята, которые его форкнули и сейчас пытаются все там отрефакторить и сделать как надо. Либерый ССЛ, да. Да-да-да, точно. Так, ну, тогда к следующей теме. Подожди, подожди, я не согласен на что. У остальных нет такой проблемы с безопасностью? То есть оно само там как-то обновляется и багов нет, и что? И вы ничего не шифруете? Паралли никто? То есть нету брутфорса, нету спама? Вы что? Какой спам? Какой брутфорс? Нет, ну у тебя, Вань, понятно, никакого брутфорса, а вот то, что у Валеры и, ну, хорошо, у Светы тоже понятно, что, наверное, нету спама. Так нет и ни у кого ничего. Там объективно реально нету такой проблемы. Хорошо, Валер, у тебя в проектах не бывает спама и брутфорса? Спама и брутфорса-то о чем? Ты же один в этом мире. Ну вот серьезно, у нас нет, как бы, как это, в принципе у нас сейчас появился чатик в игре, я не знаю, ну пока он запущен очень узко, где, ну если он пока не на весь мир запущен, и пока там никакого спама и говна нету. Брутфорс, как бы, ну, у нас логин через фейсбук, нас-то что брутфорсить? А, ну да, это во многом решает проблему. Еще от брутфорса и спама очень сильно помогает авторизация по телефону, если что. Капча и так далее ломают только так. Ну вот, давайте тогда в следующий раз я тут один, кто о безопасности беспокоится. Ну, хорошо, у нас тут двое, у нас тут два Александра, и оба беспокоимся о безопасности. При чем тут брутфорс и секьюрити? Ну да, вот то, что аккаунты ломают и потом продают в играх, это совсем к секьюрити не относится. Ну, относится немножко, да, но... Расскажи нам все о безопасности в Яндексе. Ну, я даже не знаю, что рассказать. Она там есть. Ну вот скажи, например, программистов пускают на боевые серфера, вот прям по SSH, или как? Ну, то есть, например, я знаю, что в мейли не пускают. В былые времена пускали. Но сейчас там все стало гораздо более серьезно, нет, не пускают. Даже на тестинг порой не пускают. Обычно есть место, где можно почитать логи, и это все. А в базу вы ходите напрямую или через хранимки? Потому что в одной компании, где я работал, хождение было только через хранимки, потому что не дай бог кто-нибудь что-нибудь заинжектирует или сделает какой-то запрос, который нельзя делать. Это по-разному, это зависит от сервиса. На тех, что я работал, мы ходили всегда напрямую. Хранимые процедуры кое-где используются. Вот я знаю, что в почте там очень много их там, все написано. Подождите, то есть, SSH на ноду зайти нельзя, да? А в базу данных, в реальную, в боевую залезть можно, да? Ну, не напрямую. Ты можешь как бы из кода что-то сделать с ней, конечно. У тебя backend всегда работает с базой. А чем это безопаснее, чем зайти по SSH на систему? Я могу ответить, чем. Ну, тем, что ты перед тем, как свой код раскатишь до прота, он там пройдет 10 код ревью, во-первых. Во-вторых, у тебя все равно нет прав на дроптейбл и такого рода вещи. А в-третьих, если ты сделаешь там select password from users, то там все так затормозит, что ты не выполнил до конца свой запрос. Ну, во-первых, пассворд у нас в базе не хранятся. В любом случае. И вообще, это отдельный микросервис в Яндексе. Сервис, который занимается аутентификацией. Это, по-моему, единственное применение микросервисов полезное, которое я когда-либо видел. Жирно, очень жирно. Нет, микросервисы живые будут жить. Да, конечно, но просто на пустом месте плачет. На поэтаже фарчит. На сегодня плотва прям шевелится. Слушай, классная шутка, Валерий, мне вообще понравилось. Так, поехали дальше. Там что-то про функциональные базы. Про функциональные базы кто-нибудь читал? Я посмотрел эту статью, и она какая-то очень академическая. Не понял, честно говоря. Сначала что-то понятное, а потом ужас какой-то идет. Они там случайно не предлагают хранить иммутабельные данные и там кем-нибудь gc выбирать? Ну, когда ты их удаляешь. Они предлагают там каким-то образом функции, как я понял, хранить прямо в базе. Причем не как хранимая процедура, а на каком-то более высоком уровне. В общем, я думаю, что кто-то защитил по этой теме диссертацию, и вот теперь бумага такая есть. У меня просьба к слушателям. Вы когда темы предлагаете, вы учитываете, что у нас там тоже работа есть, и мы не можем выкидать видео на полтора часа или там пейпер. А что вы о нем думаете? В целом я готов читать пейперы. То есть почему бы нет. Вопрос в том, что когда бывает подобная академическая статья, которая недостаточно сильно применима в актуальной работе и в жизни и так далее, то читать ее жалко времени. То есть если бы это было что-то ближе к тому, что непосредственно со мной связано, или то, что меня интересует, я бы с удовольствием прочитал. Так я прочитал только introduction и выводы, что у них все получилось, и что получилась многоуровневая система, которая состоит из слоев. Можно эти слои перемешивать, заменять и оптимизировать. И функция – это first class citizen, и все отлично работает, но возможно не очень быстро. Ну то есть как бы да. Вообще если говорить о функциональных базах данных, то мне вспоминается такой DSL для работы с базой данных, который был описан в книжке Practical Common Lisp, которую, по-моему, Павел Грехов написал. На протяжении всей книги он показывает, как создать такой простой DSL для обращения к базе данных на Lisp. Это действительно интересно, и практически видно, где применимо. Не то, что в этой статье. Ну и где же это применимо? Это применимо в сервисах, которые ты пишешь на Common Lisp. Ну а здесь на Haskell'е код точно так же применим к коду, который ты пишешь на Haskell'. То есть я не вижу больших разниц. А вот, господа, покритикуйте идею. Меня в свое время такая посещала, я думаю, Валерию будет что сказать. Идея примерно такая, что давайте писать в базу всегда только неизменяемые данные, при этом у тебя есть какое-то множество корневых элементов, ты их как-то задаешь. И получается следующее. Ты, когда хочешь изменить данные, ты на самом деле их создаешь новые и меняешь линки. Ну по аналогии с иммутабельным каким-нибудь мэпом. И главная проблема фоне приходится как-то удалять данные, на которых больше не осталось ссылок. Преимущество этого хозяйства, я честно говоря уже плохо помню, в чем целиком идея заключалась, но похоже там не возникает особых проблем с транзакционностью, потому что у тебя есть ссылка на элемент, какой-то глубокий там хрен знает где. И тебе все равно, что кто-то в это время меняет деревья, у тебя база целиком иммутабельная. И можно делать транзакции там с комперенс мэпом корневого элемента. Саш, ты знаешь, в Яндекс некоторое время назад приходили ребята, которые пишут постгресп и рассказывали про то, как он устроен внутри. Вот он устроен внутри примерно так же, как ты говоришь. Ты когда меняешь запись какую-то, он просто создает новую версию этого row в базе, а старая при этом остается. Именно для того, чтобы транзакционность поддерживать, и существовало несколько версий одной и той же записи в какой-то момент времени. С одной стороны, Саш, ты придумал snapshot isolation, с другой стороны, реализация snapshot isolation в распределенной системе все еще нетривиальная штука, потому что одного корневого элемента, ну если у тебя будет ровно один корневой элемент, то у тебя все в итоге в него будут ходить на поклон, и у тебя все в нему и упрется. Ну понятно, не один, например, по юзерам как-то пошардить. На самом деле я бы предложил всем, кому интересно, как делать транзакционные базы данных распределенными, я бы сейчас всем рекомендовал смотреть на CockroachDB, она совершенно далека от продакшена, но их дизайн довольно правильный. И главное, он у них довольно неплохо описан. Иван, дальше? Дальше я мьют нажал. У всех, кто будет мьют на сегодня. Та самая тема, которую Валера так сильно хотел. Давай, Валера, жги. Ну вот, да, короче, тема поменьше на Иване, а жги, Валера. Ну ладно, Валера так Валера. В общем, ребята из фейсбука положили в опенсорскую кусок кода на Acamly и утверждают, что этот кусок кода на Acamly поможет вам найти баги в ваших кодовых базах на Cишечке и джаваньке. И вот на этом все. Такие, насколько это правда. Почему нам это интересно. Во-первых, они сами, честно говоря, про limitations, что эта штука не является таким уж, как это. То есть обычно обещание статического анализатора в том, что если он говорит какую-то фигню, что он что-то у вас нашел, это правда и проблема точно есть. Другое дело, что эта проблема может вас не беспокоить. Но она там, скорее всего, есть. Точнее, скорее всего, она там точно есть. То есть это не совсем классический статический анализатор, потому что они сделали, но зато он позволяет проверять более нетривиальную магию. И при этом... То есть эта штука даже ближе не к классическому статическому анализу, а скорее к верификаторам на основе каких-нибудь свойств. Только трюк здесь в том, что свойства ручками писать не приходится. И еще проблема многих верификаторов, существующих, в том, что они работают очень долго. А здесь оно у них работает достаточно быстро, это раз. А во-вторых, оно еще и инкрементально умеет. То есть если вы один раз прогнали все на вашей системе, один раз дождались результата, то все последующие изменения будут уже только на дельте применяться. То есть только изменения будут проверяться на не сломалось ли. Звучит как магия. А что за свойства-то они проверяют? Ну вот подожди, подожди. Я сейчас к всему подойду. Зря что ли я всю эту фигню пытался читать? Ну вот. Как я уже упомянул выше, когда промахнулся темой, это делали ребята из какого-то стартапа, который Facebook купил. У них там есть парочка забавных идей, на которых, я так понимаю, они даже, ну если не защитились, то пока не написали об этом кучу статей. У них две интересных идеи. Первая называется separation logic, это как раз то, что позволяет, видимо, делать им вот это вот дельтодостраивание, ну и вообще анализировать программу за приемлемое время. То есть ребята, по сути, придумали такой формализм, который позволяет рассуждать только о части программы, а после этого как бы слить два рассуждения в одно. То есть можно как бы, если кому-то интересно, там у них есть прямо отдельная статья про то, как это все, про эти все пробы-два формализма, такая довольно не очень матановая, так что в принципе ее можно понять. Можно почитать подробнее. Биабдукция – это как раз вот про свойства. Идея в том, что оно может вывести свойства из каких-то, то есть, например, у вас есть какие-то там malloc и free, и про них у вас написано свойство какое-то, например, что malloc должен заканчиваться free или, например, что на каждый open где-нибудь должен быть close. Эти свойства написаны за вас как бы разработчиками верификаторов или другими разработчиками, которые к нему эти свойства, к верификатору подсовывают. А дальше эта штука начнет ползать по программе и как бы выводить, то есть оно, если кто-то знаком с диалайзером или вот с клажурами типами, оно работает похожим образом, то есть оно для более наружных функций будет протаскивать варианты вверх, пытаться угадать, что же там должно быть за вариант, за инвариант. Мы вот как раз вот это назвали биабдукшн. То есть вообще абдукция – это такое, есть индукция, дедукция, есть абдукция. Абдукция – это когда мы строим гипотезу, что же там было. Но вот как бы, видимо, если я правильно понимаю, как раз вот эта штука, как я сказал, уже должна по идее догадываться о том, что это за инварианты. Насколько хорошо работает, я понятия не имею. Они честно пишут, что на некоторых проектах работает отлично, а на некоторых проектах работает так себе, на некоторых проектах показывают больше фалспозитив, чем чего-то полезного. Но вот это самое плохое. Ну, как бы, я так понимаю, на их кодовой базе вообще хорошо работает, но на гну утились, на гну накрутился, не запускали и сказали, что получилось совсем плохо. Ну, с другой стороны, в принципе, мне приятно, что Facebook в это инвестирует. Мне приятно, что они это выложили. Это значит, что, возможно, со временем это станет гораздо лучше, потому что, скорее всего, туда подключится больше людей. Ну, вот, собственно, все. У кого-нибудь есть еще что сказать? Да, мне еще приятно, что они пытаются делать оптимизацию по скорости. Ну, то есть, вот этот вот инкрементальный анализ, он реально бывает полезен, если у тебя очень-очень большой проект, попробуй как-то запускай там. С другой стороны, это ограничение самого Facebook. У них же большая-большая кодовая база, и это помогает им самим, так что... Я так послушал, по-моему, звучит как просто статический анализ, но, наверное, у него... Я просто мало понимаю в статическом анализе, и я любой статический анализ всячески одобряю, так что, ну, молодцы, пусть продвигают, тем более на АКАМУ. Кстати, ребята, а вы видели, по-моему, сегодня был... А, нет, прошу прощения. Да-да-да, сегодня был пост про то, что Кодеклимайт, знаете, такой сервис? Нет. Это такой облачный сервис для статического анализа кода. И они открыли свои статические вот эти вот анализаторы для того, чтобы их можно было запускать на своем собственном сервере. И еще разработали какую-то спецификацию так, чтобы можно было писать статические анализаторы тем, чтобы они запускались в их облаке. Как-то так. Вначале они были заточены подруби, поэтому я самим этим сервисом не пользовался никогда, но теперь получается, что его можно будет по-всякому расширять, запускать разные линтеры для других языков. Ссылочку занеси обязательно. Да, сейчас я добавлю в чатик наш. Ну, а пока ты добавляешь в чатик, я зачитаю вторую рекламу. Конференция HappyDev. Приглашаю докладчиков. Если вы имеете солидный опыт разработки, тестирования или сопровождения проектов, готовы не только рассказать доклад, но и привести мастер-класс по технологии или методологии, то мы будем рады видеть вас 5-6 декабря 2015 года на базе отдыха им. Стрельникова возле Омска. Бывалые докладчики знают, что именно для них пользуют конференции максимально. Приезжай, зарядись, получи новый опыт. HappyDev – действительно полезная конференция. Вот. А дальше, Саш, ты рассказывал про Яндекс, но ты совсем не говорил, сколько ты там работаешь уже. Да вот в августе будет уже 10 лет. 10 лет в Яндексе? И не надоело? В 2005 году я пришел туда. Ну, ты знаешь, задачи все время разные появляются. В этом плюс большой компании. Кроме того, всегда у нас есть возможность, если в одном месте тебе надоело, пойти поработать в другой отдел или перестать быть бэкендером, переучиться на фронтенд или на мобильную разработку перейти. Было бы желание. Ты проходил? Вот, да, я думаю, хочу продублировать весь этот вопрос. Ты сам проходил это или, может быть, знаешь кого-нибудь, кто проходил? Потому что, честно говоря, я с большим трудом представляю, что ты сидишь такой, пишешь, например, на Ирландге бэкенд, и говоришь, что-то мне надоело писать на Ирландге бэкенд, пойду-ка я переучусь в соседнюю команду. А почему ты не веришь? А потому что у тебя есть команда, которая поддерживает проект. Если ты из нее куда-то уходишь, кто будет его поддерживать? Скорее всего, это будет так, что типа, ну, да, чувак, почитай книжку, попробуй, покомпиль. То есть, она будет на словах только. Еще один момент. У нас, наоборот, насильственно поддерживается довольно большое число людей, которые разбираются в проекте. То есть, число людей больше, чем число людей, которые на проекте сейчас. И не просто поощряется, опять-таки, это политика компании людей на бэкенде, менять между проектами. Саша, а у вас как? Я думаю, что если ты единственный человек, который пилит какой-то проект на Ирландге, то это неправильно. Потому что найти второго такого, который будет пить этот проект на Ирландге, не очень просто. Переучиться с Ирландга на что-то другое можно запросто. Я считаю, опять же, было бы желание. Но вопрос-то был не в этом. То есть, как оно на практике? Это так, просто на словах, или реально, прям, ты знаешь кейсы? На практике, ну, не знаю, я с плюсов селез на питон. В принципе, мне было бы, наверное, интересно заняться мобильной разработкой. Но пока вот текущий проект есть, не горю желанием прям бросать все и переучиваться. Мне на самом деле кажется, что здесь больше проблем. Каждый человек. Дайте мне сказать. Дайте свет. Давай, давай, свет. Хорошо. Я часто слышала, что в компаниях есть такая практика. Вот вы пришли на один проект, и, в принципе, вы можете перейти на другой проект через какое-то время. Даже можете сменить технологию. Но обычно это крайне неэффективно для компании. Вот тебя приняли, да, допустим, вы сеньор где-то, и вы пишете бэкэнд. И вы, если вы хотите перейти на фронтэнд, например, вы там не будете сеньором. Ну, просто банально у вас нет квалификации. И тут возникает вопрос для компаний, а как вам платить? То есть вы будете меньше пользы приносить компании, потому что вы все-таки будете там много разбираться, потратите на это много времени, хотя есть люди, которые это уже потратили время, и они могут более эффективно работать. И обычно эти переходы, они такие на бумаге. Да, это возможно. А на практике так никто не делает. И вот насколько реальный случай перехода именно в Яндексе, мне хотелось это услышать. Ну, чтобы прямо кто-то переучился на фронтэнд, бэкэнд разработки, я не знаю, обычно поток идет в обратную сторону, потому что фронтендеры, они такие, писали-писали на своем джаваскрипте для браузера, а потом бах, появляется нода JS, и они давают, значит, пытаться делать код для бэкэнда. Вот, в эту сторону переходы бывают довольно часто. Вот да, я знаю про случай, когда, например, support становился там QA, потом QA становился, например, программистом, то есть я вот такого рода переходы знаю, а так, что программист становился программистом другим, про такой я, честно говоря, на практике совсем не слышал. Ну, в смысле, вархатная камера. А другим это, ты думаешь, как? Ну, вот представь себе, сидишь ты такой, пишешь бэкэнду на скале, да, и что-то тебе надоело писать бэкэнду на скале, и ты такой говоришь, а пойду-ка я попишу под Android, да, например. И возникает, вот в дополнение к тому, что уже было сказано, возникают проблемы. А что, у тебя на бэкэнде прям все офигительно, все задачи выполнены, нет багов? Если есть баги, то как бы, а кто их будет за тебя закрывать? Вопросы, ты неправильно ставишь вопрос. Тут вопрос надо ставить так, либо если человеку неинтересно, он идет куда-то в другое место писать на Android, или он останется у тебя. То есть если ты заинтересован в человеке, почему не разрешить? Если не заинтересован, то, конечно, туда ему и дадут. Андроида в два раза больше, чем команда бэкэндеров, и там и так ребята справляются без тебя. Если так, то, конечно, да. То есть проблема в том, что команда, куда ты хочешь, ей и так норм, а там, где ты, и так работай вагон. И ты хочешь переучиться на что-то, что ты пока не умеешь, и это никому, кроме тебя, собственно, не нужно. Какой-то админикальный случай рассказываешь. Нет, это во всех компаниях так. На практике такое. Вот эти переходы, они по большей части на бумаге. А на практике это такая редкая ситуация, и не так легко осуществима. Я согласен с вами, но я считаю, что это редко осуществляется, потому что сами люди с трудом отрываются от своей текущей работы. То есть я знаю, что у нас на предыдущей работе, на текущем месте работы с удовольствием возьмут куда-то в новый отдел, потому что у нас работают нормальные люди, и все понимают, что перейдешь в другое место, будешь там плодотворно работать. Руки лишними не бывают. Так, так, ты спонсора уже зачитывал. Все, давайте я, что ли, свои 5 копеек вставлю. У нас в компании это реально бывает. Фронтенд до бэкэнда, конечно, обычно не доходит, потому что у нас есть, может быть, один фронтендер, который немножечко умеет в бэкэнд, и просто иногда посмотрев в ту сторону, может немножко помочь. У нас есть, зародился институт Мидлэнда, это ребята, которые умеют туда и туда, и пишут вещи типа SDK. И у нас есть по меньшей мере один бэкэндер, который сейчас пишет на Юнити, просто потому что когда у нас формируется команда на прототип, обычно есть один дизайнер, в смысле геймдизайнер, и один инженер. Но вот при этом совершенно не обязательно, чтобы инженер был синером в технологии, потому что надо просто прототип набросать. Ну вот, и так получилось, что бэкэндер, которому было интересно Юнити, он взял руки Юнити и пишет прототип. Понятное дело, что когда это выйдет из прототипа, притом он пишет и прототип, и бэкэнд одновременно. Собственно, почему так получилось? Потому что игре нужен бэкэнд с самого начала, а брать двух инженеров в прототип дорого и неоправданно. И он вполне себе справляется с Юнити, вполне себе справляется с прототипным бэкэндом, и он этим довольно доволен. И понятное дело, что когда понадобятся синеры в проект, они придут и просто выкинут ту Юнити, которую он сделал, совсем. При том, у него-то опыт останется. И это совершенно нормальная ситуация, потому что прототип часто выкидывается полностью. Когда понятно, как будет выглядеть геймплей. Я, кстати, хочу дополнить, что интересный есть сценарий, когда если люди в компании не ленятся разбивать проекты на артефакты и заливать их куда-нибудь в Nexus какой-нибудь, или хотя бы просто делить на разные репозитории, возникает интересная ситуация, когда, например, ты пишешь бэкэнды на Джаве, и под Android у тебя пишут на Джаве. То есть ты, например... Вот я понятия не имею, как писать под Android, никогда не писал. Но если есть какая-то библиотечка, там, джавная или скальная, и она в виде отдельного репозитория, и она там лежит такая с тестами, как отдельный проект, то я вполне могу в него вонзиться, немножко что-то поправить, добавить, например, какой-нибудь клиент для сервера. И фактически я тем самым пишу под Android, но не касаясь самой мобильной разработки. Вот это интересный сценарий, и это что-то, что реально может быть на практике. Это как раз плюсы опенсорса. То есть если бы это было закрыто, и ты туда не мог вонзиться, ты бы так не поделал. Да? Я предлагаю уже дальше переходить. Да. Следующая тема... О, это я добавил следующую тему. Это... Я не знаю, ребят, вы когда-нибудь задумывались или нет, почему многие люди предпочитают сидеть в Midnight Commander, или подобных вещах, и, если что, переходить сразу в сложное большое IDE, типа там Intel GID или Eclipse, и не пытаться сидеть под консоль. Лично мое мнение, что это из-за того, что не хватает опыта работы в консоли. И я тут наткнулся на хорошую статью на GitHub. Это что-то вроде Awesome список вот этих был у нас, Awesome списки. И здесь примерно то же самое, только не про какую-то конкретную утилиту, а про основные тулзы и основные команды, которые могут пригодиться вам при ежедневной работе. И документ примерно так и разбит. То есть, то, что вы применяете каждый день, то, что вам иногда нужно, и то, что вы можете изредка применить, но можно не запоминать, а просто глянуть в этот документ, типа такого. Вот. И я понял, что то, что в ежедневной работе у меня полностью список покрывается, то есть я это реально использую, и подчеркнул для себя парочку новых приемов в среднем списке там. И я так понимаю, что если всех приходящих сотрудников взять и строго научить, а потом заставить экзамен сдать, то может они забудут про бинднайт-команды и улучшат свою производительность. Как вы думаете? Я думаю, это отличная идея. Мы даже иногда на собеседованиях в Яндексе спрашиваем, просим кандидатов составить список команд консольных, которые они смогут вспомнить. Там двух буквенных, трех буквенных, четырех буквенных, хотя бы по пять штук. Не все справляются. Хороший вопрос для собеседования. Я хотел только дополнить, что вопрос засчитан, и я знаю очень многих разработчиков, которые отлично пользуются консолью и тем не менее пользуются IDE. То есть одно другому оно не мешает. Согласен. Примерно никак. Но если ты пользуешься IDE и ты пользуешься бинднайт-командой, скорее всего ты в консоли вообще ничего не делаешь. То есть ты без разницы какой пользуешься IDE, просто если ты сидишь в Vimit, тебе без консоли вообще никак. Без консольных каких-то дополнительных вещей. А если ты сидишь в большой сложной IDE, где рефакторинг, переименование, запуск, и все это в одном флаконе по нажатию кнопки, то ты консоль можешь вообще не касаться и не знать. Но не всегда так, потому что иногда нужно зайти на сервер, что-то там донастроить. Возвращаясь к теме про безопасность, тот же firewall настроить, там чего-то поотлаживать. То есть, например, довольно часто нужно зайти, посмотреть back-ender, который не умеет TCP-Dump. Я вообще таких с трудом представляю. Ну вот, я думаю, ты меня просто троллешь. Есть немножко, да. Я вот не очень понимаю, у нас некоторые ребята умудряются работать в IDE, при этом код back-endа у них крутится где-нибудь там в виртуалочке, в облаке, данные синкуются, ну, не данные, а код из IDE на сервер и обратно. Как-то, по-моему, это все чересчур сложно. Я вот предпочитаю в консоли запускать и Max, или Win, и прямо в ssh-сессии что-то кодить. А я, по-моему, на Erlang в свое время так писал. Нет, довольно удобно. Как, когда туда-сюда код гоняется? Но он не туда-сюда, он только от тебя на dev-сервер. Ну, если у тебя, прикинь, у тебя там 5 микросервисов, с которыми ты должен взаимодействовать, у них нет никаких mock-версий, потому что, разумеется, ни у кого нет времени писать mock-версии сервисов. Ну вот, и тебе нужно код как-то протестировать. Ну, ты его пишешь тут локально, он у тебя Ersync-ом заливается, и там тестишь. Удобно. Все правильно, поэтому... Да, это удобно. Поэтому я запускаю и Max прямо там на сервере, и работаю. Ну, я тоже так. Я поначалу так и делал, только не в Emax. И сталкивался с проблемой, что у тебя, например, начинает как-то подтупливать Wi-Fi, а я, честно говоря, ни в одной компании не видел стабильную Wi-Fi, которая просто работает. И вот после 3-х таких случаев я начал писать код локально. Это же хорошо. Когда Wi-Fi подтупливает, он просто стимулирует тебя больше использовать шоткаты. Нет, он стимулирует тебя разламывать клавиатуру. Плюс один. Да, и сильно волноваться. Да, если совсем Wi-Fi от Wifi, то это хороший повод задуматься о том, чтобы засунуть свой WIM, Emax и все остальное внутрь Tmux. Да, плюс один. Как это поможет? Код набирать? Код это набирать не поможет, но у тебя хотя бы все окружение будет восстанавливаться после того, как ты переподключился к серверу. Понятно. В Tmux, например, удобно переключаться между консолькой, редактором, запущенным каким-нибудь TAIL, который смотрит логи. У меня обычно в Tmux штук 8 вкладок и несколько проектов еще в параллельных сессиях может быть. А я Tmux White Army пользуюсь, я уже рассказывал. Так, ну поехали дальше. Саш, дальше твоя. Она не столько моя, сколько ваша, просто вы бы такую не добавили. Дело в том, что опубликовали 3 0D уязвимости в продукции Apple, iOS и OS X. И там такие серьезные уязвимости, то есть приложение как-то злонамеренное может ходить в эти ваши кейчейны. Я, честно говоря, не очень силен в Mac'ах, но насколько я понимаю, можно тырить спокойно все пароли. И что самое печальное, вот ты там читаешь, такой охреневаешь, охреневаешь и известно, что Apple об этом знала с октября 2014 года, то есть им зарепортили эти баги очень давно и с тех пор они их не пофиксили, поэтому, собственно, их и выложили в паблик. Я считаю, это абсолютно нормальная ситуация, в том смысле, что ну все как обычно. Куча адских багов, их как обычно закроют и всем как обычно будет пофиг. Это, собственно, то, о чем я рассказывал в своем посте про корректность. Ну, как я понимаю, баг там все-таки один, просто он на трех платформах. Потому что они шарят ядро, и баг на основе ядре. Я так понимаю, он просто трижды зарепортит по три разные платформы. Или все-таки там три разные бага. Судя по описанию, это не один и тот же баг. Они про похожие кейсы, но баги разные. Знаете, меня больше печалят баги в головах людей, потому что на Mac'е программа частенько спрашивает «Обведи-ка свой пароль, потому что мне надо что-то сделать». Что они собираются делать? Непонятно. Пароль не введешь, они не выполняют просто свою функцию, программа бесполезна. Например, CleanMyMac частенько спрашивает пароль для чего-то, не знаю, может быть, кэши какие-то почистить или еще что-то. Я уверен, что большинство людей вводит пароль от своего компьютера, просто не задумываясь о том, что происходит. Лучше бы в Apple сделали механизм, который бы заставлял разработчиков в приложении указывать, что они делают, и когда я ввожу пароль, чтобы пермишины выдавались только на это действие. Потому что так они с паролем могут пойти в тот же самый кейчейн и слить оттуда вообще всю информацию. Мне кажется. Я присоединяюсь к этому, потому что меня сильно удивляет в принципе подход яблока, что ты когда делаешь приложение для бокса, ты подписываешься под собой и говоришь, я честно-честно буду использовать только это, это и это. И понятно, что когда ты честно говоришь, что ты будешь использовать только это, это и это, тебе нужно подписаться как это я. С другой стороны, ведь можно было бы сделать даже анонимную возможность гарантированно отказаться от чего-то, чего-то и чего-то. И это бы работало для более широкого спектра приложений и даже для тех, которые не подписаны разработчикам. Потому что не надо доверять приложению, которое добровольно отказывается. Вообще не надо доверять приложению. Больше можно не говорить ничего. Да, они строят систему типа, что вот оно подписано, значит мы ему доверяем. Вот это все. Но когда человек доверяем, будет запущен ему в сэндбоксе. То есть мне это вообще поражает, что яблоко запускает в сэндбоксе приложение, которое подписано и проверено доверенным разработчикам написано. Блин, ребят, защищаться надо в обратную сторону вообще-то. Вот. Во-вторых, да, совершенно та же самая проблема. Я когда вижу приложение, которое спрашивает мой пароль, у меня автоматическое желание запустить его в виртуалке. Или просто не запускать. У меня есть огромнейший набор приложений, которыми я правда знаю, что можно ввести пароль, остальное стараюсь просто не использовать. Потому что блин, ребята, ну, не надо так. Тут хорошо бы, если был бы некоторый аналог ОАУса для приложений, чтобы я точно знал, что у него есть такой набор скоопов, и желательно мог бы некоторый отменить. Запретить. Вот это было бы круто. То есть делать хотя бы то же самое, что они для мобильных сделали на лэптопе? Да. То есть я хочу зайти в файловую систему вот в эту директорию. Ну, ладно, давай, создай себе эту директорию. Но не более. А так пароли, пароли, даже непонятно для чего вот он его сейчас спрашивает. Что он сейчас там хочет сделать? Он из посуды скорее всего что-то запускает там у себя внутри. Да. Ну что, пошли дальше. Так, следующая тема – это тема моя. Я наткнулся случайно на статью, в которой очень здорово показывается, как человек заинтересованный может достигать интересных вещей. То есть некто Марек Майковский написал статью, в ней он рассказывает, что он слышал внезапный разговор двух коллег, которые разговаривают, что вот там медленный стэк, network stack у Линукса и не больше 50 тысяч сообщений пакетов в секунду на ядро и никак невозможно это превозмочь. Он задумался, откуда взялось вообще это ограничение и начал проводить разные эксперименты. И своей целью он поставил достигнуть 1 миллиона UDP пакетов в секунду. И вот он показывает свои шаги, как он делал сначала одно, потом другое, каким образом настраивал сеть, каким образом он раскидывал пакеты по ядрам и так далее. В целом вообще интересно посмотреть. Во-первых, интересно посмотреть, как он пытался понять. Я просто прикладываю на себя его опыт. Вот ты наткнулся на какой-то затык. То есть у тебя пришла цифра N пакетов в секунду, и все, дальше не идет. Как разобраться? И вот он очень здорово описывает, что я посмотрел то, потом посмотрел это, а вот здесь оказалось, что у меня затык похожий, что в этом? Дай-ка я покопаю. И вот именно что любопытство и плюс разностороннее понимание системы может привести к чему угодно, привело в том числе, что он достиг 1,4 миллиона UDP пакетов. То есть он приводит примеры кодов, он приводит, какие он строчки выполнял, что он на экране получал и так далее. Интересная статья посмотреть тем, кто любит разбираться в кишочках и поглядеть, что к чему. И раз нет комментариев, переходим сразу к следующей статье. А следующая статья это VIV 1.0. Валер? А что 1.0, прости? ВИВ? Как это читается? W E A V I А, ВИВ, понял, да, о чем вы. Да, не сразу дошел, но, короче, докер, докер, докер, докер, докер. Закончили тему. В общем, есть такая штука для докера, она в начале зародилась, если я правильно помню ее историю, она в начале зародилась как набор костылей для докера, а потом выросла в нечто большее. То есть все, кто пытался работать с докером, знают, что сетка в докере посасывает причмокивая. Вот, это дико неудобно, если нужно сетку докера объединить в одну сетку за пределами одной машины, вы будете страдать. Вот, при этом был набор костылей по названию Weaver, или как он там, я уже не помню, как он раньше назывался. Идея в том, что возьмем, определим такую, не знаю, наверное, это может сравнится с VPN, они это называют Software Defined Network, что у них там, короче, виртуальный Ethernet switch, который на самом деле работает через WP Network. В общем, все круто распределенно и технологично. Я, честно сказать, не пытался ни разу пользоваться, я на это немножко посмотрел, подумал, ну, ребят, вы бы хоть подробности ему понаписали, чтобы я поверил, что это у вас правда работает. Но вроде у них есть даже какие-то продакшн клиенты уже, которые платят бабла за саппорт. Видимо, я так понимаю, это им дало денег дожить до релиза 1.0. Вот, если я в следующий раз когда-нибудь буду поднимать кластеры на докерах, я, может быть, даже попытаюсь этим попользоваться. Не стоит. Почему? Следующая статья сразу в тему. Кластеры на докерах или вообще докер? Нет, имеется в виду VIV можно не использовать. Есть такая статья, я сразу после этой, ты как начал говорить про VIV, я вспомнил, что я ее читал совсем недавно. Подожди, я до VIV закончу, и потом перейдем дальше про докер, докер, докер говорить. Ну, так вот, они к релизу 1.0, кроме, собственно, управлялки сеткой, завезли еще за интересную штуку. Я, опять-таки, совершенно не представляю, насколько хорошо это или плохо работает, но звучит оба интересно звучат. Первая штука позволяет визуализировать все, что вы там понаделали с этой вашей сеткой, и, так понимаю, даже какой-то трафик ходит, и что с чем соединено в плане контейнеров. А вторая штука позволяет вам контейнеры DNS пробрасывать, при том, оно чем-то похоже, наверное, на консул отдаленно, то есть, это не просто DNS, это еще и лоан-балансинг, и сервис-дискавери. Но, в отличие от консул, оно без центра... То есть, вообще, весь Viver, он без центральной точки принятия решения, поэтому стоит ожидать возможно нетривиального поведения, то есть, неочевидного, неинтуитивного, потому что, если у вас есть peer-to-peer сетка, которая в данный момент переживает разрыв и объединение, вы можете наблюдать странное. Поэтому, как сервис-дискавери, я бы, наверное, рискнул пользоваться, а вот как лоан-балансер, наверное, нет. Я кончил. Отлично. Спасибо. А вторая статья, которую я сразу добавил, это статья, которая называется With is kinda slow, в которой рассказывается про бенчмаркинг, в которой показывается, что VIV не очень хорош в сетях, в которых есть хоть какая-то нагрузка. Я вот, когда читал, примерно так подумал, что, наверное, оно не годится ни для чего, кроме control plane, потому что этот data plane на таком количестве уровня виртуализации строить, наверное, нельзя. Вот, да, ты все правильно почувствовал, и здесь рассказывается в принципе, в чем в этой статье, в принципе, рассказывается, в чем проблема с сетью в докере, рассказывается, как VIV ее решает, и рассказывается альтернативное решение Flannel, которое строится решение на VXLAN. И в самом конце есть такая табличка, в которой показывается, что бы мы имели, если бы мы работали нативно, на машине, без всяких контейнеров, что бы мы имели, когда используем VIV, и если мы используем VIV, то пропускная способность около 6% от нейтива, то есть, в смысле, если бы не было контейнеров, при этом лейтенси увеличивается в 4 раза, то есть 400%. А если мы будем использовать Flannel с VXLAN, то пропускная способность будет порядка 96%, при этом лейтенси увеличивается на 40%. То есть, значительно-значительно это значительно-значительно-значительно лучше. Поэтому, если вы что-то будете использовать, лучше... Подожди, то есть уже один Flannel дает 40% лейтенси, сколько же там у VIV лейтенси? Ну вот 100% на нейтив, у VIV 405%, у Flannel 140%. Ну, в смысле, это не... он дополнительно 140% дает, это суммарно меряется пропускная способность. Я понял, да. То есть VIV дает 4-кратное падение лейтенси, то есть я понимаю, что он должен throughput ронять. Я вот думал про throughput, но там такая потеря в лейтенси, мне кажется, этим вообще нельзя пользоваться, ни для чего, даже для контроплея этим нельзя пользоваться. Там такое увеличение латентности, этим просто нельзя пользоваться. Вот так вот. Так, ну мы докер-докер поговорили, можно переходить к следующим темам. И... Следующая тема, это Саша со Светой. Статью видела по поводу того, как одна компания решила использовать у себя акк-кластер, и как они заменили свою систему, такую большую... Как они сошли с ума их всех в дурку забрали. Нет, вообще, это интересная статейка. Она такая забавная. Они большую свою инструментальную систему решили заменить на микросервисы. В первой половине они описывают, как хорошо микросервисами жить. В второй половине они говорят, что для этого они избрали акку-кластер, и вот поверх акки-кластера они пишут приложение на акке, которое выполняется. И... Вот эта вот идея, это, конечно, что-то такое необычное. Хотя, учитывая, что я с акка-кластером не сталкивалась именно в продакшене, нигде у меня это не крутится, я бы хотела слышать мнение Саши по этому поводу, что он думает. Ну, я хочу сказать, что это действительно свежая идея, выражаясь словами Валеры. Да что ж ты меня троллишь-то, а? Ну, я форщу мем, понимаешь? Так вот, и еще я считаю, что это очень неудачная, так, если мягко говорить, идея. Она просто писец какая неудачная. Потому что ребята гребут по полной, когда у них там немножко поменяются сообщения, и нужно будет поддерживать их обратную совместимость. Потому что ребята гребут по полной, когда они вспомнят, что у них там есть какая-то гарантия на доставку сообщений между нодами, что вообще-то при обновлении акки с одной версии на другую, то есть факт, что они будут очень сильно совместимы, то, что сериализация в АКК-кластер не обязательно хорошо всегда совсем работает, то есть, например, если у вас есть классы, которые вы генерите трифтами, то они не всегда очень хорошо сериализуются. И так далее и тому подобное. То есть ребята гребут по полной и будут сильно страдать. Я им сочувствую. Обязательно. Не используйте для микросервисов ничего, кроме мобилизациона. Ну, XML на самом деле даже можно. Но не используйте всякие распределенные акторы для микросервисов. Влад, по поводу этой статьи, потому что это такая странная идея. Но в статье было упомянуто такая... Извини, просто пока не забыл. Маленькая ремарочка. И они ничем, кроме Java, не смогут ходить в эти микросервисы. А одна из идей микросервисов, что можно разными языками ходить... Нюанс. Подожди, подожди. У них есть REST API. Для JVM-приложений есть возможность на прямую ходить в эти микросервисы. А для не-Java-приложений они делали REST API на Play. Потому что у тебя два конца, которые нужно тестировать. Это создание самому себе лишней работы. При том, один из этих концов всегда будет протестирован хуже. На самом деле, я хочу сказать, что на самом деле они уже в статье написали, что у них есть подпорка. Потому что они делали бы все на нормальном REST API. Им не нужен был бы сервис на Play еще дополнительный. Я там не говорю про то, что он ленд-ансиоз и так далее. В статье была поменята такая штука. Называется TypeSafeConductor. Вот кто-нибудь о ней слышал до этого? Что-то там они где-то пиарили, но я не очень внимательно читаю. Я не очень внимательно читаю статьи TypeSafe. Ну, это такая... Я тоже об этом впервые сейчас услышала. Я раньше даже ничего не знала. Это такая штука. Это такая прослойка. У тебя есть твой кластер железа. Поверх этого ставится этот кондактор. А вот поверх этого ты уже ставишь свои приложения. Это что-то типа Метаса или нет? Или я не поняла идею? Вот тут написано, что TypeSafeConductor дает тебе возможность удобно работать с C2, например, с Docker, Puppet, Shure, Funzible. И вот так всё в списке. Они ничего там не путают. Я уверен, что эта штука очень веб-скейл, очень реактивная. И в ней есть стримы. И, короче, это на самом деле чумовая технология. Ты просто ничего не понимаешь. Просто это довольно интересно звучит, но как-то очень тихо. Я не знаю, зачем и как с этим жить. Просто я об этом только что сейчас узнала. И стало мне очень интересно. Ну, короче, я сейчас по диагонали прочитал этот их маркетинговый анонс. Ну, это чисто маркетинг. Там нет никаких конкретных деталей. Ну, там типа у тебя ноды нарисованы, а у нод можно посмотреть акторы прям с именами, временем пингов. Там такой кружочек крутится. Видно, когда нода в последний раз давала на себя знать. Ну, хрен его знает. У TypeSafe, у них есть дурацкая привычка делать... что-то выкладывать, а потом через годик чисто тихо деприкейтить. При том желательно сделать это 1 апреля, чтобы никто не догадался, что они серьезно. Они же свое название задеприкейтили. Они поменяли или нет? Я намекал про TypeSafe консоль, которая по-моему так она называлась, да? Которую они тихо задеприкейтили 1 апреля. Она, по-моему, перестала быть отдельной частью довольно давно. И они ее поместили в TypeSafe активатор. Я не знаю, погибла она там или все-таки осталась в активаторе. Там есть такая штука, да, но она не годится примерно для ничего. Да, зачем вообще нужно активатор, если ты умеешь уже на этом всем писать? То есть, активатор меня дико бесит. Плюс один. Такой огромный кусок костылей для тех, кто вообще никогда в жизни не программировал на скале. Блин, ребята, я знаю, что такое SBT, умею его даже до некоторой степени под себя подстроить, при том, что я на скале не особо пишу. И как бы не нужна мне ваша груда костылей, пожалуйста, избавьте от нее, дайте мне возможность от нее использовать только те куски, которые мне правда нужны. Да-да-да. То же самое, как я когда столкнулся с этим активатором. Что это? А вы хотите мне таким образом сделать работу легче? Ну как-то наоборот, не мешайте. А вот это вот непонятно, зачем это для кого-то нужно. На самом деле, если я правильно помню, я давно трогал плей именно с нуля, по-моему, активатор генерирует для него вот эти леса. Шаблон проекта. У меня SBT неплохо справлялся. Он прям тебе генерирует шаблон проекта на плей? Не помню, но что-то вроде было такое. Слушай, Саша, ты как-то обещал проугать плей, но ты этого не сделал. Да? Самое время. Да, самое время, мне кажется. Ну плей, он нормальный, просто он немного... Я не люблю вот эти тяжелые фреймворки. Я даже об этом в блоге пишу. А где он тяжелый же? Я вот надеялся, что я с ним поработал, и я не нашел его тяжелого. Мне он тем понравился, что я ожидал, что он будет гораздо более тяжелый, чем я ощутил на себе. Нет, понимаешь, первые ощущения, конечно, были исключительно приятными. То есть это реально хороший фреймворк. Он хороший. Просто вот я лично, я предпочитаю взять что-нибудь такое маленькое, типа фенегл или скотти, если провести аналогию с хаскером, перекрутить к нему стендалон шаблонизатор, перекрутить к нему стендалон клиент к базе данных, там какой-нибудь сверху написать небольшой... Так в плей же нету этого... походил к их базе данных вообще, а шаблонизатор тебе никто не заставляет. Плюс к этому плей, он довольно медленный по сравнению с тем же фенегл. Ну фиг знает. Мне вот, например, очень понравилась их система экшенов. Мне очень понравилась. Это удобнее, чем в рельсах, например, сделано. Нет, фреймворк хороший, спору нет. Вот все, что я говорю, мне лично нравится легковесный фреймворк. И плей, это все, что угодно, кроме легковесного фреймворка. Собери у него пакет и посмотри, сколько он весит. Кстати, в плей очень удобно объявлять роты, и ты очень хорошо видишь, как у тебя расположены, вообще структурируются урлы. А возьми тот же спрей, и это там совсем не очевидно. То есть тебе нужно так полазить по кону, чтобы прикинуть, во что тебе превращается твой рест. Я вот тоже обычно адепт легковесности, и я вообще адепт... Когда я пишу на рубе, я предпочитаю вместо рельс брать Синатру. Но вот именно, что я попытался взять Скаллатру, я понял, что со Скаллатрой нужно больше проблем и мороки, чем с плеем. Скаллатра замороченная, ты ее точно взял. Ну вот, как бы я говорю, что я подумал, что аналог Синатры для Скаллатра? Но она оказалась замороченной. Я в итоге взял плеен, оказался гораздо менее замороченным. То есть в моем понимании определение легковесности, это когда у тебя куча там... ты не говоришь, что дипендов с фреймворком, а вот сколько тебе код нужно написать, чтобы сделать то, что ты хочешь. И там сколько всего тебе нужно прочитать и понять, чтобы сделать то, что ты хочешь. Вот даже скорее второе. И вот в случае с Синатрой, ты просто берешь, объявляешь маршрут прямо в коде и прямо, что тебе нужно из параметров, что вернуть. Play, конечно, посложнее, но тоже, блин, объявляешь route в одном месте, пишешь скала-функцию, которая выходит, и это все. Это прекрасно. Я прикрепил в шоу-ноты ссылку на блог-пост, если кому-то очень интересно, собственно, там мои рассуждения на тему плея и не плея. Но я об этом уже писал, мне не хочется рассказывать. Окей. И что? А мне кажется, Ваня отошел от себя чего-нибудь на листь, и следующую тему добавила Света. Что вы добавили снова? Я ее третий раз пытаюсь запихнуть. Ну, видимо, ее разные... А, кто-то там... А, понятно все. Ваня отошел и добавил разных тем. Вы издеваетесь. Не самых интересных. Ну, хорошо, вот эту тему, которая Свете не нравится, мы уберем. Следующую тему добавил я, но она такая мини-тема. Есть журнал Хакеры, и он больше не выходит в виде журналов. Ребят, мне кажется, вы не туда смотрите. Там тема еще сверху есть. Нет. Да, есть там еще тема сверху. Я думаю, у кого-то опять не синхронился Google Docs. Ну, там как минимум мы не обсуждали галлюцинирующие нейросети. Я думаю, у кого-то не синхронился Google Docs. Ты что-то путаешь, Валера, да. И... собственно, я считаю, это хорошо, что все переходят на электронный формат и все издания становятся электронными. Я как блогер такое категорически одобряю на самом деле. А вы? А я против. Я тоже одобряю. Мне кажется, что глянец останется только для тех, кому приятно читать глянец, кто читает глянец всю дорогу и вот это все. И журнал Хакер не обслуживает аудиторию ни в коем случае. И я хочу поругаться на того, кто убрал тему про галлюцинирующие нейросети. Я хочу ее обсудить, кто ее убрал. Обсуди. Давай. Давай, обсуди. А что я ее Ване добавил? Ваня! Шевелись, Ваня. Мне все сказали, что все давно уже посмотрели в интернете А, Баян, да, неинтересно. А никто не в курсе достаточно за нейросети, что... То есть я, честно говоря, из гугловского описания не очень понял, что они с нейросеткой делают. Они ее обучали на каком-то списке заранее известных образов. Нет, так с любой нейросетей поступают, которая про диплеринг, про изображение. Тут вопрос в том, как они ее наизнанку вывернули. Ну, то есть... В смысле наизнанку? Ну, то есть они же потом... То есть у тебя обычно как? Ты нейросети кормишь картинку и спрашиваешь у нее вопрос это вот там это или не это? Вот. А тут они сделали так, что они у нейросети не спрашивают, что ты там видишь. Они просят усилить те черты, которые... На которые заточена сама нейросеть. Да, да, да. И как они этот вопрос из нейросети вытаскивают, мне непонятно. Но, насколько я понял, у них многослойная сеть, и каждый слой отвечает за какую-то часть логики. Да, это любая сеть такая. Как они ее попросили наизнанку вернуться? Они просто просят не какой-то ответ, а просят немножко переструктурированный вход. Ну, вот как они это делают? Никто не знает, это просто экспериментали. Насколько я понимаю, я там оригинальные их пейперы не видел, но у тебя классическая многослойная нейросеть, у нее есть backpropagation. Вот видим им. То есть она прям по определению выворачивается наизнанку. Ну вот, как бы я так... При этом у тебя backpropagation, он же... А, то есть они что ли потом обратно смотрят на вход, подают что-то на вход и обратно смотрят на вход вместо выхода или что? Ну да, то есть ты задаешь ей выход и смотришь, какой должен быть вход, условно говоря. То есть это как раз не проблема. Это примерно как бинокль смотреть с другой стороны. Окей, окей. Я подумаю еще над этим. Я в свое время недостаточно кормил нейросети. Погодите, надеюсь, картинка. Я-то хотел добавить из-за того, что реально... Картинки шикарные. Реально научились скормлять компьютеру грибы. Я счастлив за компьютер. Я прям восхитился. Вы в конце досмотрели внимательно? Вот на этом сайте, который мы сейчас привозим Медузу, там по-моему не все картинки есть. Там еще были дополнительные интриги немножко. А у них там в конце есть ссылка на галерею, они на одной страничке такие большие. А, точно, точно, да. Галерея инцепционизма. И в общем на этой галерее все было получено... А нет, не все. Там большая часть была получена из белого шума. То есть реально белый шум подают на вход. И на одной из картинок водопады, галереи какие-то зеленые. Там же сложнее. Они подают белый шум на вход. Точнее, на выход. Смотрят, какой должен быть вход. Подают его на выход. Смотрят, какой должен быть вход. Растягивают. Циклично. Но в целом вообще замечательно. А это сборище цветной капусты, которая там... Я не знаю. Я сидел, восхищался, смотрел. Чудесно. Просто чудесно. Реально научили вот все вот эти абстракционистские картины. Все, можно уже отменять художников. Больше художники не нужны. Больше не нужны художники, которые рисуют под веществами. Я бы сказал так. Да. А других не осталось. Вообще уебывать вещества больше не нужно. За вас-то будут делать компьютеры. То есть мы тоже, ребят, все. Чудесно. Я помню, были... То ли аудио... Слушайте, а у меня Google случайно не открыл филиал в Омске, потому что это же очень пропущенная шутка про омскую птицу. Были какие-то аудио-наркотики или как это тогда какую-то фигню называли. Вот у нас теперь есть еще визуальное представление. Да. Ну а пока мы не ушли далеко, давайте я зачитаю наконец третью рекламу, третью и последнюю рекламу от конференции fp.conf. Она пройдет в Москве 15 августа. Цена билета 6... 6 тысяч рублей. 6 000. Два потока, один день. Проходить будет в Альфе Возмайлова. Есть промокод для скидки Devzen 200 рублей. Сайт fp.conf.ru и можете зайти посмотреть, уже появляется список участников. И пожалуйста, добро пожаловать. Так, а следующая тема это тема Саши. Че? Заговор. Ты хочешь ее обсудить? Да, да. Хорошо. Ну, собственно, да, правильно, потому что тем слушателей чего-то мало. Со мной случился забавный случай, я о нем рассказывал, что мы с коллегами сидели на работе, и я как-то так пришла в голову идея, что было бы неплохо иметь турку для варения кофе, но чтобы у нее внизу был подогреватель. Такая электро турка, которая тебе просто варит кофе. Вот. Нам стало интересно, есть ли такая идея. Я зашел в угол, вбил там электро турка или какие-то такие запросы. Оказалось, что устройства такие действительно есть. И они там чуть ли не от USB работают. И стоят даже не очень дорого. То есть, если кому-то нужно, то можно купить. А что меня поразило, что на следующий день я заходил во Вконтакте, и он мне вот слева в рекламе, у них не очень навязчивая реклама, поэтому я там не включаю Adblock, я вообще не включаю Adblock там, где реклама меня не бесит. Ну вот. И у них в рекламе прям первая ссылка, и чувак, купи электро турку. И у меня подозрение, что кто-то, блядь, следит за моими запросами, и кто-то там заговорил с Google, и меня это очень сильно тревожит. А вас? Я последнее время, последний год, наверное, стал реально замечать, что все, что я пытаюсь найти в интернете, появляется у меня в рекламе. Раньше это было не так назойливо, иногда такого даже и не было. А сейчас... Ну, то, что телефон у меня связан с компьютером, это как бы мне понятно, почему оно появляется, но вот так назойливо, так быстро, так сильно, конечно, такого раньше не было. А связанная тема, что у меня была большая проблема, что я иногда захожу в Google+, ну, да, Google+, правильно? Так называется? Googlecrest. Googlecrest. И мне оттуда лень разлогиниваться, и поэтому во всех сервисах Google у меня вот справа красный кружочек, который мне циферку показывает во всех. Меня это ужасно бесило. И мне в Твиттере подсказали решение, оно оказалось очень простым, можно этот див со всеми нотификациями вырезать от блока. А потом я еще немножко подумывал и понял, что на половине сервисов Google можно тупо запретить кукисы, и проблемы уходят. Так что если вас бесит этот красненький кружочек, то его можно очень легко выпилить. А еще его можно изолентой наклеить. Уголок экрана. Вместе с камерой. Да, и камера обязательно. Вы будете смеяться, но я как-то случайно увидел однажды, что у меня на макбуках рядом с камерой всегда зелененький огонечек горит, если вы камеру включили, знаете, да, видели. И однажды на созвоне я увидел, что у меня этот зелененький горит, и я заинтересовался, а чего это он горит, когда я его не включал. Оказалось, что GoToMeeting включил видео, и весь тот час, пока мы болтали, я не знаю, что я сидел, ковырялся в носу, или еще что-нибудь делал. У меня спокойно камера меня всем показывала. Я об этом даже не знал. Ну, может, не час, конечно, там я увидел довольно быстро, там минут 10 прошло, но все равно пугающая тенденция. Иван, ты знаешь, страшнее другое. Страшнее то, что мы не знаем, может ли камера записывать, когда огонечек не включен. Да-да-да. Кто знает, вот сейчас она пишет меня и передает мне? У меня точно не пишет. Вот 100%. Откуда такая уверенность? Я выковырял. У меня есть камера? Сейчас, да. У меня здесь Mac Mini, и на нем нету камеры. Ты уверен? Черт. Скрытая камера. Там есть какие-то дырочки, которые смотрят на меня сейчас. Буквально сегодня прилетала новость, я не уверен, что найду ссылку. В Debian оказалось, что Chromium, который идет в обычных пакетах, он после установки скачивает из интернета какой-то проприетарный кусочек, который всегда слушает твой микрофон на случай, а вдруг ты скажешь, окей, Google. И вот, во-первых, они там в Debian, им всем сразу бомбануло, потому что они там вообще против проприетарного всего. И еще сильнее им бомбануло от того, что твой микрофон постоянно слушает. Вот такой у нас SPO. Так какой-то был продукт то ли у Амазона, то ли у еще кого-то, который постоянно слушает тебя и хочет тебе подсказать и помочь. Где-то обсуждали такое, наверное, в RadioTee обсуждали этот продукт. Да, это в RadioTee было, и кажется, это была приставка, по-моему, какая-то. Да, это какая-то приставка была, которая постоянно тебя мониторит. А следующая тема? Я говорю удобно. Ты, например, забыл чего-то, что говорил. Слушай, что я там только что сказал, и она тебя переигрывает. А еще можно случайно записать подкаст и выложить. Да, вообще она должна просто реагировать на ключевое слово cut и сама заливать в сеть все, что ты наговорил до нагазирил или после? То, что до. Конечно. Не знаю. Жесть. Так, ну все, хватит спекулировать. Давайте следующую тему. Я на нее сегодня наткнулся, поэтому это прямо вот быстро. Быстрая ссылка, мгновенная. Google открывает часть своей инфраструктуры, в том числе Network, и они показывают свой Юпитер супер блок, как они его называют. Идея в чем? Они в Гугле, я не знаю, я не очень слежу за тенденциями вот этими, но я вот на этот наткнулся на ссылку и с циферками меня поразили числа. Они наткнулись на тенденции и поняли, что нет смысла иметь какой-то мощный циферский сервер, который стоит миллионы, не знаю, сотни тысяч долларов. Гораздо проще взять и соединить сотню маленьких, дешевеньких, более дешевых, конечно, не самых дешевых, более дешевых роутеров в один блок большой, каким-то образом все это запрограммировать и получить примерно то же самое по производительности, но гораздо дешевле и надежнее, потому что ты сам этим управляешь, у тебя какой-то софт за этим стоит, который может по твоей прихоти что-то улучшать, увеличивать и так далее. И они собрали, начали переходить, ну я думаю, это все те же микросервисы, просто уже на уровне управления сети.",
    "result": {
      "query": "лучшие практики тестирования микросервисов"
    }
  }
]
[
  {
    "segment_id": "b3fa90cb-274c-4237-9780-d4f27b5edf87",
    "episode_id": "4d7a7148-c76a-429d-a98f-fe7107372c9b",
    "episode_number": 7,
    "segment_number": 7,
    "text": "Ребята это решают тем, что они строят Merkle 3 специальным образом, специальным образом их хранят, синхронизируют эти Merkle 3, и когда у нас новый пир входит в кластер, ему не дается право голоса, пока его Merkle 3 не засинхронизирован, пока остальные пиры не валидируют его Merkle 3. Так ты самое главное не сказал, эти транзакции, они что позволяют? Поменять атомарно группу ключей? Один ключ только, я же сказал, это строго key-value Paxos. То есть у тебя на каждой key отдельный Paxos. А в чем бенефит от транзакции на один ключ? Смотри, это очень, смотри, если у тебя есть примитив копии, вообще в любой системе, не только в распределенной, если у тебя в системе, вообще в процессоре, например, есть инструкция Copy and Swap, ой, Compendium Swap, да, прощение, оговорился, Compendium Swap, то ты на основе этой операции можешь реализовать что угодно остальное. Соответственно, ты можешь написать, например, по каким-то рандомно сгенерированным ключам в рандомных местах какие-то вещи, потом в одном месте атомарно изменить указатель. Точно так же и в распределенной базе данных. Ты можешь сгенерировать ключи, сделать записи, много везде сразу, и потом прийти в какую-то запись указателем и сказать, что тебе новые данные искать там. Один раз переключить и атомарно изменить указатель. Я, может быть, не совсем понял, то есть смотри, я правильно понимаю, что речь идет о том, что ты какие-то данные считал, и потом их как бы транзакционно, вот то, что ты считал, изменил? Или же речь идет о каких-то foreign key? Смотри, на основе этого примитива можно в ходе не очень быстро работающей выразить почти любую консистентность. Я не могу это сейчас доказать, конечно, как теорему, но если бы это было неправдой, у нас бы компьютеры не работали, скажем так, потому что у нас почти все логарифмы синхронизации, которые у нас есть на рабочем столе, на столе компьютеров и на серверах, они почти все так или иначе выражаются через compare and swap. И, соответственно, точно так же ты все то же самое можешь перенести на распределенную базу данных. Понятное дело, что это не самый эффективный на свете подход будет, но ты, тем не менее, на своей высокодоступной базе данных можешь выразить какую-то атомарность. То есть у тебя, например, есть профиль, там, не знаю, человека Джона какого-нибудь, у него там есть, например, комменты к его ленте, например, какой-нибудь коммент к какому-нибудь посту. И у тебя юзер, там, не знаю, Вася, сидящий на другом континенте, например, читает список комментов, видит коммент там какого-нибудь юзера Васи и хочет на него ответить. И он берет, как бы читает айдишник этого коммента, пишет, какой-то ему ответ и является какой-то новый айдишник. Этот коммент пишется в какое-то отдельное место по ему табл-ключу и больше никого не меняется. Дальше мы просто берем и обновляем указатель на всю ленту комментариев. Только в том случае, если он у нас не изменился с того момента, когда мы что-то читали. Таким образом, это один из вариантов исключить ситуацию, когда мы ответили на удаленный коммент. Потому что если коммент удалили, у нас изменится указатель на всю ленту комментариев, и тот коммент, который мы записали, вымотавили на какое-то место, он просто никому никогда не станет виден. И мы потом можем идти его почистить каким-нибудь механизмом garbage collector. Ну ясно. А в Rayek 1.4 была такая проблема, что ты не можешь добавить, например, эффективно добавить сразу 10 новых узлов кластера. Они в 2.0 с этим что-то сделали. Слушай, ты про 1.4 загоняешь. Это было гораздо раньше. В 1.4 это как раз починено с версии где-то 1.3, то что ты говоришь. Но я же не специалист, ты понимаешь. Короче, это починено давно, и я помню, даже с тобой в ложе в твоих комментариях обсуждал, что это было до 1.2, или даже может быть раньше, может быть даже до 1.0 это было. То есть с тех пор, как у них появилась внушенность Climbant, с тех пор у них можно эффективно докинуть узлов. То есть ты вместо того, чтобы по одному узлу добавлять и потом ждать, пока он перебалансируется, ты составляешь так называемый план обновления кластера, потом говоришь commit, и этот план применяется сразу автоматом. Не, ну погоди. Они в 2.0 полностью поменяли вообще всю логику. Во-первых, управление вот этих вот ключей, во-вторых, они там сделали вертикальный паксос и так далее. Подожди, а при чем здесь стронг консистенции? При чем здесь стронг консистенции и добавление узлов? А одно не влияет на другое, ты хочешь сказать? Да, вообще никак. У них React Ensemble, он интегрируется с остальным React довольно просто. React Ensemble сам по себе вообще никак не завязан на код остального React. У тебя связка происходит внутри только приложения React KV. То есть Core про Ensemble знает немножко. Ему нужно ключик просто что-то в супервизор Ensemble поднять. Да, Ensemble не знает ни про кого другого, Core знает про Ensemble, и KV знает про Core и Ensemble. Соответственно, Core просто все события, которые случаются с кольцом, транслирует специальным актерам, которые есть в React Ensemble, которые потом переконфигурируют Ensemble. То есть в Ensemble есть независимая по системам переконфигурации кластера своя, тоже на основе Paxos, в которой передаются события, которые произошли с кольцом. То есть у тебя вначале что-то произошло с кольцом, это завершилось, у тебя на... я Core сообщил об этом Ensemble, в Ensemble пошел, переконфигурировал Ensemble. Окей, а... Кругом говоря так. Слушай, у меня в нервном вопрос. Я насколько знаю, у React есть какая-то проблема с медленным MapReduce. Это так? Был ли это починено? Это тоже починено давно. Смотри, раньше MapReduce работал так, у тебя весь MapReduce, на самом деле MapReduce'ился чуть ли не на одном узле. Ну и в общем-то это, понятное дело, довольно странное решение. И это было скорее соображение, что бы было. То есть ничего серьезного в этом было сделать нельзя. Потом они, конечно же... То есть невозможно взять и написать сразу все круто. Это надо понимать. И при том, что, сколько я помню, React стартнул чуть позже Cassandra как проект. Потом они где-то в версии, я не буду врать, наверное, в 1.3, может быть чуть раньше сделали, может быть даже в 1.2, сделали ReactPipe. Это такая библиотека, которая по сути позволяет... Если писать на Erlang, это позволяет почти любые вычисления раскидать на вот эту модель выполнения React, когда надет вместе VNodes, и как-то на них сроутить какие-то запросы, на них что-то покрутить каких-то worker'ов, потом собрать обратно. То есть сейчас там MapReduce работает как в любом нормальном MapReduce framework, когда у тебя задача идет на все узлы, на каждом узле считается, потом делается Reduce локальный, потом делается Reduce на каком-то одном узле последнем. Поэтому с этим сейчас там все нормально, через этот же ReactPipe работает Second Intensys и подобные вещи. Единственная проблема, я не знаю, подчинили ее или нет с ReactPipe, которая была, это то, что он был сравнительно не отказоустойчивый. То есть если там какая-то часть мэппера обломалась, то мы просто куска данных не увидим. То есть по сути мне для этого нужно сейчас использовать ReactPipe, правильно? ReactPipe, смотри, ReactPipe, тебе нужно использовать это hardcore на Erlang программист, ты хочешь фигачить чего-то суровое такое на Erlang, чего тебе не позволяет сделать MapReduce. Нет, нет, потому что я не могу это использовать из какого-то другого языка, то есть мне нужно обязательно из Erlang только. Нет, смотри, я сказал, что ReactPipe тебе нужно использовать, если ты суровый Erlangист и хочешь сделать что-то такое, чего тебе не позволяет сделать внешний интерфейс MapReduce. А внешний интерфейс MapReduce, я не знаю насчет произвольного языка, но абсолютно точно можно писать на JavaScript, как у него. А что сейчас в React с добавлением нод? То есть допустим, если мы значительно расширяем кластер, допустим, было у тебя порядка 5 нод и стало 50, то насколько хорошо это сейчас работает? Знаешь, я не могу тебе сказать насчет конкретного масштаба на 50, потому что я так не делал, у меня нет такого опыта, у меня есть опыт максимум расширения до 10 нод, и там с этим все нормально, я уже отвечал Саше, что сделали, собственно, еще где-то в области 1.0, 1.1 или 1.2, сделали нормальный механизм, который решает эту проблему, и он уже давно продакшен у всех. Валер, ты в ExCast обмолвился в свое время, что ребята планируют помимо Erlang поднимать виртуальную машину Java и очень классно используют там солвер для полнотекстового поиска. Они в итоге его заюзали? Да, да, да, они его заюзали, у них есть full search integration на патч-сервер, как раз вот мы сейчас с вами идем прям по списочку, которая у них написана в пресс-релизе, мы поговорили про Data Types, поговорили про Consistency, и теперь у них три... Это совпадение, а совпадение, потому что я его не открывал. Окей, у меня нет причин тебе не верить. Вот. Собственно, я этой фичей не пытался пользоваться, я не могу ничего про нее сказать, кроме того, что в плане протестированности, я не сомневаюсь, потому что ребята ее долго и хорошо тестировали, и я не сомневаюсь в том, что это точно лучше старого серча, потому что иначе бы они, скорее всего, не катили бы. Но этот лучше старого серча, кому-нибудь потому, что можно использовать весь солвер. В принципе, из-за того, что вселяет в меня какую-то уверенность, что это будет более-менее работать, у них есть механизм антиэнтропии довольно давно, и React-Search новый, точнее, подсистема называется Ecosuna, ее антиэнтропия связана с антиэнтропией подсистемы, которая хранит данные, поэтому если у нас что-то случилось с ключами, если система антиэнтропии где-то нашла какое-то расхождение, то у нас ключ будет переиндексирован. Понятное дело, это происходит не мгновенно, но есть механизмы, которые поддерживают индекс в консистентном состоянии, даже если у нас что-то разъехалось, и мы это поздно заметили. Насколько я знаю, это была одна из проблем со старым React-Search. Но, правда, про старый React-Search еще ходили страшные сказки, про то, что он очень ужасный, что у него очень ужасная производительность. Я, опять-таки, никак не могу это прокомментировать, потому что я не React-Search, и Ecosuna не пользовался ни разу. Слушай, а если ты ее не пользуешься, ее можно не включать? Да, само собой. Ну, то есть, как бы, что не будет запускаться эта виртуальная машина с Java, и не будет использоваться ресурсы. Ну, это полезно. Да. Следующая фича Security. Насколько я понимаю, они как-то интегрировали React с системным PAM. Это раз. Во-вторых, они запилили возможность для разных операций через HTTPS, и насчет протобаффного API, не знаю точно, абсолютно, это есть для HTTPS API, но подозреваю, для протобаффного тоже, разделять привилегии. Я, опять-таки, с этим почти никак не пересекался, потому что я React использую исключительно в закрытом окружении, где к нему ходят только свои. Мне мультитенанс был не нужен, поэтому я не могу комментировать, насколько эта фича хорошо проработана. Но фича есть, теперь, как бы, ее давно просили, в том числе, например, как у GDB это было давно. Теперь можно по бакетам разделять доступ, по операциям разделять доступ, может, кому-то нельзя, кто-то делать. Ну и, в принципе, если у вас есть пользователи, и у вас так как-то сущность фактически на вашу базу данных, если у вас, например, делаете какой-то сервис для обслуживания, что-то типа какой-нибудь пасса, например, и у вас есть разные клиенты, и эти клиенты так или иначе соприкасаются с какой-то вашей базой данных, наверно, это было бы удобно. Вот. Еще у них очень сильно изменился внутренний механизм для передачи метаинформации. То есть раньше у них был Gossip, обычный самый довольно наивно реализованный, и вся метаинформация, то есть все кольцо, ходило через этот Gossip. То есть, в частности, там была такая проблема, что чем больше заводилось, скажем так, бакетов, не просто бакетов по количеству, а количество бакетов с разными настройками, тем больше был overhead на этот Gossip, потому что каждые новые настройки бакета, даже каждая новая пара бакет-настройки создавала новый кусочек данных в том, что в кольце, и это все дружно гусепилось через сеть и сразу одним большим куском. Сейчас у них они сделали, реализовали какой-то неплохой алгоритм эпидемического броадкаста, поверх него сделали довольно классную подсистему в React-Core, которая называется Cluster Metadata, которое, по сути, такое кв-хранилище, которое один в один реплицируется на все ноды, и оно реплицируется очень эффективным Gossip-механизмом, который не всем подряд постоянно что-то куда-то входит, броадкастит, а который строит что-то вроде такого Spanning Tree, которое в случае, если оно развалилось, перепочинивается, или, например, если нет гарантии, что оно там до всех сюда летело, с первого раза там будет перепослано. То есть они стараются минимизировать оверхед на Gossip. И, соответственно, все тяжелые вещи из г-ца переехали в Cluster Metadata, теперь оверхеда на конфигурацию гораздо меньше, плюс они ввели новую сущность, кроме бакетов, теперь есть еще Bucket Types, поэтому теперь конфигурацию от имени бакета можно отковырять, и в принципе в целом хранить меньше лишних метаданных. Ну и, собственно говоря, там сейчас есть некоторая странность, что у нас есть новый механизм Gossip и новый Cluster Metadata, и кольцо, как оно было раньше, в принципе оно осталось, просто из него часть данных вынесли. У них это идет как строчка Simplified Configuration Management. А, кстати, да, там еще эрлогистов заинтересует, они сделали такую библиотечку, называется Cuttlefish, это каракатицы, короче. Это прикольная такая штука, которая позволяет писать конфиги в неподобном формате, и оно из них потом делает конфиги в AppConfig и в VMArgs. Для эрлоговых релизов, что в этом классного, это то, что можно в каждом приложении вашим эрлоговым независимо писать схему, которая потом, все эти схемы потом будут собраны в одну большую, и у вас будет один большой классный валидатор на ваш конфиг, и проблема с тем, что у нас запустилось приложение, потом какое-то значение из конфига доехало до своего местоназначения, потом упало, когда приложение уже работало, где-нибудь через полчаса просто приложение запустилось, потому что валидацию никто нормальную не сделал рано, теперь с этим есть классный механизм бороться, потому что вот есть Cuttlefish, в котором можно писать схемы. Все два Erlang-программиста, которые нас слушают, в полном восторге, при том, я думаю, что я этих двух программистов знаю по именам. Один из них написал уже такую платформу самостоятельно, второй использует подобную штуку, написанную кем-то еще. Что-нибудь еще про React 2.0 нам следует знать, или можно уже переходить? Я не знаю, у меня сходу в голове больше ничего такого не осело, они там очень много кода написали, большая часть этого кода довольно классная. Вот это меня пугает, если честно. Я имею в виду, что я не буду пытаться даже делать что-то на React, пока там 2.1 не выйдет хотя бы. На 2.1 там запланированы вещи типа... Добавить еще новых фич? Нет, типа заставить эти фичи работать вместе. Судя по тому, что у них там дико багов не полезло, вроде все хорошо, это раз. А в-третьих, что приятно, они работали над новыми фичами, на самом деле старый код, над ним были только баг-фиксы. То есть если ничего из новых фичей использовать не планируешь, то скорее всего тебе багов не написали.",
    "result": {
      "query": "React 2.0 новые фичи"
    }
  }
]
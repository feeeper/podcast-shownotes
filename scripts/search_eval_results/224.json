[
  {
    "segment_id": "1554abb0-3e6d-4242-ab27-59553ff38250",
    "episode_id": "32e2022c-2fc2-4523-b42f-7f6164a27261",
    "episode_number": 224,
    "segment_number": 11,
    "text": "Ну, да-да, я не говорю, что я просто к тому, что мне, как Валерии Мелешкину, а не как, не знаю, владельцу какой-то компании или там сети. Какому-нибудь интересному именно сообществу, и почему мне вообще GitHub, не BitBucket может быть интересен, как вот приватной персоне, потому что на GitHub есть тусняк. А на BitBucket нет, как правило, ничего. Хотя, кстати, некоторые open-source проекты, которые я сам пользуюсь, до сих пор развивают на BitBucket. То есть, например, есть такая тула для macOS, для перепаковки видосиков в нативные контейнеры, видео, которые понимает, например, iPad или iPhone. Ну, то есть, если вы не в курсе, то есть у нас есть кодек видео, называется H.264, например, в котором закодировано очень много, почти всё видео. Честно, если вы откуда-нибудь возьмёте mkv файл, mkv, это, на самом деле, просто контейнер. Как правило, в современных mkv файлах кодек как раз-таки H.264. Ну и там звук, может быть, Tempo3, может быть, AC3. Проблема в том, что mkv зачастую яблочным устройством, то есть есть в ELC сейчас, который, в принципе, всё прекрасно проиграет, но прям совсем-совсем нативно он не поддерживается. В частности, нет возможности на Apple TV послать, без какого-то стороннего софта, этот файлик просто типа что «Эй, Apple TV, играй». А вот если его перепаковать в правильный контейнер, то всё прекрасно работает. При том, что в отличие от перекодирования всего файла, что более такая знакомая людям операция, перепаковка в другой контейнер, она почти мгновенно выполняется за пару минут, в худшем случае. И, в общем-то, ограничена исключительно скоростью записи диска, а не тем, с какой скоростью ваш компьютер может кодировать видео. И эта Тула, Саблер называется, да, ещё она умеет подсасывать субтитры и добавлять всякое такое, она живёт на битбокете по сей день. И, в принципе, как бы хорошо себя чувствует. Но в целом, большинство вот такого рода Тулов, да и вообще большинство проектов, с которыми мы с вами так или иначе сталкиваемся в своей ежедневной работе или ежедневной жизни, оно живёт на GitHub. И хотелось бы, конечно, как обычно, не держать всё в худший мест, хотелось бы какую-то одну платформу, мне всегда очень хотелось, чтобы на GitHub были приватные репозитории, потому что до этого GitHub была крайне странной моделью монетизации по приватным репозиториям. Это как если бы Dropbox у вас считала не место занятое на диске, а количество папок. Прям очень странно, потому что банально в некоторых экосистемах принято делать кучу мелких репозиториев, и в некоторых других экосистемах принято делать типа монорепы. И вот как жить-то? Я считаю, а почему никто не сказал спасибо Microsoft, Microsoft такие молодцы. А вот я, кстати, не на 100% уверен, но если это действительно влияние Microsoft, то спасибо Microsoft. Но так, подожди, сервис Microsoft отдал тебе бесплатная репозитория закрытая, а ты не сказал спасибо, Валер, я считаю, ты неблагодарен. Смотри, смотри, я к тому, что мы не знаем достоверно, что случилось раньше, они запланировали это сделать, и потом пришёл Microsoft, и потом они это сделали, или пришёл Microsoft, и они это сделали? И сколько лет будет действовать вот это, мы не знаем заранее. Типа традиционной невиданной чедаристи? Ты меня что-то не знаешь, сколько будет действовать? Нет, я имею в виду, что пройдёт 5 лет, мы всё ещё будем говорить, что мы не уверены, это то ли влияние Microsoft, то ли так всегда было задумано. Ну, я бы, если честно, через полгодика стал считать, что Microsoft действительно вот здесь уже, это уже их решение. Да забейте, чьё это решение, они это сделали, это неплохо, мне это нравится. Да это отлично, это наконец как бы makes sense.",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 1904. Please try again in 3.808s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 1904. Please try again in 3.808s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
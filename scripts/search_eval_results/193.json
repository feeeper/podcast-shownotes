[
  {
    "segment_id": "3cd1c5ce-7123-49ad-8455-bc3ee231277c",
    "episode_id": "eea5acc9-111f-4dfa-bc83-f0f10a659c23",
    "episode_number": 193,
    "segment_number": 8,
    "text": "Ну к чему эта подбатка, ну я сейчас начну перечислять, назову тебе там B3, Brin и GIST и GIN и вот это вот все, ну это что? Хипа. Если говорить конкретно про типы, то там R3. Ну а кто-нибудь еще нот хипа? Сейчас выкликнули, да, это спойлеры, но... А, кто-нибудь еще что-нибудь вспомнит, еще какие-то интересные индексы кто-нибудь... Я пытаюсь подвести к идее хипа, вот сейчас прозвучала Brin, уже. Хорошо, да, я еще могу сказать, что если ты твои ключи в твоей memory базе отсортируешь, и отсортированный положенный диск, это тоже будет индекс, но собственно LSM, он недалеко от этого подхода ушел. То есть он не говорит, сам подход LSM, он не говорит, что у тебя должно быть на диске B3 или отсортированный массив в твоем, ну собственно, 3. Не, подожди, LSM отсортирован? Отсортирован, но он не говорит, что у тебя лежит на диске, вот то, что ты на диск скидываешь, это B3 или отсортированный массив или что, это просто какой-то immutable индекс. Вот, и в эту же тему, собственно, Боги какова? Bloom, чем не индекс? Вот, Bloom это уже очень хорошая подводка, и еще мы не так давно обсуждали, как индексы учить machine learning, вот, это все, то есть все знают B3, все более-менее по себе представляют, что это такое. В принципе LSM нынче популярен, это сейчас там каждый второй бекенд дисковый, это сейчас или B3 или LSM. Бывают более сложные случаи типа Postgres, где у нас есть heap и отдельные индексы, лежащие сбоку, там, не знаю, у тебя на одни и те же данные может быть и B3 и Bloom. Вот, Bloom позволяет отвечать на вопрос, если что-нибудь в коллекции с какой-то вероятностью, но при этом это только да-нет и с вероятностью. То есть вообще так, там не бывает, то есть если он говорит, что чего-то нет, то этого точно нет, но если что-то может быть, то нужно пойти проверить, если я правильно помню так. Брин индекс это такая хитча Postgres, кстати говоря, очень похожие вещи есть в колоночных форматах сохранения, если кто-то слышал про Parquet или про ORC, в колоночных форматах дисковых там тоже есть похожие вещи. То есть мы по сути берем группу значений в колонке и там один раз возле блока или возле там группы блоков пишем, что вот такое там максимальное значение, такое минимальное значение. Если мы потом делаем поиск и не находим, то есть мы точно знаем, что искового значения в этом блоке нет совсем, мы можем просто с диска вообще его не читать. Вот, еще вот там индексы пытались учить, зачем нужны такие штуки, они же вот если есть какое-то такое вот прекрасное, могущее все в B3, то есть оно прям в него можно почти что угодно запихать. Или там есть какой-нибудь, если нужно еще больше сложности, какие-нибудь джинны есть, зачем нужно изращаться делать такие странные неточные индексы, типа Brine, или Bloom индекс, или вот там, что еще, учить, ну прости господи, мы это обсуждали, тренировать вообще нейросеткой индексы, что за хрень, зачем кому это надо. Ответ на самый прост, если у вас много данных, то у вас индекс начинает давать просто на хранение довольно такой немаленький overhead, то есть, ну так на глазок процентов 15 ваших данных, это у вас будет overhead. Если у вас данных, там не знаю, скажем так, ну 10 терабайт, например, то 10 терабайт, это извини, как это, 10 процентов, это уже, сколько, это типа... Ну терабайт, ну. Да, да, сейчас, да, да, да, правильно. То есть у вас терабайт просто индексов, и вам, чтобы любые данные по этому индексу вычитать, вам нужно эти индексы еще как-то все прочитать с диска сами, потому что они тоже немаленькие получаются. Вот, в общем, это раз, да, в-третьих, потому что, в принципе, работа с индексом, его нужно обновлять, мейнтенить, его нужно, ну и просто какие-то вычисления с ним производить, поэтому люди придумывают всякие способы сделать маленький индекс, который будет давать достаточно хорошую точность. И вот сегодня мы поговорим об одной из таких штук, называется Hippo, прототип реализован на основе Postgres 9.5, его даже можно потрогать, как это ни странно, то есть это прям клево, мне идея понравилась в папере, то, что оно у них сделано так, что можно просто запустить, я, правда, не запускал, конечно же. В чем идея? Примерно в том же самом, в чем у BrinIndex, то есть мы берем и делаем summary на группу страниц, только вместо summary просто маленький-большой, собственно говоря, в папере его сравнивают от тип индексов и с BrinO, и с BrinB3, то есть такое вот, типа, а что будет, если мы попробуем сделать что-то такое, что будет достаточно точное, то есть точнее, чем BrinIndex? Но гораздо компактнее, чем настоящая B3. И вот что они, собственно, делают, они берут, группируют страницы, почти все релиционные базы данных уже сейчас строят гистограммы про данные, им это нужно, чтобы планировщик запросов мог предсказывать размерность данных и всякое такое. Или там, сколько будет, какой процент таблицы будет выбран при таком-то запросу. Соответственно, они просто сидят на этой информации, они берут эту гистограмму, только это не такая гистограмма, как мы обычно привыкли видеть со столбиками, это так называемая level-balanced histogram, то есть у нас просто как бы гистограмма, у нас же наши бакеты, они как бы, если их представлять как-то вот на графике, они будут не в высоту расти, у них просто ширина столбика будет отличаться, а по высоте столбики все будут одинаковые. То есть у нас получается, что у нас примерно одинаковое количество единиц данных в каждом бакете, просто у какого-то бакета больше диапазон, у какого-то меньше. Понятно пока что примерно? Да, продолжай. Вот, и дальше мы просто берем, ну вот если мы для начала возьмем пример просто с одной страницы, мы вот такую гистограмму построили, вообще для всего набора данных, потом берем одну страницу и для этой страницы строим просто вот как бы, точнее, для битиков, то есть берем всю гистограмму, представляем просто как битовую маску и поставляем битики для тех диапазонов, где у нас есть какие-то значения в этой странице. Но это все еще довольно много overhead, поэтому вместо того, чтобы делать это постранично, мы это будем делать, ну у нас сразу для группы страниц. И в общем-то и все, это получается довольно простая такая структура, то есть у нас есть список вот этих вот summary, список выглядит, каждый элемент списка это первая страница в нем, последняя в нем страница, страницы в нем должны идти подряд и битовая маска. А собственно, за запросы это строится тоже очень просто, мы берем из диапазонов, которые у нас в запросе есть, строим битовую маску, сверяем, понятно все, брать нам страницу в работу или нет. Понятно, что там в чем-то похоже на Bloom в том плане, что, ну и даже на Vring тоже, что то, что у нас есть значение в диапазоне, что значение есть где-то в диапазоне, это не значит, что у нас в каждой странице это будет значение или вот. То есть, грубо говоря, если у нас нет ни одного значения в диапазоне, можно точно не читать, если что-то где-то попалось, то мы прочитаем все страницы в диапазоне, но на какой-то из них мы что-то найдем. То есть и то, насколько сильно группировать страницы, в общем-то позволяет регулировать компромисс между точностью индекса и тем, сколько места на диске он займет. По их замерам он сильно компактнее, чем B3, не такой, конечно, компактный, как Vring, но зато он превосходит сильно Vring по точности и в принципе в некоторых ситуациях даже может потягаться с B3, в некоторых, то есть там для range запросов он с B3 конечно тягаться не может, но вот для точечных запросов или для запросов типа, для случаев, когда у вас есть куча данных и вам все равно делать full scan, вы просто хотите какие-то страницы выбросить, это будет хорошо работать. Там эта структура обдейтись тоже довольно просто, не буду сейчас в детали выдаваться, ссылка на paper, конечно же, будет, вот если вам почему-то нужно, вообще в принципе хочется построить какой-то такой вот эффективный индекс для большого массива данных, то это довольно интересный paper, довольно простая идея. Что еще хочется отметить, да, что прототип сделан на 9.5, а вот начиная с 9, нет, начиная с Postgres 10 можно делать custom-access методы, собственно, Bloom Index сейчас стеклоризован в Postgres, и вот я жду, когда кто-нибудь сделает это как access-метод для Postgres, а не как fork Postgres, вот такие мои мысли. Саша, ты обещал поддержать. Я пытаюсь понять, в чем существенное отличие от, собственно, Bloom Index. Смотри, Bloom отвечает на вопрос... Про всю таблицу, типа, он хранит. Да, и он отвечает на вопрос, если у тебя есть значение x, и по этому значению x ты можешь сказать, оно там есть или нет. Эта штука тебе позволяет оперировать диапазонами значений, то есть ты не можешь с Bloom работать с запросами, где у тебя есть больше-меньше в запросе, понимаешь, о чем я? Угу. Вот, а это позволяет. Звучит забавно. Вот. То есть, на самом деле, я даже думаю, что что-нибудь такое точно теперь вдохновит людей, которые делают эти всякие паркей и OLC и всякое такое, потому что это сильно-сильно лучше, чем просто хранить минимум-максимум для страйка, для страйпа. Прям сильно точнее, при том, что overhead по данным не сильно больше. Выглядит как офигенная идея, и там их даже проще реализовывать, потому что там никаких апдейтов нет. Ну, клево, спасибо, что рассказал. Ну, я не имею чего-то прям существенного дополнить, потому что, да, идея действительно простая, да, действительно клёво. Я по большому счёту согласен со всем, что ты сказал. Очень удобно, когда много данных, по ним не слишком частый поиск, и хочется сделать индекс маленьким. На самом деле, даже если поиск частый, просто... Но хочется сделать индекс маленьким и скорость не так важна. Все те же компромиссы. Не, почему скорость не так важна? Я как раз могу... Как раз мой аргумент в том, что иногда у тебя бывает такой запрос, который ему всё равно нужен full scan. Он ему всё равно нужен. Так зачем тебе индекс? Из этого full scan заведомо выбросить вещи, которые потом всё равно отбросятся дальше по тексту. Ну, то есть, смотри, у тебя может быть, например, var очень сложный, и у тебя не может быть какой-то один главный индекс. Или тебе придётся его прям много... То есть, B3 большой, и ему придётся долго сканировать. То есть, тебе нужно 5 B9-ов просканировать, ну, согласись, это недёшево. А если ты можешь просто на такие summary посмотреть, и просто берёшь очередную группу страниц в работу, смотришь на summary, смотришь, какие страницы попадают на пересечение, берёшь только их. Я в это время изучаю их репозиторий, и тут, во-первых, написано, что они смигрировали на 961. Но они всё ещё сделали это в ядре, не через механизм pluggable access методов. Но, по крайней мере, они пытаются это всё ещё допиливать. Ну, как пытаются, вот тут год не было изменений, но они сделать опять перешли. Я, кстати, не уловил, они это такие кто? Это какой-то университет. Если честно, я не помню какой. Могу ещё открыть paper и сказать точно. Это университет информатики Аризоны. Аризонский, то бишь. Юро-сайт. Видимо, похоже, это кем-то проспонсировано, потому что репозитории находятся у компании Data System Lab. В смысле, Data System Lab — это, скорее всего, просто лаба внутри универа. А-а-а-а-а. Нет, но у них сайт свой есть, зачем? Ну, так, как бы, почему нет? Т-т-т-т-т… Ща-ща-ща. Ну, хз, в общем, тут такой сайт трудно предсказать. Но вообще, выглядит как компания. Ну ок, пусть будет компания. Там ещё написано Lab Members. С чего дело, что это всё-таки… А, стоп, здесь есть даже… Нет, действительно похоже на компанию, потому что Google карты не ведут на кампус универа. Поэтому, может быть, действительно отдельная… Ну, никто не утверждает, что она обязательно там супер-как-то сконцентрирована на заработке денег, но это некая отдельная от университета сущность. Ну, может быть, сконцентрирована универа, ладно, неважно. Давайте пойдём дальше. Я вот тут на дискасс наезжал в прошлом выпуске, что он тебя меня трекает, а тут Саша мне хочет сказать, что он меня больше не трекает. Давай, Саша, расскажи мне, как меня больше не трекает. Ну, в общем, дискусс, он услышал тебя, твоё негодование и осознал свою неправоту. И решил всё как можно скорее исправить. На самом деле, я просто не слежу за политическими новостями, но там, видимо, были какие-то вот если вот акты про даты правосе и всё такое, а что, может быть, весь твиттер? Его приняли в итоге, да, похоже? Его давно приняли, он просто 25-го числа вступил в силу и принял несколько лет назад. Просто у него был дедлайн вступления в силу вчера. Со вчерашнего дня пользователи в Европе, они защищены GDPR. Я, кстати, хочу по этому поводу бросить пару моментов. От него все пересрались. Хотя на самом деле там есть такие интересные провижены, которые по сути выводят из-под... Ну, они очень расплывчатые, но они выводят из-под сомнения, как это так скажем, практики использования пользовательских данных, когда пользователю очевидно, что с ними происходит. То есть, грубо говоря, если у вас на сайте написано, оставьте здесь имейл для имейл-рассылки, то вы, собственно, и получили консент пользователя на это. Если у вас имейл используется для того, чтобы, не знаю, оформить регистрацию, а потом будете на него слать какую-то почту рандомную, вот для этого нужен консент. То же самое касается и всяких других вещей. То есть, если у пользователя есть, ну, может быть, ожидание, то есть, грубо говоря, если пользователь крикает на рекламу, скорее всего, он ожидает, что его крик будет как бы передиректно в правильное место, что он будет посчитан, и тогда все, потому что, блин, он сам тыкает на рекламу. А вот если пользователь просто комментирует, а его в это время продают каким-то другим компаниям, это, в общем, становится плохо. То есть, основная идея GDPR не в том, чтобы всех заставить собрать ваш консент, а в том, чтобы компании восприносили данные не как... Что-то, что само собой разумеется. Ну, нет, даже никаких шуток, что такое, что нужно накопить любой ценой, а что-то такое, с чем нужно строжно обращаться, как кто-то там в твиттере выразился уже, что это не... Not an asset, but a liability. То есть, что-то такое, да, что это не ценность, а, ну, как это правильно сказать, liability, обуза. Вот. Ну и так вот, да. Дисказ. Соответственно, ну, по этому поводу мне на почту свалилось, не знаю, штук 20 писем о том, что у нас изменились как-то пользовательские соглашения, там, познакомить. Ну, просто вот все компании, в которых я когда-либо регистрировался на этот e-mail, которым я 100 лет не пользуюсь, они вот все-все-все прислали письма, что все изменилось, все не так, как было. И у дискуса у него в форуме комментариев теперь всплывает форум, который говорит, что, дружище, там... Сейчас я открою скриншот. Прими условия использования, прими политику конфиденциальности и последняя галочка говорит, там, согласись с data sharing policy, с которой ты не обязан соглашаться. То есть ты можешь, тебе достаточно принять условие использования и политику конфиденциальности, но ты можешь сказать, что твои персональные данные, как бы, ты не согласен, чтобы их процессили. И продолжать пользоваться сервисом, что довольно приятно. Да, и на самом деле мне вот что интересно. Вот этот GDPR, он... Ты просто как-то очень резко ушел в дебри. Если вот простым языком он говорит о том, что нельзя собирать, типа трекать историю моего браузера и на основании этого предлагать мне товары без моего согласия на это, или что он говорит? Это как то, что вот трекать историю твоего браузера он как раз, в принципе, кто-то может. Чего нельзя делать, это отдавать... То есть он про то, что, ну скажи, да, что данные пользователя, с ними нужно делать только то, что явно разрешил пользователь. Хорошо, то есть Facebook может своим пикселем собрать историю моего браузера, но не может показывать рекламу, пока я не согласился на основании этой информации. Да, и он не должен эту историю твоего браузера связывать лично с тобой. Вот тут я даже не помню, тут вообще... То есть да, без твоего согласия он не может эту историю связывать лично с тобой. Удобно, но это только на территории ЕС это действует. Да, ну то есть скажем так, те вещи, которые там написаны, они так сделаны, но они так написаны, что очень многим компаниям, скорее проще везде так... То есть те, у кого бизнес-модель не зависит от продажи данных пользователей, то есть там, грубо говоря, Facebook и Discus, сейчас просто на европейском рынке стало ой. Всем остальным же, то вот у кого продажа пользовательских данных это не основной бизнес, им в принципе, ну это просто хорошая практика, мне кажется, так относиться к данным пользователям. То есть не знаю, если вам не нужен на самом деле его email, а нужно просто какой-то уникальный идентификатор, ну захешируйте вы его. Зачем вам email-то оставлять, вот такого рода вещи. Если вам не нужно там знать какие-то случайные данные пользователей, которые вы там почему-то увидели, то не сохраняйте их, ну и так далее. Даже не знаю, даже собственно, если вы показываете, если вы по Facebook показываете рекламу на странице Facebook, вы все еще можете там таргетировать и вот это все по самой небовой. Чего вы не можете делать, это отдавать эти данные кому-то еще. То есть те вот все, у кого на этом была бизнес-модель основана, тем стало не очень клево. Кстати говоря, Facebook в этом плане может быть даже не так плох, как Disqus, потому что Disqus-то собирает, но сам ничего не показывает, ну или почти ничего не показывает. А вот Facebook-то он как раз наоборот работает, он собирает данные от всех и догрегирует вместе с собой. То есть Facebook, он еще и место показа рекламы. Я бы даже сказал, он основное место показа рекламы. В случае с, ну да, Facebook теперь просто не сможет эти данные кому-то еще отдавать. Вот Disqus будет тяжело, наверное. Я думаю, он не разорится, потому что, ну, я небольшой специалист по рекламе в социальных сетях, но там экспериментировал немножко с ВКонтактом. И тебе не обязательно иметь историю браузера пользователя, чтобы показать ему релевантную рекламу. Тебе достаточно сказать, покажи эту рекламу всем пользователям, всем мужчинам старше 18 лет, которые стоят вот в одной из этих 15 кругов, ну условно говоря. Ну смотри, Facebook сейчас гораздо мощнее. Ты можешь, например, протрекать гемографию, хорошую гемографию для твоего приложения. То есть, скажем так, здесь какая-то BI-система. Ты можешь протрекать всех пользователей, которые платили за последнее время или которые там просто имеют какой-то паттерн поведения, который тот, который ты хочешь в своем приложении. Выгрузить их в какие-то не очень уникальные идентификаторы, типа вот у Apple там есть такая вещь, как рекламный идентификатор в девайсе, специальная такая штука, которую пользователь может тупо резетнуть, если захочет. Потом ты берешь эти идентификаторы, дашь Facebook и говоришь, дорогой Facebook, на самом деле даже можно проще, можно просто издока Facebook в свое приложение встроить, сказать, что дорогой Facebook, вот эти ребята, они мне хорошо платят, дай мне пожалуйста таких пользователей, которые будут вести себя так же. И Facebook даст. Удобно. Вот, ну что, про дискасс все? Слава GDPR? Слава GDPR, что еще удобно, это иметь исключение в коде. Наброс организовался, тоже снова наш гость Никита, Никита сегодня набросил на монады. А я набросил на тему, потому что я считаю, что исключение это очень клево, а вот монады нафиг не нужны. Так вот Никита тоже то же самое набросил. Клево, я не читал, но я рад, что согласен с Никитой. Ну да, я не знаю, насколько это наброс получился, насколько просто пояснение ситуации, то есть ну как бы у меня особо ничего там не бомбит, все высказали свою точку зрения. А общий консенсус такой, что ROR монады не будут работать в динамических языках вообще, из-за того, что их очень легко таким образом проглядеть ошибку, исключения будут. А типа в языках статической типизации непонятно, но мне кажется, что это все-таки не очень удобно. Люди утверждают, что это очень удобно, исключения в языках статической типизации не нужны. Но здесь как бы есть несколько вопросов, то есть возможно мы говорим о разного рода приложениях, я говорю о приложениях таких как бы веб-сервисах, еще о чем-то, кто-то может быть говорит о маленькой страйвовой программке какой-то, которая читает число из SD-in и пишет число в SD-out. Тут конечно будут какие-то условия. Ну и плюс я не пользовался такими языками статической типизации и рормонадами какими-то хорошими, типа Rust, ну не Rust, Rust, ну Rust там тоже приводили в пример. Поэтому я не могу сказать, насколько это удобно. Мне кажется, это неудобно, типа check it exception неудобно. Ну может быть, все-таки я неправ, поэтому у меня здесь нет мнения. Ну вот я буквально сегодня утром прочитал твою статью, и ты не упоминаешь про как раз динамически типизированные языки, ты просто говоришь, ну можно пропустить, вот, без, ну насколько я запомнил, по крайней мере, без вот этого вот подчеркивания, что это в динамически типизированных языках, просто пропустить.",
    "result": {
      "query": "Hippo индекс в Postgres"
    }
  }
]
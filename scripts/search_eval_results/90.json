[
  {
    "segment_id": "2b84a8bc-29c0-4587-b1e5-38ef0201e25e",
    "episode_id": "7b916cf7-e445-487f-8830-91597eedbff3",
    "episode_number": 90,
    "segment_number": 5,
    "text": "Я предлагаю переходить к следующей теме. Идущая тема – это Валера, твое, про пейперинг. Да, в общем мы в прошлом выпуске упоминали про CRDT, Community Replicated Data Types, или Convergent Replicated Data Types, в зависимости от того, какой именно CRDT вы используете, и собственно начнем с этого как раз. В принципе, что такое CRDT? Вот есть у вас какие-то 2 реплики, они как-то обменялись сообщениями, которые, возможно, приходили в не совсем одинаковом порядке, и после этого у них получилось совершенно одинаковое значение, это и есть CRDT. CRDT подразделяются на 2 класса, бывают Operation Based CRDTs, это как раз Convergent Replicated Data Types, и бывают Community Replicated Data Types, это когда у вас только операции между ними пересылаются. Convergent Data Types – это очень понятная штука, у вас есть просто 2 копии состояния, вы каждая из которых применяете какие-то операции локально, например, потому что к вам клиент пришел, вы сейчас что-то с ним сделали, после этого вы этими копиями обменялись, у вас есть определенная операция Merge, и у вас после этого получилось одинаковое состояние. Это очень здорово в общем случае. Есть другой вариант – Community Replicated Data Types, это когда вы пересылаете только саму операцию, которая применяется, при этом операции могут приходить в неправильном порядке, но поскольку они коммутативные, у вас оба состояния получатся одинаковыми. Но тут есть одна важная проблема. Для Community Replicated Data Types, они также называются Operational Based CRDTs, с ними проблема в том, что несмотря на то, что операции могут иметь любой порядок, они должны прийти не больше одного раза, в смысле даже не то, что они должны прийти в точности однажды. И это такая гарантия, которую большинство систем, если у вас есть в точности однажды, то скорее всего у вас есть и порядок. Если у вас нет порядка, то у вас скорее всего нет в точности однажды. То есть я не знаю ни одной системы, которая на практике реально есть в точности однажды, но нет порядка. Но, Бенжи, если ты для запросов генерируешь UUID, то у них есть уникальность – нет порядка. Да, но смотри в чем дело. Тебе нужно очень много информации хранить. Ну UUID я для примера привел. То есть можно 16-битовые счетчики использовать. Ну в общем ты отчасти прав на самом-то деле. И в paper это тоже отмечается. Но суть в том, что построить практическую систему с коммутативными CRDT – это не самая такая тривиальная задача, и они на самом деле на практике почти не применяются. Тот же самый React, который 2.0, с его CRDT встроенными – это convergent data types. Ну и почти все CRDT, которые где-либо используются, кем-либо на практике, они почти все convergent. Более того, в нашем хардкорном, нет, не так, в нашем кровавом веб-деве обычно даже проще не произносить умные слова типа CRDT, а как-то так на пальцах объяснить, что ребята, а вот давайте представим себе такую ситуацию, такую ситуацию, видите, все разъезжается, давайте мы вот как-то будем кусочки логов условно говоря пересылать, ну или как-то так объяснить. Ну, в основном, конечно, это не совсем кусочки логов, потому что в случае как раз классической convergent replicated data types, ты не кусочки логов пересылаешь, в классическом случае ты пересылаешь просто, вот у тебя есть состояние на реплике A и состояние на реплике B. У тебя реплика A посылает целиком свое состояние с реплики B, а реплика B делает обратную ситуацию, то есть пересылает свое состояние реплики A, и после этого у тебя на каждой из реплик происходит мердж двух состояний, после этого у тебя получаются идентичные состояния. Ну, я так странно сказал, потому что мы пытались писать что-то похожее на так называемое CP решение, и там реально тебе нужно было сначала получить все, что происходило до этого, потом накладывать свои изменения. Ну и если честно, там на самом деле все равно была фигня и все разъезжалось. Ну вот до этого мы как раз на самом деле дойдем, но я свалю к чему, к тому, что вот commutative replicated data types, когда у тебя operational based, там как раз нужно пересылать именно что лог операций, а при этом в этом логе операции можно переставить местами, но они все должны прийти строго однажды. И в общем, да, это не очень практичная гарантия. Но раз коммутативные, нет, не коммутативные, а как сходящиеся реплицированные типы данных, они такие популярные, и все их используют, и не нужно никаких странных гарантий для них. Что же с ними не так? Почему нужно еще какие-то delta state replicated data types придумывать? Все потому, что если у вас состояние реплики большое, вы, возможно, не хотите переслать все состояние реплики, ну долго, дорого, бессмысленно, возможно, потому что часть данных, возможно, не менялась. Вместо этого вы, скорее всего, хотите переслать какое-то необходимое достаточное изменение, которое, с одной стороны, позволит двум репликам сойтись, а с другой стороны, это не operational-based RDT, которым нужны специальные гарантии. И, собственно говоря, paper, который я сейчас обсуждаю, он именно это и обсуждает. Он за авторством все тех же людей, которые придумали весь RDT. На самом деле, во многом работа идет в параллели с тем, что вот как раз два года назад сделали ребята из Башо для того, чтобы иметь CRDT в РИАКе. То есть, скажем так, это, по сути, более формализованная и обобщенная версия того, что сделали ребята из Башо. У ребят из Башо тоже был их paper. Вот. По сути, все сводится к тому, чтобы найти такой вот минимальный кусочек CRDT, который, с одной стороны, можно переслать по сети независимо, с другой стороны, он при мерже с CRDT даст состояние, которое общее. Очень простой пример, самый такой минимальный, интуитивный. Это каунтер, счетчик, который можно только увеличивать. Такой счетчик в классическом CRDT будет представлен как вектор счетчиков, каждый из которых... То есть у нас есть однишние реплики и счетчик, который считается на этой реплике. И так для каждой из реплик. Потом, чтобы получить значение счетчика на самом деле всего, мы просто берем и складываем все счетчики. Вроде бы понятная идея, да? Ну, так более-менее. Продолжай. Вот, да. Ну, понятное дело, что в классическом случае, чтобы обменять... То есть, ну и когда мы... операция мердж для такого классического счетчика, мы просто для каждой реплики, ну, если у нас есть два состояния, мы для каждого ID-шника реплики берем просто максимальное значение. Но понятное дело, что если у нас 10 реплик, то если им нужно обменяться между собой, каждый из которых будет переслать 10 состояний, это довольно бессмысленно, потому что каждый из них делал изменения только про свой локальный каунтер, все остальные она просто отсматривала. И на самом деле для конкретно этого типа данных у него очень тривиальная дельта. Достаточно просто взять тот компонент вектора, который для этой конкретной реплики, его переслать, и его мердж с любым другим каунтером, он будет давать точно такое же значение, как если бы мы переслали целиком состояние этой реплики. Понятно почему, да? Звучит круто. Ну, я бы не сказал, что конкретно это еще не звучит круто, там в конце папера очень крутые вещи действительно происходят. Здесь это довольно такая простая идея, мне кажется. Что если у нас есть, ну, не знаю, 10 каунтеров, реплика 1 — ее каунтер, реплика 2 — ее каунтер, реплика 3 — ее каунтер, и так далее, и общее значение каунтера — это сумма всех вот этих подкаунтеров, и чтобы переслать значение, чтобы обменяться значениями между репликой, скажем, 2 и репликой, скажем, 5, нам не нужно переслать их целиком состояние, достаточно переслать только вот каунтер для каждой реплики, достаточно только ими обменяться. Вот. На самом деле grow-only-counter — это такой очень скромный тип данных, их сильно больше, и папер на самом деле обобщает это до вообще всего чего угодно, включая вложенные, рекурсивно вложенные типы данных. Я не буду это пересказывать, потому что уже с каунтером довольно тяжело получается. Кроме того, папер поднимает интересный вопрос, связанный с тем, что как только мы переходим от полного обмена стейтами к обмену дельтами, у нас может потеряться, ну, в общем случае, convergent replicated data types, они обеспечивают casual consistency, и вот если мы переходим к дельтам, у нас casual consistency теряется, у нас просто остается только гарантия на то, что у нас реплики сойдутся в значении, что стейт посередине вполне может быть не casual consistent, что не очень хорошо. То есть, ну что такое casual consistency? Это когда у нас есть, не знаю, есть какое-то действие, мы это действие увидели, в ответ на него сделали какое-то другое действие, и мы гарантируем, что вот то действие, которое спровоцировало наш ответ, оно всегда будет, любой репликой и любым агентом в системе будет обозрено до того, как ответное действие будет обозрено. Это как раз есть casual consistency. То есть оно может быть в любом порядке с любыми другими действиями, но вот самый главный момент, что действия, которые спровоцировали реакцию, они всегда будут в определенном порядке. И при переходе к delta CRDT мы можем потерять эту гарантию, и авторы на самом деле приводят необходимые подпорки, скажем так, которые нужно сделать, чтобы этого не происходило. В частности, они вводят понятие, такое понятие как delta interval, или там delta batch, не помню, как они это называли, да, delta interval они это называли, и вводят условия, которые должны выполняться, чтобы это не терялось. То есть механизм обмена дельтами должен быть таков, что, это же называется заодно механизм антиэнтропии, что вот у нас есть реплика А, есть реплика Б, и реплика Б чего-то не видела из того, что видела реплика А. И вот дельта, которую реплика А пересылает реплике Б, должна быть такова, что самый первый элемент в дельте, скажем так, дельта интервала, который будет пересылан между А и Б, должен удовлетворить условию, что никакое другое действие не должно быть между вот этим интервалом и тем, что видела Б. То есть, грубо говоря, он должен быть плотно поджат к тому, что видела Б. То есть там не должно быть дырок между тем, что видела А и между тем, что А послала в качестве дельты реплики Б. Я понятно объяснил или очень непонятно? Лично я потерялась. Ну, в общем, представим, что у нас есть некоторый набор дельт, мы их можем в такой лог выстроить. То есть все операции, которые мы делали с реплика А, их можно на самом деле в какой-то лог выстроить. Даже если нам не очень важен порядок, но их можно все равно выстроить. То есть реплика А в любом случае в каком-то порядке их приняла. И есть какие-то операции у реплики Б, их точно так же можно выставить в лог. По сути, дельты-интервал – это не одна операция в логе, а вот прям целый кусок лога, который мы хотим переслать. Ну, хорошо. И вот свойство, которому этот кусок лога должен удовлетворять, чтобы сохранить казуальную консистентность, таково, что реплика Б должна была увидеть достаточно информации, чтобы вот этот кусок лога можно было пристыковать к реплике Б так, что потом никакого другого куска не нужно было бы пристыковать между стыком. Все еще непонятно? У меня она все равно очень сложно воспринимается на слух, и это нужно рисовать, смотреть, потому что так это очень тяжело. На самом деле, вот тот же самый Андриан Коллер, у которого есть краткая выжимка статьи, он как раз очень хорошо нарисовал, и на самом деле, все, кто не понял с двух раз, я очень призываю вас посмотреть в лог, там есть красивые картинки, вот я вас призываю смотреть туда. На самом деле, статья дальше приводит примеры очень многих ассертитий, таким образом сделанных, а также дается некоторый набор приемов, которые позволят вам конструировать ваши типы данных, в том числе рекурсивные. И наконец, статья подводит нас к идее о том, что можно же сделать хешмэп, ну почти хешмэп, в котором будут другие ассертититы типы данных, в том числе другие хешмэпы, ассертитишек. И вводит всякие вот штуки, как это должно работать, чтобы такая хешмэпа, во-первых, работала, а во-вторых, с него можно было удалять, и она не ломалась при этом. Насколько я понял, суть такого хешмэпа в том, чтобы казуальный контекст всех ложных типов данных вытаскивать в казуальный контекст уровнем выше. И тогда, если мы даже какой-то элемент внутри хешмэпа удалили, мы знаем, что вот у него был какой-то казуальный контекст, и мы его не забудем, будем вечно помнить. И если мы потом снова добавим элемент с таким же ключом, мы будем знать, что это новый элемент, и что мы все, что нужно, увидели, и случайно ничего заново не удалим. Я в целом рекомендую статью вообще всем. Если вы не знаете, что такое сердити, и ни разу их не видели, я рекомендую вам ознакомиться хотя бы с концепцией. Да, что еще? Ну и да, если вы знакомы с сердити, и вам эта тема интересна, статья обязательно к прочтению. Что еще обязательно к прочтению? Это как минимум обзоры в том же блоге Morning Paper. Вообще на этой неделе там была огромная куча, я вот выделил для себя еще два как минимум.",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 5944. Please try again in 11.888s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 5944. Please try again in 11.888s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
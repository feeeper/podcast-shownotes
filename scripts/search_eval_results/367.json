[
  {
    "segment_id": "c1df3621-de0a-4337-a89a-0688c8a32ef3",
    "episode_id": "35c8e145-d36f-4d0c-88b7-1a0c1af65760",
    "episode_number": 367,
    "segment_number": 15,
    "text": "я как-то квалифицированный там менеджер. Вот, поэтому, наверное, вот просто с опытом другой стороны стало легче на это смотреть и воспринимать отказы. Вот, наверное, последнее, что я хотела добавить в поводу форматов собеседования, был еще один формат собеседования, который я редко где видела, когда мне дали paper и мне дали дизайн-документ, который к этому paper предлагался. Вот paper описывает там базу данных, а дизайн-документ предлагает некоторые изменения к этой базе данных. И была моя задача прочитать эти оба документа и потом поговорить с инженерами, которые написали этот дизайн-документ, и это вот для менеджерской позиции было, и позадавать вопросы, помочь инженерам прийти к более, как бы там, более элегантным решению или найти какие-то проблемы в этом дизайн-документе. Вот, то есть, что ожидается от менеджеров в плане их там импута к дискуссиям дизайнерским. Вот, поэтому вот такой формат, который мне очень понравился, он очень был прикладной, где это действительно очень похоже на то, чем менеджеры занимаются, как они участвуют в беседах, и там можно много чего показать, как вы работаете. Вот классный формат. Спасибо. Я думаю, можно идти дальше. Ну, кстати, если посмотреть на хронометраж, с ума сойти. Я думал, что мы эти, там типа три темки, пробежимся по ним быстренько, и там, может быть, там даже тем не хватит. А мы только первые три темы покрыли, а уже два часа. Ха-ха. Саш, давай ты пока по закладкам своими пройдешься, чтобы их вычистить, а потом еще подумаем, продолжим мы или нет. Давай тогда сразу и по закладкам, и по одной строкой. Ну, в смысле, да, вот по всем ним. Вот. Тема в закладке. Я посмотрел доклад, который я давно хотел посмотреть, но мы его разбирать не будем. Это доклад брендона Грега про внутреннее устройство BPF, и сейчас на себе про BPF Trace. Напомню, BPF — это виртуальная машина с джит компиляцией в гидре Linux, которая позволяет делать всякие клевые штуки, в частности... Сейчас есть исполнитель произвольный код в гидре Linux? А вот не такой же произвольный, кстати. Там очень много ограничений. Недавно увиделись была просто. А BPF Trace — это, немного не мало, полный эквивалент Dtrace в Linux, который прям клевый. Я, кстати, достаточно долго не следил за BPF и вообще пропустил его появление, а вот в Linux есть теперь прям, собственно, Dtrace. Не путать Dtrace for Linux, не путать с системом TAP и так далее. Вот BPF Trace прям топчик. Кстати, все это open source и разработано за деньги Netflix, который как компания — большой молодец и Contributor в open source. Доклад рассказывает по шагам. Вот мы запустили BPF Trace, такая-то команда, которая трейсит, я не помню, что какой-то syscall, типа open или неopen. И вот прям по шагам давайте разберем, что там происходит. А вот так происходит синтезический анализ. У нас там не Flex с бизоном, а вот та другая пара — YAC и что-то еще. Lex и YAC, по-моему, так они называются. Не знаю, почему, был сделан выборовых пользу. А потом вот у нас вот такой есть формат байт-кода, вот так мы транслируемся. А вот так вот у нас, кстати, у них два бэкэнда, дефолтные это на LLVM. А для встраиваемых систем у них собственный компилятор называется BC, который не так хорошо может в оптимизации, но у него мало depend'ов по сравнению с LLVM, он лучше подходит для встраиваемых систем, где проблема с памятью, место на диске и так далее. Вот, плюс там по ходу доклада очень подробно разбираются, в каких файлах в исходном ядре Linux поискать ап-коды для команд в VPF, в смысле в виртуальном байт-коде, потому что у него есть еще и, собственно, байт-код, где живет верифайер этого байт-кода и так далее и тому подобное. В общем, очень интересный доклад, при том он относительно короткий. Вот, я рекомендую, посмотрел на это, дыхание очень интересно. Олег Бортунов в своем твиттере пишет, что у Postgres Pro на сайте доступна бесплатная книга за авторством Егора Рогова и книжка рассказывает про детали внутреннего устройства Postgres'a. Я смутно припоминаю, что Егору на автор серии статьи на Хаббор и мое понимание, что эта книга во многом основана на этих статьях, это не обязательно глубоко разработческая книга, она больше про какие детали вам нужно знать как пользователю или админу. То есть, да, вы узнаете, как устроено B-дерево или DIN-индекс, но код вам не покажут. Опять же, насколько я припоминаю, книгу я пока не прочитал. Но статьи были клёвые, статьи на Хабборе я читал. Дальше, одной строкой, поскольку я сейчас запиливаю поддержку TimeZone для непрерывных агрегатов в таймскейле, мне стало интересно, когда у вас есть TimeZone, например, Москва, Европа slash Москва, в общем случае, у вас бывают две вещи, это перевод часов с летнего времени на зимние и обратно, плюс у вас может меняться местное законодательство о том, в какой там зоне сейчас живет Москва. И в связи с этим, вот если вы посмотрите на временную линию, время в Москве, в этой временной линии могут быть бирки. То есть время может прыгнуть на пару часов вперед и, условно говоря, там два часа ночи в такой-то дате у вас получается несуществующее время. У меня тут есть небольшой трейдинг по ссылке и, как пример, 27 марта 2011 года два часа ночи по Москве такого времени никогда не существовало. Возник интересный вопрос, что будет, если Postgres-у скормить такую дату, потому что это же строчка, я могу любую дату скормить и попытаться ее скоснуть в timestamp.tz, например. Например, будет ли брошенные исключения или он как-то иначе это хэндлет, так и я узнал, что Postgres несуществующие даты переводят к ближайшим существующим. А если вы хотите более строгое поведение, то есть если вы хотите exception в этом случае, то вы можете сделать проверку, например, коснули дату во внутреннее представление и обратно, и если вы получаете не ту же дату, которую передавали, то бросьте исключение. Вот такая вот интересная особенность. Необычно, необычно и неожиданно. Казалось бы, дата и перевод и что может пройти не так. А я даже никогда не задумывался, что у нас на самом деле есть даты, которых нет. Я о многом не задумывался, пока не столкнулся по работе с таймзонами. Но на самом деле это не так ужасно и страшно. По крайней мере, если тебе это не надо самому реализовывать, если это уже все реализовано в Postgres, тебе нужно только разобраться, как оно там устроено, то в принципе там главное не бояться. Одной строкой в блоге Depesh пишут, что в Postgres 15 занесли логирование в формате джерсон. Это особенно удобно, когда у вас есть в логе записи, содержащие не одну строку. Такое может быть, если вы трассируете запросы в логах и по разным другим причинам. И вот при обычном логировании получается какая-то ерунда и при логировании в CSV, которая тоже поддерживается, получается какая-то ерунда. А вот при логировании в джерсоне это случае можно нормально разобрать, потому что многострочная строка будет нормально реализована в джерсон. И также одной строкой, несколько интересных патчей, которые сейчас предлагаются в Postgres. Это, во-первых, патч от Федора Сегаева. Господин Сегаев у нас был в одном из подкастов, собственно, вместе с господином Бортуновым, где он предлагает сделать механизм Toast расширяемым. То есть, напомню, когда вы записываете относительно большие куски данных в Postgres, которые не умещаются в одну страницу, размер страницы по умолчанию 8 килобайт можно скаемпликировать с другими флагами. Если вы хотите положить текст, который в страницу не умещается, он будет нарезан на куски и положен в специальную таблицу, так называемую Toast, маленькими кусками. Плюс, там, поверх этого накручено сжатие, которое тоже теперь... Раньше было одно, теперь оно настраивается. Можно выбирать между LZ4 и старым, но это уже автопик. А предлагается сделать этот механизм расширяемым, потому что Postgres это всё про расширяемость. И в качестве юскейсов приводится, что сейчас механизм Toast немножко глупенький, он ничего не знает про внутренние представления данных. Например, если у вас есть джазисон документ, и вы там одну циферку поменяли, то Postgres создаст полную копию этого документа и полностью положит, типа, вот у вас было, не знаю, мегабайт данных. Postgres возьмет и сделает ещё один мегабайт данных, хотя бы вы там всего одно значение поменяли. А можно в теории сделать Toast более умным и осведомлённым о конкретном типе, и когда вы одно поле в джазисоне меняете, переиспользовать старые чанки. Вот какая-то такая идея. Это сейчас патч на ревью на Комитфесте. И второй патч также от компании Postgres Pro отправил господин Максим Орлов. Это доработанный патч Александра Короткова, который сейчас работает над ArialDB, смотри предыдущий выпуск. Патч про 6 4-битные ксиды, который нитегирует проблему Transaction Wrap Around, о которой мы уже говорили, смотри предыдущий ДФЗН. Это, насколько я понимаю, не тот патч, который Александр упоминал в своём докладе про ArialDB, но также и не конкурирующий патч. Это не так, что альтернативная идея. Это тот же патч, который Александр короткова, но доработанный другими людьми. Поэтому сообщество Postgres оно будет сходиться к какому-то консенсусу и в каком-то виде это будет смешно. Очень интересно следить за развитием самой правильной революционной СУБД. У меня всё. У нас была потрясающая тема, но я чувствую мы просто не успеем осилить, потому что она должна была быть сразу как мы будем с Нового года или перед. Но мы её уже прокрестинировали. У нас хватит на это сил? Я обещаю без GameXen на сегодня, если у нас на это хватит сил. У меня хватит. Я кофе закинулся. Окей. Для протокола у меня сейчас ночи, я чувствую, что язык заплетается, но я смогу, я буду сильным. Окей, я говорю, что я готов GameXen пожертвовать, там ничего срочного. Просто это уже нужно взять, потому что GameXen всегда можно в любой выпуск засунуть, а вот тут прямо пора бы уже заняться. И сверить Саши на предсказания на 2022 год, который он сделал в далёком 2012. Это тема, которую я совершенно... Я даже не помню, что он так делал. Я вообще не помню, что были какие-то предсказания. Это было в его блоге. Я это... эта заметка была. А, окей. Ещё до того, как мы с Сашей познакомились в лично, эта заметка была в его блоге. Да, я больше скажу, пока Валера не добавил в эту тему, в тему даже я не помнил, что я это писал. Вот, но это очень, это очень забавно, потому что я помню, как я писал комментарии к этой заметке. Мне кажется, да, и это очень-очень-очень такой странный момент, когда мы с Сашей впервые познакомились уже после того, как я читал его блог. Притом, совершенно не потому, что я его блог читал, мы совершенно случайно столкнулись, как мне помнится. Вот. И вот, Саш, как это... я искал, наверное, в записке в Сашином блоге, записке программиста ЯксМИ, наверное, я там искал что-то из старых записей ЯксКаста, и уж не знаю, какими тегами, комментами или чем меня привело вот на эту заметку, каким будет мир в 2012 году. Вот. И... Можно я сразу скажу? Я специально не готовился к этой теме, я решил, так будет веселее, поэтому рассказывай, чего я там брал. Итак, начинаем. Да, на тебя началь... на тебя начинаются статины, которые ретроэспективы, которые довольно длинные, наверное, типа, две третих статьи или половина, ну да, где-то скорее две-три статьи. Это ретроэспективы на тему того, как мир поменялся, типа, в предыдущие 10 лет. И, собственно, предсказания ты делаешь в самом конце. Итак, первое, бесспорно, нас ждут процессоры с сотнями или даже тысячами ядер. Скорее всего, преимущественно это будет с 6000-х-свехзарядными процессорами, тактовая частота процессоров не сильно возрастет в сравнении с сегодняшними 3,5 ГГц, эта цифра не менялась вот уже пять лет. Итак, что мы имеем? Тысячи ядер мы, во всяком случае, локально не имеем, имеем сотни на серверах.",
    "result": {
      "error": "API request failed: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 5441. Please try again in 10.882s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1547, in _request\n    return await self._retry_request(\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1594, in _retry_request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4.1 in organization org-xSG9D345gtYlIKC330wCyrEG on tokens per min (TPM): Limit 30000, Used 30000, Requested 5441. Please try again in 10.882s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}}\n"
    }
  }
]
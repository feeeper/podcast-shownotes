[
  {
    "segment_id": "b47c3686-e126-4e70-8717-766b37cea71b",
    "episode_id": "721d8099-0ed4-460a-976b-c8db021f63c8",
    "episode_number": 99,
    "segment_number": 8,
    "text": "В рентайне проверять? Да, да, да. Если не совпало. Ну, если не совпало, там, ругаться, например. Вот такая штука. То есть она... Подобные штуки были, в принципе, для кложи. Была самая популярная, наверное, призматик схема. Была ещё попытка запустить коррот-тайпи, по-моему, это называлось. Но это очень похоже, то есть они все очень похожи, но и в языке не очень понятно, что решение будет похоже. Ну, у ClojureSpec несколько там есть своих интересных свойств, по которым она как бы новаторская. И у неё, возможно, более радужный перспектива. Но основное, конечно, то, что она входит в язык. Она является частью ClojureCore. Она поставляется с ревизом Clojure, поэтому просто все библиотеки могут спокойно и безопасно начать её использовать и быть совместимыми друг с другом. Это, мне кажется, для подобной штуки это одна из важнейших вещей. Ну и она достаточно грамотно сделана, то есть там достаточно интересный, удобный язык, который... На котором, с одной стороны, ты можешь писать всё, что тебе нужно, а с другой стороны он тебе немножко ненавязчиво подталкивает к практикам, которые считаются более лучшими практиками программирования на Clojure. Ну и при этом он как бы учитывает то, как люди на самом деле на этом языке пишут. В общем, прикольная штука. Если пишете на Clojure, рекомендую заценить. Если честно, я понимаю систему, когда она на тестах анализирует или, скажем, как диалайзер делает, но как у тебя в рентайме обнаружил он ошибку, что ему делать? Он должен валиться или как? То есть у тебя дополнительная спецификация, что делать в случае ошибки должна быть какая-то. То есть я не очень понимаю, как в рентайме он должен решать, что он будет делать. Это на твоё усмотрение. Ну смотри, ты пишешь спецификацию, она сама по себе ничего не делает вообще. Дальше тебе нужно её включить в тех местах, которые тебе интересны, в тех ситуациях, которые тебе интересны. То есть, например, ты можешь её включить во время прогона тестов. Когда прогоняются тесты, на всех функциях во всей твоей программе включаются эти спецификации. Да, это полезно. Ты можешь включить её в рентайме, в принципе, и тогда ты будешь ругаться на неправильно пришедшие данные. Ты можешь включить, например, не падать, а логировать, например, что здесь что-то не то пришло, но я продолжу работать. То есть спецификация позволяет делать вот такой сложный выбор, да? Это да. Это такая независимый кусочек. Ты можешь это всё описать, ты можешь проверить, а когда это делать, это уже на твоё усмотрение. Понятно. И у них есть ещё классная задумка на тему того, что ты можешь это использовать для генеративных тестов или как бы property-based тестов. То есть если у тебя есть спецификация, все типы, которые используются в спецификации, они умеют работать генераторами для property-based тестов. Соответственно, если у тебя есть спецификация, ты можешь просто автоматически нагенерить данных в нужной форме и потестить. Полезная штука. Я предлагаю бомбнуть тему про property-based тесты. Правда, Валера? Ну, можно. В общем, да. Что... Как ещё можно генерировать property-based тесты? Их можно писать самому, придумывая свойства. Когда мы пишем и придумываем всякие свойства, ну, точнее, когда мы хотим писать property-based тест, часто возникает вопрос «А чёрт возьми, а какое же свойство нам придумать-то?» И тут не так давно в блоге, посвящённом F-Sharp, вышла очень интересная статья, которая непосредственно к F-Sharp в отношении не имеет. Она как раз как-то перечисляет некоторый набор техник, которые... и там, способов мышления, которые позволят прийти к правильному свойству. Так, например, можно... То есть там прям несколько таких секций с большим примером на каждый вариант. То есть, например, можно делать свойство, что у нас есть некоторая штука, и она разными путями должна прийти в один и тот же момент, в одно и то же место. То есть, например, можно таким образом проверять коммутативность чего-то, или... там, не знаю... ну, там, как это... отдавать команды вашему актеру или системе в разном порядке, и поэтому должен получиться один одинаковый результат, если там команды такие-то что-то... Коммутативность самое простое свойство, в данном случае, которое вот проинвестирует такое. Другое, прям классическое свойство, которое супер-классно подходит, например, для сериализации, это сделать, а потом разделать. То есть мы вот тут берем, пишем библиотеку сериализации, чего-то какой-то кастомный, специальный, и пишем свойство. Вот, значит, берем структуру данных, для любой структуры данных, которую можно сериализовать таким образом, мы ее сериализуем, десериализуем, и должны получить такую же структуру. Просто на ура работает. Главное свойство, такое пишется очень быстро. Еще можно проверять, например, иммутабельность чего-то. То есть если у нас трансформация и депатентная, то можно проверять и депатентность. А, ну да, можно еще проверять, что оно совсем иммутабельное. То есть, что у нас ничего не поменялось случайно где-то. Вообще, в целом, статья мне очень понравилась. Я в первую статью говорю в основном про этот F-Sharp. То, что у нас автор описал сперва правила, потом дал краткие примеры этих правил, а потом полное обоснование, чем вот это правило хорошо, как его надо сделать, какие могут быть ошибки здесь и так далее. Прям вообще полноценное введение в подобный тест. Я всем однозначно рекомендую, там, конечно, F-Sharp придется продираться в F-Sharp, хотя это не мой родной язык, я в принципе смог его прочитать. Я, наверное, не буду дальше перечитать все эти возможные подходы, но это очень интересно. И там, в частности, там реально разобраны все вот такие классические подходы к тому, как строить спортбейст-тесты от краткого введения до примеров с использованием. Как понятно, подчеркнулся даже с некоторыми разработками некоторых ошибок. То есть, в частности, я одно из концепций разберу. То есть, он опускается до деталей для того, чтобы человек понимал вообще, зачем это делается. В частности, он говорит, ну, к примеру, у нас есть какая-то ошибка, но это же ошибка очевидная, и вы всегда заметите ее в других тестировках, не обязательно проверять ее именно здесь, в Property Based. Но в дальнейшем он сам дает ответ, что когда вы формируете вот этот Property Based, вы говорите, какие гарантии дает ваш алгоритм, ваши структуры данных или что угодно вы там делаете, и эти гарантии вы должны проверять. То есть, вы одновременно создаете более мощную концепцию ваших алгоритмов и того, что вы создаете. Это немножко заставляет повернуть голову, но зато вы более высокоуровневое понимание получаете в ваших системах. Ну и вот подобных советов там прям дополно. Очень здорово написано. На самом деле я все-таки не считаю, что Property Based тест нужно, но на это нужно принимать в любом удобном случае. Очень классно писать, когда множество возможностей, состояние очень большое, при этом действий, которые может субъект совершать, не так много. То есть, классический пример, сериализация, децерализация. Там всевозможные состояния, это фигище, а вот как это... API из двух функций при этом. Или, например, какой-нибудь координатор запросов. То есть, там вообще ровно одно действие, оно координирует запрос, не знаю, селектор таким-то этим. Но при этом у селектора может быть куча параметров, и там может случиться куча всякого разного с сетью. Вот, оно при этом должно работать. Вот такие вещи, они очень здорово Property Based тестами проверяются. Если вы совсем еще Property Based тесты в жизни не писали и все еще задаете вопрос, начиная с того, вам это нужно, есть вторая статья, такая больше... более введение в это все от небезызвестного Фреда, который автор Learnings of Merlang. Она скорее просто вот про... Как раз то, что я сейчас говорил. Мягкое введение. Когда их удобно пользовать, вот как раз с примером одной FSM-ки и одной такой вот небольшой программки еще. И если вы совсем не знакомы, можете начать с нее. Вот. Я все про Property Based тесты. Света. Спасибо, Валера. Да, я продолжу тему тестирования. Буквально несколько недель назад мне посчастливилось встретиться с человеком, который является PhD-студентом и работает над фреймворком для символик тестирования. Вот вы знаете, что такое символик тестирования? Нет. Вот. Честно говоря, я тоже до этого не слышала что-то такое. Он рассказал, то есть, вот как это работает. Вот смотрите. У нас есть код. И в этом коде у нас есть какая-то логика. Как правило, всякая логика нам и описывается каким-то разветвлением, там if else. И он говорит, для того, чтобы тестировать этот код, мы, как правило, пишем какие-то тест-кейсы, глядя на какие-то спецификации. Потом мы эти тест-кейсы имплементируем и запускаем. Вот. А что если нам... Мы, в принципе, глядя на этот код, и в частности на его представление в виде байт-кода, можно понять, где эти разветвления есть. Анализируя вот байт-код, можно генерировать тест-кейс автоматически. И таким образом смотреть, как у вас код будет работать на действительно всех возможных случаях. Не брать просто рандомные элементы из множества, а действительно проверять на пограничных случаях. И это то, что они делают. Вот это называется символик тестирования. И они пишут Open Source Tool, который называется KLEE. Я в итоге погуглила, оказывается, есть и для Java, и для других языков программирования похожие инструменты. Так вот, KLEE, по сути, анализирует представление байт-кода для LLVM и генерирует все возможные кейсы и просто прогоняет вашу... код вашей программы на этом движке. Таким образом, они уже прогнали несколько Command Line утилит, такие, которыми мы пользуемся как правило в повседневной жизни в Linux. И они нашли порядка 20 кейсов, когда просто эти программы крашились. Они это все засубмитили в виде багов. Конечно, такие случаи очень редкие, и, как правило, люди такие инпуты не подают для этих утилит. Но сам факт того, что технология работает, это довольно интересно. Основная проблема, которая заключается в этой технологии, это рост, экспоненциальный рост количества кейсов, потому что оно все постоянно раздваивается, и там, может быть, расстраивается. И мы получаем огромное количество вариантов прохода программы. И им нужно это все проверять. И это то, чем он занимается в своей диссертации. Знаешь, что меня напомнило? Я помню, когда еще в бытность Якскаста у нас в гостях был Илья Ключников, который занимается суперкомпиляцией. У нас как раз вставал такой, я помню, вопрос о том, а можно ли суперкомпиляцию применить для тестирования? И ответ, что скорее всего, да. И то, что ты говоришь, что оно ведь и получилось. Это, по сути, тесты, основанные на суперкомпиляции. То есть, когда мы знаем, как у нас устроен код, и генерируем тест на основе того, что как код мог бы работать. Мне кажется, вообще нет. Извини, конечно. Если я правильно помню, что такое суперкомпиляция. Ну, суперкомпиляция, это когда мы берем и программу исполняем в символическом виде на любых входных данных и знаем, например, что у нас здесь всегда витвица или всегда не витвица, или что здесь надо будет себя вести так-то или так-то. Строим, в общем-то, такой граф программы. То есть суперкомпилятор в итоге может построить такой, более-менее, граф программы для большинства случаев, и потом ты, собственно, на узлах этого графа можешь смотреть тесты. Точно так же здесь получается, что они смотрят на lwm bytecode, смотрят, где у них там бранчи, и как по этим бранчам можно пройти, в каких случаях по этим бранчам пойдет, и как раз перебирают пространство состояния. Как раз, мне кажется, похожий подход в этом плане. Да, да, да, да, да, да, да, согласен. Вот, но штука довольно интересная. Есть docker-container, docker-image, если кому-то интересно с этим поиграться. Ссылки будут в шоу-нотах. Звучит очень, скажем, не знаю, как это на русском сказать, но многообещающее. Дальше и дальше тема про Haskell. Саше нету, нашего главного Haskell-иста. Если кому-то хочется рассказать про Haskell, то пожалуйста. Эта тема касается двух проектов разных. Первый это написанный, написан еще один язык на виртуальной машине Erlang, который был как это... Создан на основе ML'я, или глядя на концепции в ML'е. ML-flavored Erlang, ML-FE. Вот. В нем автор пишет, что он начал ее писать в начале 2016 года, то есть полгода всего языку. Сейчас вышла версия 0.1 с лицензия patch. И почему он решил это делать, это из-за того, что ему очень нравится виртуальная машина, но ему не хватает возможности языка. Ну, логичная такая отговорка. Я думаю, ему было просто еще интересно дополнительно. И список литературы, в котором он пишет что он советует почитать, и на основе чего он что-то делает. Пока Erlang что-то говорит, что получится или не получится, версия 0.1 будет еще полгода, и там будет куча еще ошибок выгребаться, но в целом я считаю, что виртуальная машина Erlang довольно такая большая система и большая вещь, на основе которой можно делать много разных интересных продуктов.",
    "result": {
      "query": "property based testing techniques"
    }
  }
]
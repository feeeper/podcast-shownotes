[
  {
    "segment_id": "9f9edb72-3e0e-4364-b098-e823c5dd52a7",
    "episode_id": "48cbb983-f314-42da-8b2d-7b9865f5c099",
    "episode_number": 206,
    "segment_number": 3,
    "text": "Так и подсчет каких-то важных денежных метрик или каких-то подсказок для пользователя в реальном времени. То есть, если он что-то искал пять минут назад, то хочется, чтобы, то, наверное, он будет искать что-то сравнимое дальше, поэтому хочется именно использовать эту предыдущую информацию, для этого, соответственно, необходимо обрабатывать, что же он, как же он себя ввел. Вот. И для этого существуют разные фреймворки, которые обрабатывают данные. Значит, существует несколько подходов. Самый простой, это не более одного раза, то есть, когда мы берем из входного потока и рассчитываем данные и записываем в выходной поток. При этом, если мы упали, мы просто продолжаем с какой-то предыдущей позиции и не перепосылаем эти данные. То есть, они просто теряются. Это называется at most once. Отлично простой подход, но этот подход теряет данные. Есть подход at least once, когда мы пытаемся перепослать, и когда-то принимающая сторона в выходном потоке сказала какие-то, мы принимаемся за следующие, до тех пор мы пытаемся послать одно и то же. И в случае падения мы тоже пытаемся обработать тот же самый кусок еще раз до падения. Понятно, что эти два способа приводят либо к дупликатам, либо к потерям данным. И часто, особенно если дело касается денег, хочется все-таки чтобы была обработка ровно один раз или execute once по-английски. И в таком случае предлагаются достаточно сложные подходы, как правило они включают в себя транзакционное поведение, двухразный коммит, вот это все. На самом деле это тяжеловесное поведение. Соответственно, в чем тут суть? И что нам авторы статьи, которые говорят, что на самом деле execute once не существует и прочее, они говорят следующее, что вот мы начали обрабатывать какие-то данные. Мы начали обрабатывать, начали изменять наше состояние, не успели например записать выходной поток и упали. Для того, чтобы execute once гарантию нам сохранить, для этого нам необходимо заново вычислить то же самое значение, то есть заново вычислить то же самое данные из потока и обработать опять. Получается, что мы данные и вычисления над одними и теми же данными выполняем несколько раз. И они говорят, ну вот смотрите, мы же выполняем несколько раз, это не execute once, execute once говорит, что мы с данными работаем только один раз и поэтому они переобозвали это effectively once. На что я замечаю следующее, что во-первых, никто никогда не гарантирует, что физически будет исполняться процедура ровно один раз. И более того, этого не нужно. Потому что процессор, например, если мы возьмем цикл, который выполняется 10 раз, что в процессоре происходит? То есть он натренировался, понимает, что после 8 и 9 раза и на 10 разе, скорее всего, он пойдет опять выполнять тело цикла в 11 раз. Предсказатель переходов кидает начало цикла, начинает исполняться код, а потом оказывается, что срабатывают условия и мы эти действия откатываем. Получается, что вместо 10 раз мы выполняем 11 раз, то есть никакой это не execute once. Получается такая абсурдная ситуация. Отсюда мы приходим к простому выводу, что на самом деле нам не важно сколько раз физически, то есть реально, исполнилось наше действие. Важно то, как мы видим ситуацию снаружи, то есть как если бы она выполнялась. То есть можем ли мы увидеть, что выполнялось несколько раз или нет, или не может. Я бы перефразировал это с точки зрения результатов. То есть какие мы получаем результаты, как будто бы мы выполнялись 10 раз или 11? Именно так. Нам важен конечный результат. То есть если конечный результат такой, как если бы, исполнялось ровно один раз, значит мы свою задачу выполнили. Соответственно, когда у нас процессор не сбоит, то есть не может упасть и прочее, то execute once достигается достаточно просто. Вся мякотка и вся сложность в этом месте именно то, как гарантировать то, что у нас в случае падения, то есть вот мы начали выполнять действие, выполнили действие, теперь начинаем записывать выходные потоки. В один записал поток, в один поток мы записали, а в другой не успели, мы упали. Получается какое-то промежуточное состояние, неконсистентное. Exactly once гарантия как раз и говорит о том, что все, ребята, будет нормально, либо запишется везде одинаково, считается, из входных потоков запишется выходные, и правильно состояние поменяется. Либо ничего такого не произойдет, и мы просто повторим эту операцию. То есть exactly once, оно говорит о том, что система должна быть транзакционна. Это, кстати, я уже перехожу плавно ко второй, к следующей части. Подытожив, что я хочу сказать, что автор просто вместо того, чтобы реально дать определение exactly once, такое, что мы получаем результат, как если бы система вела себя один раз, он считает количество физических исполнений, что, на мой взгляд, не является верным. Вот, таким образом... Извините, перебью, возможно, мы одно и то же хотим вставить, что это может играть значение, если речь идет о чем-то вроде отправки смс-ок. Если речь идет об отправке смс-ок, нужно делать. .. Это, кстати, очень хороший вопрос, как раз его можно затронуть в следующей теме, потому что мы приходим к тому, что у нас вообще говоря выходные потоки могут быть гетерогенными. То есть, вообще, АПАЧ-КАВКА и другие способы обработки данных в реальном времени подразумевают, что у нас потоки входные и выходные являются частью одной и той же системы. Если же входные и выходные потоки являются частями разной системы, если состояние у нас тоже куда-то в другое место пишется, тогда в таком случае мы говорим о гетерогенности такой задачи. И, насколько я знаю, таких систем пока не существует. А нельзя эту задачу разбить просто на две? То есть делать гомогенную одну, которая... Выходной поток типа послать смс-ку, то есть на выходе будет не смс-ка, а сигнала посылания смс-ки, а следующая система, соответственно, уже получает сигнал и посылает. Да, именно так и надо делать. То есть мы при обработке понимаем, то есть обработчик понимает, ага, надо послать смс-ку. Соответственно, что он делает? Он посылает в определенную выходную очередь сигнал о том, что да, надо послать смс-ку. Но потом другой обработчик должен зачитать из этой очереди и послать смс-ку. И там, соответственно, в зависимости от того, как устроен API посылания смс-ки, если он устроен правильно, то тогда можно и там гарантировать exactly once. Могу я немного добавить? Выше было сказано, что exactly once он говорит, что система должна быть транзакционной, я не полностью с этим согласен, то есть это возможная реализация, но не обязательно единственная, и как контрпример я могу привести, что если выполняются идемпатентные операции, то можно получить exactly once без транзакций. Да, все верно ты говоришь, то есть если мы делаем идемпатентные операции и при этом делаем at least once, то мы таким образом суммарно получаем гарантию exactly once. При этом транзакционности тут нет. Но на самом деле в каком-то смысле она есть, потому что создать идемпатентность операции это значит, что нам надо где-то хранить, что мы это уже делали, то есть не все операции можно сделать идемпатентными, вообще говоря. Да, согласен, это очень сильно зависит от решаемой задачи и предметной области, то есть это не для всех случаев. Но хочется сделать такой подход в реальности, чтобы было как можно для более широкого класса задач это подходило, то есть не задумываться о том идемпатентно ли операция, просто сделать алгоритм, который бы брал на входе какие-то значения, обработал их, выдавал на выход и дальше происходила какая-то магия, транзакционно ли, нетранзакционно, но результат был такой, как если бы это было обработано один раз, то есть сохранять гарантию exactly once. Вот, понятно, что когда я имею ввиду транзакционную, я имею ввиду, что используя транзакции, то есть когда мы транзакционно меняем позицию входного потока, меняем значение выходных и меняем состояние нашего обработчика и делаем это транзакционным образом, тогда понятно, что гарантию exactly once в этом случае можно добиться. Но действительно, если мы используем транзакцию, то есть либо она полностью применилась, а все действия и все побочные эффекты ее откатились, то есть транзакция подразумевает атомарное поведение. И оказывается, можно использовать не только транзакции для описания и для реализации этой идеи, но и использовать более хитрые способы. Вообще говоря, тут я уже перехожу к своей статье, тут я предлагаю подход следующий. Помимо того, что этот подход может использоваться при использовании гетерогенных хранилищ, то есть разнородных хранилищ, также есть одно интересное свойство, на котором я бы хотел остановиться более подробно. Это свойство называется concurrent exactly once, то есть конкурентная обработка ровно один раз. Что это означает? Тут главное не путать со словом параллельно, потому что параллельно означает мы все современные фреймворки допускаем параллельное исполнение. То есть мы просто берем очереди, шардируем и каждый шард обрабатываем отдельно и параллельно. Соответственно тут простая параллелизация и простая масштабируемость. В случае конкурентной, когда я говорю, что обработчик конкурентный, это значит, что он зачитывает один и тот же поток и существует как минимум два обработчика, которые зачитывают данные из одного и того же потока и делают одно и то же действие. У них находится одно и то же состояние. В чем идея конкурентного? В принципе понятно, что они будут друг другу мешать. Если один из них запроцессил данные, закоммитил, то другой получается сделал лишнюю работу. Это действительно так. Но при этом, если какой-либо один из потоков, например, упал, то другой обработчик просто берет, коммитит и мы, соответственно, не теряем времени. Никакого. Также, если один из обработчиков мог затупить по какой-либо причине, не знаю, там диск стал хуже работать, сеть стала хуже, габарит коллектор заработал. У нас существуют ситуации, когда обработчик может в какой-то момент затупить. В этом случае другой обработчик, который работает параллельно с ним, он просто сделает свою работу. Соответственно, получаем гарантию, что у нас не только получается обработка без падений, как если бы не было падений, но и вдобавок к этому, если бы не было обработчики, связанными с какими-нибудь физическими процессами, происходящими в ЗУНе. Это более сильная гарантия. И, например, опачкавка, опять же, если мы о нем говорим, как типичный пример реалтайм процессинга в реальном времени, он предоставляет гарантию экзактливаций, но при этом код написан так, что нельзя запустить параллельно два падока. Конечно, можно запустить, но они будут мешать друг другу, и в результате система будет только замедляться, вместо того, чтобы делать прогресс в системе. Почему такое будет происходить? Потому что есть поколение, то есть каждый новый обработчик он регистрируется, должен зарегистрироваться в системе, и он получает большее поколение, и, соответственно, именно он будет главным по записи данных. Соответственно, нельзя одновременно зарегистрировать два обработчика с одним и тем же поколением. Поэтому существующие системы просто не обладают такой возможностью. Возникает вопрос сразу, ну окей, у нас есть такие гарантии, как их реализовать? В чем идея? Идея в том, чтобы это транзакционное поведение разбить на, я их называю полутранзакции. Что я имею ввиду? Что есть очень хороший пример, на котором можно продемонстрировать, как же разбить транзакции на полутранзакции. Например, мы переводим деньги с одного счета на другой. Как бы транзакция выглядела? Мы, соответственно, блокируем записи на первом счете, блокируем записи на втором счете. Здесь я говорю про пессимистичные транзакции, пессимистичные блокировки, так как это наиболее простой сценарий. То есть мы вначале блокируем записи, потом уменьшаем деньги с одной записи, параллельно проверяя, что действительно денег у нас в счете достаточно, чтобы снять нужное количество. И затем это количество мы добавляем к другому счету и транзакцию эту коммитию. И у нас все прекрасно. Но, в принципе, можно то же самое действие сделать другим способом. Можно взять, атомарно изменить, уменьшить значение с первого счета, в то же время проверяя, что действительно на балансе есть нужное количество. Как только мы уменьшили, дальше нам необходимо доделать вторую часть полутранзакции, точнее вторую часть транзакции, то есть перевести деньги на другой счет, добавив. Мне это чем-то сагой напоминает, извини, тебе, Ребенок, чем-то сагой напоминает. Может сразу как-то пока рассказываешь, проведешь параллели? Это что такое? Просто не слышал. Есть такой подход саги. Такая штука, часто сделают транзакции между микросервисами, которые не транзакционны. Там очень похож поход с разбитием на такие откатываемые шаги. Возможно, надо почитать. Я, кстати, не читал. Первый раз от тебя услышал. Соответственно, идея такая, а теперь возникает вопрос, а как такую идею применять к нашей обработке ровно один раз? И тут, так как хранилища у нас вообще говоря могут быть любыми, возникает вопрос, какой примитив использовать для того, чтобы работать с различными хранилищами? Понятно, что такие хранилища должны быть консистентными, то есть предоставлять достаточно высокий уровень консистентности. И оказываться таким минимально необходимым элементом может являться операция CAS. То есть это из лог-фри мира многопоточного программирования. Это compare and swap. То есть что мы делаем? Мы сначала зачитываем значение из нашего хранилища, проверяем его все ли правильно, все ли инварианты соблюдаются, которые мы хотим выполнить. Далее мы записываем значение новое по этой же ячейке данных и проверяем, что это значение не было изменено между нашими чтениями и записями. Таким образом мы гарантируем, что именно мы обновили это значение. Это и такое поведение нам будет давать как раз поведение для полутранзакции. И чтобы продемонстрировать, как это можно использовать, вот есть простой пример. Самая простейшая задача для real-time execute-once обработки это тождественный мэппинг. То есть я зачитываю данные из ходной очереди и те же самые данные я записываю в выходную очередь. Как для этого необходимо поступать? Состояние у нас у обработчика есть. Это позиция выходного потока. Что мы делаем? Первое, что мы делаем это зачитывать значение из входного потока. Дальше нам необходимо записать значение в выходной поток. Для этого мы первое, что делаем смотрим в выходном потоке какой индекс есть для записи. То есть самый последний, который доступен для записи. И этот индекс мы запоминаем в наше состояние. В состояние нашего обработчика. После того, как мы записали, дальше мы делаем запись по этому индексу. И проверяем. И во время записи мы как раз делаем каст операцию и проверяем не записали ли в эту ячейку кто-то другой. Если записали, мы тогда просто заново считываем индекс, записываем ее в наше состояние и повторяем просто до этого момента. Если там не было записи, соответственно мы туда записываем. Следующий момент, что мы делаем мы обновляем в наше состояние, что мы это данное записали. Если же при этом произошло падение, то так как у нас записан индекс, по которому мы хотели бы записать, то мы можем легко при восстановлении проверить а записано ли по этому индексу какое-то значение. Если записано не мы ли его записали. Потому что мы знаем, какое значение мы туда записываем. Если оно то, что мы записали, значит мы записали. Все, отлично, нам ничего не надо делать, мы это можем зафиксировать в нашем состоянии. И таким образом мы можем обрабатывать все элементы из нашей очереди. В случае же если у нас есть какое-то состояние, если нам надо писать не в одну очередь, в выходную, а в несколькие очереди. Для этого мы что делаем? Во-первых, мы обработчики запоминаем то есть обработчик считывает из выходных значений, из выходных потоков, делает обработку и записывает у себя локально, что бы он хотел записать в выходные очереди. Просто записываем такой слепок внутри себя. А дальше мы переходим к состоянию публикации этих записей. Берем первый выходной поток, делаем то же самое, что делали для мэппинга. То есть просто перекидываем значения с сохранением индекса предварительного и так проходим по всем значениям, которые нам необходимо записать. После того, как мы прошли по всем таким выходным значениям, мы фиксируем, что мы все закончили, и можно приступать к следующей записи. Таким образом мы приходим, что вот мы нашу транзакцию, которая должна была по идее фиксировать и изменение позиции входных потоков, изменение значений выходных потоков, изменение состояния, мы разбили на несколько подтранзакций. Первое это изменение внутреннего состояния и дальше изменение публикуемых значений в выходные очереди. Причем мы каждое значение для выходной очереди делаем отдельно, то есть их можно распараллелить для данного обработчика. И приходим к тому, что мы на основе нашей единственной операции можем выполнить вот такую сложную машинерию по выполнению гарантии экзакливанса. Если нам необходимо записать какие-то данные в другое хранилище, например, как в статье приведено, что необходимо обновить каунтер в базе данных. То есть можно просто записать event о том, что необходимо обновить каунтер в очередь, а потом просто из этой выходной очереди зачитывать значения и в базе данных делать транзакцию о том, об изменении состояния этой очереди и об изменении каунтера. Таким образом мы приходим к тому, что на всей цепочке у нас происходит экзакливанс по виде. Я несколько вопросов можно задам? Мне кажется, что здесь у системы все равно получается довольно много ограничений. Ну то есть, к примеру, вот вопрос с мэпом. Ты же, насколько я понимаю, ты предполагаешь, что у нас может быть не один обработчик, а любое количество обработчиков, и они все равно все вместе сделают экзакливанс, верно? Абсолютно. Получается, что у нас должно быть обязательное требование к системе детерминированность. То есть любой обработчик делает этот мэп, и у нас получается один и тот же результат в итоге. А иначе мы можем столкнуться с кучей всяких сайд-эффектов. Хороший вопрос. На самом деле как раз статья об этом заостряется, что этот подход применим в том числе для недетерминированного поведения. Это достигается за счет того, что изменение состояния внутреннего также происходит через CAS. То есть мы перед тем, как обрабатывать, мы зачитываем версию текущего состояния нашего обработчика. И дальше, когда мы получили входное значение, обработали, получили выходное значение, вот это состояние комплексное пытаемся обновить. И мы предполагаем, что версия должна быть та, которую мы зачитали в самом начале. Если она не та, значит кто-то другой уже поработал и нам просто необходимо подтянуть свежее состояние. Если же никто в этот момент не работал или не успел обновить, мы, значит, записали, мы первые, все отлично. При этом не важно, детерминированны или недетерминированны, мы проверяем, что именно мы были теми, кто изменил состояние на один шаг, грубо говоря. И в этом как раз нам CAS тоже помогает. Просто, насколько я помню, у CAS у самого есть ограничения, то есть не любой регистр можно сделать CAS, обновлять CAS, особенно в конкурентной системе. В CAS есть некоторые особенности, когда мы говорим о многопоточных алгоритмах. Если мы уже говорим о распределенных системах, то там, как правило, для CAS существует версионирование. То есть есть не только само значение, которое мы проверяем, но и версия этого значения. То есть, когда мы зачитываем какой-то элемент, мы не только, нам хранилище должно вернуть не только сам элемент, но еще и версию для этого элемента. И, соответственно, если у нас значение будет одно и то же, но версия другая, мы это поймем, что значит, что-то все-таки изменил. И версия каждый раз увеличивается на единицу при изменении. Например, в ETCD, консистентное хранилище, но не транзакционное, оно именно позволяет реализовать такую операцию CAS. Потому что на самом деле можно легко показать, что без версионирования возможны всякие спецэффекты. Поэтому если распределенное хранилище не обладает возможностью поверсионировать, то с консистентностью у нее могут быть проблемы. Лучше таких, конечно, избегать хранилищ. Я бы иначе сказал, если нет версии, то любая реализация поверх будет попросту некорректной. Кто заинтересованных слушателей, могут погуглить ABBA и подобные эффекты. Да, это именно ABBA-проблема, которая достаточно тяжело решается в многопоточном программировании, потому что очень легко на нее наткнуться и очень тяжело его фиксить, потому что в регистрах нет атомарных переменных, нет тегов, нет версий. Есть такой финт, кстати, у 64-битных регистров. Дело в том, что там используется только 48 бит, и другие биты не используются. Их можно использовать как раз для того счетчика, для версии. И еще 3 бита младших, потому что поинтеры, как правило, выравнены определенным образом. Их тоже можно использовать для этого счетчика. И таким образом, в каком-то смысле, решить эту проблему ABBA, о которой мы говорили. Есть интересный подход, почему-то малоизвестный. Альтернатива CAS называется LL slash SC, то есть LoadLinkStoreConditional. И интересный факт про архитектуру RISC-V, которую мы несколько раз упоминали в этом подкасте, что на ней нет CAS, но на ней есть LL SC, который как раз не допускает проблем ABBA и подобного. Вот кому интересно, я приложу ссылку в шоу-ноут. Да, прикол в чем, что почему не используется подход LL SC, да? LoadLinkStoreConditional. В чем вообще идея? Давайте коротко объясню. Значит, мы берем страницу памяти и читаем из нее какие-то ячейки. Читаем, а потом хотим что-то обновить. И у этой страницы памяти, оказывается, есть определенный счетчик. Если запись произошла, то счетчик просто увеличивается. И когда мы выполняем StoreConditional, мы можем посмотреть, а изменился ли счетчик? Изменился ли этот счетчик до нас? Если изменил, значит мы просто не применим эту операцию. И оказывается, что вот такая штука, она обеспечивает некоторое более общее транзакционное поведение на странице. То есть получается, что CAS можно выразить через LL SC, но обратно неверно. То есть через CAS очень сложно или практически невозможно эффективно, так же эффективно реализовать такое поведение. В этом смысле она более мощная, более общая. Так как распространенность процессоров x86 гораздо больше, чем таких процессоров, то как правило все живут с предположением, что CAS есть, а всего остального нет. Потому что одно через другое выражается. Поэтому имеем то, что имеем. Но стоит отметить также, что современная распределенная система, им ничего не стоит реализовать аналог LL SC. При этом вместо страницы памяти, которая 64 байта, может выступать один шарт. То есть, если возьмем, не шарт, а микро шарт. То есть микро шарт это то, что выполняется на одной ноде в одном потоке. В этом смысле хранилище распределенным не стоит, скажем так, с точки зрения корректности, консистентности и алгоритмичности именно взять версию для целикова шарта и проверить изменилось ли набор ячеек, которые были прочитаны. То есть, не нужно придумать какие-то новые сложные алгоритмы. Все это можно реализовать на существующих системах. Поэтому в этом смысле можно гораздо более эффективно реализовать поведение экзаклюанс. Но я взял самый минимальный уровень, когда у нас есть CAS и ничего больше. И оказывается, что даже с использованием такого достаточно простого примитива, можно реализовать такую сложную транзакционную модель обработки в реальном времени. Спасибо за хорошее объяснение. Хотя теоретически надо картинок и рисовать на доске, но с этими словами достаточно понятно пояснить. И еще лучше статью написать. Если вы хотите детали, есть статья, там есть картинки. И действительно, если бы я это рисовал на доске, все бы было гораздо более понятно. Но надеюсь, что статья, там очень подробно все расписано. Если будут какие-то вопросы, легко читаете и все проясняете для себя. Отлично. Вопросы? Вопросов нет. Тогда переходим к еще одной интересной, но многословной теме. Это надспектр. Кто-нибудь, кроме меня, читал этот пейпер? Я не читал пейпер, я читал краткую выдержку в виде новостей. Ага. Так можно было, черт. А ты прям хочешь пейпер обсудить? Прям подробно? Ну, я хотел вообще рассказать его. Давайте сначала вкратце. Что это такое? Надспектр это удаленная така на чтение произвольной памяти, не требующая запуска локального кода, работающая по сети, работающая по сети как в локальной сети рядом с десктопом каким-нибудь, так и в каком-нибудь клауде. И разработчики смогли сделать утаскивание 6 бит в час с соседней машины. Можно сразу вопрос? Как человека, который читал только выдержку, это специфичная проблема для x86 процессоров, амида 64, или она более широко? Типа для всех архитектур. Да, они 60 бит в час смогли добиться на процессорах, где есть AVX2 расширение, а так они работают через кэш со скоростью 15 бит в час вообще на любой архитектуре. Давай так, на любой созвездочке архитектуры. То есть идея в том, что ты должен четко понимать, что на архитектуре делается, и искать куски кода, работающие на машине, которые ты сможешь использовать для этой уязвимости. Netspectre использует идею, что лейтенсы чтения из памяти влияет на лейтенсы любого сетевого запроса, или лейтенсы не только чтения из памяти, как я уже говорил, выполнения каких-то инструкций, в частности вот этого AVX2. Вот. И из-за того, что все это делается по сети, у тебя нет возможности, как с оригинальным спектром запускать все локально и измерять сюда на секунд время исполнения команд, поэтому ты должен усреднять по большому количеству запросов, но при большом... при долгом времени у тебя есть это количество запросов, и они говорят, что 100 тысяч запросов для того, чтобы вытащить один бит, вполне достаточно для того, чтобы вытащить любой бит. Вот. И вот на этом все основано. Вот я вкратце рассказал. Пойдем глубже. Кто-нибудь хочет? Давай. Но у нас слушатели жалуются, что им мало хардкорных. Не хватает, да. Вот. Для того, чтобы объяснить NETспектр, надо сначала немножко объяснить спектр. Итак, есть в современной вычислительной технике такая вещь, как последовательное и непоследовательное исполнение команд. Последовательное – это понятно. Вы написали программу, вы ожидаете, что она будет исполняться шаг за шагом. На самом деле все не так, она выполняется непоследовательно. В частности, используется спекулятивное исполнение, и когда у вас пайплайн вашего процессора заполняется, происходит какой-нибудь неправильный переход, неправильное предсказание перехода, или еще что-нибудь такое, все выполненные куски кода, которые шли не по тому бранчу, грубо говоря, ну, возьмем на примере предсказателя перехода, хотя спекулятивное вычисление, они намного шире используются, отбрасывается, и все состояния, которые были вычислены, все полностью зануляется, превращается в предыдущий вид, и начинается исполнение дальше. Теоретически вы не можете вытащить из этого состояния, из того, что оно уже посчитало, ничего, потому что в процессоре все четко продумано и просчитано, чтобы вы это не могли сделать. Как я уже говорил, предсказание переходов это один из примеров, но он наиболее часто используется, потому что, во-первых, его легко использовать, легко сделать, и, во-вторых, его легко понять. Для того, чтобы еще опуститься и понять, надо понять, что такое side-channel атака. Side-channel атака – это атака, которая основана на дополнительном знании о строении компьютерной системы, а не на основе знаний о том, как написана ваша программа. К примеру, время выполнения команд, как работает кэш-система, как потребляется энергия, электромагнитное излучение, даже звуки вентилятора используются как side-channel для того, чтобы атаковать вашу систему. Атаки на кэш – одни из самых частых атак – это они используют разницу во времени холодного и горячего считывания кэша, и вот Spectre в том числе использовал эту возможность. Что такое Spectre? Это side-channel атака, который использует спекулятивное исполнение и тайминги доступа к кэшу. Спектр не будет работать, если мы перейдем к последовательному исполнению всех команд, как мы пишем нашу программу. И что самое интересное, в пейпере есть пояснение, я не видел подобного объявления от Intel, но они приводят ссылку. Spectre 1 не будет пофикшен в ближайших поколениях CPU, и поэтому они, как и наверняка большинство других исследователей, используют именно Spectre 1 в данных исследованиях. То есть Meltdown и Spectre 2 будут пофикшены, это уже пообещали. Итак, что такое Spectre, как вообще устроена эта атака? Они сделали очень хитро. Разработчики сказали, что в отличие от Spectre, где все исполняется локально, где у вас есть полный, ну, теоретически полный доступ к компьютеру, вы можете запускать что хотите, здесь вы не можете запускать что хотите, мы работаем через сеть удаленно. И поэтому мы должны разбить нашу атаку на две части. Точнее, они говорят это в терминах гаджета. То есть на Spectre гаджеты, это два типа гаджетов. Первый гаджет — это leak от слова «утечка». И второй — это transmit гаджет, который передачу делает вот этого утекшего бита. Итак, leak gadget, что это такое? Это чтение... leak gadget просто читает битовый поток по индексу, который контролирует атакующий. То есть вы посылаете пакет, в этом пакете есть какой-то индекс, и leak gadget должен попытаться прочитать по этому индексу спекулятивно. Можно чуть-чуть дополнить. Тут был такой неплавный переход, то есть гаджет — это на самом деле кусок кода на стороне атакуемой системы. И предполагается, что я, например, знаю, что там линк с такой-то версией, и поэтому у него там по таким-то адресам вот такие-то куски кода. Вот этот читает, а вот этот передает что-то в сеть в ответ на запросы. То есть гаджеты — это куски кода на системе. Да, спасибо. Более того, как говорят сами разработчики, у нас была цель, чтобы... то есть они генерализируют эту идею. Это может быть необязательно Linux, это может быть необязательно ядро, это может быть какая-то программа, это может быть что угодно. Поэтому они сперва говорят это все в общем смысле, что такое leak gadget. Но это на самом деле кусок кода, который каким-то образом получает сетевой поток и пытается его парсить, обработать и так далее. Вот. transmit gadget — это тоже какой-то кусок кода, который тоже работает на атакуемой системе. Вот. Итак, leak gadget, он читает битовый поток, который составил в том числе атакующий, и в какой-то момент времени он выполняет какую-то операцию по чтению по индексу, который передал атакуемый... а, атакующий, прошу прощения. Вот. Соответственно, в этот момент мы можем читать уже в спекулятивном режиме, и если мы выходим за рамки, то вот этот результат чтения, он в дальнейшем отбрасывается, потому что мы выходим за рамки того пространства, где нам разрешено чтение. Вот. И в этот момент происходит изменение вот этого микроархитектурного состояния, как они это называют, то есть для того, чтобы потом по сайт-ченнелу каким-то... по каким-то дополнительным каналам вытаскивать данную информацию. Вот. Они это называют микроархитектурное состояние. Итак, задача лик-гаджета — это взвести флаг бита для микроархитектурного состояния. А transmit-гаджет — это другой кусок кода, который следит за этим микроархитектурным состоянием и вытаскивает его из системы и уже передает обратно атакующему. Вот эти две части системы, одна фактически считывает из памяти, а вторая посылает, они как раз ее разбивают на две части. Это очень интересное новшество вот этой статьи, я с таким раньше не сталкивался. Вот. При этом получается так, что, к примеру, вот мы прочитали в каком-то куске памяти и записываем там, флаг равняется true, если этот бит взведен, а если бит не взведен, то записываем там, ничего не записываем фактически. И получается, что transmit-гаджет, он может посылать, без разницы что, он может посылать сам вот этот флаг взведенный. На самом деле, важно не то, не та информация, которую он посылает, а нам важно, было ли закешировано это значение или не было. И именно измеряя время по отсылке вот этого, возможно, закешированного значения, мы получаем, взведен был флаг или не взведен. Вот. При этом, здесь как бы понятно, я на пальцах объясняю, хотя там куски кода и графики, и получается там намного удобнее в папере читать. Или надо как-то еще прояснить? Давай ты мне скажи. Я думаю, ты нормально рассказываешь. Продолжай. Окей. Итак, получается, что и leak и transmit-гаджеты, они могут работать, они должны работать на атакуемой системе, но не обязательно должны сидеть на одном даже интерфейсе. Они могут сидеть на разных интерфейсах, но главное, что тот, кто атакует, он имеет доступ к обоим. При этом эти гаджеты могут работать в разных спейсах. Кто-то может работать в юзерспейсе, кто-то может работать в кернелспейсе, и, соответственно, скажем, если leak-гаджет работает в кернелспейсе, то нам доступна вся память, потому что в кернелспейсе мы видим ее всю. Если мы работаем в юзерспейсе, то, соответственно, мы видим только память данного процесса, который работает, но зато в юзерспейсе у нас гораздо больше программ запущено, и, соответственно, область атаки гораздо шире. Соответственно, в чем идея? Идея, на пальцах попытаюсь объяснить, то есть атакующий постоянно посылает пакеты на какой-то компьютер. Эти пакеты приводят к тому, что получение этих пакетов на компьютере приводит их к их обработке. Сперва ядро получает эти пакеты каким-то образом, что-то с ними делает, потом рассылает их, возможно, в другие программы. Ну, скажем, если вы слушаете трафик SSH, то вы пошлете этот пакет в SSH. Если вы там веб-сервер какой-нибудь, то в какой-нибудь Nginx, возможно, и куда-то еще. И если атакующий знает, что и как, где было запущено, он знает версии, он знает, какой код исполнялся, он может понять, каким образом ему использовать эту систему. В частности, вот здесь идет хороший рассказ про использование с помощью кэша и с помощью avx2. И наиболее интересный случай — это avx2, потому что это очень легкое и простое пояснение, как это можно эксплуатировать систему. avx2 — это расширение при работе с широкими... Как это правильно объяснить-то? Это команда single instruction multiple data, когда у вас одна инструкция выполняется на широком наборе данных, там 32, 64 бита. Там может быть много одновременно полей, и вы одновременно что-то делаете. Например, побитовое сложение. То есть вы запихали туда 8 байт... Не побитовое, а все-таки словами или байтами. Давай словами. Я не помню, что они использовали. Может, словами, может, байтами. Но не суть. Получается, что у тебя... Вы можете запихнуть несколько байт с одной стороны, несколько байт с другой стороны, сложить их, и вроде бы все хорошо и просто, но дело в том, что AVX2 требует прогрева. Прогрева в каком смысле? Если он какое-то время не использовался, то ему надо порядка 0,5 микросекунд, если я не ошибаюсь, если я правильно помню, для того, чтобы выполнить эту инструкцию. Если он до этого недавно только что работал и не успел еще остыть, и у него тоже есть какой-то заранее известный период, когда он не выходит из рабочего состояния, он сразу, мгновенно обработает. Если он не использовался долго, то, соответственно, он какое-то время прогревается, прежде чем включиться. Это сделано для того, чтобы экономить электроэнергию, чтобы процессор постоянно не включал эти устройства. Логические, арифметические устройства. Соответственно, получается, что, если у нас Leak Gadget в какой-то момент времени при считывании из произвольного куска памяти в спекулятивном режиме считал бит 1, и этот бит взведен, если он попытается выполнить AVX2, он его выполнит. Все равно, в спекулятивном режиме, рано или поздно пройдет, прогревание не пройдет, неважно. Но если сразу после этого Transmit Gadget попытается использовать AVX2 инструкцию, и она не сработает, вы понимаете, что это значит, что AVX... Ну, в смысле, не сработает сразу, потребуется прогрев. Это значит, что до этого AVX2-модуль не работал. Вот AVX2-модуль, это, соответственно, получается микроархитектурное состояние в терминах данного пейпера, с помощью которого мы и утаскиваем информацию о том, был взведен флаг или нет. То есть это аналог КШ, который мы использовали в Spectre 1, здесь они используют AVX для того, чтобы это было более быстро, удобно и наглядно. Вот. С помощью... То есть здесь вектор атаки понятен, и как атакуется, все понятно, да? Они говорят, что есть два основных использования NETSpectre. Первое – это, соответственно, вытаскивать память, как они и делают, это основное направление. А второе – это тоже интересная вещь, есть такая вещь, как ASLR – Address Space Layout Randomization, то есть когда у нас программа находится не по нулевому адресу, а каким-то случайным образом куда-то размещается. Только я должен все-таки поправить. Давай. То есть программы не находятся по нулевому адресу, они находятся в виртуальном адресном пространстве и находятся по какому-то своему базовому адресу, который указан в ELF файле или в PIF файле. Но ASLR действительно перемешивает страницы, да. Спасибо. Ну, как бы по умолчанию все считают, что все в нулевом, а с ASLR у тебя получается есть какое-то дополнительное смещение. Но разницы нет, я согласен. Из-за того, что Leak Gadget найти довольно сложно, а может быть в вашей системе их вообще нет, есть... Когда вы пытаетесь разобраться, точнее не разобраться, а сломать ASLR, вы пытаетесь понять все вот эти смещения всех программ в виртуальной памяти, вы можете использовать Leak Gadget, в котором меньше требования к Leak Gadget. Они не дают пояснения в пейпере, возможно, это в какой-то дополнительной литературе они ссылаются, куча ссылок. Но они говорят, что в случае попыток слома ASLR гораздо больше вариантов для гаджетов, больше возможностей. И это тоже неплохой вектор атаки, потому что если вы знаете точно смещение, то есть много других способов взлома, то когда вы знаете это смещение, уже сможете сломать систему. Вот. Про цифры я уже говорил, что они 60 бит за час с помощью AVX2 вытаскивают. Про 100 тысяч измерений в среднем для того, чтобы вытащить один бит я тоже сказал. Пожалуй, все. Как-то так. Отсюда выводы. Выводы такие, что в общем всем хана. Я вообще не представляю, как жить в современном мире. Утаскивают любую информацию, никому ничего не надо запускать, ничего не надо подключаться, и никто не поможет. Ну, мой вывод такой из всей этой истории с спекулятивным исполнением кода, что надо делать систему как можно проще, потому что когда вы делаете систему сложной, придут злобные хакеры и найдут сайт-чаналы. И в частности, если говорить про мою любимую архитектуру RISC-V, то существующие сейчас процессоры, они не реализуют спекулятивного исполнения, и поэтому не уязвимы к Meltdown, к Spectre, и Netspectre, и к всему этому. Так что да, пишите, простые системы. А с точки зрения... Да, да, говори. Тут дело не в том, что системы сложные. Дело в том, что система пытается оптимизировать. И она становится сложной из-за того, что применены очень крутые оптимизационные вещи, но при этом они забыли про разделение и прочее, которые были на уровне ядра, юзерспейса и прочее. Получается, что кэш уже общий, он уже не знает, кому он принадлежит. Поэтому возникает из-за сложностей, связанных с производительностью, вот такие вот спецэффекты. Это плата за производительность. Поспешишь, люди и насмешишь. А вообще никого не пускаете в свои сети. То есть, если ваш компьютер стоит в закрытой сеточке, не подсоединенной к интернету, то вас не взломают. Ну, знаешь, с другой стороны, нет никакой гарантии, что у тебя там банальный браузер, черт возьми, не используется какого-нибудь инструкции, связанные с какой-нибудь вектором инструкции, который используется в какой-нибудь сети, ну вы поняли. А, кстати, да, они же говорят, что это атака не только на сервера. То есть, фактически, если вы подключаетесь через браузер SSH или FTP, или чего угодно, к кому-то еще, точнее, это должен быть двунаправленный канал, то вас точно так же могут пытаться взломать, потому что вам тоже что-то посылают, вы что-то тоже отсылаете и так далее. Главное не сидеть на сервере больше одного часа. Желательно еще меньше. Пять минут на один сайт, не больше. Саша Бондаренко опять смешно шутит в чате, что вектор атаки на векторные инструкции. Какая ирония. Вообще, я согласен, что здесь все из спекулятивного вычисления. Вообще все из спекулятивного вычисления. Давайте уберем чертям спекулятивное вычисление. ARISK5. А можно купить его уже? Спекулянты проклятые. Да, можно. Давайте уже все надоели своими спекуляциями, давайте что-нибудь позитивное поговорим. В общем, вот кому из вас приходилось когда-либо продираться сквозь, ну скажем, хотя бы 100 гигабайт JSON? Поднимите ваши виртуальные руки. 100 гигабайт. Это каждый день. Шучу, конечно. Ну, вот, короче. Если мне пришло 100 гигабайт JSON, я бы записал их на HDD, такой потяжелее, потом пришел с этим HDD тому, кто сгенерил 100 гигабайт JSON, я им дал бы по голове. Ну, к сожалению, у некоторых бизнес принимать 100 гигабайт JSON в час или типа того. А, я думал в одном запросе. Нет, нет, нет, нет. Я скорее про логи. Вот у тебя есть логи, там, не знаю, ну, 100 гигабайт JSON, например, тебе в них нужно что-то найти. Может быть даже не 100, может быть больше, может быть там 5-байт JSON, такое тоже бывает. 5-байт JSON у нас бывает, например. Я как-то раз генерил бесконечное количество JSON, это считается? Ты, главное, скажи, ты в нем что-нибудь полезное искал? Сейчас же генерил, а не читал. Вот, как бы, а как бы, в общем, ты с тем же успехом мог в Дивну генерить. Вот, а если есть какой-то большой-большой-большой архив какого-нибудь JSON, который вам слали зачем-то, ну, не знаю, у вас опишка JSON, вы логи храните за много времени и вам много шлют. Вот вам приходит какая-то фигня, типа «Здрасте, у нас не работает АБЦ, пожалуйста, помогите нам разобраться». И ты такой «Ну, елки-палки, сейчас полезу в свой 5-байт JSON-а». И, в общем, как бы вы подходили к этой проблеме? Я бы поставил Postgres, сделал JSON-беполе, построил по нему индекс и все было бы здорово. Круллстори, бро. Помощнее, греб и пошел кофе пить. Во-во-во, греб. Вот это правильная идея. Вот Ваня в правильную сторону повел. В общем... Я протестую. У него поиск за линейное время, а у меня логи алгоритмическое. Ты должен сначала их построить. Вот, да-да-да. То есть, как бы, проблема в том, что у тебя JSON-беполе, это не то, что действительно не работает, но проблема в том, что, как бы, JSON мы храним как-нибудь сжато, так, чтобы поплотнее его напихать в странном сторидже. Мы, на самом деле, не хотим его парсить в первую очередь. Мы хотим вначале отсеять все то, что точно не будет того, что мы ищем, а потом уже что-нибудь распарсить и найти точно. И вот это, на самом деле, большая идея, казалось бы, довольно очевидная, но вот за пейпером, который я хочу обсудить, точнее, я, на самом деле, обсуждаю сейчас статью в The Morning Paper, то есть я вначале увидел пейпер, положил себя в закладки, все никак не успел почитать. В итоге Адриан Койлер устроил на него написать обзор, поэтому мы будем обсуждать обзор. Но, на самом деле, ну, клево погрепали, кто-то что-то хотел сказать? Ну, то есть это какой-то некий аналог Bloomфильтра для грепа? Да, да, да. То есть даже не для грепа, для JSON-парсеров, ну и там, на самом деле, потом обобщают на паркеты всякие такие форматы. Давайте, друзья, по порядку, без спойлеров. Ну, да, в общем, идея в том, что если мы хотим сделать поиск по, например, JSON-документам, нам в общем случае нужно JSON-документы разобрать, потому что чистого грепа по JSON-у недостаточно. Потому что JSON, он в ложный формат, греп это там, ну, греп в принципе может не совсем регулярной грамматики, но в общем случае регулярным выражением у нас регулярная грамматика. Примерно те, которые реально быстро работают, это будут регулярной грамматики. И, в общем, в общем случае, чтобы что-то хорошее сделать, нам нужно все это разобрать. Не клево. Медленно. Даже с грепом на самом деле, просто классический греп с регулярной грамматикой, он в принципе, ну, не самый быстрый перформанс будет выдавать. Хотелось бы действительно каким-то образом отсечь все, где мы точно не имеем нашего искомого какого-то признака, и потом уже только распарсить. Вот. В общем, ребята сделали довольно интересную конструкцию. Вместо вот грепа представьте, что у вас есть такая штуковина, которая генерирует наборы SIM-инструкций, которые проводят очень быстрые проверки на, например, поиск под строки фиксированного размера внутри заданного массива байта. А потом такие вот маленькие, небольшие проверки, оно перетасовывает, и результат там тоже сводит в другую SIM-инструкцию, чтобы проверить, как бы, там, есть ли у нас хоть одно срабатывание. И, в общем, они это оптимизируют больше того, они как бы в начале генерируют вот такую штуковину дерева проверок, а потом они строят то есть они это дерево проверят, строят на основе какого-то сэмпла из файла. Дальше у нас в потоке начинает меняться какая-то частотность, например, не знаю, у нас в дереве проверка зачисалась дата, а потом дата другая стала. Дерево проверок будет перестроено, если оно начало хуже срабатывать. Вот. И они там совершенно потрясающие результаты приводят, что с таким подходом у них там ускорение просто в 10 раз на JSON или даже больше, может быть, там, я уже не помню. Да, в 10 раз на JSON, и они потом это обобщили, подход на Aura и Parquet, и там ну, в 4-5 раз ускорение поиска по... Подожди, я до конца не понял, можно вопрос? Да. То есть вот смотри, у тебя задача какая, в стриме это вытаскивать или у тебя есть статический файл и ты как, Саша, предлагаешь индексы строить? Нет, точно не про индексы, речь как бы или стрим, или статический файл, который просто, ну, не знаю, логи, никак не индексированные. Хорошо, и каким образом дерево... тебе все равно надо пробежаться, у тебя линейное время, ты все равно пробегаешь. Да-да-да, смотри, прикол в том, что тебе ты можешь пробегаться с гребом, а можешь сделать лучше. Ты можешь построить дерево проверок, которые вот, пройдя по всем ветвям, если ничего не сработало, там точно ничего нет, если что-то сработало, то... Но они, скорее всего, джейсона парсят? Нет, нет, нет, ну, это дело, что... А как тогда они дерево парят? Смотри, структура дерева не дерево, а внутри... я плохо объяснил. Дерево проверок. То есть у них евреистический поиск. Они берут строчечку и ищут в ней, как бы оптимизированным образом на симдах подстрочечки, и если оно там как-то мачется, то они делают вердикт, что наверное, это то, что мы ищем, но надо перепроверить. Вот, и кстати, я к этому методу имею добавить, что вообще поиск по логам, он офигительно распараллеливается по вашей ферме. Угу. Вот. И там дерево не дерево, а синтаксическая документа... Речь идет о дереве именно самих проверок. Еще раз. В третий, четвертый раз. То есть это не... И это дерево, но дерево, потому что у них разные веса. То есть у них они стараются в первую очередь проверять что-то такое, чтобы точно... Они стараются в первую очередь проверить какие-то такие признаки, которые максимально хорошо отсеивают или не отсеивают, а потом какие-то уточняющие признаки. Вот. И там они фиксируют количество этих операций, чтобы не делать больше, чем сколько-то, чтобы действие было быстро. А с точки зрения operations, то есть как бы ты на вход подаешь что для того, чтобы оно заработало? Какой-то поток байт. Но и то, что ты хочешь найти или нет? Да, то, что ты хочешь найти. Притом ты можешь сказать или под строку, или даже в случае JSON у них есть вариант с k-value, но там тогда ищется только точное совпадение, они тогда не могут искать под строку. А вот эта эвристика построения дерева операторов, они как ее строят? У нас на ВИЧе? Я не хочу это прямо сейчас сильно глубоко вдаваться. Смысл в том, что они берут sample данных, они генерируют какие-то под строки. Ну там у них есть способ поддетерминировать генерит, например, ты ищешь строку, там не знаю, Афина или… А, Афина и приветствие. Они сгенерируют от Афины все четырехбайтовые последовательности, которые встречаются в Афина, потом все четырехбайтовые последовательности, которые встречаются в greetings, потом какие-то еще более сложные проверки, изначально это сгенерируют. Они генерируют, пока у них не закончится лимит генерации, из них убирают какие-то рандомные, сэмплируют данные, смотрят, какие вариации лучше работают, в какой-то момент просто рандом останавливают, типа берут лучшее, что получилось. Начинают гнать поток, если в какой-то момент как бы качество отсеивания падает, они повторяют процесс. Все понятно, интересно. Вот, поэтому если вам нужно, да, у них есть имплементация на гитхабе, заинтегрированная, как я понял, даже со Spark, если вам нужно очень много искать по логам, у вас очень большое массив данных логов, то возможно вам стоит куда-то сюда посмотреть. Но по сути это получается такой греб на стероидах с помощью, с использованием сим, инструкции и прочего. Ну это не греб, оно не ищет регулярные выражения, оно ищет именно подстроки. Это, я бы сказал, не это греб. И получается, что результат будет очень сильно зависеть от того, как часто встречается. То есть если встречается достаточно часто, они могут построить азристику очень хорошо. Если ты хочешь найти одно, то что встречается один раз на весь документ, они не смогут свои сэмпли найти, они вообще не поймут, что делать. Нет, смотри, прикол же в том, что... То есть ты, скорее всего, ищешь что-нибудь в духе поля имя равно что-то там. Очевидно, что что-то там, скорее всего, нигде не встречается. И на самом деле для них это хороший признак, что нигде не встречается этот набор. Это офигенно означает, что у нас не будет почти положительных срабатываний. Нам на самом деле парсить не придется, мы просто все отсеем, что не нужно. А если наоборот ищешь что-то такое, что есть просто в каждом документе, ну извини, ты такой запрос сделал. Я больше про дерево операторов. То есть если я ищу веник и копыта, одним словом с подчеркиванием, то оно нигде не встречается, кроме как в одной строчке в непонятном заранее поле. Я думаю, они построят дерево фильтров, неважно, насколько оптимально. То есть они не смогут его хорошо оптимизировать, но это неважно, потому что оно нигде не встречается в своем сэмпле. Это значит, что у него очень хорошая селективность и ты можешь просто самый простой вариант брать, просто из одного оператора, и гнать его, пока у тебя оно не начнет плохо работать. Ну то есть тебе вся эта оптимизация нужна только тогда, когда у тебя что-то достаточно часто встречающееся. Если оно вообще не встречается в сэмпле, значит у тебя уже хорошая селективность, тебе ничего особо оптимизировать не надо. Но ты же на лету должен определять, встречается оно или не встречается. Ну в смысле, смотри еще раз. Задача поиска по логам – найти строку. Задача быстрого поиска по логам – отбросить как можно быстрее все то, где строки нет. Но ты не можешь отбрасывать то, где строка есть. Да. Супер. Но ты просто бежишь дальше по стриму. Например, он разделен слэшенами. Или там какой-нибудь байт-секвенсом. То есть у тебя месседжи отдельно, друг от друга как-то отделены предсказуемо. И ты просто берешь, как бы мачешь, ага, вот в этом кусочке байт есть вот эта строка? Нет. Потрясающе. Берем следующий. Но так в итоге ты должен все равно все прочитать. Ты не достигаешь ускорения. Ты за счет чего-то ускорения достигаешь. Ускорение достигает. Смотри, Ваня, я так понимаю. То есть получается, первый проход будет с использованием этого дерева. Мы отсекли все то, где этой строки нет. А потом мы итерируемся по тем частям, где то, что осталось после фильтрации. Вот тебе и ускорение. Смотри, альтернатива подходу, если у тебя есть просто куча текстовых логов, тебе нужно в них что-то найти. Тебе нужно их все распарсить. То есть имеется в виду, что пропарсить JSON, прям вот честно его на AST разбить, это дорогая операция.",
    "result": {
      "query": "Netspectre attack explained"
    }
  }
]
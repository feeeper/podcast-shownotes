[
  {
    "segment_id": "64cf2791-7168-43ac-ac78-baf7fc530274",
    "episode_id": "ec106bb6-8c89-49ca-91dc-a865e19ffb99",
    "episode_number": 44,
    "segment_number": 4,
    "text": "То есть оказалось, что семантика этого API вполне себе подходит для того, чтобы описывать и вычисления над потоками. То есть эти коллекции, которыми ты манипулируешь, они не обязаны иметь ограниченное количество элементов. И в итоге в DataFlow вошли технологии из Flume, вот этот API из MillWheel, в частности полностью детерминированная такая строгая семантика со строгой consistency и транзакционностью обработки элементов в потоке. То есть там нету никаких компромиссов, как во многих других потоковых системах, что сообщение обрабатывается максимум один раз или что сообщение обрабатывается минимум один раз. То есть фокус на том, чтобы получать из системы предсказуемые результаты, зависящие от данных, например, а не от того, в какой момент они поступили. И в результате DataFlow как потоковую систему вполне можно использовать для того, чтобы считать billing, например. Большинство других потоковых систем для этой цели, как я понимаю, из-за проблем с consistency использовать нельзя. Ответил ли я частично на твой вопрос про то, как у нас работает стриминг и как он связан с batch? Частично ответил. Частично, да, но хочется как-то все-таки более конкретно. Да, то есть как вы добиваетесь того, что у вас получается такая строгая consistency? Это потому, что это совсем не тривиальная задача. То есть обычно там exactly once это очень круто и до этого доходит уже накинь. Ну на самом деле так ведь не бывает, на самом деле exactly once. На самом деле судя по тому, что есть триггеры и возможность написать всякие такие странные штуки, типа если данные не долетели, а потом еще раз обновить, а если еще вот тут не долетели, то еще раз обновить, так по сути это не exactly once, а at least once, который за счет каких-то трюков выглядит как exactly once, так ведь? Значит давай начнем с нижнего слоя этого стека, то есть движок обработки потоков в DataFlow это фактически millwheel, и millwheel это потоковая, строго потоковая система, то есть никаких микробетчей там нету, то есть на вход прилетают данные и пролетают через вычисления, но при этом обработка одного элемента это фактически транзакция над локальным persistent storage. И в эту транзакцию входит во-первых deduplication по сравнению с тем, что уже пришло сюда, за счет этого достигается at most once, то есть если на эту ноду придет такое же событие, то мы его проигнорируем, ну понятно, на другую ноду оно не должно прийти согласно правилам раутинга. А что если отвалилась нода? Если нода отвалилась, тогда мы запустим другую ноду, приаттаченную к тому же диску. А, то есть это все поверх GFS крутится, а что произойдет с событием, которое в это время было в полете? Ничего страшного, если событие было в полете, то тот, кто его послал попробует еще раз, и если мы случайно получим событие два раза, мы его deduplicate. Значит, это само по себе не проблема, то есть есть куча протоколов в мире, которые реализуют exactly once, например, извиняюсь, тот же TCP. То есть каждый пакет для человека, который читает из сокета, выглядит так, как будто он доставлен exactly once, и в этом ничего такого сложного нет, просто надо экать и deduplicate. Интересное начинается в том, как гарантировать, что те элементы, которые ты подал на выход, обрабатывая этот элемент, тоже доставляются exactly once. Например, что если ты случайно обработал это событие все-таки два раза или второй раз обработал немножко по-разному, то есть в процессе первой обработки, которая, например, свалилась из-за того, что умерла машина, ты что-то выдал на выход, машину перезапустили, и ты еще раз обрабатываешь это событие, потому что в прошлый раз оно недообработалось, и выдаешь что-то еще на выход. Значит, как сделать, чтобы те, кто после тебя, не получили то, что ты выдал на выход по два раза? Для этого уже нужно рассматривать обработку одного события как транзакцию, и для этого нужен локальный транзакционный storage. То есть в эту транзакцию входит deduplication предшедшего события и запись о том, что ты выдал на выход, и запись о том, как ты изменил, например, так называемые таймеры или состояние, ассоциированное с этим ключом. То есть с помощью таких транзакций достигается строгая консистенция. Возникает, наверное, вопрос, как мы можем так часто коммитить транзакции. Ответ, что они, конечно, коммитятся в пакетах, и остальная часть семантики сконструирована так, что это не мешает.",
    "result": {
      "query": "DataFlow exactly once consistency"
    }
  }
]
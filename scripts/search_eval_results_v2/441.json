[
  {
    "segment_id": "e8f19124-ce22-4f6f-932c-1ce2a0aeadcc",
    "episode_id": "7d67bb19-e64c-4a93-a502-591cfc1ba339",
    "episode_number": 441,
    "segment_number": 8,
    "text": "Это их сервис, могут делать с ним, что хотят. Дальше у нас тема про квадрант. Это какая-то база данных для AI с интересными векторными фидонетными индексами. Саша посмотрел доклад, а я не успел, потому что я очень занят. У меня было очень, как это, what a week. It's Monday, Captain. Вот. У меня вот это вот было. Поэтому, Саша, жги. Неделя богатая на события. Это новый сезон того, что раньше называлось Vaccination Database Technologues, а потом как-то еще. Сейчас она называется MLDB Seminar Series. Притом между MLDB Seminar Series MLDB Seminar Series MLDB Seminar Series и DB, там две стрелочки туда-обратно. То есть как бы база данных для машин-бернинга. Первый доклад в серии читает, у меня есть с печаткой написано, Андрей Воснецов. И он, насколько я помню, CTO компании, которая разрабатывает, по-моему, он произносит квадрант, но пишется Q-drant. Что такое квадрант? Это open source давайте по-английски лучше прочитаю open source vector similarity search engine stroke database. Делается особый акцент на том, что на самом деле это не СУБД, это именно поисковый движок, как, например, Elasticsearch является поисковым движком. Но об этом наверное чуть дальше. Квадрант написан на RAST, лежит на GitHub под лицензией Apache 2.0. Ссылку на GitHub Ничего себе, ты меня аж активировал. Валера сразу заволновался. RAST, Apache 2.0, GitHub? Где крабов дают потрогать? Объясняется, при чем тут вектора и о чем речь. Не как в случае векторизации запросов, не эти вектора, а другие вектора. Вектора, как у тебя есть некие входные данные, документы или картинки, и есть модель или энкодер, который принимает эти данные на вход, а на выход возвращает вектор признаков. Например, если у тебя фотографии, то... Оно же эмбединги, если не ошибаюсь, когда речь про всякие... Современные модели. Возможно. В этом докладе такая терминология не используется, а я в ML не сяку. Так вот. Идея в том, что если у тебя, например, на фотографиях изображены похожие объекты, то и в N-мерном пространстве, где находятся твои вектора, соответствующие точки тоже будут находиться близко. То есть у тебя кошечки получаются близко к кошечкам, хот-доги близко к хот-догам, а не хот-доги, не близко к хот-догам. Хот-доги близко к корге. Идея не новая. Все это давно известно. Вот что поменялось со слов докладчика, это то есть не идея, а доступность движков и данных для широкой аудитории. Например, тот же OpenAI. И как в своей компаниях они ведут свою задачу, это сделать удобный поиск по векторам, которые вектора признаков. Кстати, они делают облачный сервис, и я так понимаю, собираюсь на нем зарабатывать. То есть, если вы хотите on-prem, то, пожалуйста, берите пакет и используйте. Если вы хотите облако, то вот у нас есть свое облако. Что мешает другим людям делать такое же облако, то, конечно, надо делать. Это в данном моменте вполне известно. Квадрант это распределенная система Валера. Данные квадрант хранит в шардах, а метаданные хранятся в рафт-консенсусе. Но сейчас у тебя сейчас у тебя энтузиазма поубавится. Это не ACID-система. Они называют себя, что мы ... Меня так и подмывает сказать то, что у Валеры сначала привстало, а потом у Валеры подупало. Простите, пожалуйста. Это бейс-система в том смысле... Я не помню, короче, проводится бейс. Валер, ты помнишь? Сейчас. Мне секунду назад было в голове, уже вылетело оттуда. Ну, короче, это вот, когда у тебя нет консистентности. То есть вот это SE, это что-то там eventual consistent, какая-то такая же балалайка. Но смысл в том, что они торгуют консистентность и транзакционность в обмен на масштабируемость и скорость. Но данные какое-то время могут быть несогласованы. Basically available, soft state, eventually consistent. Большое спасибо. Вот. Но такой сделан компромисс имеют право. В конце концов... Справедливости ради для векторных баз данных это, наверное, разумный компромисс, потому что не то, чтобы ты часто этими векторами шевелил, насколько я понимаю. Ты их туда загружаешь периодически и потом ты в основном делаешь лукапы. Наверное. Ну, то есть людям, которые занимаются ML, им, наверное, виднее. Но меня сильнее интересует, что если бы они себя позиционировали как AC, то возникал бы вопрос, а почему не Postgres? Ну, то есть, почему бы не сделать это расширением к Postgres? Расширение к Postgres, кстати, больше одного. Я думаю, имеет смысл будет в какой-то момент про них поговорить, возможно, с разработчиками. Но расширение к Postgres, это все еще Postgres, а значит, это AC от системы с другими компромиссами, с масштабируемостью, но ограниченной и так далее. Вот. То есть, здесь сделаны другие компромиссы и сразу отпадает вопрос, что, ну, это другая система с другими компромиссами. Окей. Возникает вопрос, SQL или не SQL. Прямого ответа в докладе нет, но судя по тому, что я видел на слайдах, это не SQL, это что-то в стиле REST. То есть, и запросы ты пишешь кусочками JSON. Ну, там всякие LT, GT, вот это вот все. Другой возникающий вопрос, держат ли они 10K или 100K соединений? На данном этапе остается величайшей загадкой. В докладе об этом нет абсолютно ничего. Вот. Зато в докладе есть про индексы, которые они используют. И индексы, они решают задачу под названием ANN. Approximate Nearest Neighbors. То есть, вот как в Postgres есть индексы, которые позволяют решать KNN, где у тебя находится K ближе, где у тебя есть K ближе к соседям. Здесь такая же задача, но она ослабленная. Тебе нужно примерно найти точки в инверном пространстве, которые близки к заданной. Заявлено три типа индексов. Первый это B3. В докладе он называется именно B3, а не B+, что-то на самом деле непонятно. А также графовые и кластерные индексы. Но остальная часть доклада, посвящена штуке под названием HNSW. И это расшифровывается как Hierarchical Navigable Small Worlds. Я запущу это в чат, потому что это сложное для произношения слова. Особенно мне. Это в сущности графовый индекс. И на пальцах объясняется его идея. То есть у тебя есть узлы. Узлы, как узлы Б-дерева, например. Узлы соединены с другими узлами. Притом большим количеством соединений. У тебя получается граф. Каждый узел имеет энное количество соседей. И идея индекса такая, что если ты откуда-то, знаешь, что я начинаю искать вот с этого узла, то я, ну, узла в графе, то я просто делаю, например, поиск в ширину до тех пор, пока не найду нужное мне количество примерных соседей. То есть, понятно, другими на графе соединяются вектора, которые относительно близко друг к другу. Такая структура имеет ряд проблем или челленджей. Нужно понять, сколько связей должен иметь каждый узел для того, чтобы не получить несвязанный граф. Ну, понятно, да, если он получится несвязный, то это не проблема. Есть эмпирические оценки, и приводятся графики, что вот у нас энное количество связей, и вот оно находит... И я, честно говоря, не очень помню, что там было на этих графиках, ну, то есть у тебя, например, количество найденных узлов, вот оно зависит от N, и вот у тебя полка, полка, полка, полка, а потом такой резкий провал. И ты, вот, глядя на такие графики, можешь примерно оценить, сколько у тебя должно быть связей, при том, по-моему, оно выражается в количестве узлов в графе, относительно количества узлов в графе. Вот. И, по-моему, когда у тебя вот это вот N, то есть больше 10%, то большая вероятность получить разорванный граф. Но я говорю по памяти, это не точно. Вот. Другая проблема этого индекса в том, что он делает много случайного дискового ввода-вывода, по понятным причинам, у тебя узлы разбросаны как попало. Также говорится, что он дорогой по CPU, и вставка в два раза дороже чтения, если я правильно записал. Из фичей поддерживает построение подграфов по заданному предикату по полезной нагрузке. То есть, что это значит? У тебя вот есть вектор, это просто массив чисел, а есть полезная нагрузка. Это, например, документ, и там вполне осмысленные данные, там возраст, имя и так далее и тому подобное. И ты можешь взять полезную нагрузку с полезными понятными данными, применить к ним предикат, например, где возраст больше, чем. И ты можешь построить вот такой графовый индекс по данным, которые удовлетворяют предиката. Надеюсь, понятно. Это аналогично частичным индексам в Postgres. И, в принципе, это все содержимое доклада. Я ничего кроме этого в нем не услышал. Вот у меня возник вопрос. Может быть, нам в Postgres тоже нужны такие индексы? Или, может быть, будет проще написать RDW в квадрант? Это все. Вопросы, возражения, комментарии. Ну, то есть, по факту, это просто Postgres.kl, в котором есть ID-шники двух узлов, которые соединены. Откуда ты Postgres.kl взял? Какая-то метаинформация. Я утрирую намеренно для того, чтобы понять, как бы, вообще, что это такое. Ну, это распределенная система, куда ты загружаешь свои вектора, а потом можешь сходить с запросами из Python уровня.",
    "result": {
      "query": "Qdrant vector database overview"
    }
  }
]
[
  {
    "segment_id": "e164a789-d966-4a2b-9397-ed3a542566c6",
    "episode_id": "771dbc75-7472-431d-acf2-2c2ffb3101d5",
    "episode_number": 72,
    "segment_number": 3,
    "text": "И, соответственно, в следующий раз, когда тебе надо между двумя точками найти расстояние, они просто как евклидовое расстояние высчитывают, и все. Корень из суммы квадратов. Ты сейчас про любую систему координат рассказал, на самом деле. А как они количество измерений выбирают? Вот, а дальше идет уже магия, которая... А дальше это Пеппер читать, понятно. Да, надо Пеппер читать. То есть я вкратце понял, почему они делают именно так, то есть там, я имею в виду, что в выдаче, вот когда ты говоришь, что дай мне посмотреть, покажи мне, пожалуйста, определение той ноды, там будет написано, что такое вектор, что такое хейт и так далее, джастинг. То есть идея в том, что тебе дают такую вещь, с которой тебе известна вся школа, и ты знаешь, как с ней работать в любом клиенте. А вот как она строится, ну, для тебя магия. Но работает она правильно. Кстати, о магии, следующую тему добавил Андрей. И она про ЭЛМ. Следующая тема. Вышла книжечка, которая называется ЭЛМ by Example. Написал ее товарищ Гжегож Баклэрек. Я, честно говоря, за ЭЛМом не сильно слежу. То есть я знаю, что это за язык, я знаю, зачем он нужен и всякое такое. Идея такая, что это, с одной стороны, функциональный язык, типа там Haskell и всего такого прочего. То есть у него такой ML синтексис, очень красивый, замечательно. С другой стороны, он специально создан для вебчика. Для того, чтобы писать UI на нем. Но все примеры с ним показывают, как с помощью него можно писать, я не знаю, какие-то игрушечки, демки и всякое такое. Получается, что эта книжка, это последовательная интродакшн на тему что это такое, с чем его идет. Интересная его особенность и отличие от других функциональных языков, это то, что он еще и реактивный при этом. У них есть специальный тип переменных, который называется сигналы. Это переменные, значения которых изменяются со временем. Вы можете писать логику на основе трансформации этих сигналов. Мышка подвигалась, соответственно, у нас есть поток ивентов. С этим потоком ивентов мы можем что-то сделать. Книжка хорошая для тех, кто хочет этот тему получить. Наверное, из всех таких языков, которые сделаны для веба, чтобы выполнялись в браузере, ELM, наверное, самый-самый доступный для того, чтобы на нем начать перепрограммировать. Но я пока что не начал им пользоваться, просто потому, что мне жутко не нравится то, как там сделано работа с HTML. Вместо того, чтобы как-то его встраивать, так же, как в Visio, у них отдельно HTML, отдельно JavaScript, там внутри у них свой DSL и на деле, получается, писать приходится гораздо больше, чем если просто чем если бы можно было писать HTML отдельно. И вот все примеры, которые есть по ELM, они все такие из серии, что ELM владеет страницей целиком, и поэтому, когда у тебя уже есть большой проект на какой-то технологии, внедрять ELM туда довольно сложно. То есть, Андрей ELM осуждает? Нет, я ELM люблю, но я считаю, что есть еще куда расти, есть куда улучшаться. Подожди, у нас в подкасте так нельзя. В мире, как известно, есть только нолик и единички. А, если только нолик и единички, то преимущество перетягивает до стартки. То есть, ты одобряешь, хорошо. Хорошая штука. Слушай, это почти Haskell. Как можно не одобрять почти Haskell? Конечно, одобряю. А там нет Monad. То есть, ты можешь сказать, а, ужас какой. Haskell из Monad. Там одна сплошная Monad, на самом деле. Signal — это одна большая Monad. Спойлеры, спойлеры. Так ты это одобряешь или осуждаешь, Валер? Конечно, осуждаю. Блин, ну как это? Вот как язык я его одобряю, а вот как это? Чем можно реально воспользоваться? Ну блин, ну-ну-ну-ну-ну-ну-ну-ну-ну. Скорее одобряю, чем осуждаю, но у меня есть за что его осудить. Ну, тогда к вору. Да, интересно, что там у него капеллятор, который все это проверяет. Он же не динамический, он статический. И получается, он тебе показывает сообщение об ошибках, и, наверное, это самое лучшее сообщение об ошибках, которое вообще я когда-либо где-то видел. Авторы языка, они специально работают над тем, чтобы это было как можно круче. То есть, он даже пишет там из серии, ой, ты вот тут используешь вот эту переменную, а тут вот эту переменную, и, наверное, ты опечатался. То есть, он прямо находит у тебя опечатки. А еще, когда ты делаешь новую версию какой-то библиотеки на этом уровне, он проверяет, как изменилась сигнатура метода в твоем API. И если они изменились достаточно сильно, допустим, если появилась какая-то новая функция, то он тебе предлагает поднять вторую цифру в номере версий. А если поменялось какое-то API, то есть была функция, стала другая, или там поменялись параметры или еще что-то, то он считает, что это breaking change и говорит, что надо поменять первую цифру. То есть, он автоматом заставляет тебя исследовать синдеву. И это интересный ноу-хау, и интересно посмотреть, что из этого вырастет в результате. Просто такой маленький фюрер у вас в браузере. Да, да, да. На самом деле, там еще что прикольное, там есть time-traveling debugger, и это очень прикольная мозговыносящая фича. На самом деле, у Эльмы есть один недостаток, который уже озвучил Андрей, его нереально заинтегрировать в то же существующее. То есть, нельзя взять и написать кусочек своего сайта на этом. Вот, ну нельзя. То есть, в этом плане, даже у Haskell выше шанс, потому что можно взять и написать кусочек своего продакшена на Haskell. И так, переходишь, его протаскивать. Эльм, партизанский протаскивать нельзя при всех его плюсах. Не, ну можно. Смотри, ты делаешь iFrame, и в iFrame у тебя живет Эльм. Но как? Ну, потом приходит тот, кто... Потом приходит, короче, твой коллега, который увидел iFrame, не пойми где, и бьет тебя, короче, ногами Это да. Поэтому, если вы хотите его внедрить, вначале станьте тем лидом в фронт-енд команды. У этой книги нет PDF-а. Она ужасная. А, зато она сделана в HTML, и на самом деле, наверное, PDF по этой штуке можно сгенерить. На самом деле, там всего 14 глав, и они такие коротенькие, то есть, на тему сделаем вот такой примерчик, сделаем такой, и мне, конечно, не хочется. Не, ну я, наверное, в пакет занесу, но практика показывает, что в пакет я потом не зайду. Ну, это, наверное, если тебе интересно, то ты ее почитаешь. Если тебе не интересно, то тогда ты просто ее попустишь и дождешься, когда появится еще более лучшая книжка, или когда эту книжку сделать PDF. Угу, хорошо. Давай уже мою тему. Давай, ушки. Прискочила в Hacker News ссылка на отличную статью на сайте danluu.com Files are hard, в которой автор очень четко описывает, какие могут быть проблемы, когда вы работаете с файлами, файловой системой, с разными файлами, с типами файловых систем, с разными типами ошибок, и в том числе с проблемами оборудованием под низом. Вообще, мне эта вещь очень напомнила нашего любимого... Как его зовут-то, который консистенцию проверяет? Афира. Да-да-да, Афира. То есть, это вот прям афир для файловой системы. Его там упоминают. И вот это реально оно. То есть, человек сам признается, что он не идеально разбирается в файловых системах и проблемах файловых систем, поэтому, говорит, я не удивлюсь, если у меня здесь есть ошибки. Но тот уровень, с которым он рассказывает про проблему консистенции, синхронизации и так далее, прям вот зашкаливает. Очень много разбирается вопросов вида вот мы начали что-то писать, и у нас тут поломалось вот в этой точке, а как бы нам это точно быть уверенным, что мы поломали, что мы сможем это правильно прочитать и проверить, что мы смогли правильно что-то записать, не поломалось и что-нибудь. А что у нас сделает FSCK, правильно ли нам вернет результат, а не поломает ли он нам файловую систему при проверке своего результата, ну и так далее. То есть, очень глубокая статья. Я не знаю, стоит ли углубляться в детали. То есть, там ссылка на 4 или 5 разных пейперов, относительно разных проверок. Даже не знаю, как это правильно сформулировать. То есть, пейпер про то, какие бывают ошибки, пейпер про то, какие бывают, как правильно сохранять данные, пейпер про анализ текущих файловых систем, пейпер про анализ разных аппликейшенов на разных файловых системах, и сколько там было обнаружено ошибок методом статического анализа, пейпер про количество, как это, про корректность. Там даже такая была проверка, что сделали анализатор кода в разных файловых системах, видя, если мы делаем какую-то операцию, но не проверяем возвращаемую ошибку, возвращаемый код, удалось нам это или не удалось, мы считаем это ошибкой. То есть, там куча разных проверок, я имею в виду, куча разных пейперов с подобными проверками, и очень интересно читать, особенно если вы очень верите в то, что если вы сохранили что-то в файловую систему и у вас все записалось, вот этим людям я очень советую почитать. У меня почему-то на сайте не грузятся CSS. А ты уверен, что они там вообще? Их там нету. Да. На самом деле, когда я читал эту статью, мне вспомнилось такое высказывание Кармака, что он в какой-то момент во время разработки движка для Rage, после, точнее, даже где-то, наверное, после, опубликовал небольшую статью про статический анализ кода, и в общем у него там то ли в APGirf, то ли где-то, в общем, была такая фраза вынесена, что чем больше кода я пропускаю через статический анализатор, тем больше я удивляюсь, что компьютеры вообще загружаются. Вот эта статья вызвала у меня примерно такое же ощущение, потому что, ну ладно, там, когда нам говорят, что люди делают неправильно, то есть там в первой части нам рассказывали, что люди делают неправильно, когда пишут код работы с файловой системой. Ну, в принципе, все эти вещи, на самом деле, они не идеально документированы, но они более-менее понятные. То есть я там для себя открыл, что некоторые люди монтируют файловую систему с опциями консистентности ниже, чем дефолтные. Я не знал, что так вообще, что бывают ниже, чем дефолтные. Но, тем не менее, в принципе, про то, что нужно делать DataSync и Fsync, в принципе, для меня не секрет. Не исключает того, что я могу забыть это сделать. Вот. Но когда-то потом происходит проверка типа, а как у нас используют файловую систему всякие вещи, типа LevelDB, HDFS и ZooKeeper? Ммм... Оказывается, не так уж все там и хорошо. И вот тут уже начинаешь так... Блин! То есть... Вот... Получается, что, например, у ZooKeeper есть проблемы, ну, известные проблемы, там, одна известная проблема на XT, одна известная проблема на XT с еще одной конструкцией. То есть, грубо говоря, ZooKeeper на XT работает только если на XT3. Точнее так, ZooKeeper не имеет найденных проблем на 3-м XT, который смонтирован с опцией журналирования всего. Вот. Только тогда. А остальные опции монтирования XT3, они могут давать какой-то там один тип дефекта. Точно такой же тип дефекта может появляться на 4-м XT и BTRFS. Возможно, это даже поправлено. Скажем, LevelDB на всех типах экстримит ошибку. Да, да, да. Гид с Меркурелом там не по одной. Справедливости ради, LevelDB там допотопный. Справедливости ради. Я думаю, что у ZooKeeper тоже это могли бы поправить. Но сам факт, что это вообще нашли, такого рода ошибки. То есть, ну, это софт, который вы ожидаете, что он работает. Давай так, сам пейпер пятилетний. Ну да, да. Мне напоминает то, что мы про базы данных в прошлом выпуске обсуждали. Ну тем не менее, для меня интересен сам факт того, что системы, которые вы ожидаете, что они железобетонно работают, они даже у кого-то в продакшене крутятся, у Google в продакшене крутятся. А там такие проблемы. На самом деле там один из пейперов как раз объясняет, почему это все проблемно. То есть, нет нормальной документации. Посмотрите, пожалуйста, вопрос о консистентности базы данных и вопрос о консистентности файловой системы. И дают пример из консистентности той, и потом пример, значит, как в файловой системе описывается консистентность. Там рассказывается примерно следующим образом, что вот у нас есть такая опция, она делает примерно то-то, и дальше цитирую, говорят, что эта опция в принципе одна из самых быстрых, дает производительности. Но также говорят, что она не слишком надежна. То есть, это вот в официальной документации на файловую систему. То есть, авторы говорят после этого, что если сами авторы, разработчики, которые пишут пейпер, рассчитывают на слухи и описывают слухи в своей бумажке, о чем можно вообще разговаривать. А меня вот другую интересует. Слухи описаны не в бумажке, а в официальной документации. В мане. Мне интересно, как тестировать такие вещи. Вот, допустим, я беру... Дожди, дожди, дожди, дойдем до этого. Точно? Обещаешь? Да. Хорошо. Продолжай. Я же по параграфам иду. На самом деле у меня зашевелилось волосы на всем, на чем они у меня растут, когда я дошел до параграфа, где описывают, а как у нас мило иногда работают некоторые файловые системы. Выясняется, что EX3 на самом деле в очень многих случаях просто игнорирует ошибки. Ой, не смогли записать. А ну и хрен с ним! Что спецэффект? А, сейчас, да, я пока договорю. Кто же пользуется EX3? Ну, то есть все на EX4 уже, ну что, мы говно какое-то старое обсуждаем? Ну, ты думаешь, что у EX4 нет подобных проблем? Ага, то есть, подожди, даже у него есть такие проблемы? Ну, в смысле, я не могу за это сказать, потому что папер там очень старый, тот папер, из которого взято это исследование, когда его собирали, еще не было четвертого EX-а, видимо, но сам факт того, что в третьем EX-е такие проблемы есть, означает, что говорит о том, что, скорее всего, во многих других файловых системах такие проблемы тоже найдутся, то есть в XFS они есть. Причем там есть и в EX2, и в EX3, это мне наводит на мысль, что, скорее всего, в EX4 это не починили. Ну и вот, с другой стороны, чем хорош EX3, тем что, не стоя на всей его проблеме, это одна из немногих файловых систем, на которых до сих пор более-менее корректно работает почти весь софт, потому что EX4 и вообще многие другие файловые системы, которые современные, они пытаются работать быстрее, ослабляя гарантии и заставляя тебя ходить в барьеры. А барьеры, то бишь, это F-Sync или F-DataSync, а в них забывают люди ходить, или не забывают, но не забывают через раз. То есть очень редко бывает, что кто-то злоумышленно не поставил F-Sync. Бывает так, что люди не подозревают, что операция может быть перестановлена, потому что они за 10 лет сидели на EX3, они, конечно, столько на нем не сидели, но грубо говоря, они привыкли к какому-то поведению, у них не появляется в голове, лампочка не зажигает, что на самом деле вот здесь может быть какой-то реордеринг. Потому что не знаю, когда люди пишут параллельный код, они почему-то думают о том, что может такое случиться. Когда люди пишут файлы, они почему-то не думают, что... у них поток управления последовательный, они считают, что файловые системы тоже все пройдут последовательно, потому что в этом плане языки программирования к этому приучают, что параллельные вещи происходят, только делают что-то параллельно. На самом деле нет. Файловая система работает параллельно с нами. И с ней нужно, наверное, стоит файловую систему представлять как что-то живущее в сети. Да, как что-то совершенно конкурентно работающее вместе с тобой, и которая имеет свою логику и по-своему может работать. Да, именно так. Там также еще говорится, что я говорил про параграф о корректности файловой системы, на самом деле EX3 одна из самых дырявых в этом плане, а многие другие сильно надежнее, в том числе горько известный Razer FS. Но Razer FS, так примерно, больше не развивается, что, я не знаю, к счастью или к сожалению. Так он наоборот говорит, что Razer FS один из самых надежных. Я и говорю, что он самый надежный, но он больше не очень... он печально известен тем, что вроде бы как больше не развивается. То есть они в Razer FS проверяют большую часть ошибок возвращаемых, и что-то делают с этим. В пейпере написано, что большинство проблем в файловых системах происходит не из-за того, что люди писали код неправильно, и в этой точке не обработали ошибку, а из-за того, что концептуально у тебя схема построена неправильно, сама архитектура. И ты в этой точке, даже если получишь ошибку, не знаешь, что с ней делать. И поэтому там большинство комментариев вида «если нам вернется ошибка, мы будем молиться, чтобы она не вернулась, потому что мы ничего с этим сделать-сделать не можем». И все. Вот. Дальше там пара параграфов про то, как оно все на самом деле с дисками. Но я так понимаю, с дисками все не очень плохо, кроме одного такого интересного, занятного примера, что вот, мол, была какая-то серия дисков, у которых проблемы всегда были более-менее в одном и том же секторе. И теперь представим, что у нас построен рейд на этих дисках. А ну и что? У них проблемы с пролетарией, скорее всего, примерно в одно и то же время, примерно в одном и том же месте. И привет! По-моему, не с одной серии, это вообще известная вещь, что железо купленное, ну, как бы одно и то же железо, введенное в эксплуатацию в одно и то же время, дохнет примерно в одно и то же время. Нет. Не то, что сдохнут в одно и то же время, они сдохнут в одно и то же время, и у них, если это уникальная простая рейд с зиркалированием примерно с очень высокой вероятностью данные побъются на обоих дисках в одном и том же месте. Ну а так у тебя может сгореть райд контроль, ну в смысле, окей, у тебя может контроллер на диске сгореть в одно и то же время на двух дисках. Но данные при этом не потеряешь, если контроль разгорел. Ты их потеряешь на какое-то время. Ну да, но это не так фатально, как полное протеревание данных вот настолько. Это довольно феерично, мне кажется. Но вообще да, это известная тема, я согласен. А в завершение там как раз обсуждается то, что... как раз обсуждается то, что это все так, как оно есть, потому что это проблема сложная сама по себе, что сравнивается с тем, что это примерно так, как ребята изобрели Mutex и думали, что это будет удобно и можно будет пользоваться. А как выяснилось, что люди этим пользоваться не могут. Только машины этим могут пользоваться. Оказывается, примерно такая же ситуация у нас с файловыми системами. Стоит вопрос, как это тестировать. Тестировать это нужно всевозможным... Во-первых, статический анализ и всякие другие такие вещи, которые позволяют просто как тот папер, который находил ходил по коду... где авторы папера ходили по коду файловых систем открытых и просто посмотрели, где коды возврата не проверяются. То есть статический анализ и другие инструменты анализа кода, которые ловят хотя бы вот это. Во-вторых, всевозможный JEPSON, QuickCheck и такое с обставкой файлов. То есть мы берем, мокаем наш диск и как бы генерируем, где у нас должен произойти сбой. Ну то есть какие коды, в какой момент времени, какой syscall у нас вернет какую фигню. Ну, в сисном коде, он словно говорит. Ну ты же в какой момент делаешь syscall, ты же в какой момент делаешь syscall, ты делаешь или FFink или Parit или SetSendFile, что бы ты там ни делал, ты любой из этих вызовов можешь замокать. Но чаще всего ты все равно через библиотеку работаешь, библиотеку легче мокать. И... Ну я на самом деле примерно это и имел в виду, что что бы ты ни делал, ты это всегда можешь в какую-то прослойку вставить. И как бы ты делаешь модель диска, или даже это в памяти просто хранить, то что во время теста, не обязательно реальный диск писать. Главное, что в какой-то момент, во-первых, из вызовов какую-то фигню возвращать. А во-вторых, можно делать вид, что все хорошо, а на самом деле нехорошо. И то и другое нужно делать и проверять. И только так можно понять, что работает. Еще мне понравился там рассказ про один из пейперов, который был довольно давно написан, около 10 лет назад. И там лирическое обсуждение авторы сделали, что вот этот пейпер очень старый, но мы скорее всего не увидим новых результатов, из-за того, что в научной среде считается очень непопулярным делать обновление пейпера старых, потому что вам не дается такое же количество очков в карму, как если вы напишите новый пейпер на какую-то другую тему. Там не про очки в карму. Там все гораздо более печально. Там, я так понимаю, речь про реальные очки, академические. В том плане, что если ты студент в УЗИ, и ты делаешь курсач, грубо говоря. Я так подозреваю, что предыдущий пейпер это чей-то курсач или чей-то диплом. И когда ты делаешь это в первый раз, тебе это засчитают первое такое исследование, оригинальная работа, это все. А если ты делаешь реплику чужой работы, просто применимая к современным, тебе за это дадут буквально меньшую оценку за это поставят. Хотя сложность такая же. Такая же, да. И главное, полезность у этого может быть гораздо выше, чем у какого-то кардинального нового исследования. То есть это концептуальная проблема в научной среде. Ну, наверное, все. Чем у себя исчерпало. Интересно, допустим, получается, что на практике это больше волнует производителей баз данных, да? Чем простых пользователей. На самом деле, статья начинается с того, что чувак говорит, в общем, я тут недавно окончательно уехал со всех доступных мейл-клиентов и теперь живу только в Gmail. А все почему? Потому что у меня так много писем, что примерно раз в N-времени любой зараза, клиент десктопный, там, перечисляет, наверное, в спитоках, брал и корруптировал мне базу e-mail. И, значит, мол, решил я копнуть, а какого черта так? И дальше начинается статья. Да, это выглазно, конечно. На самом деле, если вы, в принципе, пишете на диск, то есть статью стоит читать и хотя бы первый параграф стоит понимать любому человеку, который вообще пишет на диск в своем коде. Like ever. То есть, если вы, конечно, не пишете в Dev.nu, я не знаю, зачем вы тогда пишете, вам нужно, наверное, знать, что такое fsync, как его нужно называть. В смысле, пишите на диск не просто логи, а пишите на диск полезную информацию, которую вам надо обязательно потом прочитать. Ну, на самом деле, бывают логи такие, которые нужно потом обязательно прочитать. Ну, не просто отладочные логи, скажем так. То есть там как раз про то и говорится, что не все это делают правильно, а потом очень сильно удивляются, что у них не получилось. Позвольте, я вставлю музычку. Я не понял, к чему эта отсылка, поэтому я даже не посмеюсь. А я и сам не знаю, откуда это. Тут очень много из каких-то фильмов и сериалов. Окей, Саша, ты начал задавать вопрос про тестирование, а потом мы тебя увели оттуда. Ты ничего больше не умеешь сказать по этому поводу? Ну, потому что я себе представлял, как единственный способ тестирования, что вот нужно взять машину, гонять ее под нагрузку и время от времени выдергивать из розетки. Сто раз прогнал такой тест, и надеешься, что если ничего не потерялось, значит все хорошо. Окей. Ну вот, но понятно, что это не означает, что у тебя на 101-й раз ничего не потеряется. Ну, на самом деле, никто не отменяет таких вещей как model checking, но просто это тяжело делать. То есть просто файловые системы пишут как бы на C. Ну или, не знаю, представим, что мы живем в послезавтра, и их там пишут почему-то на Rust. В любом случае, даже в случае с Rust-ом, тяжело взять и применить реально model checking к этому, потому что разрыв все-таки слишком большой. То есть в model checking легко применить коду на Erlang, потому что там очень простая, и там семантика вообще буквально повторяющая некоторые model checkers. А применить model checker к коду, который работает с мутабельной памятью, офигенно сложно. То есть как бы мы недавно обсуждали пейпер про то, как в MS Research сделали такой слоеный model checking, что такой подход, наверное, может работать, возможно. Но там они все равно это делают для довольно высокого уровня языка. А здесь все-таки совсем низкий уровень, и model checking делать можно, но крайне сложно. Тут, опять-таки, можно корректность доказывать, но опять-таки тоже слишком много всего нужно моделировать и доказывать. Хотя, наверное, можно, если очень хочется. А вот всякие рандомизированные тестирования, ну, наверное, должны работать неплохо. Что еще должно работать неплохо, это интеллект. Искусственный. И так, главное, что мы так считаем не только мы, но и такие ребята известные, как Грег Брокман, например, и многие другие, например, там... Позже. Я потерял глазами. Грег Брокман, Илья Су... Не, подожди, мне кажется, ты сейчас исследователя читаешь. А, нет, это директор. Сейчас. А, нет, да. Sorry, sorry. Ты действительно читаешь тех, кто вложился в это. Я как слушатель недоумеваю, о чем речь. Короче, всякие крутые, известные ребята, типа Элана Маска, Сэма Альтмана, Алана Кея и прочих таких классных ребят, которые много лет либо прямо деятельностью занимались, либо просто этим интересовались и имеют деньги, и они там какие-то интерпренеры, они взяли и запилили такой некоммерческий фонд OpenAI. То есть, это просто фундаментальное исследование в области пикетного интеллекта, который, в отличие от всякого венчурного капитализма, они не рассчитывают иметь как бы... Они не рассчитывают, что их вложения отобьются. То есть, просто, ребята-ресерчеры, вот вам бабло, ресерчики, пожалуйста, искусственный интеллект. Мы в вас верим. Один миллиард долларов, между прочим. Так, окей, а где расписаться и что надо делать? Ну, для начала нужно быть как бы топовым специалистом по AI в мире. Ой, да. Но, то есть, нам на самом деле на наших жалких человеческих простых смертных задницах нужно просто сесть, затаить дыхание и ждать. Лет 50. Так, когда нас... Да, мне кажется, с этим набором людей и этими ресурсами, мне кажется, лет 10, наверное. А потом нас, короче, Doomsday, SkyNet, вот это все. Ну, вот мне кажется, что они объединились, конечно, и классная команда, и все такое прочее, но мне кажется, что непонятно, что они в результате будут делать. Да? То есть, да, они будут что-то исследовать, но мне кажется, что AI сегодня вот так вот без прикладной какой-то области им сложно заниматься. То есть, когда перед тобой есть какая-то конкретная задача, там, чтобы машина ехала сама по дороге, то тогда да. А если нет, то вот так вот стерический AI вакуум, непонятно, что они будут делать. Знаешь, у них там на самом деле есть CTO, у них есть как бы типа... То есть, грубо говоря, у них там есть ребята, которые будут смотреть за тем, чтобы они занимались чем-то релевантным. Просто там идея в том, что... Ну, грубо говоря... Да, я скажу. Ну да, давай ты. Они говорят, что очень важно в этот момент отвязаться от финансов, потому что финансы будут диктовать, куда и в какую сторону идти. Они будут сами смотреть направление, на котором они смогут дать, как они говорят, максимальную productivity, то есть, производительность и максимальный фидбэк для реальных людей. То есть, они нацелены именно на результат, насколько я понял вот эту статью. Если там собралось на самом деле много умных людей, на самом деле они отвязались от денег, они могут этот результат дать, причем в той области, в которой они будут максимально успешны. Я поэтому... Извини, говори. Да, продолжи, продолжи, я уже все. Просто, грубо говоря, у нас есть там какая-то область, типа сейчас у нас, не знаю, модно распознавать картинки с котиками. И все коммерческие компании бегут распознавать картинки с котиками. А у нас есть, короче, группа умных мужиков, которые считают, что завтра нужно будет... Мы сможем, короче, понимать мяуканье. Но никто сейчас не готов откалывать денег. Эти ребята говорят, что мы точно через год сможем понимать, что там намяукал котик. И, короче, у них есть денег, и они берут просто и прикладывают свой бесконечный гений, и у нас правда через год мы можем понять, что мяукает котик. Хотя никто в это не верил. То есть направление-то есть. Просто не факт, что оно вот прямо сейчас все венчуруют и считают, что там деньги. Огонь. Что еще огонь? Да, давай. Я так понял, что тема все? Да, тема все. Следующую тему добавлял я, и Валер, я так понял, тоже ознакомился. Это пост в блоге pgaddict.com называется PostgreSQL с разными скедулерами, которые не процессы скедулят, а I.O. Их, оказывается, тоже много. В статье рассматривается три. Притом ситуация следующая. У чувака два SSD диска. На одном хранится write-ahead-log, он же redo-undo-log, и на другом хранятся данные. Он попробовал, поэкспериментировал, включал для разных дисков разные скедулеры, гнал pgbench и смотрел на результаты. Где будет больше транзакций в секунду. Что интересно в этой статье, что... Вот у меня всегда был напал вопрос. Ты когда запускаешь бенчмарк, пгbench, ты запустил один раз, он тебе показывает тысячи транзакций в секунду. Ты такой, классно. Запускаешь второй раз, он тебе показывает тысяча двадцать транзакций в секунду. И у тебя есть такой разброс, он может быть довольно большой, из-за разных побочных эффектов. Потому что мы понимаем кэшфайловые системы, и рядом программы тоже немного работают. Как эти цифры трактовать, брать средние, или считать ошибку, как на лабораторных, по физике, три измерения, потом посчитали среднюю кубернатичную ошибку, или как там ее. Не ясно. А в этой статье мне очень понравилось. Тут приводятся такие красивые графики, видим в гнуплоте нарисованное. Рассматривается вероятность получения определенного... Представим себе график. По оси у и х количества транзакций в секунду, по оси у и у вероятность. И делается ряд замеров. У тебя получается такая кривая, что например мы с вероятностью 50% получаем во сколько-то транзакций в секунду. Потом график идет выше, ниже. И чисто визуально посмотрев, можно довольно неплохое составить впечатление о том, как себя ведут те или иные настройки, в данном случае вот эти шедулеры, скедулеры. То есть ты можешь понять, что вот тут какой-то разброс довольно большой, не очень понятный. Здесь у нас больше ТПСов, но вероятность небольшая и так далее. Довольно интересный подход. Я такого раньше, честно говоря, не видел. Может, это где-то в научных статьях вообще-то встречается. Вообще, CDF, я в принципе видел раньше CDF. Это действительно очень здоровский подход. И действительно очень мало где бенчмарки прям так это делают. Но одна из не более таких не очень известных программ для бенчмарки для баз данных, которую я бы хотел посоветовать, это BASHO Bench. У них есть драйверы не только DARIAC, у них много для чего есть драйверы. Так, по секрету. Они не рисуют CDF. Во-первых, они не собирают достаточно данных, чтобы CDF нарисовать. И они рисуют все равно R. Во-вторых, они рисуют просто отдельные процентили. То есть CDF, конечно, интересен тем, что там можно посмотреть, какие процентили разлетаются. Притом как бы сразу все. BASHO Bench просто рисует те процентили, на которые обычно реально смотрят. То есть в принципе, это довольно валидный подход. Особенно учитывая, что если мы бенчмаркаем конкретную базу, нам, наверное, интересно посмотреть на те же цифры, которые у нас будут потом в метриках собираться. Наверное, поэтому выбран такие данные для нарисовывания. Но в плане в целом подхода к бенчмарку, что там не один-два раза прогнали, ночь гоняем, потом собираем такую статистику и показываем. В этом плане BASHO Bench тоже довольно хорошая штука. И тоже правильно и хорошо собирает статистику. Что еще мне в этом бенчмарке понравилось, он вообще в целом довольно грамотный. Здесь полностью описана конфигурация. То есть железо, версия, в данном случае djento. Софта, которые используются вообще все, лежат исходники на битбоксе. То есть прям любой желающий может взять и попытаться повторить. И какие результаты получены, что интересно, не имеет большого значения, какой используется скедулер для диска, на который пишется write-ahead-log. Ну, кстати, я бы сказал, что это неудивительно. Ну, потому что последовательная запись, да? Все примерно одинаково хороши. Так, при том... Что я хотел сказать? Видимо, я продолжил твой мысль, я пробовал предложить, что большое значение при том оказывает то, какой скедулер выбран для того диска, который стоит на перезаписываемой колдунце. Да, я вспомнил. Считается, что это стандартная конфигурация, когда у тебя write-ahead-log и данные по двум дискам разделены. То есть он говорит, что большинство реальных клиентов, они делают так. Поэтому, собственно, такая конфигурация используется. Да, продолжай, Валер. Что же имеет значение? Имеет значение то, какой у нас скедулер стоит на диске с перезаписываемыми данными. Традиционно считается, что там, ну, CFQ, как там, completely fair queen, наверное, или что-то такое. Не помню точно, как он шифровывается. Он самый плохой вообще традиционно считается. Дальше deadline считается такой, типа, дефолт, который, ну, более-менее всех устраивает. И рекомендуется, если у вас там rate массивый или за диски ставить вообще no-op, типа, вам на самом деле не нужен скедулинг, вам нужен просто довериться диску. Тут внезапно бенчмарк показывает ровно противоположную картину. То есть deadline, как обычный середнячок, а вот CFQ и no-op, они, короче, вот так получается, что CFQ всех ровет, он, во-первых, очень быстрый, ну, если быстрее, заметно быстрее, а во-вторых, он при этом еще и гораздо более стабильно себя ведет, то есть у него меньше разлет процентилей, что по задержке, что по количеству транзисторного, причем попугая в секунду. И, как бы, автор в самом блоге он не очень, как бы, сказал, типа, ну, это интересный результат, надо попытаться понять, почему. К нему в комментарии пришли и сказали, что, чувак, ты бенчмарки проводил на Linux с Kernel 4.4, тут буквально в Linux Kernel 4.2 занесли интересный патчик, который CFQ, то есть раньше CFQ работал всегда так, что он, типа, честность замерял просто по времени, проведенному в диске. А всякие диски типа SSD, с ними это не очень хорошо коррелирует. Но там у них есть какая-то хардварная фича, не помню, как называется, которая позволяет, там, какую-то другую, короче, метрику запрашивать. И, грубо говоря, теперь CFQ умеет не по времени шедурить, честно-честно, а по количеству потребленных IOPS-ов, или там каких-то еще попугаев, которые вот этот железок отдает. И внезапно, после вот этого вот изменения, он становится гораздо более крутым, чем все остальное для, вот, как бы, workload-ов, даже на SSD. Рейды не измеряли, но я подозреваю, что рейды это, скорее всего, тоже поддерживает, большая умная железка тоже должна поддерживать. Вот. Единственный бенчмарк, в котором NOP все равно выигрывал, это минимальная латентность, ну, в принципе, неудивительно, потому что отсутствие подланировщика, ну, это минимальная латентность, которую можно гарантировать. Но, притом, максимальная латентность страдает. И, при этом, эта самая минимальная латентность, она не то чтобы значительно отличается от CFQ. Вот. Там реально какие-то, короче, десятки микросекунд. Ну, они все рядышком идут, эти трибуки, они, вообще, минимальная латентность, она у этих всех планировщиков отличается незначительно. Ну, там, где-то в районе, наверное, то есть там самое минимальное значение от самого, типа, большого значения стоит на, ровно на сотню микросекунд. Вот, типа, самая-самое большое, нет, даже не-не, самое-самое большое, от самого-самого большого значения, наверное, на две сотни. Ну, короче... Сотни микросекунд, и при этом как это, между кривыми расстояния... Нет-нет, подожди. Между кривыми всегда расстояние десятки. Да, ну, то есть, вот, ты не так посмотрел, тебе нужно провести под оценку чего-то. Я посмотрел так, я имел ввиду, что, типа, самое минимальное значение по любой кривой и самое максимальное значение по любой кривой, то есть, типа, вообще глобально, опазон, по которому мы смотрим, он в несколько сотен микросекунд. Я это имел в виду. А разлет кривых при этом между собой десятки микросекунд в каждом месте. И к тому, что даже скейл рассмотрения у нас тут недостаточно, чтобы оно одно другое как-то било куда-то. Вот. На самом деле, чувак ушел делать бенчмарки на старых версиях Кернелла, а также на новых версиях Кернелла на рейдах. Он обещал вернуться, но пока не вернулся. Я подписался на комментарий к этой статье и буду с попкорном ждать обновлений. Он улетел, но обещал, да? Да. Кто еще нам обещал? Это Андрей обещал рассказать про статью. Да. На самом деле, я ее не принес. Но мне ее подкинули. Продолжая тему... Статья подкидыш. Да. Да-да-да. Продолжая тему баз данных, в частности, POSGrid, хорошая... Удивительная рядом хорошая статья на Хабрахабре. Такого давно не видел. Которая громко называется применение машинного обучения для увеличения производительности POSGrid QL. Статья от компании. Компания называется POSGrid Professional. Наверное, это какой-то там из серии. Сервис провайдер POSGrid. И, соответственно, статья больше имиджная. Там же Бартунов. Я же в России не живу. Я их никого не знаю. И POSGrid для меня это просто скили туда и скили обратно. То есть, я не слежу за тем, что там внутри происходит. Но в целом статья хорошая. И на самом деле компании большое доверие возникает после ее прочтения. О чем они говорят? О том, что когда мы делаем запросы, то, соответственно, база данных хочет как-то спланировать эти запросы. То есть, мы пишем просто там из таблиц. Мы их как-то джойним. Соответственно, у таблиц могут быть индексы. И в каких-то случаях, если, например, мы делаем джойн трех и больше таблиц, то можно воспользоваться джойнить эти таблицы в разной последовательности. Соответственно, у нас для одного и того же запроса могут быть использованы разные планы. Планы выполнения. И они рассказывают о том, как эта такая немножко обзорная статья, как это все выглядит внутри. И после этого они говорят, что да, это хорошо, но в результате для того, чтобы базе данных работать, она должна примерно оценить разные варианты. Или понять, какой план выполнения запроса использовать. Есть разные реферистики. И в конце концов, когда мы выполняем запрос, мы как бы изначально имеем какую-то оценку, estimate базы. Сколько нам придется рядов обойти. Причем, не только рядов таблиц, но и рядов индексов. А в результате у нас появляется какое-то фактическое значение. Сколько же пришлось обойти на самом деле. И вот чем ближе исходная оценка и конечный результат друг к другу, тем лучше. Потому что база может прогнозировать, сколько времени запрос займет. И соответственно, там можно иметь какие-то инструменты поверх, чтобы понять какие запросы делать стоят, какие не стоят. И они говорят, что вот у нас есть набор исходных оценок, у нас есть набор конечных результатов. И если использовать машинное обучение, то можно постепенно наш алгоритм получения estimator улучшать со временем. Рассказывают о том, как они это видят. Что там можно линейной регрессией смотреть на вот эти результаты. Что условия внутри спецзапроса могут быть зависимые и независимые. И что в каких-то случаях это можно каким-то образом использовать. К сожалению, статья на самом деле состоит из двух частей. Первое, мы подумали, как она устроена. И такой problem statement. Второе, мы сделали какие-то эксперименты. И вот как оно получилось. Но в конце хотелось бы увидеть ссылочку на какую-то вундервафлю или ключик, или еще что-то, что можно было бы включить, и оно бы работало у вас. Но на самом деле вундервафля никакой нет. Я так понимаю, что это все-таки в процессе. И в конце они говорят о тех, какие есть риски с этим связанные. И какие есть как бы какие есть идеи на тему как этот процесс можно улучшать дальше. Вопрос о дополнении. Как я понял, оно... Пока нет хорошего решения. Это просто теория. Я так понял, это патч, который не работает. Я думаю, да. И возможно, этот патч какой-то... Возможно, в какой-то момент они его захотят продавать отдельно, как настройку, поверь. А может быть, как бы... Может быть, если вам интересно этим заниматься, возможно, можно им постучаться, устроиться к ним на работу и добить эту работу до конца. На самом деле, если бы я читал об этом... Это вот сейчас, когда я много-много лет занимаюсь разработкой, я сразу смотрю серии. Какое я могу поставить себе сейчас, чтобы у меня все было хорошо. Но если бы я темой того, как база данных устроена изнутри, или темой того, как можно... Как обладает машинное обучение, просто вот интересовался, то это клевая вводная статья, чтобы показать с одной стороны из серии исходники базы или еще что-то. То есть лет 10 назад я бы эту статью прям вот зачитал до дыр, и все-все ссылки, которые в этой статье были, все посмотрел. Поэтому, если вас интересуют вот такие темы, то обязательно посмотрите и почитайте. Мне кажется, она интересна не столько даже с точки зрения машинного обучения, про него здесь как раз довольно немного, а с точки зрения того, как устроены кишки подгросса, то есть что такое сексскан, что такое индексскан, какие есть три способа реализации джойнов, то, что как реализовать кишки подгросса, то, что как работает оптимизация запросов в Postgres, например, что есть генетические алгоритмы там где-то внутри. То есть прям можно неплохо... Да, еще какие возникают проблемы при зависимых условиях. Прям реально интересно. Следующую тему добавил я. Она опять про Postgres. У нас такая пачка тем про Postgres. Две статьи, небольшие, поэтому буду краток в известном блоге dpsz.com. Я не знаю, как это по-другому произносить. Это блог, в котором описываются нововведения, которые нас ждут в ближайшей версии Postgres. Чувак следит за коммитами в мастер и как бы разбирается, что за изменения попадают в будущую версию. Сейчас будущая это 9.6. Первое изменение это мы говорили про возможность параллельного распараллеливания некоторых запросов в Postgres. И была проблема, что нельзя было посмотреть какие... Не было подробностей про время выполнения запросов по воркеру в X-Plane, в X-Plane Analyze и так далее. Это появится в 9.6. И второе изменение касается флагов усилителя psql. Сейчас есть такая проблема, что если ты говоришь psql-c какая-то команда, притом там может быть несколько команд через точку запятой, то виден результат только последней команды. Патч заключается в том, что можно указывать несколько команд с разными флагами. Они все выполняются, у всех вводится результат. Я понимаю, что это не супер такая грандиозная новость, но я с очень большим удовольствием читаю этот блог и советую всем подписываться, чтобы быть в курсе таких маленьких, но важных вещей. Вы как считаете? Нужно, не нужно? Кто вообще кроме меня читает этот блог? Я читал, когда мы сильно Postgresом пользовались. Сейчас перестали и я перестал. Отписался. Полезный, согласись. Полезный, если ты сидишь и хочешь видеть, что происходит и какие улучшения добавляются и в ближайшем будущем появятся в версиях. Я примерно похожим образом слежу за React, а за Postgres я пока так пристально следить не готов. Мне кажется, чтобы иметь хорошую пользу от такого блога, нужно иметь уже более-менее приличное представление о том, как оно все уже внутри работает, чтобы по описанию комита понять, что происходит. Нет, нет, подожди. Тебе как читателю этого блога совсем не обязательно понимать, как оно внутри работает, потому что здесь именно идея этого блога в том, чтобы объяснить тебе фичу. Тут в статье приводятся примеры SQL. Смотрите, вот мы выполняем тот, и раньше она работала так, а теперь мы можем сделать вот это. То есть это он анализирует комит и объясняет тебе, что там происходит? Звучит довольно здорово, потому что в случае с React я подписан на пол реквеста. Ну и тут, разумеется, есть ссылки на сами комиты, то есть при желании можно и понять, какие изменения были сделаны в ходе. Но это уже там по хардкору надо угорать. Возвращаясь к React. Нет, возвращаясь к угоранию по хардкору. Ну, в общем, возвращаясь к обоим темам, я последний раз, когда был в подкасте, сказал, что был на Erlang Factory Berlin, и там были записи, была запись видео. Наконец все видео полностью выложили, из них собрали плейлист, как бы, я приглашаю слушателей к просмотру этого плейлиста. Он будет в шоу-ноутах. К сожалению, один из докладов, похоже, сняли оттуда, ну, то есть, как бы, там в плейлисте энтри с ограниченным доступом. И, как бы, тот самый первый открывающий доклад, видимо, не знаю почему-то, видимо, там что-то, видимо, произошло такое, чего не захотели оставить на записи. Не знаю. Вот. Я доклад, как бы, я его пропустил живьем, и я не успел посмотреть его онлайне, поэтому у меня даже нет идей, что могло такого быть. Я напоминаю, что интересными докладами, то есть, если вы хотите посмотреть один доклад, смотрите QuickCheck Mini for Elixir за авторством Томаса Артса. Если вы хотите, если вы уже знаете про QuickCheck, но почему-то не знаете про то, как дизайнить распределенные системы, можете посмотреть закрывающий ток Франческа Чезарине Concurrency Plus Distribution Equals Scalability Plus Availability. Если вы более-менее в теме, то мои фавориты это Diabolical Database Design Heinz Geisse, и потом вслед за ним Unleashing the Core Value Торбена Хоффмана. Вот. Остальные, ну, как бы, в принципе, более-менее можно пропустить. Там, ну, дальше решайте сами, короче. И из таких маленьких хайлайтов еще там есть такая штука Lightning Talks. Там есть, ну, два доклада. Один из них лично мне интересен, потому что там был не кто-то, а Сергей Юрьевич, который мы упоминали еще в нашей бытности Ягдскаста. Автор такой интересной базы данных, как Actordb. Вот. Он там немножко про него рассказывает. Второе, это Shameless Plug. Я там небольшой доклад 5 минут на Pre-Record сделал. Правда, если вы не знаете, о чем идет речь в докладе Unleashing the Core Value, то, как бы, о чем пойдет речь в моем докладе вы тем более не поймете, поэтому как бы стоит посмотреть вначале Diabolical Database Design, потом Unleashing the Core Value, а потом, если вдруг вы почему-то хотите меня посмотреть и послушать, можете посмотреть и послушать в Untaught. Вот, как-то так. Отлично. Есть пара ссылок, которые я хочу просто упомянуть. Это, во-первых, на сайте Hacker.ru элитным грандиозным сайте. Появилась новость об том, что утекла инфа о всяких шпионских устройствах. Очень интересно с ней ознакомиться, особенно будет интересно тем, кто считает, что их телефонный разговор нельзя подслушать, что СМСки не перехватываются. Тут даже есть специальное устройство, которое может удаленно сливать заметки в удаленные заметки из телефона, такого рода. Просто сходите, знакомьтесь, чтобы знать, что такие вещи бывают. Вот. И еще, если кому-то интересно, есть такая игра, называется Street Fighter. У нее в 2016 году выйдет Street Fighter 5 и новый заключается в том, что он будет под Linux. Я лично, наверное, даже ее куплю. То есть, это все через Steam. Подождите, подождите. У меня такой вопрос. В файтинге на вообще PC под любой операционной системой выходит крайне редко. По одной интересной причине. Как правило, у владельцев PC нету геймпада. А владельцы геймпадов обычно имеют геймпад, потому что у них есть какая-то приставка. Зачем тебе геймпад, объясню. Для игры в файтинг? Серьезно? Ну, слушай, я вот играл в какой-то старый Street Fighter. Это выглядит так, что это как аркада. Ты такой идешь по городу, у тебя как бы WASD и там кнопочка типа бить рукой, бить ногой, и все. В чем проблема? Аналогично. Я тоже играл в Street Fighter. Когда мне говорят в файтинг, я конкретно в Street Fighter не играл. Это не Mortal Kombat, это не такой файтинг. Это больше такая аркада, где ты не стреляешь, а машешь руками. Окей. Да, больше похоже на игрушечки на Dendy. Так, так, так. Я предлагаю попробовать тема слушателей. А там как посмотрим. Нет, не так, как получится. Согласны? Окей. Пока я открываю, я помню, что там точно было про DataGrip, кто хочет рассказать? Если честно, у меня темы слушателей открыты, но в принципе я могу про DataGrip рассказать. Когда-то это был XDBA, то есть это проект от Intel JBrains, компания, которая делает вот эти среды разработки идею и всякое такое. И они решили делать среду разработки для SQL, для баз данных. Вот. Ее были очень-очень давно, я не знаю, наверное, больше года. И сейчас они наконец-таки ее зарелизили, переименовали ее, вот это название XDBA, оно там с нулем в начале, что-то там такое, оно было рабочим, и теперь оно называется DataGrip. Вот. Это такой отдельный инструмент. В принципе, я вживую от разработчиков на SQL, которые писали много-много SQL, последний раз выйдет где-то году 2012, наверное, и тогда они все сидели там на уроке на SQLDeveloper, и даже самый первый яблон был сильно-сильно интереснее, чем SQLDeveloper.",
    "result": {
      "query": "PostgreSQL scheduler performance comparison"
    }
  }
]
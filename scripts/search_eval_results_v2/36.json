[
  {
    "segment_id": "5a51a686-3b7e-48cd-9d6e-8aa050c082c3",
    "episode_id": "549d427b-ee49-43d2-b570-b8d49923902f",
    "episode_number": 36,
    "segment_number": 3,
    "text": "Неправда. Довольно странно получается. Неправда. Во-первых, backend это одно, фронтенд это другое. Во-вторых, если говорить о интелском компиляторе, то, что я говорил, это относилось к интелскому компилятору несколько лет назад. Сейчас там происходят довольно бодрые изменения динамичные, про которые, наверное, я не могу говорить, потому что это немножко коммерческая тайна. Кому очень интересно, приходите к нам на собеседование, вам там может все и расскажут. А если говорить о GCC и LLVM, вот LLVM сейчас это жесткая C++ программа. Читать код LLVM без какого-то тула, который тебе помогает найти определение вызванной функции, сложно, потому что там есть перегруженные какие-то операторы, которые тебя перенаправляют бог знает куда и так далее. Поэтому LLVM, по крайней мере, программа на C++ 11, и она так хорошо на C++ 11. Про GCC не скажу, но GCC Community имеет свойство такое, средняя длина бороды в GCC Community, она слишком большая, чтобы они динамично переключались на C++. Но там этот процесс, по-моему, тоже двинулся с мертвой точки. Так, неужели у нас кончились вопросы к гостю? Есть ещё парочка, но я думаю, что это всем будет неинтересно, я поэтому стерпел и не задал. До после шоу. Ну тогда если походу возникнут, то мы зададим. Я предлагаю пока потихоньку двигаться дальше, там всё равно очень много тем за C++, за RUST и за всё остальное. А следующей темой Ваня расскажет, где его носило два выпуска. О да. Я первый раз отсутствовал, потому что поехал на конференцию, и как раз в тот момент, когда вы записывались, я был в этот момент на конференции Erlang Factory. И это была моя первая поездка в Сан-Франциско именно на большую конференцию Erlang Factory, а не какие-то там минорные Erlang Factory в других городах, которые обычно намного меньше. В целом я очень доволен, мне всё очень понравилось, я пофоткался с Джо Армстронгом. У меня теперь есть такая личная фотография, я очень рад и счастлив. Извини, я просто заметил, что все Erlang-исты, настоящий крутой Erlang-ист должен иметь фотографию с Джо Армстронгом и держать её дома в рамочке, ты просто не первый, кто этим хвастается. Ну вот, я не крутой Erlang-ист, фак. Добро пожаловать на следующий Erlang Factory. И в целом мне доклады понравились, то есть уровень докладов довольно высокий. Есть, конечно, совершенно полный неинтересный отстой, но зато есть такие доклады, которые редко где ещё дополнительно услышишь. Я могу вкратце приближаться, что мне понравилось, и ссылки потом накидать в шоу-ноты. Во-первых, мне понравился Кристофер Майкледжон. Майклджон. Майклджон, спасибо большое. Distributed, Eventual and Consistent Computations. Вот этот доклад был вторым на конференции, ну в смысле, вообще по счёту, куда я пошёл. То есть, первый – это почти вступление, а второй – это как раз этот доклад. И он просто реально взорвал мне мозг. Если вы будете смотреть видео, я думаю, вы поймёте. Человек по стилю… Да, вроде там всё нормально. Он всё нормально, он интересно делает вещи, но если ты не очень сильно знаком с тем, чего он касается, то есть, какие-то он упоминает, например, концепции, какие-то он упоминает тулзы и так далее, и если тебе это не всё очень сильно известно, то при его скорости рассказывания и упоминания всех этих концептуально сложных вещей довольно тяжело даётся. К концу он постоянно начинает ускорять темп речи, и к концу он говорит намного быстрее Валеры. Я вообще думал, что такое невозможно, но вот оказывается, такие люди и есть. И когда он переходит к последним 5 слайдам, он последние 5 слайдов пролистал за 5 секунд, вкратце рассказывая, что это такое. Это вообще было просто чума. Очень здорово, мне прямо понравилось. На практике, я боюсь, у него было время ограниченное, он пытался уложиться. Так и есть, да, но я так не смогу, вот это точно. То есть, даже если времени мне не будет хватать, я забью на часть слайдов, вот и всё. А, кстати, там был очень интересный человек, который, я сейчас уже не помню, на каком-то из докладов, но мне понравилось, что он рассказал полностью свой доклад, всё чётко, вот вопросы, это последний слайд, типа такого. Ему задают вопрос, он отвечает вопрос, отвечает потом какой-то вопрос, он говорит, о, кстати, это очень интересный вопрос. И вот у них последний слайд questions, он перелистывает на следующий слайд, и у него там ещё десяток слайдов, которые специально для таких вопросов, и вот для этого вопроса есть два слайда, он там про него рассказал что-то. То есть, я вообще первый раз такое видел, чтобы именно для отдельных вопросов, которые, может быть, зададут, создавали специальные слайды, которые не показывались на основной части доклада. А это, кстати, довольно уже часто виделось на презентациях, вот идёт последний слайд, спасибо за внимание, вопросы, и потом идут бонусные слайды. Да-да-да. И там такая, я часто это уже встречаю. Ну, их ещё называют backup слайды, туда действительно выносят часто какие-то интересные вещи, которые, скорее всего, спросят. Вот-вот. Значит, на второй день был Андреас Олафсон, Why Simplicity Matters, Hardware Perspective, и он рассказывал про, это вообще не про Erlang в целом, а про железячную тему, они взяли, я так понимаю, на кикстартере начальное вложение денег, и сделали за счёт него какую-то платку с большим количеством параллельных процессоров, ядер, ядер на одном процессоре, и он высоко параллельный, они добиваются большого количества, большой производительности, при этом маленького потребления энергии, то есть у него текущая вещь, которую они сейчас доделают, там 50 дает гигафлопов, при этом меньше 2 Вт энергии. И это всё здорово, за исключением того, что вот эти ядра, они очень-очень маленькие, у них очень-очень мало памяти, и они работают как бы в параллель. Для того, чтобы их правильно загружать, нужно либо специальное новое программное обеспечение, которое они пока не могут подобрать, как это правильно сделать, и ближайшее программное обеспечение, которое близко по духу, но пока не способно покрыть эти нужды, это как раз Erlang. Он как раз рассказывал по этому у нас, в смысле у нас на конференции по Erlang, потому что ему необходимо рассматривать эти отдельные ядра как отдельный эктор, который выполняет свою линию поведения и обменивается именно какими-то сообщениями, микросообщениями с другими ядрами для того, чтобы построить вот эту высокопроизводительную систему. Но в целом у них roadmap очень страшный, я не знаю, смогут ли они его выполнить. К 2018 году, например, у него цель сделать 64К ядер на маленькой платке. Размер платки, чтобы вы понимали, это размером с кредитку, то есть это вообще реально микроустройство. И 0,2-12 Вт мощность должна потреблять. Они говорят, что теоретически, судя по текущим оценкам, они успевают это сделать. Вопрос только, кто будет потребителем, потому что пока нет возможности их полноценно заиспользовать. Тоже очень интересный доклад, чувак очень легко рассказывает про довольно сложные вещи, я рекомендую, если кому интересно. У меня вопрос. Какие задачи они пытаются там решать? То есть понятно, что ядра очень слабенькие. То есть с вычислительной точки зрения, если ты хочешь молотить очень много чисел, тебе гораздо выгоднее поставить большое количество вычислительных устройств и их сделать достаточно энерго-жрущими. Фактически у тебя получится GPU. Если они делают большое количество очень слабеньких ядер, значит они решают какую-то очень специфичную задачу. Вот как раз интересно, что же они пытаются сделать. Я не готов тебе полностью ответить на вопрос. Я могу сказать, что он говорил про их видение трендов развития современной архитектуры чипов. И это ему очень сильно напомнило именно Erlang-архитектуру. То есть максимальная параллелизация с уменьшением ценности каждого отдельного ядра. Почему-то ему кажется, что именно за этим будущее возможно не только с точки зрения, что так, не знаю, правильнее программировать, а возможно с той точки зрения, что это намного легче прототипизировать. То есть у тебя не надо делать очень сложные ядра, которые будут сильно-сильно производительными. То есть чем дальше, тем сложнее их становится создавать. А можно сделать какой-то шаблончик на маленькое ядро, а потом его параллельно поставить, их там куча штук с разводкой какой-то. Очевидно, по одному запросу или по одному коннекту на ядро. То есть поднял 10 тысяч ядер на каждый по актеру, нет? Он на самом деле там касался именно железячных вещей, которые я сейчас частично уже не помню. То есть он говорил про теоретические пределы, к которым движется текущая технология, как скоро она его достигнет. И для примера он давал такую вещь, что если посмотреть, как программное обеспечение развивалось в конце 90-х, я сейчас не помню точно года, они сделали оценку и поняли, что через 20 лет, если точно так же, и не будет никаких улучшений в способах разработки именно ядер, то через 20 лет для того, чтобы разработать ядро, которое по уменьшающимся технологиям будет нужно к тому моменту, потребуется количество человеко-часов больше, чем есть людей на планете за интервал выпуска этого процессора. То есть именно сложность увеличивается нелинейно и становится все сложнее это делать. Я не знаю, есть ли в этом резон какой-то, я потому что далек от разработки железяк. Вань, давай я вставлю свои 5 копеек. Конечно, конечно, ты ближе всех. Я ближе всех, наверное, к железякам и к архитектурам. Так вот, если речь о ядре как таковом, который пытается выполнить сингл сред с максимальным перформансом, то мы практически уже уперлись в предел. SuperScalar улучшается, то есть Intel выпускает каждые 2 года новую архитектуру, микроархитектуру, и улучшение за счет непосредственно смены архитектуры, ну процентов 5, 10, 15. Вот такой порядок. То есть это совсем копейки. Весь прирост идет за счет закона Мура. Но вопрос в другом, что мы можем поставить огромное количество ядер рядом, если мы их можем загрузить, прекрасно, но большинство задач это требует сингл сред перформанс, и в один поток как раз очень непонятно, как считать. А мне вот понятно, как считать, просто надо писать не на этих тормознутых Java или Erlang, а на C++, ну или Rust хотя бы. Не, ну конечно, язык, который позволяет тебе максимально эффективную программу написать близкую к железу, он тебе позволяет раскрыть потенциал железа. Но железо-то тоже очень ограничено в своих возможностях. Есть исследования, которые говорят, что в современных сингл сред программах, то что мы называем сингл сред, есть потенциал параллелизма, который позволяет ускорить их в несколько раз. Вот как вытащить этот параллелизм из сингл среда и исполнять его в параллель, это очень интересная задача архитектурная, кто ее решит, тот будет следующим королем архитектур на ближайшие пару десятков лет. Я извиняюсь, а Intel разве своих еще чуть ли не Pentium не научился это распараллеливать? Вот конвейерная, как это называется, конвейерная обработка инструкций, вот это все. То есть на самом деле инструкции ансэмблерные, которые идут друг за другом, они выполняются параллельно, если они по данным не зависят. Естественно, любой современный чип он auto-forger. Что это означает? Это означает, что мы исполняем поток команд, и когда уперлись, что в следующей команде у нас данные не готовы, мы ее откладываем, берем следующую, пытаемся ее исполнять. Если для нее данные готовы, то мы ее исполняем, и так далее. Так вот, здесь возникает проблема в том, что, во-первых, окно auto-forger ограниченное, потому что, фактически, чтобы сделать окно auto-forger для N команд, сложность в железе квадратичная. Для 10 команд у тебя сложность 100, для 30 уже гораздо хуже. Если я ничего не путаю, в современных auto-forger процессорах, десктопных, окно порядка 30 команд. Могу немножко напутать, но порядок примерно верный. Но при этом не стоит забывать, что все эти пляски с бугном, которые делает процессор внутри себя, они не идут бесплатно. Во-первых, мы адски сжем электричество и энергию на это дело. Во-вторых, мы тупо могли бы заняться, вместо того, чтобы пытаться этот параллелизм вытащить, просто полезной работой. Есть исследования, которые говорят, что в 2-3, может, в 4 раза можно ускорить эти программы просто за счет того, что извлекать больше параллелизма из этих single thread программ. Кстати, вот этой темой у нас активно в интеле занимается в России небезызвестный товарищ Борис Арташевич Бубаян, который активно занимается архитектурами. У него там есть свой взгляд на то, как решить эту проблему. Опять широкое слово? Нет, широкое слово, оно в прошлом. Все уже точно забыто? Да, оно критикуется активно всеми людьми, которые занимаются архитектурами сейчас. У Бубаяна новая идея, я, наверное, не могу так открыто про это говорить, но смысл в том, что я говорю об общих архитектурных трендах, поэтому тут, наверное, не есть большой секрет. У нас всегда есть какой-то artificial binding в архитектуре. Что такое artificial binding? Это какое-то свойство архитектуры, которое не свойственно для задачи. В современных процессорах в single thread именно single thread. Мы иногда хотим писать в несколько потоков, которые бегут рядом одновременно, не на соседних ядрах, а на соседних исполняющих устройствах. А система команд нам говорит, что нам нужно записать это все подряд. Соответственно, программа приходит записанная последовательно к процессору. Процессор снова ее раздербанивает на параллельные исполняющие ветки, исполняет. И после того, как исполнил параллель, он должен убедиться, что результат будет записан в память и эффект виден вне процессора снова в последовательном порядке. Это вот artificial binding. Когда широкое слово, у нас получается, что artificial binding сохраняется. Мы просто пытаемся заставить процессор, эти исполнительные устройства работать синхронно. Следующая идея, которая витается в воздухе, и я ее слышал много от кого, то, что надо как-то избавиться от этой архитектуры, которая нас заставляет либо все в одну линейку исполнять, либо у нас есть такая гребенка, как в широком слове, когда мы исполняем несколько инструкций одновременно, переходим к следующим инструкциям, и если одна инструкция там встала, то чехол. Надо от этого как-то уйти. Все решают эту задачу по-разному. Борис Арташевич и есть свои оригинальные взгляды и идеи. Но я думаю, мы в индустрии в любом случае увидим, как эта проблема будет решаться в следующие несколько лет или несколько десятков лет, наверное. Вань, продолжи. Да, я в лес тут. Ты очень интересно в лес, ты молодец, что в лес. Ты все правильно делаешь. То есть мы-то Ваню расспросить, где он шлялся, всегда успеем, а вот гостей послушать не всегда. Тем не менее, Вань, продолжай. Я дальше пойду. Да, следующий доклад – это доклад Лукаса Ларсона про изменения в самом Erlang, о том, какие проблемы, оказывается, в Erlang стояли с таймерами и с правильным отображением и пониманием, сколько времени в настоящий момент в системе. Имеется в виду как раз последнее изменение, которое появилось в 18.0 релиз кандидатия, о том, что Erlang Now необходимо разделить на несколько функций.",
    "result": {
      "query": "CPU architecture parallelism future"
    }
  }
]
[
  {
    "segment_id": "bff499d5-ab20-4afd-b1e3-1e661cc6fecf",
    "episode_id": "eca52432-b91c-4544-bf75-7b32a5e2f7de",
    "episode_number": 405,
    "segment_number": 12,
    "text": "Размер ключа должен быть где-то от 8 до 105 байт. И вот меня особенно зацепило, размер базы данных, сколько на диске будет занимать твоя база данных, задаётся в библиотеке в compile time. Я сначала очень сильно это не понял, но потом, когда я дальше смотрел доклад, я вдруг понял. Я понял, что у них очень особый use case, потому что что они на самом деле пишут... Вот у тебя есть диски физические, которые ты пробрасываешь клиентам как виртуальные, а есть индекс, который виртуальные адреса клиентов маппит физически. И у них задача – это взять отдельный диск. Опять же, как я понял, это прямо нигде не говорится, но моя интерпретация – они берут один или несколько дисков в RAID, который всё равно у них виден как виртуальный файл, с точки зрения этого их движка. И нужно вот в этот RAID массив или в диск положить индекс из виртуальных адресов в физические. По этой причине у них... Ты должен в compile time сказать, что мой RAID с индексом, у него, не знаю, 1 терабайт. Всё, ты это знаешь, мы точно в этот RAID больше дисков засовывать не будем. И после этого они обладают информацией и работают. И обладая вот этой информацией становится намного легче понять остальную часть доклада, потому что если её вот без этого контекста слушать, то можно очень сильно удивляться. То есть они говорят, что хранят всё в блоках по 4 килобайта, и их задача, собственно, построить индекс из этих блоков. Теперь мы понимаем, откуда эти 4 килобайта берутся. Видимо, они считают, что в современных дисках это соответствует какому-то физическому размеру блока на SSD. Я должен признаться, я не настолько секунду, я слышал, что это правда. Потом очень долго и мучительно объясняется их придуманное имя, структура данных. Оно называется B-Эпсилон Деревья. Честно, я пытался понять, но понял не всё. Отчасти потому что сложно, отчасти потому что мне было не настолько интересно, и я не то чтобы очень сильный алгоритмист, так по правде сказать. То есть в целом оно работает не как B-Деревья, не как B-Плюс Деревья, у них там всякие странные кейсы уровня. А вот у нас есть корень дерева, в корне есть специальный кэшик. И мы, когда пишем значения, мы их сначала всегда пишем в этот кэшик, а когда он переполняется, то мы из корня перемещаем данные в дочерние узлы. Какая-то такая структура. Почему-то, во-первых, достаточно не очевидно, почему это должно быть более выгодно, у тебя получается как будто ты одни и те же данные пишешь несколько раз, но возможно это как-то аккумулируется во времени. Я особо сильно над этим не думал, честно скажу. Почему-то идёт очень много сравнений с B-Деревьями, хотя все современные базы данных используют B-Плюс Деревья. И я смогу припоминать, что... Возможно, они просто это используют как синонимы, часто так делают. Это была моя первая мысль, но если я правильно помню слайды, там прямо говорится, что вот если мы сравним с B-Деревьями, которые хранят ключи значения не в листах, а во внутренних узлах, то мы выясняем, что B-Эпсилон Деревья синтетически более выгодна при каких-то случаях. Вот, большая часть доклада посвящена дотошному объяснению алгоритмов, вставки, удаления, где в какой момент нужно сделать сплит, куда данные перенести, какова будет асимптотическая сложность в оптимистичном случае, в пессимистичных случаях. А потом ещё вводятся несколько модификаций этой структуры данных. Одна из них называется Size-Tied B-Эпсилон Деревья или сокращенно STB-Эпсилон. А ещё у них есть Mapped B-Эпсилон Деревья. Они такие же, как и B-Эпсилон Деревья, но другие. После чего, поскольку мы придумали три структуры данных, нужно рассмотреть их отличия, опять же, в оптимистичных, пессимистичных случаях построить графики, а потом их ещё и померить на конкретных бичмарках и тоже построить графики, на их основе сделать выводы о том, какая структура данных получилась более лучшей. Спойлер, Mapped B-Эпсилон Деревья на их бичмарках оказались лучше всех. Попутно с этим идут вопросы из зала, и это затрудняет восприятие, надо сказать. Вот, в целом, мне кажется, я из доклада понял процентов 20. Если вы угораете по алгоритмам и структурам данных, и вот всему, что было озвучено выше, я думаю, что вам зайдёт. Тащить SplinterDB в продакшен ни в коем случае нельзя. Вот, и они об этом прямо пишут в ритме, что мы ещё не зарелизили версию 1.0, мы не реализовали даты рекавери, ну, тот самый, вот, то, что у них нет, не валу ничего. Фактически, у них реализована вот эта их структура B-Эпсилон на каком-то стороже, и больше у них нет вообще ничего. API в библиотеке не фиксированный, формат на диске не фиксированный, то есть мы всё будем менять, и когда мы получим что-то более-менее production-ready, тогда мы зарелизим 1.0. Вообще, мне показалось, что вот у VMware, у них где-то есть отдел алгоритмистов, где вот сидит несколько человек, и они вот просто угорают по всей фигне, ну, в том смысле, что у нас вот такая особо интересная задача, давайте мы придумаем несколько правдоподобных подходов к её решению, потом очень внимательно их проанализируем сначала в теории, напишем об этом пейпер, потом сколько-то месяцев, лет потратим на аккуратную реализацию, тестирование, потом прогоним все бетчмарки, сделаем из этого выводы, потом придумаем модифицированные структуры, где что-то где-то кэшируется и так далее, и тому подобное. Звучит как будто вот этот отдел, где они пишут SplinterTB, это очень весёлое место, чтобы творчески проводить время, а тащить это впрод не надо, но пейпер должен быть бомбически просто. У меня всё, вопросы, возражения, комментарии. Больше всего в этом докладе мне понравилась необычная задача, мне кажется, мы такие вот прям задачи, что у тебя есть система, которая прям отвечает за маппинг физически, логических адресов физически, это бутылочный горлышко, тебе нужно прям выжать максимум производительности из этой подсистемы. На моей памяти такого не было в подкасте. Прямо такого не было, но мне кажется, мы периодически какие-то интересные пейперы приносили про странные эксперименты, но тут прям ближе, опять же не к продакшену, ближе к какому-то, как это надо назвать-то, юзкейсу, который мог бы быть у продакшена. Мне интересно, рассматривают ли они вариант, слышал, Ваня, твой вопрос, секунду, просто мысль пришла, рассматривали ли они вариант придумать такой алгоритм, чтобы его ещё можно было в железе реализовать потом, вот это было бы интересно.",
    "result": {
      "query": "B-эспилон дерево базы данных"
    }
  }
]
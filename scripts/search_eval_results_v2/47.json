[
  {
    "segment_id": "0e5d752e-0b1f-4bc3-9b5a-cea6ba27f774",
    "episode_id": "d9f3d4cd-2f9a-4c1f-b5bb-228a2ce1e11c",
    "episode_number": 47,
    "segment_number": 8,
    "text": "И когда что-то из heapа в heap переезжает, оно копируется. Я предлагаю гостя направить к соответствующей литературе, потому что лично я очень советую прочитать второе издание Армстронга «Программинг Ирландг» или «Ирландг Программинг», их там две книжки постоянно путаю. А я, кстати, «Армстронг» не терпеть не могу. А мне второе конкретное издание понравилось очень у Армстронга. И вот если прочитал там «Паперла» все хорошо, тогда можно прочитать «Ирландг энд ОТП ин экшен». Это она немножко старенькая, но все еще актуальна. Спасибо большое. Там больше хардкора, да. О, это я люблю. Ну короче, я строго за «ОТП ин экшен», потому что Армстронга можно читать только если у тебя очень много времени. И ты не то чтобы хочешь что-то выучить, ты просто так это для себя, из интереса полистываешь, там лежа на пляже. Вот как-то такое мне впечатление от Армстронга сложилось. Хотя он очень любит свой язык, он его очень интересно описывает, но после книжки Армстронга мне как бы не было точного понимания, как братьев фигачить. Я не знаю, какое издание ты читал, я читал второе. И там было именно про то, как фигачить. Там он прямо в книге объясняет, как пользоваться ковбоем, как пользоваться ребаром и так далее. А, ну значит второе издание пободрее, да. Потому что в первом издании, то есть там понятно, как писать код на языке, как даже приложение на нем сделать, но как братьев в продакшен фигачить, ну далековато все-таки это было. Вот второе издание мне очень понравилось. Давайте дальше. Да, конечно. Следующая тема, Света, настало твое время. Угу. Как-то мы говорили по поводу аккастримов, и что вообще они очень сложные, они не нужны. И наткнулась на статью инженерного блога некой компании под названием Intent, я впервые не слышу. И они занимаются вообще процессингом данных, и вот то, что касается NLP, видимо в том числе. Они строят какой-то продукт, называется Topic Graph, я про него немного почитала, и это такой движок, можно сказать, который строит здоровый граф, просто вот данных, которые с друг другом связаны. Вот вы там говорите, например, машина, и у вас всплывает в голове куча всяких ассоциаций. Вот это вот это все умеет строить. Вот штука интересная, я про него мельком почитала. Должно быть, у них такие занятные задачи. А, собственно, они у себя используют много разных технологий и захотели посмотреть на реактив стримы в АКЕ. И приводят пример, что решили сделать дамп Википедии, именно английской версии. И самое удивительное, что они сказали, это было 4.8 миллиона статей, и в итоге получился XML размером 50 гигов. Мне кажется, это маловато. Совсем маловато. Может, они только какую-то часть взяли в Википедии. Но странно. Нет, ну это, видимо, один текст. Извини, что перебиваю. Ну, то есть 50 гигабайт, прикинь, сколько это часов в видео, например. Я вполне верю, что умещается. То есть у меня как-то не сложилось в голове, что вот это вся английская Википедия, вот только 50 гигов. Нет, ну смотри, если не брать видео в 1080 и 720, взять второе, да убрать такое видео на балаваночках, то у тебя на одной балаваночке, 700 мегабайтной, помещалось около 3 часов видео. Теперь умножишь 3 часа видео на 10, это 30 часов видео. В таком низком качестве. А теперь, да, не на 10, на 50. Ты говоришь 50 мегабайт. То есть умножь на 50, это получается где-то 150 часов видео в низком качестве. А текста там еще больше, блин. Ну, то есть это правда дофига. Ну, так и ничего не с ними сел. У меня тоже приходится в процессе текст, и у меня вот пока что в голове не укладывается, либо у нас реально очень много данных, либо Википедия очень маленькая. Ну, ладно, не суть. Они берут этот дамп и решили его, во-первых, распарсить, потом что-нибудь из него извлечь, и поскольку это POC, некоторый продукт, они решили там просто печатать некоторый прогресс, либо считать некоторые метрики. Они расписали, как это делать на стримах, прям пошагово, что зачем идет. И это вот все у них есть в блоге. Я читала, и мне очень понравилась статья тем, что очень здорово описано, какие шаги, какие функции мы будем применять, как оно будет мапиться из текста в JSON, из JSON в какие-то наши объекты, и за что отвечает каждый шаг, и какие примитивы стримов используются. Мне статья очень понравилась. Есть пример этого всего кода на GitHub, и этого кода очень мало. Так что я крайне рекомендую всем тем, кто хочет ознакомиться со стримами, посмотреть какой-то живой пример. Мне очень статья понравилась. Я хочу попробовать это сама сделать. Так что я рекомендую. На Spark похоже, правда? Чем-то похоже, но вообще, понимаешь, это все, что касается стримов. Но у меня первая ассоциация была, это как-то больше похоже на шторму. У него свои примитивы, там не болты. И здесь понятие такое, как flow, есть понятие, как еще там на букву S, я не знаю, как ее, не помню, как она называется. Синг. Синг, да-да-да, оно. То есть это сказать, брать вот эти болты шторма, но вернуть на них функционалы и назвать их по-другому. Это вот у меня такая была ассоциация. У Spark есть стриминг, вот оно скорее на Spark стриминг будет похоже. Но это своя история. Мне захотелось попробовать делать какой-то стриминговый процессинг чего-то, использовать Ааку вместо шторма. Просто попробовать покрутить. Я не понимаю, ты на работе больше работаешь со штормом? Ты вообще Spark у вас есть? Есть, но других проектов у меня его нет. У меня есть шторм, но в последнее время я вообще занимаюсь совершенно другими вещами. Это кубы. Так что я немножко отошла от того, чем раньше приходилось заниматься. Извини, я не расслышал, это что? Кубы. Ну, OLAP. А, всё, я понял. Ну, то есть ты не можешь так более-менее сравнить Spark со штормом? Боюсь, что нет. Spark в продакшене я не использовала, к большому сожалению. Может быть... Всё, понял. Нас появится как раз-таки для кубов, но не в ближайшем будущем. Саша, у вас Spark есть? У нас нет Spark пока что, но я недавно закончил чтение книжки по Spark. Могу посмотреть название, но попозже. И я пытался понять, для каких задач он нужен и подойдет ли он нам для каких-то задач. Могу сказать, что сейчас у нас таких задач нет, но очень скоро могут появиться. То есть, например, фильтрация спама, например. В таком роде. Ну, короче, смотри, там больше всего много задач. Совершенно точно можно смело использовать как более современную и быструю замену MapReduce, ходупь его. Просто потому, что Spark работает в мемории. То есть, родовая травма ходупа, которая может быть... Ну, не совсем он в мемории работает. Дай договорюсь, всё-таки. Он синкает, понимаешь? Ну, да, синкает, но я немножко не то хотел сказать. То есть, родовая травма ходупа, которую, может быть, уже поправили, но по крайней мере, с которой боролся Spark изначально. То есть, модель MapReduce, она обязана после каждой фазы MapReduce писать обратно на диск. Ну, то есть, там просто модель такая. Просто потому, что сейчас для того, чтобы не терять промежуточные шаги выполнения, если что-то сломается. Spark, они, знаю, как перечислять в случае, если что-то отвалилось. То есть, можно попросить его вообще не перечислиться во время выполнения, если у тебя данных не так много, если они в память влезают. Можно попросить перечислиться. Ну, тогда он будет диск трогать, но он не будет писать, читать, писать, читать, читать. Он будет дампить какие-то результаты, которые не влезают в память. Но это не значит, что он будет вести себя, как MapReduce джеба, который на каждой чих пишет и читает. Во-первых. Во-вторых, еще такой момент. Трогать, трогать. Продолжай. Еще такой момент, что, насколько я понимаю, Spark все-таки будет под себя писать. То, что Свет сказал, дампить, то, о чем я говорил, он все-таки, даже если он работает с диском, насколько я понимаю, он под себя пишет. Поправьте меня, если кто-то знает лучше. Изначально, да, он берет HDFS или HBase и потом кладет, куда скажешь. А при этом промежуток результатов пишет просто под себя. То есть, нет еще такой медленной абстракции, как HDFS или что-то такое. У меня какой-то адский пинг до тебя. Больше секунды, я не понимаю, что происходит. Так что, извините, если я буду иногда тупее, если меня слышат, то хоть нормально? Ну да. Периодически ты квадратным становишься. Квадратным? Ну, звук такой, как будто он робот. Давайте я помолчу, а вы пока там продолжите. Алло, я не слышу. Валера? Что, я на месте? Я, кажется, знаю, что с чем проблема, потому что я имел глупость попытаться задеплоить нахероку и забыл, что у меня довольно небольшой исходящий канал. Самое время. Так, вот. Сейчас я вырублю депло, потому что он почему-то зараза. Нет, они... Да, ты пока, Света, возьми следующую тему своего. Я продолжаю, да. Саша закинул такую тему, касающуюся Spark. Это еще один небольшой тьюториал, как с ним работать. Я его просмотрела, прочитала полностью. В принципе, дает вообще представление, как вообще с Spark работать, откуда его скачать, что скачать, как запустить, как запустить примеры. Но есть нюанс. Там есть ссылки на файлики. Именно такие сырые, которые будут потом обрабатываться. И эти ссылки битые. Вот, можно... Может, я напишу автору, чтобы он добавил что-нибудь корректное. Но в целом идет пример того, как распарсить некоторые GSOD, посчитать что-нибудь в нем, небольшую статистику. Использование библиотеки Spark, SparkML. Но оттуда используется чисто базовая статистика. Дальше, пример использования SparkSQL. Довольно интересная штука. И она дает довольно хорошие результаты по производительности. И, скажем, если брать сравнение с Impala, то это быстрее. Если сравнивать по качеству, или не по качеству, а по предсказуемости времени обработки, то Impala ведет себя более предсказуемо, а Spark могут быть ситуациями, когда он очень долго обрабатывает. И опять же, на эту тему был доклад. Я, может, постараюсь найти ссылку. Приложу. Дальше. Еще здесь пример небольшой про то, как мы берем какую-то дикшенери слов, и потом подсчитываем количество слов, которые начинаются с одной и той же буквы. Вот такие базовые примеры здесь рассмотрены. Как введение в Spark я бы советовала эту статью. То есть очень просто, понятно, и на самом деле стартануться с парком очень легко. Так что бояться нечего. Я статью просмотрел, и, честно говоря, мне больше понравилась книжка Learning Spark. Она хоть и там пообъемнее. Вот, кстати, книжка называется Learning Spark, которую я упоминал. Слушай, хрен ее знает. А, Орелли. 15-й год, верно. То есть, в принципе, это, знаешь, как такая чисто базовая поиграться. Но здесь даже непонятно, как мы строим в наше приложение. Вот этих вещей нет. То есть здесь просто запускается Репл, и из Репла они что-то там считают. Это прикольно, но мы, когда пишем какие-то приложения, нам нужно понимать, как с этим вообще работать. И про продакшн здесь ничего не будет сказано. Чисто введение и общее представление, что это такое, какие базовые примитивы. Гость, ты у нас не отвалился еще? Нет, я здесь, да. Гость, а расскажи, что ты думаешь по поводу Spark. Я на самом деле со Spark вообще дела не имел, поэтому я даже боюсь сказать что-нибудь, чтобы соврать. Я вот сейчас смотрю на эту статейку, ну да, круто было бы повязать, но у меня нет своей какой-то точки зрения, которая бы имела вес. Потому что я его банально не использовал. Извините. В следующий раз лучшее домашнее задание сделаю. Мне вот очень интересно, наверное, вопрос Свете как главному специалисту. Я же из предыдущего выпуска, правильно? Или какого? Когда у нас специалист из Google приходил в прошлый раз? Это про Хером, которая была. Я правильно понимаю, что стрим процессинг и MapReduce, они, скажем так, по вычислительной мощи одинаковы. То есть я все, что могу посчитать на Hadoop, могу посчитать и на Spark. Да, конечно. Просто там вопрос в том, что происходит, когда данные не дошли, что происходит, когда данные еще не дошли, и что происходит, когда тебе... То есть, круто говоря, это латенсии, VS, учет всех или не всех данных. Ну и причем, наверное, имеется в виду, что в одной из технологий, прямо внутри топологии, заложено какой-нибудь persistence, а в другой придется ручами это делать на каком-нибудь этапе, когда у вас есть стримовая обработка, но персистить его самостоятельно. Ну, обязательно. Нет, в Spark ты говоришь, что у меня тут поток посчитался, и его там закешировали на диске. То есть там нет такой проблемы. Окей. Обсудили или идем дальше? Да, я предлагаю дальше. Ну вот, я всем прошу прощения за незаминуточку. Я у себя в Project обнаружил баг и решил поправить. Там был однострочник поправки, решил прямо сейчас поправить. Давайте деплоить во время записи подкаста. Что может пойти? Ну, хоть не продакшн деплои, но хорошо. На самом деле, о чем я хотел поговорить, я хотел поговорить про свежую... То есть буквально вчера, 25-го, сегодня 26-го, вышел свежий стабильный релиз RUST 1.1 и RUST 1.2, соответственно, вышел в бетку. Что нам принесет релиз 1.1? Самое главное изменение – это очень сильно ребята поработали на скорости компиляции, то есть они на 32% ускорили компиляцию. И следующий, вот тот релиз, который сейчас в бете, он еще на 30% ускоряет компиляцию. Местами над эргономикой поработали, ну и оно теперь умеет собираться с MUSE-лем. MUSE-лем – это такая крайне минималистичная липси для Линукса, которая хороша тем, что она маленькая и минималистичная, и с ней можно линковаться, то есть ее прямо можно в себя влинковать и быть независимым бинарем. Вот, такие дела. А еще в бету вышла компиляция MSVC. А как много на RUST сейчас вокруг вас, господа, программистов и проектов? Ну я вот на RUST взялся пописывать как на таком домашнем языке немножечко. Мне он очень нравится. Ну понятное дело, что продакшен проектов на нем сейчас нет вообще, на нем есть некоторые серверские проекты, типа та же самая Mozilla, на нем делают сервер сразу. То есть RUST – это язык, на котором уже есть браузерный движок, который, конечно, не продакшен-браузерный движок, но вот он тем не менее написан на нем. Короче, все хренюхиваются. Ну, вокруг меня тоже есть некоторое количество людей, которые очень восхищаются RUST, но при этом ни разу на нем ничего не писали, но они считают, что это вау, это круто, это здорово. Я даже подозреваю, что они не смотрели, что с собой представляет RUST, даже в документацию. Да, это вообще большой проект. Но они, знаешь, так услышали где-то и загорелись, и говорят, что вау, это же классно. Нет, я скажу, что это правда классно. Я, кажется, уже в прошлом выпуске ты озвучил, у меня он такой, знаешь, такая смесь с Scala и C++. Ну, то есть, конечно, два довольно монструозных языка, но я имею в виду, на данном случае, по ощущениям от того, как себя ведет система типов, как ведет себя, ну, не знаю, то есть от C++ там низкая уровневость, и компиляция сразу на типщину, и возможность там в битиках поковыряться, от Scala как раз по системе типов, то есть там действительно довольно сложная система типов, он тоже ориентирован больше не на иерархию, а на трейд, точнее там вообще нельзя делать иерархию, там только трейды. И тоже есть местами стык, то есть стык между RUST, например, и более низким уровнем, он примерно такой же неуклюжий, как стык между Java и Scala, ну и так далее, то есть в плане ощущений сильно действительно напомнил Scala. То есть это в принципе первый нормальный язык для системного программирования, если кому надо новый проект делать? Ну вот Саша так не считает, а я так считаю. Саша не системный программист, он не имеет возможности что-то считать на этот счет. Саша считает, что для его задачи этот язык примерно абсолютно бесполезен, поэтому не особо им интересуется. Мы уже много говорили про RUST, давайте дальше. Саша, твое слово. У меня парочка анонсов. Во-первых, в Москве пройдет тренинг по облакам Амазона, как вовремя я эту тему добавил. Состоится это 2 июля, и честно говоря, ни разу не был на тренингах, может там маркетинг-маркетинг, но ребята обещают вас всему там научить про облака. Советую не верить всему, особенно тому, что у вас там все обычные сервисы заменят все базы данных, и их самим не придется поддерживать, потому что по моему опыту это совсем не так. Но тем не менее, если вам это интересно, нет повода не сходить. А второй анонс это то, что в Твиттере пролетала вакансия, а не есть я их видел, вакансия для программистов на Клодже. Компания называется Flaktory, и ссылка на твит и на саму компанию на Headhunter будет в шоу-ноутах. Так что если вы всю жизнь мечтали писать на Клодже, вот он, вот он ваш шанс, быстрее. У меня все. Про облачные технологии. Уже было только что. Все, я пропустила. Так, про кластеры замену плюсов, как по-моему мы тоже поговорили получается, или нет? Нет, это новая статья, совершенно новая статья. Потому что, да, давайте это обсуждать, потому что то, что я хотел обсудить, я не до конца прочитал. Окей, Свет, действуй. Ну, собственно, есть такая штука, называется DMP. Это в первую очередь касается рекламной сферы, называется Data Management Platform. Для чего это нужно, что это такое? Вот у нас есть некоторый поток пользователей, точнее не поток пользователей, а поток транзакций, а действий пользователей. И по этому потоку транзакций вы можете понять, чем интересуются данные пользователи, к какому сегменту он принадлежит. Это пол, это возраст, это интересы и так далее. Таких сегментов можно очень много насчитать. И задача DMP это сказать, выдать по сути профиль пользователя, выдать сегмент этого, ну, сегментация пользователей. Соответственно, есть множество подходов к написанию таких систем. И вот статья на HubR, она просказывает про опыт одной из компаний, про то, как они переписывают свою систему, написанную с использованием Hadoop и Produce Framework, на Aku, на Aku Cluster. И в целом довольно неплохо расписано, хотя по большей части такие архитектурные вещи, но без каких-то примеров кодом. Что было раньше? Раньше было так, что у них все эти данные приходили и сохранялись в HDFS, потом HBase используют как база данных для того, чтобы получить эти профили и найти эти ивенты. И потом эти все ивенты прогонялись через аналитик NGINE, это такая много MapReduce Job, либо это одна здоровая джоба, в которой несколько скриптов. И каждый из скриптов просто делает эту сегментацию, выясняет, какому сегменту принадлежит этот пользователь. Соответственно, эта штука работала, и она продолжает работать до сих пор, но проблема такая, что она работает медленно. И по статистике, вот у нас приходит пользователь какой-то, он если ввел в Google какую-нибудь, там, купить машину, например, и было бы здорово ему показывать рекламу или таргетировать ему то, что в то же время, когда он этим стал интересоваться, а не через 24 часа после этого показа ему выдачи. Соответственно, получается проблема, что при обработке оффлайновой, ориентированной на Hadoop, мы теряем очень много клиентов. И поэтому было бы здорово делать real-time обработку. И решили... Извини, мне кажется, нужно еще раз подчеркнуть. То есть, ребята использовали для своего определения, что чуваку продать, Hadoop. Проблема с Hadoop в том, что на обработку данных ему нужны примерно сутки. В статье приводится такой график, вероятность покупки в зависимости от времени, когда ты покажешь человеку баннер после запроса. Например, я сегодня искал электротурку. И вот если мне показать рекламу через час или через день, то вероятность покупки падает примерно в 10 раз. Поэтому ребятам очень важно именно не за день обработать данные и понять, что я хочу купить электротурку, а как можно быстрее. Для них это реально очень важно. График... И поэтому им не подходит Hadoop, и они решили использовать некий стрим-процессинг. В итоге решили использовать свой. График представляет собой ветку гиперболы. И так, они решили использовать свой стрим-процессинг, и для этого им подошла модель акторов. Они прочитали и сказали, что круто, здорово. При этом у Аки есть кластер из коробки. То есть задачи про масштабирование, про отказоустойчивость, это есть. И они решили этим пользоваться. Как это реализовано сейчас? У них есть RabbitMQ, который получает все эти ивенты. Дальше есть некоторое количество диспетчеров, которые разгребают очереди с Rabbit и отправляют данные в акторы. Для каждого юзера создается отдельный актор. Для каждого юзера применяются некоторые скрипты. Все те же скрипты, которые умеют сегментировать пользователей по их действиям. После этого они решают, в какой сегмент попадают пользователи, и записывают эти профили в AeroSpyc. Есть некоторые API, которые умеют работать напрямую с акторами, напрямую с AeroSpyc, чтобы читать. Читение из AeroSpyc быстрое, в целом это неплохо масштабируется на бумаге, хотя на практике есть нюансы, как всегда. В целом всё. Странное решение, что не используют RabbitMQ, но описано было так, что у них пока что только часть системы переведена, и поток событий это 3000 в секунду на текущий момент. Это несерьезно, это очень мало. Дальше показан график, что у них получилось неплохо по производительности. Что ещё есть такого? Меняйте статьи больше. Извини, продолжай. Ещё один момент. Были некоторые вопросы заданы в комментариях, и был вопрос задан по поводу того, какой протокол используется для передачи сообщений от актора к актору. Они сказали, что у них есть свой протокол, который имеет обратную совместимость. Меня смутило, что они на самом деле навелся и делали свой Spark, но они честно говорят, что мы не очень поняли Spark, никогда с ним не работали, но зато мы давно и хорошо знаем Аку и Яку Кластер, поэтому мы как бы написали своё, но наверное имеет право на жизнь, действительно, если ты в чём-то хорошо разбираешься, почему бы это не использовать. Меня больше смутило то, что я в комментариях задавал ряд вопросов, например, сейчас промотаю, почему там они... А, ну, простой вопрос. А используете ли вы Камон? А что вы делаете, если у вас там падает одна из машин, потому что Ака Кластер далеко не моментально это детектирует, и у тебя актеры продолжают долбиться в упавшую машину, не осознавая, что она упала, и у тебя из-за падения одной машины тормозит весь Кластер. Ну и так далее, там целый список таких вопросов. Они на него не ответили, и меня это очень печалило. Наверное, у них какая-то там просто фон... Ну, как бы, это такая аналитика, которая... Ну, если сломалась, то как бы, ну и пофиг, там через час подняли и пусть дальше считают. Ну, смотри, мне кажется, они с таким особо не сталкиваются. У них реально небольшая нагрузка. 3000 сообщений в секунду. Это вообще смешно. И они используют Рэббит, при этом, по-моему, у них только один инстанс Рэббит, он справляется, он всё хранит в одной очереди, как они написали в комментариях. Я думаю, там совсем нет никакого ни хайлоуда, ничего. Ну, работает, работает хорошо, есть, не просит. Я думаю, если они пойдут увеличивать нагрузку, они столкнутся с интересными моментами, ну, в первую очередь, скорее всего, они заменят Рэббит на Кавку какую-нибудь, и, возможно, пересмотрят подход, когда по актеру... Ну, один актер задаётся на каждого юзера. Вот, может быть, это будут менять. Ну, не знаю. А вы Кавку используете? Да, да. Какой версии? Ну, там их есть какая-то старая, есть новая. Ну, последняя, последняя которая. Всё, понял. Мне кажется, во всей этой истории, вот именно потому что они не ответили, сценарий был какой-то следующий. У людей была задача о процессе данной, они знали MapReduce, причём, судя по всему, изначально задачка-то была процессинга онлайн, принятие решения, и никакой офлайн, там, надобности делать не было. Но люди просто хорошо знали MapReduce, вот и сделали MapReduce. Вот. А сейчас, когда поняли, ой, это у нас же онлайн-процессинг, полезное на что-нибудь онлайновское с решением на MapReduce. Ну и да, они вот пока только изучают, раз на вопросы бы они отвечали. Ну, а что бы и нет. И мне кажется, название статейки «Мы ошиблись выбором MapReduce для нашей задачи лучше Ака» ну, или что-то такое, потому что, ну, не согласены с тем, что MapReduce умирает, и вот это доказательство того, что MapReduce умирает. Просто задачи другие. Ну, оно как бы всегда было так, что шруп, забитый молотком, держится лучше, чем гвоздь, который заментили отверткой. Вот. Ну, да. Ну, а просто вот, еще после прочтения этой статьи, мне показалось, им куда бы больше подошел в сторону. Ну, чисто вот так, субъективно. Да, да, да. Я бы, конечно, Kinesis им посоветовал. Ну, да. Я в рамках этой статьи хочу упомянуть еще одну статью. Она, на самом деле, у нас такая, в специальном разделе статей, на которые можно забить. На Хабре была еще одна статья на этой неделе про архитектуру игры StarGhosts, про их бэкэнд. И меня удивило то, что они там сделали очень много велосипедов. То есть, вот эти ребята переизобрели, как его, Spark, да? А эти ребята переизобрели, у них там свой ORM, который не поддерживает Na'Vi, у них там свой скриптовый язык для квестов, при том, такой страшненький язык, надо сказать. То есть, ни JavaScript, ни ничего такого. У них свой бинарный протокол, они переизобрели Protobuf и Trift и так далее. У них... Ну, короче, там много всего. И самое... Вот, что меня больше всего удивило, я там в комментариях тоже отписался, там типа, ну, ребят, ну, Trift, ну, Trift же, ну, зачем? И мне там в комментариях ответили, что, типа, почему ты считаешь, что если люди велосипедят, то это обязательно плохо, не работает и так далее. Может, я что-то в жизни не понимаю, может, действительно надо все свое делать. То есть, вот я удивляюсь тому, насколько люди бывают разные. Я сегодня уже там в одном чатике писал, что у нас на работе один коллега сказал, что вот он хочет писать на скале в... Как он? В Sublime. Почему? Потому что в Sublime можно вот минус и больше отображать красиво, как стрелочка. И вот это... Это прям вот... При программировании на скале самое главное, понимаешь? И он это серьезно. Он не троллит ничего такого. Вот. Что для другого человека очень важно. Потом вот мы обсуждали вакансию по Clojure, да? В моем понимании Clojure это самый ужасный язык, который можно придумать. Почему? Потому что там динамическая типизация. Я очень большой не любитель динамических типизаций. Потому что там макросы. Я очень большой не любитель макросов и так далее. Но кто-то очень любит Clojure. И вот здесь люди доказывают мне, что велосипеды это на самом деле очень хорошо. И брать готовые трифты, это типа не всегда самое лучшее решение. Вот удивительно, насколько по-разному могут люди думать. Ну скажем так, трифты для игр это правда херовое решение, потому что они шире, чем надо. И даже протобаф, он... Да, они еще и летность дают не такую, не слабую. И как бы большинство игр, которые мне известны, они либо велосипедят, либо берут игровой мидлоуэр. Мне непонятно, почему ребята не взяли существующий игровой мидлоуэр для сериализации. Оно, конечно, даже иногда бывает не бесплатное, но всяко дешевле, чем свои ресурсы тратить на разработку этого. Раз, во-вторых, есть некоторые такие фреймворки, не помню точно название, но вот есть CapnProto, есть еще один, GodGoogle, которые именно про то, чтобы сериализация, именно для игр, именно только сериализация без остального фреймворка, и чтобы было быстро, чтобы было компактно. Ты сказал две странные вещи насчет рифтов. Во-первых, ты сказал про летенсию, летенсия там не связана с сериализацией примерно никак. Ты какой транспорт хочешь, такой исплатишь. Нет, я про другую, я про сериализацию, потому что сериализация занимает время, я про это. А, ну вот не могу сказать, у нас как бы нет такой прям суперреалтаймности в проекте. А второй момент, это про компактность рифтов. Может быть, у него есть несколько схем сериализации, и у него есть прям специальный протокол, очень компактный. Мы, кстати, использовали в нашей прошлой работе, играми занималась, у нас был протобаф, и никто никаких проблем не испытывал с этим. Я не знаю, конечно, какую тут, ребята, игру писали, я не буду спекулировать на эту тему, но смотри, если игра не реалтаймовая, там вообще спокойно можно по хттп ходить. Это реалтаймовая игра, да. Если игра реалтаймовая, в которую там, например, персонажи перемещаются по карте, им важно, чтобы у них не лагало. То есть, ну реалтайм не просто что, какая-то социальная активность и реалтаймовость, когда у тебя есть прям два персонажа в двухмерном или трехмерном пространстве, и они там между собой, например, соревнуются. В таком случае тебе люди типично выжимают каждый битик, чтобы поменьше переслать. Ну, не настолько, но... Ну, короче, я поняла, то есть, если тебе несколько персонажей на карте, им нужна немножко другая специфика была игра. Ну, вот как бы да. А это же мы ещё в контексте велосипедов, потому что я что-то тонкую нить как-то потерял. Это мы ещё насчёт велосипединья? Ну да, потому что у них свои протоколы, когда велосипедить нужно и полезно, когда у них какая-то очень левая резьба. Я просто хотел вспомнить такой пример из Яндекса. У них там долгое время, по-моему, в сяшном коде был тип данных свой — строка. Вот именно так, транслитом и строка, который был просто, банально, намного быстрее имплементации string, который был в то время. Ну да, иногда вот, ну надо, что сделаешь. Да, и в скобочках я ни в коем случае не оправдываю человека, который sublime для стрелочек юзает. Но в целом, да, иногда надо. Ещё, кстати, один момент, это из прошлой темы. Ты сказал, что там люди перезабылили Spark. Ну, я вот сейчас подумала, но это же не так. В Spark вообще основная концепция, которая оперирует, это RDD. И она оперирует, скажем, большой, такой здоровой, ленивой коллекцией, по сути, своей. А здесь, в статье, у нас string, конкретно мы по одному процессим, они работают вообще отдельно, мы не работаем с ним, как с большим датасетом. Почему ты сказал, что это Spark? Ну, давай спишем на то, что я не подумал, хотя у меня есть как бы другие аргументы. Я предлагаю ещё одну тему обсудить, на самом деле. Ну, наверное, упомянуть, потому что я должен был подготовить Ваня, но Ваня сегодня не смог участвовать, у него большой праздник. Докер 1.7. Докер, докер, докер, докер, докер. Для себя самое важное изменение, которое я отметил, это они там как-то очень сильно улучшили работу с сетью, можно прям несколько контейнеров, чтобы они друг друга как-то очень хорошо видели. Честно скажу, не пробовал. Они дырочку проковыряли, да. То есть, как в самом докере, как была никакая поддержка сети, так и осталась. Просто теперь можно стороннюю воткнуть. Второй важный момент, они там каким-то образом сделали поддержку ZFS, а надеюсь, у нас теперь есть файловые системы без слоёв, но я не уверен. Никто не изучал, да? Мне бы очень хотелось, чтобы была файловая система без слоёв, но я не уверен, что это про то. У них такие релиз-ноутсы, из них не очень понятно. И ещё что интересно, из статьи на OpenEdge я узнал, что они объединились с Ракетом и некоторыми другими проектами, и теперь пишут спецификацию общую контейнеров. То есть, у нас теперь контейнеры можно будет переносить с докера на Ракет, и так далее, когда они вот это допишут. Это прям большое дело, я считаю. Я согласен насчёт общей спецификации, потому что было бы прекрасно, если бы у нас когда-нибудь была такая спека, которая, во-первых, всех бы устроила, а во-вторых, везде работала бы. Ну, тогда, может, настало время? Да, давайте зачитаем последний кусочек и пойдём по тему. Да, в общем-то, нашим третьим спонсором является компания MachineZone, известная своей игрой Game of War, которая в топ-гроссинге регулярно появляется, App Store. Сейчас активно компания набирает разработчиков в Россию и ждёт свою команду разработчиков, пишущих на Erlang и Python. И вам предстоит разрабатывать облачную инфраструктуру наподобие Amazon EC2, а также всякое сопутствующее. В общем, если вам нравится Erlang, Python, вам интересно ковыряться в распилённых системах, и также Docker, Docker, Docker, Docker, а также вот это всё, и вы готовы к релокации Ульяновска и Новосибирск, ну и к периодическим командировкам в долину, то вам, пожалуй, на machinezone.ru или напрямую Jobs, собака, machinezone.ru, писать можно. Всё, скоро ребята из Amazon останутся без денег, потому что на Erlang напьёшь Amazon. Такие дела, да. На самом деле, по темам слушателей сегодня очень забавная ситуация, потому что Erlang-18 мы уже обсудили, Rust 1.1 мы уже обсудили. Очень хорошо. Дальше тема про хаксы. Ну, что могу сказать. Я с хаксой знаком довольно поверхностно, я знаю людей, которые пишут на этом игре, я даже в комментарии добавил. То есть язык в принципе живёт до некоторой степени. Меня очень подкупает, что это один из немногих языков, на которых можно спокойно писать как раз платформенные игрушки, которые действительно запустятся на таком приличном количестве платформ. Я правильно понимаю, что главная фишка, что я вот написал на этом хаксе какой-то код, потом могу его странслировать хоть в Java под Linux, хоть в C-sharp под Windows, хоть в JavaScript. У меня код один раз написан, он транслируется вовсё. Ну, то есть транслировать код, это не самое сложное, что можно делать. Хакс хорош тем, что в случае игрописательства под нему есть ещё немножко экосистемы. И это уже действительно становится интересно. Я ещё смотрю картинки, у него там прям поддержка всякими редакторами, и IDE вроде как есть. Я не знаю, насколько она крутая, но это большой плюс. Ну вот, короче, я не знаю за поддержку IDE, я знаю, что люди на этом действительно пишут игры, и это делать можно, и они при этом правда как раз платформенные получаются. И это, например, гораздо меньшая боль, чем Cocos2dx. Хотя вот есть иллюстративное мнение, что Cocos2dx приятнее, чем хаксы. Ну не знаю, лично мне хаксы, кажется, приятнее. Кстати, C++ тоже транслируется, поэтому может быть даже быстрее. А он по философии на что похож? Он типа функциональный? Ну, на C-sharp что-то такое. Смесь C-sharp с ActionScript, честно говоря. Ну, норм. C-sharp это почти скалы. С C-sharp он в отличие от Java гораздо бодрее развивался. У него, конечно, натащили всякого, но он не такой электроградский, какой была Java пару лет назад, скажем так. Ну так чего дальше идем? Дальше нам сообщают, что ним умер. Саша, ним умер? Ну, статья называется Goodbye, Nim, and good luck. Старая статья, насколько я понимаю, там типа в апреле написана. А, еще раньше, в феврале 2015. Ну, что тут сказать. Чувак писал на ним. Потом ему там что-то не понравилось, что он там немножко ломался и что-то еще. И он сказал, что больше не будет писать на ним. Ну, я считаю, что чувак сам себе злобный, бурлативный, не за чем писать на всяких экспериментальных языках. То есть я, например, хотя и всякие там хорошие слова про ним говорю, я его ближайшие года-два трогать точно не собираюсь. То есть когда он там более-менее зарелизится, то есть станет более-менее стабильным, вот тогда он действительно будет интересным. Сейчас-то чего его трогать? Ну, я примерно так про Rastro сразу говорил, я на нем так Hello World-ы подписывал, разной степени Hello World-ности. Но вот сейчас уже им таки можно пользоваться. Я, конечно, хотел им пользоваться для серверов, но асинхронные ватулы туда пока не завезли даже в виде библиотек нормальных. Почему? В стандартной библиотеке все есть. Я про Rastro. А, все, я тебя понял. А ним я говорю, ним мне не так интересно просто потому, что я с тем же успехом могу на Ирландии писать. Такой вопрос. Какую ним проблема решает? Если с Rastro еще хоть как-то понятно, окей, первый нормальный человеческий язык для системного программирования, то вот ним это вообще куда его привинчивать? Ну, давай я попробую ответить. Что действительно интересно в языке? Для начала он компилируемый. В нем, что называется, soft real-time GC. Такой, с маленькими кучками счетчиками ссылок и вот этим всем. То есть на нем можно, например, UI писать и без необходимости тянуть 30 мегабайт какого-нибудь JVM и так далее. Считается быстрым. Ну, понятно, пока нет никаких особых бетчмарков. Что еще? Считается довольно простым. Без кучи объектов и так далее. Он вообще, по идее, почти процедурный. Но при желании ты можешь использовать функциональный подход, при желании ты можешь немножко объектов использовать. Вот в таком роде. Понимаешь, это просто действительно неплохой язык общего назначения. Вот есть куча задач, которые надо решать на C. Например, ты решил свой алгоритм LZV написать, сжатие. Или аудиокодек. Понятно, берешь C и не паришь мозг. А есть вот все остальное. Вот все остальное, в принципе, можно и писать на языке вроде NIM. Он очень похож на это. Но пока еще как бы сырой, незрелижный. Просто понимаешь, все остальное можно писать еще много на чем, а вот альтернативы C пока немного. Да не надо делать альтернативы C. Почему не надо? Вот понимаешь, мне было бы гораздо приятнее какой-нибудь LZV новый писать на не C. Если бы была технология, которая была бы примерно такая же по скорости. И вот RUST вполне может стать примерно таким же по скорости через короткое время. Но зачем? Он уже, в общем-то, немедленный. Ты, Саша, очень часто приводишь такой аргумент, что там индексация с баланс-чекингом. Я вот когда последний раз писал на RUST, точнее вот сколько я сейчас на нем пописал, я индексацией напрямую в массив пользовался ни разу. Ну, хорошо. Так я вот врываюсь в эту дискуссию. По-моему, если я правильно понял философию Нима, он все делает через thread-локалы. То есть, в принципе, залазить из одной памяти из одного треда в другой нельзя. Соответственно, в принципе, кучу задач на нем не решишь. То есть, он вроде, с одной стороны, компилируемый, что приносит огромную кучу проблем компилированного языка. А с другой стороны, он еще не позволяет весь тот спектр возможностей, которые позволяет C. Как говорит Валера, капает и скворчит. Значит, действительно, по умолчанию память между процессами неразделяема, и данными они обмениваются по асинхронным каналам. Но ты можешь также использовать общую кучу, управляя памятью вручную. В Ниме есть вручное управление. Плюс к этому они до релиза обещают общие кучи для групп процессов. Вот так вот. Ну окей, хочешь что-то? Ну короче, пока что я могу просто спокойно продолжать писать на Erlang, то, что я писал на Erlang, грубо говоря. Но тогда будут кучи общие между процессами, тогда посмотрим. Потому что я эту фичу очень давно хочу от Erlang. Вот, у меня примерно такое же отношение. То есть, вот те задачи, которыми я занимаюсь, вот Scala прям отлично подходит. Прям совсем отлично. Нима это просто такой интересный язык на будущее, когда он выйдет. Ну и к тому же мы выяснили благодаря слушателю Русламу Ибрагимову, что он умер. Так что, давайте дальше. Дальше пустота, потому что там дальше темы, за которые мало голосовали. Мы сегодня вроде все обсудили, поэтому наверное можно начинать прощаться. А ты не хочешь еще там пару бонусных темок обсудить? Бонусных темок? А мы же этот, Докера обсудили. Там из бонусного... А, Мускуль, ну давай, да, рассказывай про Мускуль, жги. Прилетела с Hackers News ссылка на баг в баг-трикере MySQL. Баг заключается, ну я навру, наверное, насчет деталей, но там в общем и целом примерно такая суть, что у тебя есть таблицы, в них есть foreign key и у тебя есть триггеры. И смысл в том, что когда ты там типа вызываешь какой-то триггер, он не ходит по foreign key, он ходит по foreign key или наоборот. То есть там какая-то есть неконсистентность в этом. И на самом деле это просто писец как плохо. Ну потому что понимаешь, да, ты ожидаешь некоторые семантики от СОБД, а она не имеет этой семантики. И что интересно, багу этому недавно исполнилось 10 лет. То есть он зарепорчен 21 июня 2005, и вот на этой неделе ему исполнилось 10 лет, он все еще открыт, ура-ура. Это удивительно, как можно... Быть таким сказочным голобоебом. Спасибо. В смысле спасибо, что сказал это за меня. То есть да, такой серьезный баг, он реально серьезный, ребята из MySQL держат открытым 10 лет. Не используйте MySQL.",
    "result": {
      "query": "стриминг данных Spark Akka сравнение"
    }
  }
]
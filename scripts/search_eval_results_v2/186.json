[
  {
    "segment_id": "8996ff8f-aacf-4b19-9c58-68008f18b7dd",
    "episode_id": "ff2102a7-b54a-47ae-866f-24f39b7bbbc0",
    "episode_number": 186,
    "segment_number": 2,
    "text": "Ну, ладно, да, в принципе можно, наверное. Хорошо, и с какими системами вы работаете? Да, мы работаем с двумя билд-системами основными, это Gradle и Bug. Вот, соответственно, проблема какая, что когда кода базы начала расти пару лет назад и начали сильно модернизировать проект, где-то после 40 модулей Gradle начал задыхаться, потому что на тот момент он не был к этому готов, то есть к большей модернизации, к сильно параллельной сборке. Можно для меня и для тех остальных слушателей, которые с этим мало знакомы, модули Gradle почему сложно? Да, да, точно, хороший пойнт. В общем, смотрите, какие варианты у нас есть по организации проекта, да? Мы можем просто пихать все условно в один модуль, это практически во всех билд-системах есть такое понятие, как модуль, это какая-то группа кода, которая в итоге продюсирует какие-то артефакты из него, правильно? Соответственно, у нас проект может состоять из одного или нескольких модулей. Проблема с нахождением всего кода в одном модуле в том, что если у вас компилятор неинкрементальный, вы начинаете как бы постоянно рекомпилировать большой, ну, чем больше у вас там кода, тем больше вы начинаете рекомпилировать на каждую сборку. Есть системы сборки и компиляторы, которые позволяют вам инкрементально это все делать, но дальше начинаются другие проблемы с тем, что в рамках одного модуля вы ограничены фичами языка, синтаксическими, как правило, или каким-то его структурированными фичами, которые вам позволяют код разграничивать, то есть из этого пакетжа только внутри, из этого класса, например, только внутри пакетжа можно доступняться и так далее, и тому подобное, но так или иначе этого часто недостаточно, и хочется какого-то большего контроля, какой код с каким кодом может работать, потому что иначе все это начинает смешиваться в одну кучу и поддерживать достаточно сложно. Поэтому достаточно разумная идея начинать разделять ваш проект на модули, чтобы добиться большего контроля над тем, как код структурирован в проекте. Дальше это позволяет вам еще сделать реализабельность между разными модулями, то есть у нас, например, в проекте это 470 модулей на данный момент, и три из них — это приложения, то есть они зависят от других модулей очень сильно, и они, по сути, флируют в себя кучу других модулей, и за счет того, что это все живет в одном проекте, это нам позволяет добиться очень большого реюзабилити этого кода. То есть у нас шарятся большие куски и UI-кода, какие-то фичи прям конкретные, и куча фреймворкного кода, все это шарится между приложениями, просто потому что все это живет в одном репозитории и в одном проекте. Можно вопрос сразу? Вот ты говоришь много, и я хотел бы понять порядок, то есть у вас сколько еще раз модулей там? Ну, где-то 470. Ну вот 470, то есть конечных приложений три, да? Да. То есть получается остальных 477 — это все какие-то библиотеки или модули, которые участвуют в сборке этих трех приложений. Вот из этих 477, насколько много переиспользований? Переиспользование — это значит количество использований больше одного. Да, конечно. Ну, скажем так, фреймворкных модулей у нас около 100, то есть они все переиспользуются между приложениями, то есть это какие-то библиотеки или фреймворки, которые мы шарим дальше. Дальше идут фичи, то есть это фичи в случае андроид-приложения — это, как правило, какой-то UI и какая-то функциональность. Из них, наверное, где-то 30 шарятся между приложениями, то есть это какие-то общие экраны настроек, еще что-то, то есть мы даже какие-то маленькие компоненты, типа там, ввод эмейла, да, и полностью его обработка там с посылом на сервер, то есть не просто какой-то UI-виджет, а прям какой-то такой кусок функциональности. Вот такие вещи тоже шарятся, то есть из них, наверное, ну, в итоге получится, что где-то, наверное, процентов 35 проекта, я бы так сказал. Переиспользуется. Ну, да. Понятно, то есть как бы артефакты в данном случае сильно помогают, потому что ты один раз собрал, и потом уже переиспользуешь в разных кусках остальных. Да, все так. Продолжай, пожалуйста, я перебил. Вот. Соответственно, когда вот к этому процессу начали идти, Gradle начал затыкаться, потому что он изначально не был задизайнен для такого большого количества модулей, и ребята, ну, меня в тот момент не было в компании, ребята начали смотреть на другие билд-системы, и они выбрали Bug, потому что Bug изначально, как и Bazel, как и Pence, задизайнен для работы с монорепозиториями, в которых очень большое количество модулей. Тут, наверное, можно сейчас поговорить про концептуальные отличия вообще, какие билд-системы бывают, и почему, там, есть, например, билд-системы ориентированы для монорепозиториев и билд-системы ориентированы для там, менее больших репозиториев, но это опт-вер. Да, конечно, конечно, это очень интересно. Ну, в общем, тут стоит сразу сказать, я не большой фанат монорепозиториев, так что мне просто приходится его поддержать. Значит, что вам дает монорепозиторий? Весь код живет в одном месте, но у этого много проблем. То есть вы начинаете хитать лимиты системы контроль версии. В системе контроль версии многие вещи перестают иметь вообще какой-то смысл, то есть, там, типа, теги, что значит тег для одного из приложений, когда он отражается на коммитах вообще других проектов. То есть, ну, всякие такие вещи, они начинают концептуально еще вам голову ломать. Что еще интересно? Вы хитаете лимиты билд-системы в том плане, что ей надо даже вот, окей, если у вас есть все инкрементальное, вам все равно надо обрабатывать большое количество файлов, потому что в монорепозитории может жить миллионы файлов могут там жить. Соответственно, дальше еще что? Еще самая большая боль для нас – это экспириенс для разработчиков в EDE, потому что EDE надо все это индексировать, и это просто очень большая боль. Такое количество кода прожирается очень медленно, и там приходится всякие трюки придумывать, типа там часть проекта, например, отключить, потому что там этот человек работает только, например, с этим приложением, надо подключить в EDE только это приложение и все его зависимости. Вот такие трюки приходится делать, иначе все достаточно печально. Можно сразу вопрос? Это же все печально становится из-за объема кода, но это не только EDE страдает, это страдает все, включая даже, когда ты делаешь git-клон, я не знаю, у вас гид или не гид. Да, у нас гид. То есть получается, сколько у вас репозиторий занимает в полном объеме? Я имею в виду, когда ты git-клон сделал и натравил на него там DU и посмотрел, сколько disk usage? Сам git-клон тянет где-то гигабайт и сто мегабайт, соответственно, он еще потом разэктивирует часть этого, ну то есть там достаточно много, да, очень много кода. Слушай, ну это прям ужас-ужас. Да, да. Это причем, что не так много бинарников. Вот у вас нет бинарников в репозитории, просто... Они есть, но их не так много. Я просто хотел спросить, что... Да, да, да. Вот недавно, кстати, гитхаб сделали кутифитту, git-стайлер вроде называется, можно приложить потом в ссылочке, она позволяет оценить вообще плачевность вашего гид-репозитория, и там есть очень интересная такая шкала, которая показывает, типа, насколько уровень консерва, короче, вашего репозитория по разным показателям. Уровень зашвара. Да, да, по бинарникам у нас около 100 мегабайт бинарников, то есть, ну это не самое плохое, наверное, что можно. Ну да. И сейчас их выфиливать достаточно больно, конечно, то есть это придется историю переписывать. Слушай, ну вот допустим... Не, ну хорошо, а как у вас новые люди работают? То есть у меня часто бывает, что я там гид-клон делаю в двух разных папках для каких-то вещей. Ну редко, конечно, но бывает. А тут даже одному человеку гид-клон ты можешь делать там пару часов. Да, поэтому делаешь гид-клин, потом цп, потом опять работаешь для... Ну, на самом деле в офисе у нас гигабитные сетки, то есть там нормально вытягивают, и гитхаб где-то тут рядом, похоже. Так что тут не так плохо в этом плане. На CI, да, есть проблемы, то есть нам приходится использовать специальный API гитхаба, чтобы скачать снапшот файлов из репозитория. То есть не скачивать, ну не делать клон, а делать именно вытягивание. Как в svn, короче говоря, то есть вытягиваешь только кусок, и при этом гид-историю вообще там забиваешь на нее. Подожди, это фактически на стороне гитхаба значит экспорт и отдать тебе последнюю ревизию? Или даже часть этой ревизии? То есть это... Да, у них есть... Это можно сделать через гид, а когда делаешь феч или клон, там можно указать количество коммитов, насколько надо историю намотать назад. Если так делать, тогда к вам придет гитхаб и скажет, что вы делаете на них очень большую нагрузку на CPU, потому что к гиту надо это все вычислять каждый раз. А у них там есть какой-то отдельный API, который прям позволяет просто архив скачать текущего снапшота, типа скоммита. Почему-то это быстрее у них работает, я не знаю деталей. Мы вот это и знаем на CI. А там нельзя скачать какую-то ветку? То есть у вас же большой монорепозиторий, это значит там в нем два проекта, три проекта, внутри каждого проекта есть библиотека, вот тебе надо эту библиотеку собрать, зачем тебе все остальное качать? Мне кажется, даже у гита, как у git севера, есть какая-то такая фича, которая позволяет запросить под дерево в сжатом виде. Там, по-моему, есть такая фича. И по-моему, даже конкретную ветку можно спросить. Ну, там это не нужно, конкретно скачивать библиотеку, этого не приходится делать. Потому что иначе тогда смысл монорепозиторий, то есть тогда мы бы разбили это все на много репозиторий. И тогда бы все это... Да, логично, логично. Еще интересно, кстати, сказать, в лифте мы единственный монорепозиторий. Вот андроид кусок. Ну, вообще, iOS еще сейчас туда движется, потому что они тоже такие же задачи приходится решать. Но похоже, что исторические люди, которые пришли в лифт из гугла и фейсбука, где были монорепозитории, настолько этого там наелись, что у нас в лифте больше тысячи репозиториев. То есть там куча из них микросервисы, какие-то библиотеки, которые не шарят между микросервисами. То есть они наоборот от этого ушли, и мне кажется, это более правильно. Слушай, я никогда не работал с большим монорепозиторием, который включает в себя все. И я плохо себе представляю жизнь в этом. То есть я чувствую всю боль, но я не понимаю, за что туда люди идут. Ну, это хороший пойнт. За что туда люди идут, я так понимаю, основная причина – это быстрый шаринг кода между проектами. Ну, реально, просто так пошарить код между джава-приложениями – ну, это надо ходить все время через мамин репозиторий, и тут возникают проблемы разные. Оно решаемо, и мне даже хочется это попробовать. То есть на основе, например, semantic versioning и правильного data group ID и так далее, просто не допускать возможности поломать проект и все время указывать, типа, скачивай версию, например, 2.+, и оно будет смайленно так вытягиваться. Если вы можете гарантировать, что вы не будете нарушать semantic versioning, то, в принципе, мне кажется, это нормальный вариант. И тогда у вас получается, что каждый проект может жить в своем репозитории, и вы в каждом проекте получаете очень быструю работу IDE, белосистемы, гита и всего вот этого. Но минус – это переключение контекста. То есть когда вы работаете над большим количеством разных проектов, переключаться между ними, даже просто в IDE разные проекты – это очень большая потеря времени и константрации разработчика. Мне кажется, в той же самой IDE можно, мне кажется, так заставить, что у тебя просто будут, грубо говоря, разные директории, разные… то есть ты не уверен, как именно у того IDE делать, но в фонт там есть VH, чтобы ты можешь, в общем-то, репозиторий иметь как другой кусок твоего проекта, или ты можешь иметь их как сабмодули к твоему основному репозиторию. Так что я думаю, что с точки зрения IDE это разрулить можно. Тут скорее вопрос именно в том, что… ну и опять же, я в монорепозиториях не жил, но обычные любители монорепозиториев приводят основной аргумент, что у тебя просто все, вот есть какой-то commit, и у тебя это срез всего проекта. Все так, так можно, но тогда придется генерировать кастомную схему проекта, чтобы она поддерживала… ну, в Intel же, во всяком случае, надо генерировать кастомную схему проекта, чтобы его можно было использовать нормально, там, была навигация по коду, какие-то папки были заигнорены, какие-то папки были подключены. Если подключать, то есть, например, натравить ее на папку projects, условно, в которой будет много проектов, мне кажется, могут начаться проблемы, потому что она настроена на то, что, как правило, она выводит структуру проекта из build.config, который у вас есть в проекте. Я не уверен, сможет ли она так сделать, если она будет все-таки выводить структуру проекта, я не уверен, сможет ли она так сделать, если там будет несколько проектов, но это очень интересная мысль, и мне кажется, это стоит попробовать. А ты, соответственно, работаешь только с большим монорепозиторием, или все-таки у тебя есть маленькие тоже? Нет, конечно, я сам-то свои тулы держу в маленьких репозиториях. Нет, я имею в виду в рамках компании, то есть, скажем, CI, deployment и так далее, ты с маленькими, скажем, 100+, маленьких репозиторий отработаешь сейчас? Ну, не 100+, но какое-то количество, конечно, да. То есть, все, что не связано с Android и мобильной разработкой, оно живет в отдельных маленьких репозиториях. То есть, ты какие-то альтернативные идеи все равно обкатываешь? Ну, я вообще сторонник не монорепозитория, мне просто кажется, что это интересный experience, попробовать это поддержать. И вообще тут, как, сейчас с другой стороны немного зайду. Смотрите, вот Google сделал Bazel, да, Blaze, Bazel, Facebook, потом какие-то чуваки из Google ушли, пока вот эта велосистема не была open-source, им тоже надо было что-то похожее, потому что они работали с монорепозиториями. И, соответственно, Facebook сделал Bug, Twitter сделал Pants. Это все сделано выходцами из Google на основе идей Bazel. У меня вообще другая концепция, то есть, мне кажется, это уход все время от стандартного тулинга, который люди из индустрии привыкли использовать. И, соответственно, я что здесь пытаюсь сделать? Я пытаюсь стандартный тулинг заставить работать на больших проектах. Стандартный, ну что ты называешь? Ну, скажем, в мире Android и, в принципе, в джайвер-разработке сейчас Gradle одна из самых популярных велосистем. В Android это точно самая популярная велосистема. И все, кто приходят не из больших компаний, они только с ними работают. И, соответственно, им очень сложно привыкать к каким-то новым workflow, когда надо генерить структуру проекта из терминала, потом какие-то непонятные команды запускать, чтобы все собралось. У нас там вообще есть nick-файлы, через которые мы стараемся абстрагировать людей от того, с какой билд-системой они работают на данной. То есть, Make это тоже билд-система? То есть, вы строите билд-систему подверг билд-систем для того, чтобы упростить работу? Кстати, вот Make билд-система спорный, конечно, момент. Ну а что это еще? Ну... Чуть-чуть лучше, чем скрипты на баше напрямую, наверное, я бы так сказал. Ну просто это билд-система, потому что она умеет строить зависимости, дерево зависимости. Она декларативная, в отличие от баш-скриптов, которые императивные. То есть, все билд-системы, все они декларативные, как ни посмотри. Да, да, окей. Окей. Ну, конечно, не самая приятная штука, с которой приходится работать. Особенно потому, что в интеллеже до сих пор не знают, что в Make файлах надо табуляцию использовать. Это просто мозг выносит. Да ладно? Да. Вот в Sublime сразу такой тип. Ах, а Make файл, значит, я буду табы ставить. Идея? Не. Какая у тебя настройка стоит, табы на пробелы везде, ну я и здесь буду делать. Ужасно. Anyway, да. Соответственно, у нас какая проблема? Вот конкретно в нашем случае люди из индустрии приходят, они привыкли работать с Gradle, и еще есть от Google более кастомная версия интеллежи, и называется Android Studio. Она гораздо лучше заточена под Android разработку, то есть там очень много всякого тулинга докручено, типа как профайлить приложение прямо на телефоне, с него вытянуть структуру View, ну очень много каких-то заморочек по поводу Android. Оно бэкпортится обратно в интеллежи периодически, но не настолько там хорошее все. И соответственно, людям вот этот экспириенс ломается, потому что у нас баг, как основная билд-система для, скажем так, инкрементальной разработки. И интеллежи, и там все это вот так вот костылями и палками друг на друга накручено, и как-то работает, но многие штуки просто отваливаются. Но принципы все хоть один. То есть если говорить, что они все были построены на базе одной и той же концепции для монорепозиториев, то можно сказать, что у них сходные начальные данные, результаты должны быть похожи. Ну в принципе так и есть, да. Я не скажу про Pants, но баг и Bazel очень похожи. Это 100% так. И, ну я не знаю, там вплоть до Buildfiles, они прям очень-очень похожи. Но при этом мне кажется, что проблема в том, что они постоянно переизобретают какие-то свои велосипеды, и индустрия вся из-за этого в итоге тормозит и страдает. То есть они разрабатываются как большие такие комбайны, которые поддерживают, например. Ну одна из причин, почему мне не нравится баг, например, потому что я с ним больше работаю, ну я с Bazel вообще не работаю, в том, что в нем прям закорячена в билд-систему поддержка C++, Rust, Haskell, что там еще, ну естественно Java, какая-то поддержка Kotlin. И вот вся... то есть зачем это вкорячили в билд-систему, это очень сложный вопрос. Потому что билд-систему можно строить на основе плагабл компонентов, да, и, скажем, нужна поддержка Kotlin, круто, пусть JetBrains напишут Kotlin плагин. Нужна поддержка Rust, круто, пусть там чуваки из Rust-комьюнити напишут поддержку этого. А иначе оно все вкорячено в билд-систему, и мне там, например, когда я обновляю баг у нас в проекте, мне приходится листать там просто тысячи коммитов и там выбирать из них, какие из них самые интересные, и смотреть, что у них другого там стало теперь в этой версии. Вот. И что самое плохое, они очень часто перезабирают какие-то достаточно важные компоненты, участвующие в day-to-day разработке, то есть, например, что у Bazel, что у Baka есть свои системы для инкрементальной там установки Android-приложения на устройство, чтобы оптимизировать время установки. Соответственно, просто так это Gradle не получает, да, там, или другие билд-системы, которые люди используют, и это очень сложно вытащить из Baka или Bazel, потому что они просто закладывают это прямо вовнутрь, закапывают, и, ну, мне кажется, такой подход к разработке – это такой достаточно сильный шаг назад в индустрии. Здесь напоминает мне, если честно, JPL-2, то есть, если ты начинаешь пользоваться хоть чуть-чуть Bazel, то для того, чтобы все его полноценную функциональность как-то увидеть и почувствовать, ты должен все затащить внутрь него. Когда ты его затащил, то, соответственно, все другие библиотеки, которые от него зависят, тоже начинают чувствовать необходимость залезть в Bazel. И так постепенно все затаскивается в Bazel. Но это мое впечатление, конечно. Насколько я помню, ты же рассказывал про C++, правильно, с Bazel? Да, но у нас сейчас система сборки основана на Bazel, и, соответственно, все библиотеки, которые были рядышком и были написаны на Make, или на Shell, или на Python какие-нибудь односкриптовые штуки, сейчас они начинают превращаться в build файлы и так далее. Да, так. Но мне кажется, тут важно отметить, что это относится только к некоторым языкам. То есть языки, которым нужно распространять исходные коды для сборки, потому что они не могут распространяться. Они могут распространять какой-то байт-код, который шарится. То есть, например, в случае с Java библиотеками, что баг, что Bazel, они могут вытягивать эти библиотеки из централизованных репозиториев. И, соответственно, не надо эту библиотеку переводить на баг или Bazel. Потому что в Java можно шарить байт-код, и его не надо собирать. Он просто рантаймом запустится как надо. В случае с плюсами или с Rust, да, это надо пересобирать, потому что может быть не выложена версия библиотеки, скомпилированная под вашу архитектуру. Но, мне кажется, например, если посмотреть на тот же Rust, тут более грамотно к этому подошли. То есть они изобрели какой-то формат пакетов условный, сделали карго, которые по сути системы сборки, поверх компилятора, которые могут поддерживать и вытягивать эти проекты централизованно. Соответственно, мне кажется, вполне реально написать другую систему сборки для Rust, которая просто сможет понимать структуру карго-проектов и все равно вытягивать их, не переводя эти проекты на новую эту билосистему. То есть это просто, наверное, историческая особенность плюсов EC, потому что тогда не думали про такое, мне кажется. Да и сейчас нет единой системы, которая все поддерживает. Да, да, ну боль, ну Rust, Rust получше. Переходите на Rust, разговариваем про Bazel и Babak, переходите на Rust, результат обсуждения. Слушай, ну хорошо, допустим, вот у нас есть монорепозиторий, допустим, нам нужна какая-то система сборки для его удобного управления. Я не говорю именно сборка, но фактически нам надо управлять этим репозиторием. Bazel и Babak. Ну то есть мне хочется понять, почему они получились. Во-первых, почему они получились такие монструозные, но я тут сам могу ответить на этот вопрос, потому что им много лет, постепенно годовые кольца и какой-то технический долг убивает любой проект. И система сборки отсюда не исключение. Но есть ли вообще жизнь на Марсе, то есть возможно ли система, которая будет хороша и не будет монструозна и будет удобна в использовании? То есть я, скажем, видел систему, которую сделали, как она называется, Please Build или Build Please, не видел такую? Это тоже выходцы из Гугла написали, у них идея была взять аналогично систему, которая будет заряжать все системы, но вытащить только хорошие из Bazel, грубо говоря. И одно из самых плохих, что они увидели в Bazel, то что он основан на Java, соответственно объем системы сборки может быть громадным. То есть только потому, что тебе нужны какие-то библиотеки для обработки того-сего, и у тебя получается сама система сборки может вытягиваться долго-долго, для того чтобы даже стартовать. Они хотели написать систему, по-моему, на Go, для того чтобы это был один бинарник, ты его копируешь для своей архитектуры и начинаешь работать мгновенно. А ты вообще сталкивался с… Звучит неплохо. Да, я согласен, что звучит неплохо, но вообще ты сталкивался с проблемами с Bazel именно из-за объема? Ну, бак у нас, бинарник занимает 80 где-то 7 мегабайт, то есть это не так плохо. А на чем он? Это терпимо. Бак куском на Python и основной пласт на Java. О, боги. Но на Java можно шринкать код, то есть можно вырезать неиспользуемый код, это в принципе сильно может уменьшить разъем бинарника. А Python все равно же на тайм тянет. Предполагается, что он у тебя есть на системе? Да, вот это, кстати, большая проблема. Когда хумбрию обновил, вот это было не веселое утро. Послушай, вот хумбрию обновил, я не знаю... Не, ну у меня вот самая большая проблема, я сейчас докеризирую все. То есть запуск в контейнеры в кабернетесе требует, чтобы ты все это собирал внутри каких-то контейнеров. Иметь Bazel внутри контейнера, ну это прям беда-беда. Ну как так можно? У меня там объемы сразу становятся гигабайтными. Я все еще не понимаю, зачем тебе Bazel внутри контейнера тащить. Сейчас же есть уже у докера возможность собирать. .. Имеет специальный отдельный образ, который... Мультистейдж, ты про мультистейдж говоришь. Да, мультистейдж, да. Ну то есть тебе для того, чтобы начать собирать твое приложение, нужно сперва собрать докер-образ, в который сможет собрать твое приложение, верно? Вот у меня с этим даже проблема. Чем проблема, как я и говорил, с Bazel? Бинарники мне очень много весят. У меня чаще всего... То есть как бы все системы сбора, которые я видел, они требуют Bazel, который говорит, ой, а мне, кстати, для того, чтобы вот это собирать, нужно подтянуть сейчас свои зависимости, давай-ка я их сейчас себе подтяну. Ой, кстати, а часть из них нужно скомпилировать, дай-ка я их сейчас скомпилирую. И вот начинается вот эта тягомотина, которая занимает большой объем. Вообще, мне кажется, мы так плавно неплохо перешли к теме врапперов. Я там в тему заносил Gradle враппер. Да, да, да. Тут есть такая идея, значит. Мне кажется, первые к ней пришли в билд-системе Gradle. То есть идея какая? Что исторически сложилось так, что многие билд-системы вообще инсталлятся в систему, как системные пакеты через какой-нибудь аппетит, да? Что достаточно ужасно, потому что если разные версии проекта требуют... Ну, разные проекты требуют разных версий системы сборки, это все достаточно сильно геморроет вашу разработку. Ну, и хочется докеризировать сразу просто от этого. Да, да. Значит, к чему пришли чуваки из Gradle? Они такие подумали, что вообще никакой необходимости иметь Gradle как систему зависимости нет. То есть это нужен просто бинарный, в каком-то предиктабельном месте. И хочется, чтобы любой, кто просто сделал git-клон, мог написать какую-то команду, да, и все собиралось бы, неважно, был у него Gradle до этого или не был. Поэтому они пришли к такой вещи, как Gradle Wrapper. По сути, что это такое? Это shell-скрипт для Linux и macOS, и bat-скрипт для Windows. А про Windows я сейчас не буду разговаривать. И это еще маленький джарник, который умеет bootstrap-ить, по сути, Gradle. И что происходит? Всю работу с Gradle вы делаете через вот этот shell-скрипт. То есть Gradle Wrapper. Вы его кладете прямо в проект, и, соответственно, когда он стартует, он просто смотрит, ага, есть ли у меня Gradle в папке юзера в системе. Там есть такая папочка, tilde, slash, точка Gradle, и там разные версии Gradle могут лежать. Соответственно, в разных проектах у вас могут быть разные версии Gradle. Вы, когда первый раз запускаете, он его скачает, все последующие операции просто будут уже работать на скаченной версии Gradle. И это очень сильно помогает достичь reproducible, built environment, без каких-то сильных затрат или декеризации, которые приходится форсить на юзеров. Соответственно, Bug и Bazel в самих себе, у них нет такой концепции. И мне кажется, это очень сильно усложняет вообще дистрибьюцию, например, бинарника этой билосистемы, потому что его надо обновлять. Его надо обновлять так, чтобы он у всех разработчиков был все время одинаковый. И, соответственно, конкретно с Bug мы используем такой проект от Uber, что интересно, OkBug, он поставляет свой Bug в wrapper, который у нас там немного модифицированный, но он вытягивает Bug, он позволяет абстрагироваться от того, что Bug может не быть в системе на момент того, как вы с ним пытаетесь работать и рулить его скачивание. Мне кажется, для Bazel надо что-то такое просто сделать. Слушай, ну вот я как раз о подобном думал буквально сегодня-вчера. То есть мне тут пришлось работать на Rebar 3. Это система сборки, соответственно, даже не знаю, как это правильно сказать, но то же самое примерно для Erlang. То есть он умеет скачивать зависимости, он умеет компилировать код, он умеет создавать релизы, торгозе, все что угодно. И я с ним работал в последний раз довольно давно, и у меня были очень положительные воспоминания. Типа запускаешь его, у него есть такая команда Shell, он компилирует исходники, запускает проект в Davidi, и ты заходишь в консоль, прямо внутрь проекта уже рабочего. Ты можешь сразу, это репл полноценный, ты можешь какие-то команды запускать, проверять, исполнять. Сейчас я захожу в новый скачанный проект, то есть я зашел, запускаю Shell, и я понимаю, что стало совсем все плохо, потому что Rebar сейчас начал по умолчанию подгружать, смотреть, какая версия установлена, проверять, а есть ли у него обновление, а посмотреть на всякий случай список зависимостей, обновился или не обновился, потому что ты же не знаешь. Вот представь, то же самое с этим вокруг бака, обертка, как она у вас называется, OKBAK? То есть она запускается, она смотрит, есть какая-то версия бака. Правильная это версия бака, неправильная это версия бака. Есть ли у нее зависимости, нет ее зависимости. Может, человек сам ее скачал и установил себе, но это неправильная версия. То есть теоретически для того, чтобы начать по-нормальному работать, она должна выполнить кучу проверок в реал-тайме. В момент запуска, когда ты ее в консоли стартуешь, она должна выполнить кучу проверок. Это все равно становится медленным. Нет, конкретно эта часть достаточно быстрая, с этим проблем нет. В случае с Gradle есть просто файл, в котором указана версия, которую проект ожидает. Соответственно, этот Gradle в раппер очень быстро смотрит в файловой системе, есть ли скачанная версия, вот конкретно Gradle вот этой версии. С баком было очень похоже до этого, сейчас бак вообще, окей, бак перешел на вытягивание бака из мейвен-репозиториев. Соответственно, это тоже очень быстро, и все кэши пролетают очень быстро. Эта часть не тормозит. Я понимаю, что если в случае с ребаром он будет проверять все возможные обновления, это ужасно. Нет, он на самом деле проверяет обновления не с самого ребара, а с проверяет обновления зависимости твоего проекта. У меня в файле зависимости написано, что надо версии 2.0 или позже. И он, грубо говоря, лезет посмотреть, 2.0 или позже, а я посмотрю, у меня 2.7 установлено, не появился ли 2.8, грубо говоря. То есть у вас же та же самая проблема будет существовать? Ну, тут уже немного другое. Ты сейчас говоришь про зависимости конкретно проекта, а не... Ну, то есть как бы не зависимости системы сборки, а зависимости конкретно проекта. Ну, скажем, в джайве в мире это достаточно эффективно решено моими репродукториями, которые все билдсистемы, которые для джайва сделаны, они поддерживают так или иначе. И, как правило, редко вообще не рекомендуется указывать зависимости с нефиксированной версией, потому что это может приводить к нерепродюсерному билдам. И я, в принципе, сторонник того, что не надо так указывать, анлез вы вот прям сами сильно контролируете то, что они не решают там семантики. Знаете, что делаете. Не, ну в Rebar'е тоже есть там лог файл, который там лочит текущее значение версий, но ты его можешь отключать, если хочешь. Ну, короче, своя беда. Я не знаю, как в Rebar'е, в Mix, например, алексировский, ну и, собственно, в Rude'овский Bundler, они позволяют тебе выкинуть с фазы, ну, таким, типа, с версиями, которые там специфицируют первые две цифры там в semantic versioning'е, получить тебе билд какой-то, который билдится, потом фиксирует commit, и оно не будет меняться, пока ты не скажешь ему update. Ручками, да. Но я думаю, это сейчас к этому постепенно все приходят. Ну, это, кстати, большой вопрос. То есть ручками, если делать update, непонятно, как в команде разработчиков убеждаться, что все используют последнюю версию. Нет, в смысле, ты коммитишь log-файл. Или такую же версию. Золоченный лог-файл коммитишь, то есть прикол в том, что, с одной стороны, то, что ты хочешь получить, написано через semantic versioning, когда ты можешь там сказать все, что там, не знаю, в версии, когда они ломали совместимость, и опять же у тебя то, от чего ты зависишь, тоже можно по-другому, и от чего-то еще зависеть, с такими же правилами. Вот оно как-то пытается разрешить, и оно у тебя получается какой-то билд, если оно нормально работает, оно лочится, и дальше это просто лог-файл коммитится в репозиторий, как я и сказал, и оно просто таскается, пока кто-то из разработчиков не решит обновить и не закоммитить новый лог-файл в репозитории. Ну вот это, кстати, мне, конечно, непонятно. В Rust тоже так, с Cargo, там есть log-файл, есть toml-файл, но я чего-то вот этого не понимаю. У меня есть файл, в котором написана версия, зачем мне еще один файл, в котором еще раз написана какая-то версия? Потому что в первом файле у тебя написано, типа, пожелание, да-да, то есть больше 2.6. Ну почему я реально не могу написать, окей, вот это, типа... Нет, подождите, это же конфликтующая вообще идея. В одном файле написано больше, а в другом лог. Нет, смотри, в чем прикол, в одном файле ты пишешь, типа, хочу вот такую-такую-такую-такую библиотеку, и потом говоришь, разреши мне депенденцию, то есть у этих библиотек, между собой, могут быть какие-то сложные зависимости. Они могут ссылаться на версии, которые, там, ну, там, не знаю, одной нужна версия не старше такой-то, другой нужна не младше такой-то, вот оно все, там, транзитивные зависимости разрешит, и их тоже залочат, в следующий раз ты такой, что-то давно я не обновлял депенденцию, может, там, какой-нибудь, там, в bugfix вышла какая-то библиотечка, давай-ка, не знаю, сделаю mix-deps-update. Он такой хобот, снова пытается разрешить зависимости с новыми зависимостями, делает тебе новый логфайл. То есть у тебя для сборки используется вот именно логфайл всегда, а для того, чтобы получить логфайл, используется список желаемых версий, и, как бы, если версии, как бы, депенды разрешаются, они у тебя получаются все нормально, если не можешь разрешить get-dependence, скажешь, ага, вон там у этих двух библиотек конфликтующие зависимости, то есть иди, реши конфликт. Да, ну, скажем, в Java-мире это решается тем, что большинство билосистем выкачивают, то есть, скажем, у тебя одна библиотека зависит на, я не знаю, fubar 1.2, а другая библиотека зависит на fubar 1.3. В Java-мире просто выберется 1.3 для всех, потому что нельзя запустить там в одном, там, класс-пассе несколько одинаковых библиотек. Надо одну только выбрать, правильно? Соответственно, если между ними конфликт неразрешаемый, то у тебя билосистема failed build и говорит, так, выбери, какую версию ты хочешь, я не могу, типа, понять. И ты просто в своем уже конфиге явно указываешь, что, ну, до этого я не указывал, типа, вот эту fubar, потому что она была транзитивной зависимостью других каких-то библиотек, мне даже не важно было. А сейчас я прямо явно укажу ее как свою зависимость с конкретной какой-то версией и зафоршу для билосистемы резолвинг вот этой версии. И никакого второго файла не надо, и как-то все живут. Я, может, конечно, что-то упускаю. Так, наверное, тоже можно, ничего страшного, в общем-то. Просто разные подходы. Ну, да, да. Ну вот в Rust, что интересно по поводу врапперов, мне кажется, они близки к этому очень сильно, потому что Rust не требует установки ничего условно через пакетные менеджеры. То есть там есть скрипт Rust, Rust tab, который ставит просто в текущего юзера бинарии Rust компилятора, карга и так далее. Но проблема какая, что если у вас несколько Rust проектов на разных версиях, ну, требует разных версий компиляторов, вам приходится все время каргой переключать, ой, не каргой, а вот этим Rust tab переключать версии компиляторов для всего своего юзера. Вот это, конечно, тоже, мне кажется, большой косяк. И, возможно, чем больше я буду с ним работать, Event Shell, может быть, в враппер придется запилить, потому что, ну, мне кажется, эта идея гораздо более правильная. То есть когда у вас проект может полностью декларировать, какую версию ему надо, и в проекте есть такой маленький тонкий враппер скрипт, через который можно сборку делать, неважно, установлена ли система сборки изначально или нет. Так, ну, похоже, тема себя исчерпала. Или ты хочешь что-то еще добавить? Ну, наверное, нет. Наверное, я бы сказал, что просто идеологически, если даже вы делаете какую-то большую систему, старайтесь ее разбивать на компоненты так, чтобы можно было между другими системами переиспользовать. Потому что на данный момент есть несколько больших биосистем, и между ними очень сложно обмениваться какими-то наработками. Потому что они просто в себя это намертво загорячивают. И это, наверное, просто с точки зрения развития индустрии неправильно. Вот, слушай, кстати, вот что я хотел сказать по поводу твоего предыдущего пассажа. Ты говорил, что ты пытаешься всех перевести на стандартные системы сборки, в частности на Gradle. Потому что людям это будет удобно. Но, с другой стороны, в какой-то момент, скажем, того же Gradle не было. И все, кто переводили на стандартные системы сборки, как-то переводили на какое-то неправильное Г, потому что правильной системы сборки еще не было. Я к тому, что если ты не будешь пытаться делать нового, то никогда не получишь хорошего решения. Конечно, да. Поэтому, может быть, правильным результатом нашего обсуждения будет так, давай напишем правильную систему сборки. Скажи, пожалуйста, какие у нее должны быть свойства. Да. Мне кажется, это очень хороший пойнт, что не просто так Google сделал Bazel, а потом Facebook и Twitter сделали Buck и Pence. Действительно, у них были причины для этого, проблемы, на мой взгляд, в том, что видимо, это вопрос в идеологии разработки. Им кажется, что большая монолитная система, которая все их проблемы решает, это более правильный путь развития. Он, безусловно, более правильный в начале, потому что он позволяет вам быстрее итерироваться, и все этот монолит используют, и всех проблем внутри компании все эти решают. Но это не значит, что потом не будет проблем, если вы попытаетесь в индустрию это впихать. В индустрии проблема в том, что у людей очень много разных конфигураций, и тут выигрывают системы, которые основаны на плагабл-подходах, то есть когда вы можете в систему добавить что-то, не меняя саму систему. В Gradle он так и сделан. В Gradle десятки тысяч плагинов для билд-системы, которые решают разные проблемы, и они в принципе все достаточно хорошо работают. Поэтому, наверное, если билдить какую-то новую систему, хочется, чтобы она сразу была плагабл, но тут стоит вопрос с тем, что чтобы сделать ее плагабл, нужен какой-то рантайм, который позволяет эти плагины подгружать. И хочется, чтобы она была быстрой, идеальной она будет на каком-нибудь расте, безопасной, быстрой, минимальное количество локаций, потому что на Java все эти билд-системы ужасны. Настолько все живет память и стартует очень медленно каждый раз, что невозможно с этим работать. Поэтому хотелось бы, конечно, чтобы она была... идеально вообще без UFI и с минимальным оверхедом для рантайма, но тогда встает вопрос плагинов, то есть это реалистично сделать, но достаточно сложно будет их как-то подгружать в билд-систему. Можно набросить? Конечно. Я, кажется, знаю такую очень модульную, расширяемую штуку, которая очень быстро работает, написана на максимально портированном языке, может быть не супербезопасная, но точно дико расширяемая. Ты про makefile? Да. Ну, когда они стабов перейдут на пробелы, тогда поговорим. Нет, вот это серьезно, вот так вот и сижу я такой, я понимаю, в чем прикол языко-специфичных систем сборки, потому что они заточены под какие-то конкретные вещи, специфичные для языка, типа репозитория пакетов, типа того, как, не знаю, Rebar в Erlang знает, как собирать C-экстеншены для виртуальной машины, то есть там нитки или драйвера, как собрать, вот это все. Это дико специфично для языка, рантайма, это логично запихать в языко-специфичную систему сборки, но даже это часто потом обматывается make, и make такой lingoframe, то есть, я не знаю, я видел makefile вокруг SBT, например, вот это все. Или makefile вокруг Docker. А зачем вообще делать такой баг еще что-то там, чтобы, не знаю, я слышал, чтобы артефакты менеджить, еще есть какие-то аргументы за то, чтобы делать специальную мега-систему сборки, которая может работать с разными языками, и при этом не makefile? Ну, makefile же есть какая проблема, насколько я и мой опыт, в нем нет какой-то удобной reusable pluggability, то есть тебе придется его сильно редактировать, и если в каком-то проекте, даже в open-source, кто-то реализовал в нем какой-то функционал, то это просто приходится копипастить и как-то адаптировать под свой makefile. Нет, подожди, там есть лучшая аргумент плугабили, ты можешь позвать любую команду из Shell. Так, дальше что? Как ее интегрировать в lifecycle билда? Ну, в смысле, у тебя есть цели, просто ты говоришь, что у тебя один из стейджей, где-то какая-то одна из целей, это позвать вот ту шеллевую команду, и вот дальше делать, что хочешь, максимально плугабилить. Это все так, но, скажем, если посмотреть на Gradle, у Gradle, мне кажется, вообще самая богатая система плагинов и API, то есть эта build-система предоставляет огромный пласт API для плагинов, чтобы они могли интегрироваться вообще в разные стейджи билда, то есть ты в build-файле добавляешь просто apply-plugin такой-то, а у тебя интегрируется, например, что-то в этап Java компиляции или в этап publishing артефактов и так далее, и не приходится это руками промапливать во все эти этапы, особенно это сложно, когда у тебя много модулей, и там этапы-то повторяются, просто есть какая-то категория каких-то задач, которые выполняются для всех модулей, и хочется что-то заплайить для всего этого. То есть мне кажется, это просто неменеджабл в make-файлах. Я не пользуюсь Gradle, мне тяжело сейчас поспорить, но мне кажется, что make-файл – это такая штука, которая пишется под твой проект, у тебя все файлы уже будут, ну или какой-то шаблон, например, подходящий более-менее для любого Java проекта, и ты просто из него потом можешь нужные места дописать, нужные действия, как тебе нравятся. То есть мне кажется, здесь большая разница между том, что Gradle, он просто видит Java проект и он знает, как его собирать, а make-файл – тебе нужно сделать некоторое количество действий в самом начале, сказать, что вот-вот-вот, собирать как-то вот так вот мои стейджи, и потом ты их можешь менять, как хочешь. Слушай, make-файл – замечательная штука, я тут с тобой согласен, но как только проект достигает какой-то сложности, когда у него становится несколько шагов… Я валю! Не, я понимаю, что ты троллешь, но я люблю make-файл, вот реально я люблю make-файл, и везде, где можно использовать make и не использовать ничего другого, я так и делаю. В том числе у меня, скажем, обвязка, всегда есть make-файлы вокруг докер, всяких целей, для того, чтобы просто тупо не запоминать команды вот эти, для того, чтобы не вбивать все эти переменные окружения там, или не повторять, что и как, ты куда хочешь пушить. Ты нажимаешь make, build там, потом нажимаешь make, push – все, у тебя две команды, больше ничего писать не надо. Но, блин, вот я реально не видел ни одной системы сборки, которая бы полностью удовлетворяла всем возможным вариантам. Может, надо иметь не одно, а несколько? Вот как раз если ответить на троллинг, мне кажется, что надо иметь несколько make вокруг, и вообще просто заживем в идеальном мире. Вот у нас так, очень больно, у нас две build-системы и make-файл вокруг них. Ну, спорно, спорно, не экспириенс. Ну, потому что у вас одна из них пытается заменить make-файл. Ага, ну да, в принципе, да, логично. Ну тут, make-файлы, смотрите, какая еще проблема, то есть надо что-то сделать чуть больше, чем вызвать какой-то шеллинг, ну, окей, не шеллинг, а вызвать, например, компилятор. Или докер. Возникают проблемы, то есть хочется, например, обработать строчки, да, или еще что-то, что вы будете делать? Вы будете писать bash, скорее всего, потому что он там есть на всех юниксах, да, и тут такие проблемы устревают, то есть bash это настолько ужасный язык для написания вообще чего-то, кроме запуска других программ, то есть там проверить, начинается ли строчка с вот этой строчки, да, начинаются всякие приколы с тем, что там используют что-то, грепп, есть там gnu, есть bsd, у них разные там флаги, и все вот это, ну, это такая головная боль, что хочется нормального какого-то языка, у которого есть нормальная стандартная библиотека, которая позволяет вам работать там с коллекциями, со строками, все, что вы можете делать там во время билда, да, условно. Вот, и тут, как бы, ну, мне кажется, makefile просто сразу проигрывает. А ты считаешь, что внутри системы сборки обязательно должна быть какая-то система написания, тьюринг полное на каком-то языке или dsl? Да, для более-менее какого-то, ну, чуть больше, чем небольшой проект, да, скорее всего, да. Зачем? Вот мне тоже кажется, что если нужно как-то обработать строчки, и скорее всего, каким-то специфичным способом, то делаешь отдельную программу, собираешь до сборки остальной программы, которая будет обрабатывать тебе строчки. Ну, или имеешь ее на, я не знаю, там перле, питоне, ну, я имею в виду какие-то стандартизированные, ну, и, скажем, C, скажем, ее писать. Ну, да, конечно, это возможный вариант, но, смотрите, есть причина, почему, там, например, Gradle выиграл там популярность и все остальные билд-системы в Drive, потому что эти ребята подумали, что XML-конфиги, ну, такие статические, они очень сильно ограничивают вашу должность, и на каждый чих приходят какие-то, например, для мамины плагины, как-то их распространять. Ну, то же самое, там, если пишете на каком-то другом языке программу, которую вы собираете до, там, сборки других программ, и она, там, участвует в этой сборке. Соответственно, в Gradle они подумали и решили, что вообще сборка – это тоже программирование, и они, их основной язык для описания конфигурации – это Groovy. Это, конечно, очень спорный выбор языка, я тут не спорю, но, благо, они сейчас переходят на Kotlin Script, чтобы сделать там его TypeSafe и автокомплит, вот и нормально, чтобы было, когда с этим работаешь. Но это настолько облегчает некоторые задачи, то есть, ну, я вам просто для примера расскажу, у нас большинство, то есть у нас как это делаемо? У нас в проекте только Gradle конфигурации, а баг, билдфайлы мы генерируем из Gradle конфигурации, то есть вот этот проект okbug, он читает модель проекта Gradle и генерирует багфайлы, чтобы баг дальше с ними мог работать. И вот эти багфайлы, ну, там просто сотни строк, иногда некоторые в тысячи, а в Gradle это там десятки. И вот в этом и вся разница, потому что в Gradle можно что-то напрограммировать, добавить каких-то плагинов, и оно вам просто бутстрайпит всю эту функциональность гораздо более компактно. И, ну, мне кажется, это неоспоримое преимущество таких биосистем. Вы там живы? Я да, просто не знаю, куда дальше добавить, что сказать. Ну, согласишься, не согласишься? Понимаешь, это довольно холливордный момент, то есть ты или, как мне кажется, или делаешь систему, которая специфична для твоего языка, и встраиваешь его в полную эту систему, и позволяешь как-то интересно что-то расширять, или ты хочешь универсальную быструю штуку, которая будет совсем работать и при этом быстро. То есть, ну, или ты хочешь Makefile, или ты хочешь Gradle. Ну, вот тут как-то, я не знаю, мне тяжело придумать, но, не знаю, вот есть такой Makefile, условный Makefile с полным языком, например, Rake. Ну, тут более-менее то же самое, просто можно еще на ругах писать. Ну, уже как бы становится медленнее. Ну, все так, да, у всего есть трейд-охраня. Пошли дальше? Да, давайте, я предлагаю пойти дальше. У нас там еще было, чтобы добить уже про систему сборки, там было еще что-то про то, что Errorpron компилятор от Google. Что это? Это компилятор, в котором ошибки, или компилятор, который ищет ошибки? Это компилятор, в котором ошибка, на мой взгляд. Ну, в общем, в Лугле давно уже, где-то с 2010-го, по-моему, начали работать над Errorpron. Это такой Java-компилятор, который прямо во время компиляции ищет проблемы в Java-коде, и, соответственно, их репортят сразу, и ломают компиляцию, или выводят вординги. И у них есть целый тейпер, который, пришлось прочитать эту тему, описывающий, что даже самые лучшие разработчики делают глупые ошибки, поэтому мы решили инвестировать в статический анализ частичный, чтобы от этих ошибок просто избавиться. Интересно, что изначально они задизайнили вообще, по сути, Fork, но в OpenJDK-шный компилятор для Java, и прямо в процессинг IST добавили анализ каких-то вещей. И их мотивация была в том, что запускать какой-то отдельный тунинг для поиска ошибок – это все время мимо cycle development, то есть это надо как-то сложно интегрировать cycle development, хотя на самом деле это не очень понятно, если у них есть build-система, которая позволяет это интегрировать после компиляции, и как-то прогнать это. Но второй их основной был point в том, что анализировать код после компилятора – это неэффективно, потому что компилятор уже анализирует IST вашего языка, и вы просто этот IST берете прямо в память компилятора, и его проверяете еще на какие-то вещи. То есть идея, кажется, на самом деле достаточно неплохой, если performance брать в такой consideration. И если вы их в paper посмотрите, ну, paper достаточно старый, но прямо в paper у меня сейчас здесь лежит написано, они обнаружили, что он добавляет 9% overhead по времени и 0.95% – то есть меньше 1% – memory overhead. Я вот тут недавно пытался интегрировать наш проект, короче, 3.46 раз медленнее, еще и на 20% больше памяти IST. У вас просто проценты другие. Подождите, да-да-да. И, короче, я такой, окей, наверное, это что-то специфичное для нашего сетапа. Я его заинтегрировал в другой one-source проект на Java, и там это все набенчмаркал, напрофайлил, она вот прям практически один в один повторяет, и там такой вот… это просто, конечно, в тему того, что если проект находится под Google Slash или Facebook Slash, это не значит, что он там хорошо написан. То есть у них там очень большое количество времени уходит на проверки, которые вообще коду могут быть релевантны. А давайте проверим, что вот эта библиотека используется правильно. Она не используется. А эта проверка, например, 2 секунды тратит на анализ переходов во всей вашей программе. Хотя они могли бы проверить, что в ClassPath вообще нет ни одного класса, просто ничего не делают. И вот такие вот вещи, то есть они там… Я его профайлил сейчас, и там просто весь, например, если сравнивать с OpenJDK или Oracle NGDK компилятором, то есть там, например, Flow, часть компиляции, анализ Flow в OpenJDK на вот этом проекте, на RxJava я проверяю это, он занимает там 50 миллисекунд. В HeroPro он занимает 8 секунд. То есть там настолько некоторые этапы пайплайна компилятора перемолотили плохо, что это просто диву даешься, и никто не заботит MTicket вообще на то, что это медленно, потому что все, видимо, полагаются на то, что у вас очень много маленьких модулей, и на каждом модуле не страшно, если они все закешированы в какой-то распределенной, например, системе хранения кэша. Но это, конечно, просто физически… Идея достаточно интересная, что это интегрировали прямо в компилятор, потому что он уже ст видит, но при этом вы теряете сразу возможность переиспользования это для других языков, потому что есть универсальные ст, у JetBrains, например, есть UIST, который несколько языков поддерживает, там, Java, Kotlin, и при этом вы работаете агентством этого UIST, и можете писать какие-то чеки, которые вообще на всех языках будут работать, на которых UIST реализовывается. И тут как бы все время был вопрос, насколько же оно быстрее, чем если это в компилятор интегрировать. Похоже, что можно настолько сильно накосячить, что, скорее всего, отдельные чеки еще и outperform это все. Вот такие интересные находки. То есть все-таки error prone – это значит много ошибок внутри. Ну да, там статическим анализом error prone не скажешь, что он медленный, но если человек почитает, то понятно, почему он тормозит в некоторых местах. Че, тогда пошли к следующей теме? И следующая тема моя. Мы начали уже темы, которые отвязаны от гостя, которые принесли мы сами, но я надеюсь, Артем, ты с нами обсудишь их. Да, посмотрим. Первая тема – это тема, которую на прошлой неделе нам принесли гости, которую я обещал осветить, и на самом деле я не хочу сильно погружаться. Это Kubernetes 1.10. В двух словах – это очередной релиз Kubernetes, который… то есть сейчас есть активная стейбл-версия Kubernetes 1.9.6, по-моему, 1.9.7. И вот 1.10 вышла, это уже, соответственно, следующая версия. Они поменяли некоторые API с точки зрения… то есть как бы у них очень интересная работа с API, если вы еще не смотрели, когда вы начинаете работать с ресурсами, вы объявляете, какому API ресурс принадлежит. То есть вы можете сказать, например, app-v1 – это значит версия 1, applications. Все новые API, они приходят в бету, то есть вы пишете, например, apps-v1-beta, что-нибудь типа такого. Или extensions-v1-beta. В дальнейшем, после того, как из бета они выходят, они переходят, то есть исчезает имя бета, и вот в текущем релизе тоже они перевели часть интерфейсов из беты в обыкновенную, из альфа в бету. Поэтому смотрите, переводите, те, кто переходит на новую версию. Это означает, с одной стороны, то, что добавили и проверили стабильность, исправили какие-то баги. С другой стороны, обозначает, дает знак сообществу, что вот некоторые вещи все уже полностью ушли из бета, и это можете использовать где угодно в продакшене, все проверено. Больше всего изменений функциональных связано с группой по интересам SIGNODE. Node – это в смысле нода. Появилось много новых фишечек. В частности, вы можете написать конфигурационный файл для кублета и написать какие-то специфичные для кублета настройки в этом файле. Положить его, скажем, в version crawl и использовать. Это довольно удобно, потому что этого можно было делать только через command-line параметры. В частности, вы там можете сказать, что кублетам следи за памятью, если осталось там меньше 200 мегабайт, удаляй поды, потому что тебе нужно больше памяти. Появилось много конфигурационных параметров. Например, вы можете сказать, чтобы в поде контейнеры шарили один и тот же процесс namespace. Или, например, для того, чтобы вы привязывали эксклюзивно какие-то ядра к каким-то процессам. То есть вот такие удобные фичи, которые позволяют лучше следить за перформансом, особенно если вам это критично и важно. Скажем, если у вас latency или какая-нибудь real-time система. Появилась поддержка huge pages. Это такая вещь, которая говорит, что вот этот под может взять предалацированный большой объем памяти и использовать только он его. Мегабайты, гигабайты, что хотите. Дополнительная работа с device-plugin. Для того, чтобы работать с всякими разными GPU, FPGA, InfiniBand и так далее. Я вот сюда еще не смотрел, собираюсь посмотреть, потому что это выглядит интересно. Это особенно будет удобно работать на железе, на bare metal. То есть если вы не в Амазоне и у вас какие-то специфичные железяки есть, теоретически вы можете написать свои собственные ресурсы, операторы для того, чтобы работать с вашим собственным железом. Наверное, они идут сейчас в эту сторону. И это хорошо. Улучшены какие-то свойства в storage. В частности, с volume PVC, persistent volume claims, работа с ними была улучшена. И куча Windows, OpenStack, Azure. Туда, куда я вообще даже лезть не хочу. Есть отдельно написанный сценарий, как правильно переходить с предыдущих версий, потому что это мажорные изменения. Не смотрите, что там. Да, это мажорные у них. То есть 1.9 на 1.10 надо очень внимательно смотреть, с какой версией можно, с какой нельзя, и какие ручные изменения потребуются для того, чтобы перейти. Всем ура! Хлопаем в ладоши и радуемся кубернету, что он так активно развивается. Да, я хочу сказать, что если вы хотите посмотреть на changelog, то реально changelog со всеми полными, с полным списком изменений занимает, я не знаю, 20 страниц. То есть там читать не перечитать. А у них реально настолько много изменений? Или они просто как бы git log туда? Нет, нет, прям дофигища изменений. Все написано очень аккуратно. Я листал, листал, и у меня сейчас застыла на странице scheduling. И тут говорится, мы исправили вот такой баг, номер такой-то, ссылка отсюда-то, он связан с тем-то, тем-то. Мы добавили такую-то фичу в GitHub issues и pull request ссылка. Мы добавили то-то, мы изменили то-то и так далее. Нет, нет, это звучит не как release notes, это звучит как реально git log, который мы дополнили сейксом. Но то, что они исправили багов, это всего одна строка в release notes, типа мы поправили багов. В чем отличие тогда git log от release notes? Release notes написан для людей, git log написан для программистов. Но я к тому, что ух ты, у них там 20 страниц изменений, это значит, что они плохо пишут release notes, а не то, что у них так много изменилось.",
    "result": {
      "query": "лучшие билд системы монорепозиторий"
    }
  }
]
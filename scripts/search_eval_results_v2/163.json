[
  {
    "segment_id": "ad3a5eac-04ae-4380-b696-2ff1bc8952d0",
    "episode_id": "3ce5bd4f-2f7c-48b5-9ec5-00685d42bc7a",
    "episode_number": 163,
    "segment_number": 8,
    "text": "Отвечая на твой вопрос, конкретно я работала над проектом по аутентификации юзеров на смартфонах, задача была делать это не с использованием паролей или каких-то специальных сенсоров, там распознавание отпечатков пальцев и так далее, а использовать те сенсоры, которые уже есть внутри прибора, то есть это может быть, опять же, не знаю, камера, микрофон и так далее. Я работала над такими сенсорами, как оксидрометр, гироскоп, магнитометр, и задача наша на 3-4 месяца была понять, есть ли в этом сигнале движения некая биометрическая информация, которая могла бы помочь аутентифицировать юзера. Но могу сказать, что вердикт был, можно сказать, положительный, потому что сигнал определенно есть, он достаточно слабый, но если используется несколько разных видов сигналов, они все комбинируются, наша группа показала, что это может быть даже более эффективно и безопасно, чем использование отпечатков пальцев. Ого, а расскажи подробнее, как это было технически реализовано. Мне это очень интересно лично, потому что я сама сталкивалась с такой задачей и делала анализатор именно данных сенсоров мобильного телефона. Поэтому мне просто очень-очень интересно знать, как это технически делали. Конкретно для этого исследования Google собрали базу данных, там было полторы тысячи юзеров этих смартфонов, которые были осведомлены о том, что их записывают. Google разослал полторы тысячи Nexus-ов волонтерам и в течение нескольких месяцев мы записывали показания всех датчиков с этих телефонов. Не все, конечно, юзеры были активны, но датасет получился достаточно большой и репрезентативный. И, соответственно, где-то тысячу девайсов мы использовали для обучения и остальное для тестирования. Задача была в том, что поскольку... Наша задача была, конечно, попробовать решить этот метод с помощью Deep Learning, поскольку сигнал такой достаточно неинтуитивный, какие-то там ручные методы, может быть, не очень эффективны. Поэтому у нас была большая нейронная сеть, которая считывала все эти показания акселерометрия, гироскопа и так далее, создавала какую-то там репрезентацию, формулировку данных. Как в Deep Learning это была большая LSTM, просто с сверточными слоями на входе, несколько слоев LSTM. И на выходе мы сначала тренировали эту сеть просто как задача классификации. То есть у нас есть тысяча девайсов, задача распознать, с какого девайса приходит этот сигнал. И затем какие-то там репрезентации, которые получались в каком-то промежуточном слове, использовались как модель для данного юзера. И уже эти репрезентации на мобильных устройствах используются уже в условиях бинарной классификации. То есть либо юзер собственных девайсов, либо какой-то новый человек, который отличается по поведению. Вот ты упомянула, что технически это был LSTM с несколькими сверточными слоями. А кто занимался проектированием архитектуры нейронной сети? Наша задача как раз была оптимизация архитектуры и именно экспериментов. То есть, как я уже сказала, надо было посмотреть, в принципе, получаем ли мы какой-то полезный сигнал или нет. И мы не фокусировались на том, чтобы эта имплементация была как-то эффективной и так далее. Именно занимались настройкой сети, подбором параметров. И иногда кажется, что этот процесс придумывания архитектуры нейронной сети, он кажется таким, как это приходит из головы. Вот давайте это попробуем, давайте это попробуем. А что если так сделать? А что если здесь параметр поменять? Расскажи, есть ли какая-то методология научная за этим? Я понимаю, что есть научный метод, и нужно проводить много экспериментов. Но может быть есть какой-то более подходящий способ это делать? Либо какой-то более правильный способ придумывать архитектуры, тестировать их, смотреть, как они стоят. Может быть есть какие-то способы это делать более эффективно? Если коротко, я думаю, ответ скорее нет на данный момент. То есть, с одной стороны, если вы этим много занимаетесь, у вас получается уже вырабатывается какая-то интуиция, грубо говоря. То есть вы просто смотрите на эти кривые, как ваша сеть обучается и становится понятно, либо она слишком маленькая, либо она слишком большая и так далее. Ну, соответственно, смотрите на какие архитектуры используются в каких-то смежных задачах. Для настройки hyperparameter используется либо просто search, если у вас есть достаточное количество учительских ресурсов, просто запускается большое количество jobs с разными параметрами. Либо есть какие-то методы немножко оптимизировать это пространство, где вы производите этот search. То есть там есть какие-то базовые методы поиска и так далее. Но да, в большинстве своём на данный момент это было. Существует несколько статей сейчас, которые направлены на автоматическое получение этих архитектур. То есть обучение не только непосредственно самой сети, но и мета-обучение, где мы пытаемся найти оптимальную архитектуру задачи. Но это скорее такой очень экспериментальный research, и я не думаю, что на практике это где-то серьезно используется. Пока. А технически как была реализована нейронная сеть? Может быть какие-то фреймворки использовались общеизвестные, не внутренние, гугловые, чтобы и человек, например, наш слушатель мог что-то подобное реализовать? Это было достаточно давно. В тот момент мы еще работали на Ciena, это фреймворк от университета Монреали. Недавно они объявили, что она больше не поддерживается. Тензорфлоу тогда еще не было, каких-то внутренних распространенных фреймворков Google тоже не было. Ну, понятно, что у них была внутренняя система, но мы не имели к ней доступа, потому что у нас был такой изолированный кластер. Поэтому они, в принципе, были совершенно открыты к тому, какое программное обеспечение мы хотим использовать.",
    "result": {
      "query": "биометрическая аутентификация смартфон сенсоры"
    }
  }
]
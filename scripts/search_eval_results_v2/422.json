[
  {
    "segment_id": "de63d010-9c6d-4822-aa7e-ad281f94cd2a",
    "episode_id": "47ff5a0a-995e-4947-9a81-6a35dd3df6f2",
    "episode_number": 422,
    "segment_number": 7,
    "text": "вот он делает вот это большое разграничение всех giltsys 7 на те которые могут использовать контекст полученный в ходе работы предыдущих тасков в следующих тасках и те которые не могут соответственно это maker у них все приколочено все работает это вот тот же shake и например excel вот и получается что подставив просто там заменив одно на другое вы получаете как раз новые свойства системы и как раз интересно даже иногда бывает в таких случаях потыкать туда вообще разные там ограничения разные реализации и чтобы посмотреть а чё еще можно здесь сделать например берем описываем shake и ну это make и подменяем ему ограничения что он теперь не пользуется что он начинает пользоваться контекстом и что с этого мы можем приметь ну давайте я уточню то есть сперва мы разобрали какие есть системы сборки и какие у них свойства чуть ниже мы ввели с помощью хаскеля что у нас вот есть прям реального кода на хаскеле что у нас есть аппликативные ограничения у нас есть мододические ограничения у нас есть такие то типы у нас есть такие сетей да типа потом мы говорим а давайте мы построим систему сборки шейк и вот здесь прям приводится код что для того чтобы построить систему сборки шейк он говорит мы система сборки шейк равняется и дальше он говорит мы используем такой тип здесь такой тип здесь такой тип всего здесь а вот сюда подставляем такую-то функцию и все у вас есть система сборки которая полностью по семантики повторяет шейк вот при этом если вот в этом функции вы поменяете этот тип на этот то у вас уже получится шейк с небольшими изменениями. А так как все эти типы уже определены выше, для вас сделать шейк 1, шейк 2, шейк 3 – это просто скопировать код и подставить другой тип. То есть это реально очень простая операция. Это не то, что надо написать заново с нуля шейк. Нет, не надо. Надо просто переиспользовать часть уже написанной инфраструктуры, часть написанного кода, и скопировав готовый шейк и сделав шейк 2. Это реально удобно и реально легко. На этом Haskell коде они сделали очень классные абстракции. Прямо потрясает легкость, с помощью которой можно экспериментировать и глядеть на все эти концепции. Например, вам не нужно просто бежать, патчить базе для того, чтобы опробовать какой-нибудь новый принципиально формат, стейк для него или еще что-нибудь такое, посмотреть новые варианты для того, пересборки, для обнаружения новых штук. Вы можете прийти вот в эту модельку и примерно как на каком-нибудь тела плюсе ткнуть туда, сказать, что теперь у нас планировщик будет топологический, такой Redon или Bazel. Окей. И что мы с этим можем узнать? Ну, наверняка у этого тоже есть какая-то штука, наверняка тут тоже можно что-нибудь ускорить за счет этого. То есть вот этот фреймворк, как раз a la carte, он как раз про то, что вот вам меню и такой как-то шведский стол. И вы оттуда набираете себе фич. Вы хотите там такие-такие-такие-то фичи, а вот и что у вас получилось. И в принципе у них как раз в пейпере каталогизируется и там потом в следующей версии добавляются еще уточнения про облачные, про всякие никсы, баг опять же упоминается. Там описывают, какие проблемы могут возникнуть, если вы вдруг начинаете использовать походы в облако. Подожди, подожди, давай следующий пейпер разберем отдельно. Давай сначала по этому пройдемся. Так, что я нашел здесь важного в этом пейпере, то, что раньше я об этом не задумывался, это то, что они отделили две сущности между собой. Они отделили сущность шедулера, который либо топологический, как в мейке, либо рестартующий, как в Excel или в Bazel, либо suspending, это как в шейке, то есть он ожидает, пока цель не будет готова, зависимости не будут готовы для того, чтобы цель пересобрать. То есть вот этот шедулер, это как отдельный тип, он существует, и вы можете использовать либо первый, либо второй, либо третий. Но отдельно существует идея, типа это rebuilder, то есть как бы это определение того, каким образом, что должно быть пересобрано. То есть как бы вот в make файле мы сделали touch на файл, мы поменяли ему время обновления, и, соответственно, это привело к тому, что вот все цепочки, которые основываются на этом файле, они будут должны пересобираться. То есть как бы это вот помечание, как dirty bit, то есть как бы грязный бит, вот. И, соответственно, rebuilder, это как раз отдельная концепция. Поэтому в этой системе типов и в этой системе концепций вот это разделение для меня прям показалось очень интересным. Оно позволяет комбинировать разные системы. И, соответственно, вот в rebuilder есть, соответственно, вот как я уже упомянул, грязный бит. То есть когда мы говорим, вот мы файл потрогали, теперь файл грязный. И, соответственно, все цепочки, которые от этого файла идут, они автоматически становятся грязными. И мы должны все это пересобирать. Вот. Или есть альтернативное решение. Это проверочные трейсы. Это, соответственно, мы должны запоминать значения и хэши зависимости, которые были в последний раз и сейчас. И, соответственно, если по этому трейсу мы идем и в какой-то момент хэши становятся точно такими же, все, мы можем дальше не протаскивать этот грязный бит. И мы говорили, что как бы все, цепочка опять вернулась в чистое состояние, мы можем дальше не вести. Это позволяет делать ранний выход сборки. Вот. Или конструктивные трейсы. Это, да, он, помимо того, что он сохраняет хэши того, что у нас получилось, он еще и сохраняет результирующее значение. Это позволяет сразу получать значения, чтобы получить результат. То есть не только говорить, что ой, мы можем дальше не ходить, вы там где-то поищите, но мы можем сказать, о, кстати, на этом шаге у нас получилось вот это, вот можете вот это оттуда скачать. Вот. Или есть еще последнее. Это глубокие конструктивные трейсы. Не помню, чем они отличаются, если честно. Вот. Но идея в том, что как бы вот, вот, я не знаю, как бы я много работал с мейком, и мне понятна эта концепция, но я никогда не задумывался, что внутри мейка в коде на самом деле они сделали неправильно. Ну, понятно, почему неправильно, потому что это вообще была одна из первых систем сборки. Но они объединили в несколько концепций, и они запихнули это в один код. Из-за этого, когда вы читаете код мейка, если вы читаете код мейка, это реально мешанинок всего, потому что у него в одном алгоритме происходит и анализ ситуации, и попытка понять, что нам пересобирать, и вот эти вот протаскивания dirty bit, и параллелизация, и вот эти вот протаскивания dirty bit, и все это вместе в одном флаконе. Если вы начинаете это все растаскивать по концепциям и на разных уровнях это размещать, вы можете не только комбинировать, но у вас и код становится чище. То есть реально вот здесь вот весь этот paper это там 29 страниц, весь paper. Но в этих 29 страниц хаскеля, ну, я не знаю, сколько там хаскеля, Алекс, но может страниц там 10, я не знаю, 8, может даже меньше. И вы его читаете, этот код, и он на самом деле это простой код, это легкий код, который понятен. Это прям офигенно, это очень мощно. И в итоге, и в итоге мы приходим к системе, что вот весь этот код, здесь весь код всех систем сборок приводится, то есть вот Excel, вот значит мы написали такую функцию, такую функцию, подставили такие типы, и вот у нас получилась такая вещь. Вот, и вы по коду, судя по коду, вы можете сразу понять, как работает Excel, каким образом он пересобирает эти цепочки, что он там строит, очень классная система. Вот, и так, что дальше? Дальше идет дополнительное, как это, мне очень понравилось введение вот в эту часть, они говорят, как бы мы все очень классно придумали, у нас классная концепция, мы вообще крутые программисты, вот, но жизнь на самом деле гораздо богаче. Вот, жизнь гораздо богаче, поэтому это мы отдельно обсудим в части, которая называется инженерные аспекты. Жизнь гораздо богаче, потому что у нас есть постоянно куча ошибок, и начиная с ошибок, ой, мы не смогли тут скомпилировать, потому что компилятор упал с секфолтом, и заканчивая тем, ой, мы тут записали файловую систему, а что-то сбойнуло, что-то нам надо делать. Вот, и вот все эти, все эти подобные вещи, они в отдельном, в отдельной части описали, блин, мне вот это вот прям вот я ради этого уже, я уже не могу, я уже не могу, я уже не могу, я уже не могу, вот прям вот я ради этого уже, я очень радуюсь, когда читаю подобные, подобные пейперы. Так, так, так, так, так. Да, вот, что значит они изменяют? То есть, как бы, вот они создали модель, а потом они начинают ее дополнять. В реальном мире у нас очень часто бывают ошибки, типа, а мы вот тут не нашли файл, или compilation failed, и поэтому мы вместо того, чтобы вводить тип, там, a или v, мы вводим тип maybe v, или там either, то есть, как бы, либо ошибка, либо v. Это позволяет нам, значит, как бы, сам тип, как уже более сложная концепция, становится. Вот, и он автоматически протаскивается везде в глубину, и мы там дальше уже вытаскивая из него, мы можем сказать, ой, на этой этапе нам пришло не значение, нам пришла ошибка, нам надо что-то в связи с этим сделать. Вот. Так, так, так, параллелизм. Параллелизм. Каким образом параллелизм влияет на шедулеры, на топологический, тупо логическому мы заранее все известны, т.е. как бы вот топологический шедулер это идеальная система для параллелизации. Вы можете запустить заранее, вы все знаете, что надо запускать, и вы запускаете это в столько веток, сколько вы можете запустить. Вот. В рестартующем шедулере все сложнее, но самое простое это иметь какое-то ограниченное количество потоков, и туда подавать какие-то задачи, когда у вас известно, что надо подавать, а потом, когда происходит рестарт, вы, как бы, сначала в эти потоки загружаете шедулеры , и другими задачами вот со спиннинг все еще легче потому что вы можете сказать о я тут давай к после папа спи пока тебе не придет какой-то пинка другого от другого потока что тут дальше так я вот не помню про это нечистое выполнение импера компе тэйшнс ты не помнишь что такое а ну это как раз про джесси который мы говорили что джесси версия джесси это тоже зависимость и что исходники внутри версии же сера тоже зависимости и мы их точно также должны протаскивать везде но мы это уже обсудили вот потом изменения в связи с облаками с cloud то что немножечко меняется то есть рейдов когда вы собираете локально это все-таки совсем не то что когда вы собираете в большом кластере и у вас где-то данные хранятся отдельно потому что локально когда вы собираете вы исходить из предположения что все у вас находится по другой а когда вы делаете большую сборку огромного проекта в облаке может оказаться что скачать какой-то кусок блоба это тоже может быть очень дорого и это надо тоже принимать во внимание иногда маленький файл легче скомпилировать а иногда легче скачать. И вот это все надо как бы принимать во внимание. Плюс вы после того, как что-то собрали, вы это тоже должны куда-то закинуть. Тоже это какой-то дополнительный... дополнительная задержка и дополнительная коммуникация. Плюс со временем у вас хранилище начинает раздуваться, и вам это надо каким-то образом выкидывать из кэша. Ну, скажем, кэш сборки какого-то объектного файла 20-летней давности уже точно никому не нужен. Можно это выкинуть. Но когда это выкидывать, это опять же от вас зависит. Плюс есть такая концепция, она здесь тоже проходит сквозной... сквозной... чем сквозным проходит? Это shallow builds, когда вы можете какие-то сборки не давать пользователю значения, типа там, объектных файлов или каких-то промежуточных этапов, а можете прямо сразу давать готовый вариант. Но внутри же у вас где-то хранятся вот эти вот объектные файлы. Как вам с ними работать? Это тоже сильно влияет на вашу систему сборки. Да. А дальше мы приходим к системе, к вопросу, который я, если честно, до конца не понял. Алекс, вот смотри. Bazel это вроде как не динамическая система. Она не позволяет тебе делать динамические таргеты. Но из-за того, что у него есть вот эта система, из-за того, что шедулер у него, рестартующий, он доходит до какой-то точки и говорит, о, а в этой точке мне сказали, что мне надо дальше под граф построить с помощью какого-то правила, давай-ка я его построю. Он начинает его строить, а потом как бы подгружает в память и говорит, о, теперь мне надо заново эту систему, эту цепочку пройти, этот граф пройти. Вот. По факту это обозначает, что он у нас как бы не динамический. Он у нас просто в момент, это как lazy evaluation, то есть как бы в момент построения он еще не знает, что надо делать, но потом он рестартует с самого начала. И он фактически статический, статический с рестартом. Поэтому прямо здесь в таблице он указан динамический со звездочкой. И вот здесь возникает вопрос, так у нас получается, все они статические с рестартом могут быть? Ну то есть как бы все статические могут быть восприниматься как динамические с рестартом. То есть я make файл могу запускать в цикле, пока он не сойдется, а внутри make файла я могу переопределять какие-то цели и добавлять туда каких-то .d файлов. Ну если у тебя есть таргет, который генерит .d файлы, то ты как бы не заглядывая внутрь просто говоришь, что добавь сюда зависимости из вот этого .d файла. Но я же могу поставить звездочка .d и если у меня на каком-то этапе возникает новый .d файл, я говорю, а ну-ка рестартуй мне make заново, потому что у нас появились новые .d файлы. Я не уверен, что он по ходу его подцепит, хотя... Нет, я могу... Выключаем, а потом заново запускаем. Тогда по факту какая-то часть этого рестартинга добавляется. Тогда вопрос, в чем отличие монадических от аппликативных систем? Нет. Это здесь вообще про другое. Я думаю, это будет в пеппере про баг больше понятно и будет подробно рассказан. Там пример есть. Окей, давай. Согласен. Так, ну что, я с этим более-менее так уже закончил. Я прошел по основным пунктам. Ты хочешь что-то добавить? Или пойдем уже к следующему? У автора Шейка есть еще интересный кейс для... А что такое билд-система? Это они сделали первую версию хаскельного ленгуль-сервера, который в VDE работает и шерстит файлики и пересобирает все. И, собственно, они сделали ее на Шейке в качестве прототипа. В принципе, если у вас как в SQLite есть база данных в Memory, то вы можете билд-систему гонять также в InMemory, а-ля Excel какой-нибудь. И получается, что если у вас есть какие-то входы на диски, модули, которые вам надо рассматривать, а выдавать значения вам надо в виде... Не значения, а результаты в виде готовности отвечать на запросы со стороны VDE, то у вас есть уже из коробки обнаружения таргетов, у вас есть обнаружение зависимости между модулями, у вас есть распарсили, узнали, какие символы в модуле есть, а другие модули от них соответственно зависят. Если где-то кто-то поменялся, то он у вас может переиндексировать. Таргет — это индекс проекта. И до какого-то момента оно работало, а потом сломалось. И на эту тему есть как раз у автора этого Нитчела. В общем, у него есть серия пейперов, даже не пейперов, а блокпостов вида билд-системы для маленьких проектов и отдельной билд-системы для огромных проектов. И в частности там как раз разбирается как Шейк, будучи билд-системой для средних проектов, сначала не попал как языковой сервер-индексатор для маленьких проекторов Haskell, а потом как весело ломался на больших проектах. После чего они воспользовавшись всем этим своим опытом, сделали специально заточенную ну, не то что версию, аналог под языковые сервера и с тех пор она более-менее работает. То есть не только Excel это система сборки. Например, много разных других вещей тоже можно рассматривать в таком разрезе. Да, я привел в ссылку на несколько постов Нейла Митчела в следующий на следующей теме. Давай, может быть, тогда плавно перейдем к ней. Да, и тут в чатике висит вопрос, который продолжение истории с динамическими рулами. Вот, и я думаю, сейчас мы к нему еще раз вернемся. Потому что он пока не закрыт, я считаю. Давай посмотрим, как его попытались закрыть в Фейсбуке. Давай. Так, подожди, я еще не открыл. У тебя есть ли у нас еще один вопрос? Если он открыт, то можно начинать. А что там начинать-то? Facebook, давайте с новости начнем. Facebook выпустил новую систему сборки, которая называется Bug2. Пишется B-U-C-K, поэтому читается Bug. Вот, а так читается Bug. Вот, и если Bug1 был написан на Java, то они поняли, что Java не очень подходит для подобных систем и переписали его на Rasty. Как это ни странно. Так, Алекс, что-то вышло. Алекс, у тебя все в порядке? Что-то у меня дропнуло. Понятно. Вот, они переписали его на Rasty, и по этому поводу я привел здесь несколько ссылок на их блокпост, инжиниринг-блокпост. Вот. Плюс ссылку на GitHub, в которой сам проект находится. Они большую часть проекта выложили в open source, за исключением некоторых вещей, которые специфичны для Facebook. Но вещи специфичные для Facebook, они не находятся в системе сборки, это просто дополнение в виде каких-то отдельных плагинов. В этом смысле вся система сборки у них под open source. Вот. Ты предлагаешь с paper начать или с их блокпоста? Давай, наверное, с блокпоста. Давай. Я paper открыт. Вот. Значит, блокпост. Открываем. Вот, поехали. Итак. Они задаются вполне логичным вопросом. Зачем же надо переделывать баг, если он у нас уже есть и он работает? Вот. И в качестве ответа они говорят, что ошибкой было добавить в систему сборки информацию о языке или какие-то специфичные для языка вещи. И они пришли к выводу, что ядро системы сборки должно быть полностью без этих знаний, и оно совершенно чистое. Все, что относится хоть как-то к языку, оно должно добавляться снаружи в виде каких-то систем плагина. Вот. И, соответственно, ядро написано у них на расте, то есть баг 2 написан на расте. А все языковые правила, например, как собирать там C++, как собирать Java или там... Ядро. Я не знаю, кого Erlang. Кстати, есть пример там с Erlang прямо в блокпосте, представляете? Вот. Оно написано на StarLarg. Я не знал, что такое StarLarg до этого. Оказывается, оно используется и в Bazel. Он изначально был SkyLarg, да? Вот. Потом они его переименовали в StarLarg. Может быть, не переименовали, может быть, скопировали, не знаю. Вот. И это система, я так понимаю, питоноподобного описания, который не является... Поправляй меня, если я не прав, я с ним не работал. Он не является тьюринг полным, это просто описание, кто от чего зависит, кто как строится и так далее, да? Ну да, фактически они просто взяли синтаксис питона и накрутили поверх него маленький-маленький эволюатор, который может какие-то там вычисления делать, но по большому счету, да. Но по большому счету он не позволяет никаких там... То есть нельзя просто импорт антигравити и улететь куда-нибудь. Если чего-то нет в ядре, этого нет и в правилах. Вот. И изначально это гугловый язык, а потом в Facebook, вот в первый мир CBUG его вытащили, ну, тоже переиспользовали. И, по-моему, они то ли распиливали, то ли как-то дополняли, но по факту это просто... Ну, это просто... Примерно знакомый массовый синтаксис, которому не нужно использовать табы слева. Вместо этого используются скобочки питонячие. Вот. Но там на самом деле простой синтаксис, как бы ничего сложного нет. Второй, почему они... Как бы идем дальше по причинам. Они сделали баг 2 основанным на paper, который называется единая инкрементальная система, то есть единая инкрементальная система зависимостей. Мы про нее поговорим чуть позже. Вот. Потом весь API и все взаимодействие они затачивали под производительность. И я не знаю, в чем отличие в данном случае по производительности от баг 1 API, но вот как бы эта производительность была одной из целей создания. Я не знаю, в чем отличие производительности от баг 1 API, на чем он там был написан, но базель написан на Java, и время старта у нее большое. И время скачивания и депло его нетривиальное. И когда я зашел по ссылке, типа вот смотрите, релиз баг 2, скачать вот этот один статический бинар на расте, вот. То ты запускаешь... Вот ты запускаешь, там, баг 2 help, он бац, готово. Это... Впечатляет. Там несколько порядков разницы. Понятно. Я чувствую твою боль. В том случае, когда не зря переписали на расте, это совершенно осмысленно. Я чувствую твою боль. Вот. Плюс они в баг 2 как бы сделали маленькое ядро, все остальное сделали снаружи, и вот снаружи в том числе они добавили возможность интеграции, с удаленными выполнениями. То есть они используют, имеют возможность использовать API базеля, или buildbarna, или engflow. Это, я так понимаю, разные системы удаленного выполнения. Не работал с ними, не могу ничего сказать. Плюс он написан с возможностью интеграции с виртуальными файловыми системами. В частности, в качестве примера приводится, что если у вас есть, система, которая зависит от, система сборки, которая зависит от времени, когда файл был последний раз обновлен, то для маленьких проектов это ок, но когда у вас проекты включают в себя миллион файлов, то просто проверить, что где обновлено, становится практически невозможно. Поэтому вам нужна вместо, как это, pull, вы должны использовать push-модель, то есть система сборки, получают уведомление, а вот этот файл был обновлен, и вот этот файл был обновлен, а все остальное, как бы значит, не обновлено, у вас получается очень огромное преимущество с точки зрения времени сборки. Так, здесь они разбирают два примера. Это сборка зависимости для OCaml, и сборка зависимости для C++, в качестве примера, почему bug2 хорош. Я, если честно, не понял, в чем там преимущество по сравнению с bug1, но, наверное, да. То есть я не использовал bug1, и я не использовал Bazel, для меня вообще читать эту статью было тяжело. Ну вот проблема, которая здесь рассказывается, то, что у тебя есть какой-то модуль, здесь и Mail, и вообще в Haskell такая же фигня, в принципе, в Rusty тоже, но во всех языках, где компиляторы слишком до хрена знают про модули, пакеты и вот это все, начинается перетягивание одеяла с внешней системой сборки. И, соответственно, если у тебя, допустим, ты используешь какой-нибудь Cargo, и он говорит, что, ну, короче, я здесь запущу код генератора, там под шаблоне какой-то выхлоп будет, и, короче, доверься, у меня все соберется, то в Bazel это дело заканчивается генератором рулов, в частности, вот, то ли для Go, то ли еще для кого-то. Изначально кином называется Bazel, и это несколько не то же самое, что там выше показывали, и потребовалось навертеть вот эту огромную еще гору кода для того, чтобы поддержать вот эти вот автообнаружения, которые можно вести на ходу. Даже те, которые ты не знаешь. Хорошо, а как они здесь это решают? То есть, как бы, если, на самом деле, Cargo слишком умный, то как здесь можно будет определить, что надо что-то делать, и как добавить зависимости? Ну, вот в Erlango примере, там, например, используется, что компилятор запустись и скажи там какие там зависимости, и он это к себе куда-то там его прикапывает и запоминает. Вот. И это никаких рулов, никаких ничего, ты просто говоришь точку входа main здесь, и оттуда оно само все разматывает. Причем, добавлю, что все это разматывается с помощью плагина Erlango, написанного на достаточно простом языке, с помощью декларативных описаний, поэтому это становится проще к пониманию. Собственно, это даже не плагин, это просто язык конфигурации, который поставляется, это просто библиотечка с функциями, которые ты можешь в своих билдах использовать. Вот. Аналогичные библиотеки есть для разных языков и на базеле, но они там, опять же, намного более развесистые, и все равно ручной писанины там много, реально много. Если у вас куча модулей, там какой-нибудь большой проект, и вам особенно, если вам нужно импортировать ее в какую-то старую кодовую базу, эмигрировать ее в сторону, хотите там облачную сборку или еще что-нибудь такое, чтобы модно-молодежно было, то первоначальный вход будет, я не знаю, можно просто встрять. Вот. Если они в баг 2 этого не требуют и просто говорят, где у тебя мейн, скажи мне дальше, я сам справлюсь, то они могут получить себе кучу пользователей очень быстро. Я думаю, пора перейти к paper, который объясняет разницу между аппликативными и монетическими системами. И давай зажигай. А то я начну сейчас вопросы спрашивать. Ну, сам paper-то тоже не супер большой, там полторы страницы. Они просто рассказывают как раз то, что вот у нас раньше было в ядре куча разных костыликов под разные штуки, плагины писались. А, а, а, алекс, а ты можешь не щелкать мышкой? И не этот, как его, и по микрофону, не знаю, что ты там вводишь, но это... Наверное, моя клавиатура. Да, да. Спасибо. Вот, после того, как он взял и распарсил свой StarLarq, у него уже достаточно, его вот эта ядерная модель, она достаточно гибкая, чтобы оттуда размотать все остальное. Вот, и за счет какого-то маленького количества примитивов, реализованных на Rust, они позволяют вот эту всю динамику выдать пользователям. Да. То есть, вот как раз вот эта та штука, которая позволяет писать, там, затаскивать ярдлан, яркамли и прочее, она достигается за счет этого принципиального ограничения, отказа от затаскивания ядра. Вот, и у них это как раз моделируется примерно как в BLCS T-ModalCard. Вот, и единственное, что вместо Monadac'а у них Rust'овые аналоги, но суть это не меняет. Идея в том, что они моделируют как раз эффекты, допустимые в системе сборки. То есть, есть как бы принципиально два типа эффектов, которые у них тут есть. Это, там, так называемые, ну можно сказать, что чистое, это когда там все готово, значение вот, вот. Словно Makefile. Это, ну нет, скорее артефакт. Вот, и они используют вот этот второй, то есть программа во время своего исполнения может либо, ну какая-то функция, либо выдать готовое значение, либо выдать зависимость. Где зависимость описывается как, чтобы, вот для того, чтобы получить такой-то таргет, да. Дай мне такое-то значение, а я с ним выполню новое какое-то действие. Где действие, опять же, это может быть либо готовая зависимость, либо готовый результат, либо новая зависимость. Вот, и у них здесь используется конкретная, конкретный вот этот вот эффект добавления зависимости, но в принципе он может быть реализован, то есть сюда можно добавлять еще новые штуки, что типа, сходи в кэш, сходи там, посмотри на часы. Вот, и получается, что за счет использования вот этих свободных монат и, ну, свободных в том смысле, что туда можно свои какие-то штуки загружать, которые потом дальше код будет интерпретировать. Вот, эта система расширяемая и тут на ней можно выражать всякие разные примитивы, помимо того, что добавь новую зависимость и вот тебе готовые штуки. То есть, вот те эффекты, которые в Build System, а вот те, которые в Build System, а вот те, которые в Build System, а вот те, которые в Build System, типа неопределенность, работа с ошибками, параллелизм какой-нибудь, они как раз переезжают сюда, как просто ядерные типы. Ну, на этом в принципе PEPPOR заканчивается. Подожди, подожди, подожди, не заканчивается. То есть, фактически, они вводят еще один уровень в, то есть, в System like Art они говорили вот у нас есть вот такие стадии и мы между стадиями, вот такие стадия и мы между стадиями, стадиями идем вот такой цепочкой, поэтому как бы у нас все просто, да, то есть мы сначала определяем там, что мы делаем, потом строим граф, потом по этому графу там и так далее. Здесь они фактически вводят еще один шаг, когда они говорят, ну вот мы, кстати, построили все зависимости, но если у нас в качестве зависимости не готовый артефакт, а нужно еще раз запустить этот шаг, мы фактически его повторяем и еще раз делаем. Я правильно понимаю? То есть как бы вот это вот разделение между action, это либо артефакт, либо зависимость от другого action, и мы, соответственно, должны его еще раз проходить, и еще раз проходить, и, возможно, там большое количество раз проходить. С помощью этого мы как раз создаем динамику. Да? У тебя получается, что не граф выполнения, здесь можно сказать, что это трейс выполнения, что у тебя, грубо говоря, развертывание мира, которое там происходит, оно если смотреть снапшоты, то у тебя есть, допустим, сначала одна зависимость, потом она запустилась и произвела свои какие-то зависимости. Окей, вот теперь в этом нашем мире запускаем следующую задачу. А вот одна освободилась, и окей, она выполнилась, она теперь просто значение. И это просто значение мы передаем дальше по цепочке, кому оно там дальше нужно. Но это как раз вот те рестарты с базилем, которые я до этого упоминал, верно? Ну, да, только это рестарты с базилем, это как бы один экземпляр вот этого паттерна. А сама вот эта идея о том, что давайте связывать связывать текущее действие с предыдущими результатами, даже с результатами предыдущих действий, она как раз отражается вот этими монатками. Вот, и именно они и эффекты, которые в них завернуты, а не манипуляции зависимостями, они отражают весь функционал. Почему тогда они говорят, что мы по факту аппликативная сущность, если они по факту монадическая сущность? Нет, аппликативные, это они до введения вот этой штуки. То есть в аппликативной сборке ты можешь пользоваться только теми правилами, которые у тебя есть. В самой сборке, да. Ну да, у тебя есть какой-то каталог эффектов, которые ты можешь исполнять. И какая-то финальная агрегация всех этих эффектов, это будет твоя финальная сборка. А монадическая, это когда ты исполнил один эффект, а теперь его результат идет дальше кому-то там, кому он нужен. Да, да, то есть как бы ты фактически протаскиваешь состояние между стадиями, между этими снапшотами, и в зависимости от этого состояния ты генерируешь следующий шаг. Да, и вот конкретная реализация вот этого протаскивания, это, ну, я так понял, что карта, это как раз вот этот планировщик. То есть он как раз связывает разные шаги. То есть у тебя может быть реализация вот этого паттерна протаскивания разная. Она может быть там со спейдинг, рестарсинг и так далее. То есть вот этот вот монадик, это просто паттерн проектирования. Да, вот в этом смысле как раз мне бы хотелось увидеть это в одной... То есть они усложняют модель сразу по парочке направлений. И в этом мне тяжело воспринимать две эти статьи одновременно. Потому что когда ты читаешь а-ля карт, ты понимаешь, что имеется в виду и какие определения. А здесь они немножечко видоизменяют эти определения. Нет, они используют ту же модель, просто они говорят, что мы в нашей штуке используем вот такую реализацию. Мы... У нас есть среди доступных эффектов, во-первых, порождение новой зависимости, и этот эффект доступен в пользовательском коде. То есть ты в StarLark пишешь, вот такая-то функция, вызови ее, а на кароке я вызвалась, теперь мир изменился навсегда. Продолжаем мы из этой точки. То есть они добавили еще одну, еще один тип. Да, я понял тебя, о чем ты имеешь шага. То есть помимо эффектов типа считай файл, добавился эффект или вот генрул, который в чатике упоминали, я так понял, что он как раз вообще-то чистый, он даже не аппликативный, то есть это просто результат его исполнения, эволюции, это какое-то множество новых правил, может быть. Да, да. А они здесь ввели то же самое, только уже с предыдущим состоянием, то есть ты еще в качестве параметра передаешь предыдущее состояние, и поэтому динамика получается богаче. И поэтому динамика вообще допустима, я бы сказал. Допустима в пользовательском коде, у тебя пользователь по-прежнему не может просто вызвать какой-то произвольный там я не знаю, сходить из конфига, создать файл. Нет. Но он теперь может сказать, что а, вот у меня теперь есть еще таргет, что вот такой-то должен быть создан, и вот его как бы рецепт. Который зависит от предыдущего состояния. Да, это непроизводный вообще вычисление в любой момент времени, там, во время компиляции, во время... В сборке, чего угодно. Очень ограниченное. Вот это ограничение, оно как раз помогает упростить систему сборки и систему восприятия всех этих правил. То есть у тебя не получается сложная вещь типа makefile, в смысле, система сборки make, которая внутри кода содержит все. А у тебя получается простое ядро с очень простыми языковыми конструкциями на этом DSL, как он там, StarLark. Ну да. Да, прикольно. То есть как бы давайте ограничим пользователя, при этом ограничим его максимально сильно, но при этом ограничим его так, чтобы все юзкейсы были покрыты. Я бы сказал тут себя, давайте ограничим. Ну, в смысле... Максимум свободы, наоборот. Ну, не знаю. А, ну да, да, да, да, прости, конечно, да, да, да, я не так выразился. Да, себя ограничим. То есть систему сборки мы максимально упрощаем, но для того, чтобы пользователю хватало богатства вот этого DSL для описания чего угодно. Да. Вот. Мне кажется, на этом мы покрыли, и баг 2 тоже. А, кстати, вот мы упоминали блокпосты Нейла Митчелла. Он эту серию блокпостов вел в какое-то время назад, а сейчас он как бы делает ссылки, а он является одним из авторов баг 2, и он сейчас делает ссылки, вот смотрите туда, смотрите сюда. Мне так очень... Мне очень понравилось именно вот как бы, что он в прошлое показывает, какие проблемы, и каким образом мы сейчас их решили в баг 2. И по этому поводу у меня есть некоторый оптимизм, то есть как бы эта система не на пустом месте создана, а там на самом деле люди, которые создавали систему сборки в прошлом, и на собственном опыте они улучшают баг 1 в том числе, и используют правильные языки. Вообще молодцы. Как говорил Филипп Водлер, открыватель некоторых, а еще Монадок в Хаскеле, есть некоторые системы, которые создаются инженерами, а есть системы, которые открываются, discover, и это видно на них, на них есть вот этот след, что не то, чтобы у Гугла нет опыта в создании билд-систем, и их базель, он в принципе отражает Гуглову, историю тоже, что у нас была такая, потом нам потребовалось то, потом нам потребовалось все, и в этом отношении баг 2 он идет с другой вообще лайнэйдж, с другой родословной, он типа, а что вообще бывает, а какая, что такое система сборки, ну вот система сборки, окей, реализовали, пользуемся. Насколько ты оптимистичен про баг 2? Я надеюсь, что он либо закопает базель, либо даст ему такого пенделя, что он решит свои проблемы наконец же. Так я чувствую боль. А если он заменит семейк, это будет просто я буду в раю. Немного тебе надо для счастья. Но семейк уже заменен мизоном. Ну, у мизона как раз такие же проблемы, вот как у примерно у базеля, наверное, и там тоже они дерутся с компиляторным ключей, сейчас я туда кину ссылочку, там, ну и опять же, пользователи других сишных и плюсовых биосистем не согласны, что они заменены не мизоном, а заменены теми биосистемами, которыми пользуются они. И это тоже сказывается. Ну это, по крайней мере, то наш, что переходят более-менее видные открытые проекты. Даже не могу придумать, как сделать плавный переход к следующей теме. Саша, помогай. А что является видным открытым проектом? Это Postgres. А Postgres является базой данных. И системой сборки. Это на этот... Как это? Новая система сборки Postgres. У меня видны... Вечер я начинаю... Тот момент, когда Саша начинает заговариваться. Насчет того, является ли Postgres системой сборки, существует больше одного экспертного мнения. А кто является экспертом, это Энди Павло. А что есть у Энди Павло, это курс. В курсе есть лекция, в частности, под номерами 20 и 21. Мы говорим про Advanced Database Systems 2020 года. В прошлый раз мы не обсуждали этот курс, поэтому сегодня, конечно, будет две лекции. К счастью, они связаны. Это реализация оптимизатора запросов. Часть 2 и часть 3. Часть 2, собственно, можно сразу скипнуть, потому что я убежден, что мы все это обсуждали. И это... У меня здесь написано... Мне тоже сейчас сложненько, я это две недели назад смотрел. То есть вещи, которые мы в этом подкасте уже знаем, просто хорошо структурированы. А вот у нас есть логический план исполнения запроса, а вот есть физический план. Соответственно, мы можем производить логическую оптимизацию, а можем производить физическую оптимизацию. Соответственно, если мы делаем несколько join'ов, то мы можем построить несколько планов, которые можно путем permutation переводить один план в другой план. И задача оптимизации сводится к задаче поиска на графах, где узел графа — это твой конкретный план. А дуги между узлами — это permutation. Планы из одного... Ну, собственно, от одного плана в другой. И, соответственно, это можно делать логически и на физическом плане. Дальше говорится, что вот, допустим, у нас есть select с несколькими условиями, есть фильтр, да, по var, и там несколько условий. Давайте разобьем его на три условия. Такое, что вот у нас первый var, потом ниже него другой var, ниже него третий var. Получается как бы три фильтра. А вот эти фильтры мы можем пушать там вниз по join'ам, если мы видим, что в соответствующем подделье у нас производится под выборкой из соответствующей таблицы, то мы можем сделать вот такой вот сканер. И, соответственно, у нас вот... Если мы достаточно сильно пропушим этот фильтр, то мы можем понять, что вот нам нужно на самом деле делать не последовательное сканирование таблицы, а использовать какой-то индекс. Индексов тоже может быть больше одного. Или наоборот, мы можем решить, что, возможно, вот эти фильтры, их нужно пушнуть выше в план исполнения запросов. Тогда мы сделаем sexscan, но фильтровать будем в памяти для маленьких таблиц это может быть и более эффективно. Дальше подробно разбирается система под названием Cascades. Точнее, это не совсем система, как я далее понял. Говорится, что вот есть paper про Vulcano Model. Cascades является OOP реализации Vulcano. И дальше говорится, что вот, например, Apache Call Site это как раз реализация Cascades. А также Pivotal Org является реализацией Cascades. Что же именно собой представляет Cascades, я не очень понял. Ну, это вот, собственно, то, что в paper описано. Это framework для оптимизации планов, который родом из систем микрософтовских, типа SQL Server. И все его производные, которые в Azure крутятся. При том, у самого Microsoft что-то типа трех форков Cascades. И, соответственно, есть те реализации, которые вдохновлены Cascades Paper. Я понял, окей. Вот, и дается пояснение о некоторых тонкостях Cascades, например. А вот мы вводим такое понятие как группа. Что такое группа? Это когда у нас есть n-ое количество планов, и одни возвращают один и тот же результат. Тогда мы говорим, что вот эти планы — это группа. А еще у нас есть такое понятие как multi-expressions. Это как группы, но такая чуть-чуть абстрагированная. Мы говорим, что вот у нас есть план, но вот в этом плане вот этот кусочек нас не очень интересует, как он реализован. Тут есть какой-то абстрактный кусок. Кто-то за нас потом это выяснит. И потом мы вот... Этими multi-expressions можем в Cascades как-то оперировать. Я так понимаю, это уменьшает пространство поиска на... Ну, когда ты оптимизируешь планы. Это я уже так догадываюсь по контексту. А еще мы вводим понятие rules. И rules — это такая штука, которая определяет, что join можно вот в плане вращать тем или иным образом. Ну, в смысле, перестраивать план, менять в нем порядки join. И при этом у нас получается логический эквивалентный план, который возвращает тот же результат. Вот, безумный интересный материал. Особенно если вы вот не работаете напрямую с Calsight или Orca. Но если вы работаете с Calsight, то, наверное, вам рано или поздно встретятся понятия rules и группа. Если память меня не подводит, Валера трогал... ...как раз, когда ты работаешь с Calsight. Это правда? Это правда было такое. А там у тебя встречались группы и rules и multi-expressions? Multi-expressions не припомню. Rules точно были. Группы, по-моему, были. По-моему, топом были. То есть, да, из всего, что ты сказал, multi-expressions пришел, только не помню. И то, возможно, просто потому что я не... Конкретно тех узлах деятельного плана, которые меня оперировало, возможно, их там не было. Угу. Может быть, это просто более внутренняя штука, которая... А может, это просто по-другому называлось? Угу. Или я просто забыл, что это тоже очень вероятно? Да, ну а потом, да, еще отмечается, что, действительно, задача оптимизации плана, она сводится к поиску на графах. А давайте теперь подумаем, как бы нам на этом графе не зациклиться, потому что на графе-то есть циклы. Вот. А... Э-э... А еще давайте подумаем, что у нас граф очень большой, и... А... На нем мы можем искать очень долго, а очень долго мы не хотим, поэтому давайте придумаем критерии остановы. Вот. Ну, какие-то такие соображения начинаются. Ну, честно говоря, я довольно убежден, что большую часть всего этого мы обсуждали. Это все, что я выписал. В целом лекция, она хорошо структурирует то, что мы раньше обсуждали. Часть третья. Часть третья показалась мне поинтереснее. Ну, сначала нам сообщается, что самое главное, когда ты оптимизируешь планы, это порядок джойнов. Другие штуки тоже важны, но порядок джойнов, он очень важен. Чтобы правильно упорядочить джойны, нужно знать кардинальность соответствующих узлов плана. Кардинальность – это сколько кортежей возвращает узел плана. Чтобы знать кардинальность, нужна актуальная статистика. Статистика – это можно представить как гистограмму, которая говорит, что вот в этой таблице у меня по такому-то столбцу такое-то распределение. Опять же, есть разные стратегии, как строить статистику. Можно ее делать глубь некой, одномерной. Можно учитывать скалификацию между столбцами и так далее. Но в этой лекции это… Да. В такие дебри мы не уходим. И еще большая проблема, что… Именно в контексте построения эффективных планов, что DBA может добавлять и удалить индексы. Я бы сюда еще добавил, что… А, ну, в контексте mMemory у них нет таких проблем. То есть в этом курсе делается большой акцент на mMemory системах. Но в общем случае у тебя еще есть проблема, что… А вот у тебя не вся база данных, она не вся. Она в памяти. У тебя есть страницы. Страницы вытесняются из баффер-менеджера. И да, у тебя могут вот эти… И содержимость самих таблиц, и содержимое индексов может вымываться из памяти. Дальше сообщается, что есть такая штука. Называется адаптивная оптимизация запросов. Adaptive Query Optimization. Идея в том, что вот мы построили какой-то план. Начали его исполнять. И мы его исполняем. И понимаем, что вот тут мы считали, что… Предполагали некоторую кардинальность. Например, что у нас здесь вернется тысяча кортежей. А вместо этого мы понимаем, что вернется 100 тысяч кортежей. И возникает вопрос, а не хотим ли мы перестроить план, поняв, что мы ошиблись, и исполнять какой-то другой план. Или как альтернативный подход можно попытаться доисполнить этот план. Но в будущем уже учесть, что… Здесь у нас кардинальность будет другая. Возможно, у нас статистика протухла. Вот. У Microsoft есть paper про… Про штуку, которую в Microsoft они называют plan stitching. И идея в том, что у нас есть планы. Планы мы разрезаем на подпланы. При том, когда мы это делаем, мы говорим, что вот у нас есть определенный подплан. Он не обязательно относится к какому-то конкретному плану. Он может быть переиспользован между разными планами. И идея в том, что мы оптимизируем эти подпланы отдельно. А потом, исполняя запрос, можем использовать кэш этих… Подплан, чтобы составить оригинальный запрос, начать его исполнять. Потом в процессе возможно понять, что мы ошиблись с кардинальностью. Взять с кэша другой подплан, уже заранее оптимизированный. Какие-то такие идеи. Вот. Но Энди говорит, что, насколько ему известно, это не использует никто и нигде. По состоянию на 2020. А потом в конце доклада он говорит, что на самом деле это начинают где-то использовать во всех коммерческих системах. По состоянию на 2020. Я так и не понял, используют это кто-то или не используют, или начинают использовать. Валер, тебе известно, чтобы какая-то система промышленная, не так коммерческая или иная, использовала planstitching?",
    "result": {
      "query": "bug2 build system features"
    }
  }
]
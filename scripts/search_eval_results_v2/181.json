[
  {
    "segment_id": "95aa5ae2-0644-48dc-a8ee-8a1a4cb84701",
    "episode_id": "e5183f88-0a18-4145-846c-b686c2660a28",
    "episode_number": 181,
    "segment_number": 3,
    "text": "Особенно если не будет workaround от этих вендоров, что тоже бывает регулярно. То есть ты зашел в исходники Orlanc виртуальной машины, оправил тот баг, который ты нашел, собрал себе свою виртуальную машину и пошел на ней работать production. Ну то есть если тебе надо решать это прямо сейчас, потому что клиенты пришли и деньги тебе платят, ты должен эту проблему решить, так или иначе. Какие-то у меня сегодня эти самые флешбеки из юности, из программистки, прям такое, это самое, сейчас вот ты рассказываешь, это прям как будто ты topic starter на каком-нибудь rsdn форуме, и там, значит, вендузиатники спорят с линуксоидами по поводу опенсорса. Я бы, Леша, на твой месяц забеспокоился, если бы у меня жизнь начинала проноситься перед глазами. Да, как-то неожиданно свелась тема к тому, что опенсорс это хорошо. Потому что опенсорс есть в Uber и на интересных языках, да? Мы об этом хотим поговорить уже, да? Вижу, тебе не терпится, так что я не рискну тебя останавливать. Ой, тут все перепуталось, я вот просто помню, что карточка была сразу следующая, ну извините. В общем-то, что сделали господа из Uber? Они взяли и запенсорсили такую тулу, называется query parser. Что такое query parser? Это кусок кода на внезапно Haskell, в который можно сувать свои SQL-запросы. Сейчас поддерживают с dialecty вертики, боже, что же там еще было? Hive и Presto. В общем, почему такие странные диалекты? Потому что они этим анализируют запросы к своему Data Warehouse. Я так понимаю, они это изначально написали, потому что им нужно было провести довольно сложную миграцию, сразу многих систем, primary key заменить, и им, соответственно, нужно было проанализировать запросы, которые у них гуляют по системе, чтобы понять, что вообще, как трогать. И, соответственно, они сделали этот тул, то есть они кормят логи запросов из базы данных в эту штуку. Эта штука, у нее где-то есть информация о том, где какие таблицы. Оно разбирает запросы, понимает, какое поле на самом деле какое, и, собственно, анализирует. Там что-то вроде такой разбиралки языка, которые подключаются к плагинам, и сейчас у них есть плагины на то, чтобы смотреть, каким таблицам ходили, какие колонки запрашивали, что с чем сравнивали, что с чем джойнили, ну и так далее. И да, откуда что приехало, такого рода вещи. И в итоге натула стало полезно еще для много чего другого. Например, они говорят, что это дико удобно с точки зрения администрирования, потому что, ну, если у вас есть большая гетерогенная система, там в ней, ну, как минимум, уже перечисленная Hive, Vertica и Presto. И, соответственно, весь этот зоопарк как-то нужно администрировать. В этом зоопарке лежат разные данные, люди разные с разными джойнят. Соответственно, нужно понимать, куда люди ходят, какие запросы делают, где можно, там, какой-нибудь индекс построить, что-нибудь еще, где-то что можно ускорить, где что можно выкинуть. То есть, с точки зрения администрирования, потрясающе удобно. Во-вторых, они, когда апдейтят схему теперь, благодаря Tool, они точно знают, какая тема использует эту схему. И вместо того, чтобы просто делать огромную там ковровую бомбежку апдейтами, что у нас там в базе изменилось, они точно знают, какой департамент шлет какие запросы и говорят, эй, ребята, там схема поменялась, вот вы такие запросы делаете вот там-то. Еще они из этого могут прекрасно понимать, откуда, как льются данные. Им это офигенно помогает в поддержке всего этого безобразия. Еще они на основе этого говорят, что очень удобно делать всякие постморты и, в принципе, как-то чинить всякие проблемы, потому что, опять же, видно, откуда что течет, какой запрос, откуда потек, что где взорвалось. Ну и, в принципе, история изменений таблиц и так далее. Еще они на основе этого строят всякие вещи, типа кто-то прислал потенциальный оптимальный запрос, они ему пошлют обратно письмо, скажут, что, эй, ребята, пожалуйста, больше так не делайте. Или, например, даже могут превентивно отменить эту штуку. Но также это не решение всех проблем, потому что у них есть, ну, во время написания этой штуки у них было некоторое количество проблем, некоторые из которых до сих пор не решены. Например, я так понимаю, не целиком диалекты поддерживаются, потому что они развиваются, это три разных, и три – это уже много, и это даже не совсем стандартный SQL, это особенный SQL из всех их Big Data фреймворков. Во-вторых, трекать вот, собственно, каталог, то, что каталогом называется информация о таблицах в базе, это сложно. Они вначале хотели следить за всеми запросами и делать Delta, это оказалось вообще дико сложно сделать и почти невозможно, в итоге они забили, если я правильно понял, то у них сейчас где-то статически сконфигурировано, то есть видимо, у них где-то лежит фаликс, где написано что, как, откуда, и видимо, они его как-то генерируют на основе, ну, опять же, я уже скорее спекулирую, потому что в прямом тексте эта статья не написана. В общем, смысл в том, что у них где-то статически сконфигурировано, где что лежит и как называется. То есть это Delta, скорее всего, просто дамп каталогов всех этих баз в едином формате. Еще им было сложно, если я правильно понимаю, отдельные запросы, при чисто по логам тяжело какие-то отдельные SQL стейтменты отнести к той или иной сессии с баллой. Поэтому они говорят, что они это решили просто тем, что у них существующие клиенты к базе, их фреймворк для работы с этими базами просто вот эту информацию им дополнительно досылает. Ну и в принципе, что абстракция получилась не идеальная, потому что, опять же, все эти out-hive, вот вы можете туда данные вставлять, как будто бы это обычный SQL, вы можете просто взять там файлики, подбросить на уровне файловой системы, и они у вас окажутся в таблице. И с точки зрения performance, очевидно, файлики добрасывают быстрее, но при этом у вас тогда вот этот query parser может что-то не заметить. Затекло ли не это как-то странно, я не очень понимаю, зачем они... То есть у них в Uber, Docker и все прекрасно, поэтому ставить Haskell и Daemon в их инфраструктуру, где отродясь Haskell не было, им было легко, но зачем-то они на него вокруг намотали Python, то есть у них как бы в контейнере крутится Haskell-ный сервис, который слушает Unix-сокет, вокруг него крутится Python, который форвардит трафик. Я вообще совершенно не понимаю, нафига. Вот, и по поводу Haskell, они сказали, что Haskell был потрясающе удобным тулой для этой штуки, в чем неудивительно, потому что там есть parsec и куча всяких, ну, клёвая система тифов для того, чтобы моделировать язык другой. С другой стороны, они подтверждают, что инженеров найти не так просто, но при этом они отмечают, что людям настолько нравился этот проект, что они прям учили Haskell специально для того, чтобы вот в этом проекте поконтрибьютить, и в плоти того, что у них там образовалась такая группа изучения Haskell в Uber. Вот, как-то так. Что вы думаете про Haskell в Uber, господа, и что вы думаете о таких тулах для... Вот, хотели бы вы себе такую тулу на продакшене, чтобы она следила за всеми запросами, которые у вас летают, и помогала бы вам держать вас в прот высоко в небе? Я бы хотел, чтобы у меня такая тула по крайней мере анализом занималась. Я не уверен, что я бы хотел... Да, шо ж такое-то? Ты, видимо, ты не хотел бы куковать, или продолжим мысль... Выкидывать кукушку из машины, как написали в комментариях. Я не хотел бы, чтобы она у меня на лету принимала решение, пускать этот запрос или не пускать. Ну, возможно, потому что я не очень доверяю этого, или со временем это бы прошло, не знаю. Но, по крайней мере, анализировать потоки данных, кто какие строки на столбце меняет, откуда он это меняет, это, мне кажется, очень полезная вещь. Мне тоже она кажется действительно полезной. Это особенно прикольно. В случае, если там весь продакшен сидит на какой-то одной базе, это не так интересно. Потому что там можно просто сесть на лог и сделать аналогическую репликацию этой базы, если она там есть. Там такие вещи проще. Но вот именно тут сила в том, что это приделывается у них к трём разным базам, и с трёх разных баз. Ну и, в принципе, писать анализатор уже на уровне... То есть, эта штука расширяемая, к ней, я так понимаю, можно писать кастомные плагины и делать какие-то анализы, которые вам нужны. И это довольно прикольно, потому что можно работать не с голым SQL, а уже на уровне чего-то разобранного, распаршенного. Это, в принципе, интересно. Даже, наверное, для одной базы. Я считаю, что как истинные диванные аналитики мы должны сделать глубокомысленные выводы из того, что Uber... Ну, поскольку, очевидно, Uber переводит всю свою архитектуру на Haskell теперь, это недвусмысленно свидетельствует о скорой гибели Go и C++ и Rasta. Это далеко идущая аналитика, Александр. Ну, другой не держим. Давно пора. Мне вот интересно, насколько у них оно приживётся, потому что вот этот шаг с запихиванием... Мне совершенно непонятно, зачем им пришлось Haskell засовывать за Python. Если кто-нибудь про него не читал, может кто-нибудь объяснить. Может в комментарии кто придёт. Нихрена не за Python его запихали. Что мешало Haskell слушать HTTP? Ленивость? В смысле? А не Python запускают Haskell'овский CLI? Какой-то, да? Нет, в том-то и дело, что Haskell слушает Unix Socket, а Python слушает обычный Socket. И как-то хитро форвардит. Может быть они спросили, а что UserType для HTTP? Чуваки им сказали, ну UserType и Servant. Они, короче, посмотрели на Servant, на эти самые, на Routes, на типах, такие сказали, о, короче, тут типа сложно. Singleton-тайпы. И, короче, решили просто слушать Unix Socket. Ну, как они тут пишут сами, что это было сделано для, как это... Interoperability, то есть взаимодействие и... Ну вот, что там за... Единственная вещь, которая у них как-то проскакивает, это то, что они метрики шьют этой штукой. Возможно, их славка метрик для Python написана для Haskell'а, нет. Но я не представляю, как можно не написать славку метрик на Haskell'е. Ну, то есть это вообще минорный кусочек, ради которого, мне кажется, стыковать Haskell с Python будет сложнее, чем просто, ну не знаю, по камере я писал славку метрик в Graphite, это очень просто. А еще может быть такая штука, то, что этот сервис используется, ну, где-нибудь... Ну, как, более встроенно, да, то есть он используется не через HTTP, а еще где-то напрямую. Он запускается как докер-контейнер. Нет, понятно, он типа в общем случае запускается как докер-контейнер, а еще где-нибудь он используется как вот прям вещь, которая рядышком запускается, и нужно ее там очень под большим лоудом ее писать через Unix Socket. Вот такая гипотеза. Страшную вещь скажу. Во-первых, у этой статьи есть секция с комментариями. Во-вторых, у ее автора, Мэта Хелверсена, у него есть GitHub, на котором указан его e-mail, поэтому если есть вопрос, его можно задать. Прямо автору, не гадая. Скучно. А как же диванность аналитиков? А интересно, Python у них второй или третий, это очень важно. Третий, конечно. Кто на втором сейчас пишет? Ну, по крайней мере, кроме метрик и вот этого непонятного взаимодействия сервисов, ни одного больше резона в статье не упомянуто.",
    "result": {
      "query": "Uber Haskell SQL query parser"
    }
  }
]
[
  {
    "segment_id": "c63bf666-517d-4efc-b077-4a71a0e651cd",
    "episode_id": "72b26d82-9103-4d1f-9647-2f10cba98261",
    "episode_number": 48,
    "segment_number": 5,
    "text": "Длинный текст, Вань, как ты его на одном дыхании можешь читать? Ты прямо тренировался, так быстро пошло, запутался только на Continuous Delivery. Я не тренировался. Нет? Ну тогда вообще идеально. Что еще идеально? Это иметь ленивость в языке. Вот следующая наша тема, она как раз про ленивость. На сайте begreif.com, наверное так читается, по-моему это из Reddit ко мне прилетело, доступен видеодоклад товарища по имени Тихон Джелвес. Да, наверное так читается. Очень интересный доклад. Я на самом деле небольшой любитель смотреть всякие видео, технические в смысле, но вот этот о сериал, он всего на полчаса, он о ленивости в Хаскеле. И описывается его преимущества, недостатки, почему ленивость в языке действительно очень хорошо. И мне вот особенно запомнился один пример о том, что я просто никогда не думал о ленивости в этом ключе. То, что ленивость она делает, она позволяет компоновать разные куски системы. Например, у тебя есть функция сортировки и функция take, которая из списка берет первые n элементов. В строгом языке, чтобы написать функцию, которая находит n минимальных элементов в списке, ты не можешь взять sort и взять функцию take и их объединить, потому что у тебя sort, поскольку он строгий, он сначала отсортирует весь список за n log n, и потом ты возьмешь минимальные элементы, а в Хаскеле, поскольку он ленивый, ты можешь просто написать, возьми мне n элементов от отсортированного списка, и список не будет отсортирован целиком, потому что Хаскеле ленивый. И таким образом тебе кода особо писать не нужно. У тебя есть две функции, они соединяются, а в строгом языке нужно написать их три. Ну и в докладе есть другие интересные примеры. Я считаю, что есть несколько высокоуровневых вещей в языке, которые делают язык высокоуровневым. И они очень важны. Это сборка мусора, это легковесные процессы, может быть еще что-то, о чем я забыл, и вот ленивость, я считаю, это то, что делает язык высокоуровневым. Вы как, согласны? Я бы еще добавил алгебрические типы данных. Они очень сильно облегчают. Извини, продолжай. Я согласен, кстати, насчет алгебрических типов данных. Саша, ты говоришь, что там о недостатках ленивости, там действительно такое было? Потому что я начинал смотреть этот доклад, и он просто расписывал, какая ленивость клевая, может, разве что в самом конце там было про недостатки? В вопросах, да, ему, разумеется, задают вопрос, а что делать с памятью, чтобы она не утекала, ну, и его ответ такой тип, ну, помните, что вы пишете на ленивом языке. Но мне, кстати, кажется, это плохой ответ. Я буквально на этой неделе вбрасывал в рассылки husky-russian, и на самом деле мне и так было известно несколько способов, как сделать так, чтобы память не утекала при использовании ленивого вычисления, и там еще подсказали парочку. Самый простой способ, вот вы тестируете систему, вы любую систему обязательно должны потестировать, потому что даже в языке со строго статической типизацией, как Haskell, то, что он у вас компилируется, это не гарантирует корректность программы, поэтому вы должны написать к ней тесты. В Scalle мы тоже пишем тесты обязательно. И вот вы, когда эти тесты гоняете, вы указываете флажок у программы, поскольку в нее влинкован runtime system, можно сказать, что выделяй памяти не больше, например, 10 мегабайт. Если ты видишь, что у тебя программа при прогоне тестов упала с out of memory, ты понимаешь, ага, в этом комите я что-то напутал. И все, и у тебя нет проблем. Как вариант. Кстати, я со своей стороны хотел бы пояснить по поводу, на мой взгляд, и не только на мой взгляд, главной проблемой с ленивостью, главной, потому что она довольно коварная, это lazy I.O., то есть ленивый вывод, но из-за того, что многие Haskell корефии знали об этой проблеме, то вот в частности то, о чем я в своем докладе на нашем митапе, делал пример с ленивым или строгим чтением файла, но это, конечно, пример был наивный, а в более серьезном примере, который приводит, в частности, упомянутый уже ранее Снойман, к своей библиотеке Conduit, он говорит, что если мы используем вот такой вот стриминг-подход к работе, например, с файловой системой, как такое каноническое действие, почти любая программная система работает с файловой системой так или иначе, то мы, с одной стороны, через этот стримовый подход не всасываем в память файл, который весит у нас 100 гигов, но, с другой стороны, мы не играемся с файловыми дескрипторами, которые закрываются исключительно на воле Garbage Collector. Поэтому мы можем резюмировать, что проблема с LazyIO, с появлением Pypes, IO-стримов и Conduit была решена. Так, ну, мы как-то очень далеко ушли от, собственно, вот этого доклада, о котором Саша начал говорить, я хотел бы немножко тоже пояснить. Я начинал смотреть этот доклад, и там вот этот чувак, Тихон Джелвис, он рассказывает, да, вот этот пример сорт, то есть, например, если вы хотите посчитать максимальный элемент, вы можете просто взять хэд от сортированного списка, да, и вроде как все круто. Тут надо вернуться к тому, о чем немножко Денис говорил, о том, чтобы быть честным и честно обо всем рассказывать, потому что, ну, это такой немножко рекламный доклад, который показывает только хорошую сторону ленивости, да. Лукавит. Лукавит, да, да, да. Очень о многом умалчивает. То есть, очень простой контр-аргумент такой, да, а давайте, если я аналогично хочу посчитать минимальный элемент, я могу взять последний элемент этого списка, и он будет хорошо работать? Нет, не очень, на самом деле. Я извиняюсь, а что мешает отсортировать в обратную сторону, ну, в смысле, по убыванию? Вот, вот, понимаешь, его же аргумент какой, его главный тезис, то есть, вот этот пример сортом, это был просто такой пример, а главный тезис в том, что ленивость нам дает модульность, нам дает абстракцию. То есть, его идея в том, что вот у нас тут есть ленивое вычисление, его можно по-разному вычислять, да, вот, например, отсортированный список, можно вычислять, допустим, весь список брать, а можно только голову взять или только третий элемент взять, и он будет в этих случаях вести себя хорошо. Что я хочу сказать, что на самом деле этот пример, если в него вдуматься, он такой антипример модульности, антипример абстракции. Почему? Потому что, чтобы знать, что действительно head от sort будет o от n, а не o от n log n, для этого надо знать, как sort устроен, для этого надо знать, как он реализован, потому что, да, стандартный sort в стандартной библиотеке, он так реализован, если, допустим, head от него будет o от n, да, это такая прикольная штука, но для того, чтобы это гарантировать, надо просто знать, как он написан. И какие-то другие вещи, которые логично предположить, ну, если head o от n, да, то, может быть, и last так же самое я могу взять o от n, а нет, а почему нет, а потому что функция sort так реализована. И другой пример, ну вот, кстати, если я начну рефакторить функцию sort, да, я вот вам не скажу, а сам пойду в стандартной библиотеке, поменяю функцию sort, и я зачем-то буду сортировать в обратном порядке, то есть моя функция sort будет так работать, что она сортирует в обратном порядке, а в конце сделать реверс. Это же будет, ну, нормальная функция sort, она будет семантически правильная, более того, она даже будет асимптотически правильная, потому что реверс o от n, а сортировка o от n log n, поэтому в конце реверс он там особой погоды не делает, конечно, констатный фактор может быть немножко выше, но особой погоды он как бы не делает. То есть это будет вполне себе валидная функция sort, но вот этому свойству она перестанет удовлетворять, что head от sort будет o от n. То есть оно все сломает. Ну, то есть ты говоришь о том, что тебе для того, чтобы вот так вот удобно абстрагироваться, тебе нужно знать деталь реализации, и значит, ты нарушаешь этим абстракцию. Абсолютно, да. То есть это пример антимодульности. Это тебе надо знать, как она внутри работает, чтобы понять, как ее можно использовать, как нельзя. То есть одна из таких коварностей, это неправильное слово, ну вот... Нюанс, тонкость. Нюанс, да, состоит в том, что ленивое вычисление, и он, кстати, тоже об этом в докладе говорит, что его можно, грубо говоря, по-разному в него входить. То есть простейший пример. Если у вас есть tuple ленивый, то вы можете вычислить первый элемент, а второй там оставить или позже вычислить. А можете начать со второго элемента. При этом этот tuple может быть результатом одного вычисления. То есть оно что-то там вычисляет и возвращает ленивый tuple. И в зависимости от того, в каком порядке вы будете вычислять, либо первый элемент возьмете, либо второй, то внутри вычисления тоже по-разному будет происходить. И аналогично там с ленивыми списками. То есть с ленивыми списками у вас вообще там очень много возможностей. Вы можете там первый элемент форсировать, второй или третий. Можете только spine форсировать, а элементы не форсировать. И вот при разных вариантах форсирования у вас получаются фактически разные пути выполнения. И гарантировать, что во всех этих путях выполнения вы будете, допустим, потреблять ограниченное количество памяти, очень-очень сложно. То есть обычный алгоритм в обычном строгом языке вы пишете, и вы точно знаете, по какому путем он будет выполняться. Соответственно, вы можете предсказать его алгоритмическую сложность и сложность по памяти, сколько он памяти съест. А когда есть ленивые вычисления, вот такие вот, когда это не одно значение ленивое, а целая ленивая структура выполняется, то вам надо знать, как реализован алгоритм, чтобы предсказать, допустим, какое выполнение памяти будет, если вы форсируете конкретно этот элемент этой ленивой структуры. Поэтому, да, то есть ленивость. Что я могу сказать в целом по поводу ленивости и как жить с ленивостью? Что к ней просто привыкаешь. То есть так же самое, как я привык пользоваться какими-то преимуществами ленивости. Например, я могу... Вот идет какой-то LED-бандинг, где я говорю, что x равно какой-то функции, от чего-то, какое-то вычисление. А дальше идет case или if. И я знаю, что я могу спокойно определить этот бандинг. Если он в какой-то ветке не используется, он, значит, вычислен не будет. То есть он практически бесплатный мне. Если бы я писал на строгом языке, я бы, соответственно, привык бы так не делать, потому что в строгом языке он всегда вычислится, поэтому я бы спускал этот бандинг в конкретные ветки, где этот бандинг нужен. То есть я привык пользоваться какими-то преимуществами ленивости. Но с другой стороны, так же самое, я привык остерегаться каких-то нюансов ленивости. Например, если я пишу функцию с аккумулятором, и я вижу, что аккумулятор... Ну, это какой-то цикл. И аккумулятор не форсируется. У меня на уровне рефлекса поставить восклицательный знак, чтобы форсировать этот аккумулятор. Потому что если я его не форсирую, то он будет потреблять много-много-много памяти. То есть эти вещи, они не всегда тривиальны. Их надо учиться распознавать. Надо понимать, как работает ленивость. Очень многие этого не понимают. Я могу поделиться... Я когда работал в Barclays и нанимал в Киеве хоскилистов, я просто беседовал с пару десятков минимум программистов. И в принципе ребята были неплохие. Они в целом язык знали, понимали, ла-ла-ла. Но одна из таких больших проблем, когда начинались вопросы, связанные с ленивостью, ленивость не понимал почти никто. То есть у меня был банальный вопрос, слушатели могут себя тоже протестировать. Вопрос очень-очень простой. Есть список, и надо посчитать его среднее значение. То есть сумму всех элементов поделить на количество. И желательно это сделать в один проход. То есть понятно, что можно отдельно посчитать сумму, отдельно количество и поделить. Но желательно это с помощью одного фолда сделать. И корректно это сделать, так чтобы он потреблял константное количество памяти, очень-очень немногие могли так сделать. Что показывает, что ленивость штука хитрая, и далеко не все умеют с ней правильно обращаться. Но если писать на хаскеле, то очень желательно с ней учиться правильно обращаться. Это было очень интересно, потому что я никогда не думал про это сломанное абстракцию, если честно. Но как ты считаешь, Рома, ленивость стоит вот этой сложности и неочевидности для большинства программистов. Например, за то же у меня не считается то, что не должно считаться. Но если в скале я могу использовать ленивое вычтечение, там где я явно сказал, что вот этот вал, он у меня ленивый. Вот как ты пример привел, что там бесплатный вал. То есть такая возможность у меня все равно есть даже в строгом языке. Но правда я не могу вычислить какое-нибудь дерево бинарное на 42% и за счет этого память сэкономит. Кстати, ленивые вычисления не только утекают по памяти, но еще и их экономят, если правильно использовать. Вот как ты считаешь, в целом, ленивое вычисление того стоит или нет? Да, это такой многогранный вопрос. Я как человек, который с этим уже разобрался, мне с ними комфортно, для меня, конечно, стоит. Я почти не чувствую каких-то проблем с ними, я только пожинаю плоды ленивости. Конечно, с точки зрения бедного новичка, которому все это надо понять, вот эта модель выполнения кода ленивого, с его точки зрения, может, он хотел бы, чтобы это не было ленивое. Интересно мнение ребят, которые работают в Standard Chartered, потому что у них свой собственный компилятор типа Haskell, это все-таки не совсем Haskell, но язык очень похож на Haskell, называется Mew. И вот одно из ключевых различий, что их Haskell строгий, там нет ленивости. И с одной стороны, они объясняют, почему они приняли такое решение. Но с другой стороны, особенно таких вот хардкорных Haskell-истов, которые там работают, типа Ленардо Гуссон, Нейл Митчелл, они по секрету признаются, что да, все-таки без ленивости плохо, и вот такие штуки там неприятны, и такие штуки неприятны. Но тема того, что ленивость можно эмулировать, безусловно можно. Более того, для этого даже не надо специальной поддержки языка. В любом языке функциональном можно ленивость в какой-то степени эмулировать просто лямбдой. То есть заворачиваете вычисление в лямбду, и все, пока вы не дадите ей какой-то аргумент. Аргумент при этом не играет значение, то есть это константная функция. Но пока вы аргумент не дали, функция не вычисляется. Вот вам почти ленивость. Это почти ленивость, потому что классическая ленивость предполагает также мемоизацию. То есть если вы вычисляете это пять раз, то оно на самом деле вычислится один раз и запомнится. А остальные четыре раза вам вернется вычисленное значение. Этого, конечно, там не будет. Но с точки зрения просто отложенных вычислений, это вполне реальный способ эмулировать такую себе псевдоленивость в любом функциональном языке. Тут дело в том, что язык поддерживает по дефолту. Например, писать на Haskell в строгом стиле очень-очень нетривиально. Почему? Потому что все структуры данных стандартные, они ленивые. Все функции библиотечные, они работают с ленивыми данными и они возвращают ленивые данные, как правило. И поэтому, чтобы работать со строгим Haskell, вам надо будет переписать всю стандартную библиотеку. Ну, банально, тип Maybe, он ленивый. Там списки, они ленивые. То есть я общался когда-то с ребятами, которые писали свою библиотеку, в которой все типы ленивые. Все типы, наоборот, строгие. Чтобы вообще не было никакой ленивости. Но для этого действительно надо все перелопатить. И опять-таки, если вы используете какую-то стороннюю библиотеку, вам либо надо ее форкать и переписывать на ленивых типах, либо переписывать в свою библиотеку. Так же самое и в Scale. Просто с точностью наоборот. То есть пока вы пишете на строгой Scale, то у вас все круто, потому что язык это поддерживает по умолчанию. Если вы пытаетесь быть ленивым, например, хочется отфильтровать список. Но функция фильтры, я не знаю так это или нет, но допустим она возвращает неленивый список и все. И вам надо писать свою функцию фильтра и так далее. На самом деле в Scale явно разделены ленивые и неленивые списки. Ленивые называются стримы и можно написать функции, которые работают с чем угодно. Я условно говорю, что любая библиотека, очень редкий автор будет поддерживать две версии библиотеки. Одна ленивая, другая строгая. То есть если ты идешь против вот этого соглашения, против конвеншен этого языка, то тебе будет нелегко. Согласен. Идем дальше? Если никто не хочет ничего добавить. Про ленивость. Вань? Я вообще хочу поблагодарить, очень интересно послушать. На самом деле интересно. И вот это вот богатое объяснение ленивости, я думаю, надо бы куда-нибудь в книжку записать. Потому что большинство людей, которые, скажем, обсуждают... Это как мы про Rust общаемся, у меня такое впечатление. То есть вроде как потрогали, вроде как написали два Hello World'а, и все, мы теперь разбираемся в Rust. Так и большинство людей общаются на тему ленивости в Haskell'е. И не понимают небольших сложностей, которые с этим связаны, и небольших преимуществ, если они выругают. Это палка о двух концах, и оба эти конца надо понимать. Это какая-то фундаментальная проблема в программировании, как мне кажется. То есть, например, вот футуры в Haskell'е. С одной стороны, там довольно высокий порог вхождения, довольно сложно научиться с ними работать так, чтобы они проблем не вызывали в продакшне. Но когда ты научился, у тебя все здорово, они тебе такую мощь дают. Ты можешь, например, сказать, у меня на сервере 8 ядер, вот я 2 нитки буду использовать для каких-то сложных вычислений в фоне, а остальные 6 ниток будут запросы пользователя обработать. Попробуй сделать это в Haskell'е с его встроенными легковесными процессами. С другой стороны, в Haskell'е ты просто пишешь, и тебе не нужно думать о том, легковесные процессы, не легковесные. Удобно. Какая-то такая проблема компромисса, она постоянно возникает. Что с ней делать, непонятно. А я не совсем понял, в чем проблема с Haskell'ными потоками? Ну, хорошо, как ты, как пример, как ты запустишь, вот у тебя есть тяжелая задача, да? Так. Ты, конечно, можешь сделать, как называется, fork.os, да? Сделать прям физический нитку операционной системы, да? Не-не-не-не-не-не-не-не. Это частое заблуждение насчет fork.os. Форк.ос вообще не об этом. Он просто неудачно названная функция. А форк.ос не форкает дред операционной системы. Хорошо, тогда я сформулирую задачу до конца. Давай. У тебя есть фоновые, ну, то есть, есть backend, да? У него есть тяжелые вычисления, прям он там матрички перемножает, фони для чего-то, я не знаю, статистику какую-то считает. И одновременно он обрабатывает запросы пользователя. И вот тебе нужно, чтобы ресурсы твоего CPU были как-то распределены в какой-то пропорции, что гарантированно вот столько ниток они считают фон, а столько ниток они обслуживают запросы пользователя. У тебя нет такого, что, например, запросы затормозили фоновые вычисления или наоборот? Ну, вообще говно вопрос. То есть, можно с одной стороны просто ограничить число ниток, но это, скажем, не такое хорошее решение. Но если вот буквально то, что ты говоришь, да, просто ограничить число ниток, ну, банально ты заводишь там какой-нибудь условный семафор, какую-нибудь переменную, которая там, каждая нитка, которая обрабатывает запросы, она вычитает единичку, да? И, соответственно, если она смотрит, что в этой переменной нолик, то она не стартует, она не обрабатывает запрос. Но почему это плохо? Потому что у тебя же смысл ограничивать количество ниток логично ограничивать именно по ядрам. То есть, можно сделать так, что матрички у тебя условно на двух ядрах перенажаются. То есть, можно явно использовать функцию fork on, которая, ты говоришь, номер твоего виртуального ядра. Почему виртуально? У Haskell есть свои виртуальные ядра, которые условно соответствуют нитям операционной системы. То есть, когда ты задаешь количество виртуальных ядер явным образом, например, через аргумент командной строки, если у тебя количество виртуальных ядер равно количеству реальных ядер, то они мапятся один к одному. Понятно, что ты можешь там сделать меньше, можешь сделать больше. И вот, когда ты форкаешь нить, можно сказать, что ты должен исполняться на конкретном виртуальном ядре. И тогда ты можешь, если у тебя 8 ядер, ты можешь на двух ядрах перенажать матрички, а остальные, хоть миллион легковесных нитей будут на других двух ядрах работать. То есть, можно прям так, на других 6 ядрах. То есть, можно прям так дредполами управлять. Я этого не знал, если честно. Интересно. Все это тема бросить скалу и перейти на конец на Haskell. Там вообще очень интересная модель, как в Haskell работают легковесные нити. Я в свое время разбирался. И там очень интересно и нетривиально. А может ты мне сразу подскажешь, как сделать еще одну такую вещь? Допустим, я считаю, у меня есть какая-то метрика, я считаю, сколько времени выполняется конкретный код. Что, кстати, уже засада в Haskell из-за ленивости, частоты и так далее. Но не важно. При использовании Futur я могу сказать, что вот этот код, он у меня выполняется в одной Futur, он гарантированно нигде не прерывается. То есть, у меня нет такого, что, например, я начал обрабатывать запрос, потом у меня runtime решил, что что-то ты долго обрабатываешь, давай там еще 10 тысяч запросов обработаем, потом вернул управление твоему коду. И в результате, если твоя метрика говорит, что вот этот код, он выполнялся 100 миллисекунд, ты знаешь, что это 100 миллисекунд с точностью до того, что не вытеснял ли поток операционной системы сама. А можно ли этого как-то добиться в Haskell? То есть, чтобы нитка ни при каких условиях не вытеснялась, да? Ну, чтобы метрика гарантированно... Ну, скажем так, да, чтобы... Меня на самом деле точность метрики интересует. Вот насколько я понимаю, в Haskell, в Erlang, в других языках, со встроенными легковесными потоками, у тебя метрика будет прыгать, она будет в большинстве случаев показывать правильные значения, а в некоторых случаях у нее там будет пик адский. Вот в Scala это не так. Ну смотри, ты же понимаешь, что это вообще имеет смысл только когда ты тестируешь, то есть не в продакшене. Нет, не понимаю, почему? Ну, потому что у тебя получается задача померить метрику, ты ее ставишь выше, чем собственно производительность. То есть причина, по которой нитки вытесняются, ну, именно состоит в том, что рантайм думает, что так будет лучше, и как правило он прав. А ты говоришь, что мне пофиг, что там будет лучше, мне главное знать, сколько точно оно будет выполняться. Ну, не совсем так. Я могу привести пример, когда я знаю лучше рантайма, когда нужно вытесняться, а когда нет. Например, у меня есть запросы с покупкой на 10 долларов, а есть на 10 тысяч долларов. Очевидно, я не хочу, чтобы на 10 тысяч долларов затормозили и так далее. Они более приоритетные. Ну, такое. Ну, то есть я бы такую задачу, как ты говоришь, я бы решал на каком-то более высоком уровне, чем нити Хаскеля. То есть, например, я бы сделал два разных процесса, или даже на двух разных машинах и бы разнес. Я понимаю, что это очень теоретический вопрос, и что они не относятся к разряду нерешаемых. Окей, а если конкретно на вот этот узкий вопрос отвечать, опять-таки, мне кажется, но... То есть я не могу это гарантировать без того, чтобы еще раз посмотреть на исходники РТС. Но мне кажется, что если ты их разнесешь по виртуальным ядрам, то есть если вот эту важную нитку ты положишь на одно виртуальное ядро, а все остальные нитки ты положишь на другие виртуальные ядра, и при условии, что вот эта нитка, которую ты меряешь, не будет блокироваться, то тогда, наверное, она не будет вытесняться. Но если она заблокируется, то что произойдет? То есть вот это тред операционной системы, в которой работает рентайм, он видит, что нитка заблокировалась, то есть этот тред освободился, ну, тред операционной системы освободился, и как бы он думает, ну, что ему простаивать, а вот там куча работы у других ядер есть. Давай-ка я возьму какую-нибудь работу с тех других ядер на себя. То, что называется work stealing. Но если этот легковесный поток не блокируется, то, мне кажется, что он не будет вытесняться. Хорошо. Господа, кто мне расскажет про этот ваш новый модный стек, который прямо называется стек в мире Хаскеля, который прямо убьет кабал?",
    "result": {
      "query": "Haskell lazy evaluation pros cons"
    }
  }
]
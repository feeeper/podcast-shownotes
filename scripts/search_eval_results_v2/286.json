[
  {
    "segment_id": "b24cb08f-8e98-41c7-84fd-49f78c63ba27",
    "episode_id": "e0d21f08-bd15-4ad4-a832-4afdc3f22a1b",
    "episode_number": 286,
    "segment_number": 5,
    "text": "Слушай, если придумать количество способов стрельнуть себе в ногу в этой системе, я боюсь, что у нас не то что пальцев, и времени, нам вообще ничего не хватит в этой вселенной. Ног не хватит, понятно. Да, то есть, как бы, конечно, стрельнуть можно здесь в любом случае. Но, и, кстати, здесь нету ничего про защиту от дурака, хотя я прям уверен, что у них есть это в системе по-любому. То есть, наверняка у них есть сравнение того, что блин, похоже, что-то человек здесь напутал, и у меня автоматическая система говорит, что надо больше машин, а функция говорит, что надо меньше машин. Ну, что-нибудь типа такого. Я думаю, что у них есть подобная вещь. Пошли дальше. Дальше идёт интересное, фактическое описание Автопилота закончилось. Дальше начинаются интересные главы. Во-первых, это... Глава номер 4 это определение, насколько качественно работает автопилот. И в главе номер 4, подраздел 4.1, называется методология. То есть, они, целая методология, это прям двухстраничный, двух с половиной страничный раздел, который объясняет, каким образом они решили ввести методологию для подсчёта того, насколько правильно работает автопилот. Блин, такого серьёзного подхода к определению качества я не видел. На самом деле, в этом есть смысл, потому что вы не можете определить... То есть, теоретически можно было вводить какое-нибудь обетестирование. Но обетестирование надо вводить на одинаковых по типу или, я не знаю, по кластерам с запросом. А у них, получается, автопилот привязан к конкретному кластеру. То есть, если ты включаешь автопилот на кластере, то на нём больше ничего не работает. Вы можете не включать автопилот на каком-то другом кластере, но сравнивать тогда придётся кластера, на которых загрузка может очень сильно отличаться. И поэтому, фактически, они всю вот эту методологию, всю главу методологии, что, пожалуй, если мы имеем данные на истории работы вот этих тасков, а потом имеем и какую-то статистику по тому, как работает лимитер, как много у нас вышибало по out of memory, и сколько ресурсов мы использовали на вот этих типах задач, скажем, за последние два года, то вот сейчас, когда автопилот проработал здесь ещё месяц, мы можем их сравнить, потому что мы накопили достаточное количество статистики. Фактически, они доказывают вот это вот. И они рассматривают разные показатели, то есть, это первая методология, а потом дальше они рассматривают, насколько всё стало лучше. И один из показателей, который они рассматривали, это слэк, вот этот самый слэк, это зазор неиспользуемых ресурсов между тем, что используется, и между тем, сколько лимитируется. И они показывают, что в автолимитере зазор уменьшился с 60, который обычно указывает человек, до 31, если используется не ML, и до 23%, если используется ML. Если это в процентах высчитывать, то, в принципе, так классно звучит. Но они посчитали в абсолютных значениях, и если посмотреть на 10 тысяч джобов, которые они запускали без автопилота, то потеря на 10 тысяч джобах равнялась в среднем 12 тысяч машин этого кластера в это же самое время. А в терминах автопилота это было только 500 машин. То есть, они резко снизили количество потерянных ресурсов, резко с 12 тысяч до 500. И это прям очень существенно, особенно, когда у тебя это не только один кластер работает, а все кластера работают на этом автопилоте. Следующее, это я вкратце рассказываю результаты, здесь четкое объяснение с графиками, с показателем, как они это считали. Следующее – это надежность автопилота. И мне здесь очень понравилось, они говорят, что вообще, на самом деле, очень интересно, потому что теоретически тривиальный автопилот мог устанавливать везде лимиты в 0, и пока на машине достаточно ресурсов, она будет работать, но в soft limit это значит, что мы продолжаем работать, даже если мы вышли за пределы. Но если внезапно нам не хватает времени, мы будем всех убивать. И тогда получится, что мы слэк уменьшили до 0, у нас в принципе нет разницы между лимитом и текущими использованиями системы, но при этом резко увеличивается количество невыполненной работы, ну или выполненной со срочкой, потому что мы пробивали задачу. Или троттлинг, увеличивается троттлинг. И поэтому они в этом разделе рассматривали графики увеличения количества out of memory и троттлинга на кластерах с этими задачами после включения автопилота. И оказалось, что ML-версия автопилота увеличивает количество out of memory киллов на данных задачах, но из-за того, что они умеют конфигурировать, что во-первых, из-за того, что у них Borg автоматически перезапускает задачи, а во-вторых, потому что они могут по-разному конфигурировать батч и не батч запросы, они просто, я так понимаю, увеличивают количество out of memory на батч запросах, и таким образом все, что должно быстро выполняться, имеет ограничение по лейтенансу, у них не произошло изменений. А батчи, ну чуть-чуть помедлее они стали выполняться, но зато ML помог еще больше снизить количество потерянных ресурсов. И последнее... Чего тут number of limit changed? Да, ну здесь они все сравнивают, как раз показатели для того, чтобы понять, насколько введение помогло или помешало. Да, последний раздел у них посвящен интеграции автопилота, есть больше психологический момент, потому что люди не дозирают ML, особенно в критических задачах, особенно там, где с них снимут шкуру, если что-то пойдет не так, и поэтому у них был долгий процесс интеграции, потому что сначала запускали его на неважных задачах, потом показывали всеми результаты, проводили лекции, потом начинали включать по чуть-чуть везде, накапливали позитивные мнения и так далее. Я сильно не вчитывался в эту часть, не хватило мне времени, но в целом довольно интересно, потому что я не представляю, каким образом, я это, наверное, прочитаю дополнительно, я не представляю, каким образом можно внедрять подобную систему в сообществе, в котором фрики ценятся больше всего. У нас в компании фриков, я не отношу себя к фрикам, если что, фриков, которые любят цепляться за железяки, хардкод, олдстайл, C, вместо всех ваших новых модных технологий, все вот эти новомодные ML штуки, они всегда воспринимаются штыки. То есть у нас все фрики в нашей компании всегда были против когнитации. Я не представляю, каких трудов стоило просто заставить их согласиться, что, пожалуй, вот эта штука поможет. Показывать очень много цифр. У меня, кстати, была похожая проблема, когда я работала в BuzzFeed, и мы занимались тем, что делали и главную страницу, и рекомендационную систему для главной страницы. И в BuzzFeed, как и в принципе в любой медиакомпании, есть редакторы. Большая команда. И это люди, которые обычно знают очень хорошо какой-то домен, например, там редакторы новостей про бьюти-индустрию, либо новостей про политику. И они говорят, мы знаем свою аудиторию очень классно, мы понимаем их нужды, и мы лучше можем сделать главную страницу и подсветить какие-то новости, чем ваши новомодные системы. И это была огромная всегда проблема, пытаться их как-то убедить, пытаться им объяснить, что на наших данных мы видим лучшие метрики, вот смотрите цифры. И они всегда так чётко показывали, что машина всегда лучше людей, подбирает посты, которые будут больше генерировать трафика либо какую-то другой метрики, которая нам нужна. И это всегда была очень большая проблема. И это требует очень много разговоров, очень много таких общения. И это очень трудно понять, потому что, казалось бы, покажи отчёт, расскажи, вот смотрите, провели мы АБ-тест, вот что он показал. Типа, всё, мы доказали, побежали дальше. И вот даже если вы это доказываете, всё равно этого недостаточно. И это такая всегда большая-большая работа. Думаю, кто работает в медиаиндустрии, они могут как-то почувствовать эту боль. Но она колоссальная. Ещё хочу добавить, что ты, Ваня, рассказывал, и я обратила внимание, какое огромное количество цифр в статье и вообще в твоём рассказе. И тут я вспомнила, что Google, они ведь очень много про OCR и про то, как они планируют. Это всё у них через OCR. Мы, по-моему, это в каких-то предыдущих старых выпусках об этом рассказывали. И я понимаю, почему здесь написано столько цифр, потому что это, наверное, отчасти влияние OCR, когда происходит планирование, и обычно это те метрики, на которые смотрят. То есть планирование обычно... Сейчас я это объясню. Обычно утверждаются какие-то objectives, и дальше принимаются какие-то OCR, key results. И вот для каждого ключевого результата нужно придумать, как это измерять. И вот если бы... Очень трудно измерить, например, отказа устойчивой системы или там resilience системы, либо стабильной системы, либо масштабируемой системы. Говорить, ну вот система стала более масштабируема. Как бы мы так чувствуем. И вот как бы этого недостаточно для планирования с использованием OCR. И там очень естественным образом возникает очень много цифр, и когда планирование происходит, они говорят, ну, мы хотим подвинуть эту метрику с X на Y. И поэтому в пейпере очень много цифр. То есть я понимаю, откуда это берется, и как это появилось. Очень забавно. Потому что я сейчас, наверное, впервые в компании работаю, где используются тоже OCR, и я понимаю, как это сильно влияет на все остальные мои решения, на то, на что я смотрю при планировании, при... когда команда над чем работает. Вот, просто это OCR, они здесь, мы видим торчащие уши сейчас. Ребята, вы знаете, что мы совершили страшную ошибку? Мы сейчас обсуждали тему, которая... то есть у нас in discussion совершенно другая тема картинка висит, ребят. Нам придется их потом поменять, когда будем выпуск делать с шоу-нотой. То есть это был из вот этой 285. Да, пока ничего не трогай. Видимо, когда потом перейдем к дурдашу, видимо, их просто... чтобы timestamps были более похожи на правду. Я от себя хотел такой момент добавить. То есть получается, что с кубернетосом мы, по сути, задачу конфигурируем один раз, отправляем ее в плавание, и дальше у нас там ну, может быть, horizontal autoscaler, что-то autoscaled. А здесь получается, что у нас... ну, мы, конечно, все еще, наверное, один раз определяем задачу, но потом эти ручечки на задаче крутятся много раз уже... То есть как это... То есть получается, что некоторые вещи, которые в кубернетосе задаются только при создании задачи, здесь они крутятся тоже этим автопилотом. То есть я имею в виду вертикальное масштабирование вот этого всего и лимита. Или нет? Или да?",
    "result": {
      "query": "автопилот ресурсное управление кубернетес"
    }
  }
]
[
  {
    "segment_id": "2d80f85d-eb57-43d0-abf1-2f38e032ffb5",
    "episode_id": "3926a6b3-3922-4d15-90c1-ad73fc24cefa",
    "episode_number": 411,
    "segment_number": 5,
    "text": "Так, я тут настраивал микрофон, ничего не слышал. Замолчали, потому что закончили обсуждать икс селки Prod. Да, мы уже по кратовухе решили дёрнуть. Отлично, что без меня. Так, тогда поехали на следующую тему. Это про... Боже мой, а что меня не обновляется? Что же такое? У меня ничего не работает. Да все обновилось нормально. Обновилось, да? Хорошо. Оказывается, Саша не знает, как работает. Да, прискорно признавать, но это действительно так. Бывает, ты зайдешь в свой уютный блог, который стендилон и он не может быть заблокирован. И ты такой пишешь пост про то, как работает ретахедлог. Пишешь его по привычке за месяц, чтобы в процессе его перечитать, подправить и так далее. Вроде несколько раз перечитывал, вроде бы все нормально. Публикуешь, вот он неделю висит, там люди палец вверх ставят, то что да, да, отличный пост. И вот хоть бы один человек пришел и сказал, что Саша, ты в своем блоге херню написал. Вот бери свой пост, распощивай его, переписывай и запощивай нормально. Но нет, нет, к сожалению этого не происходит. Но ошибка была найдена, ошибка была исправлена. А теперь я предлагаю подумать, в чем она заключалась. Целиком пересказывать не буду, потому что это достаточно много материала. Но в краткостей поддержания поста. У нас есть... Валера, ты внимательно слушаешь? Я на всякий случай. Ну, сопривлек мой внимание, давай так. Хорошо, ты там... Я просто не знаю, может у тебя там кратовуха внутри венная уже и Валера все уже не соображает, совсем опизденел. Валера уже неделю не соображает, да, все так. Так вот, у нас есть страницы. Страницы лежат в разделяемой памяти и пишутся на диск. И есть write a headlock. В write a headlock мы пишем, что в такой-то странице по такому-то смещению нужно что-то поправить. Есть некоторые правила, что там страницы всегда пишутся раньше, чем вытесняются страницы. Еще раз. Есть некоторые правила, что в write a headlock, в журнал записи пишутся сначала, потом страница вытесняется, нельзя сначала вытеснить страницу, потом записать write a headlock, на это несуть важно. А алгоритм восстановления выглядит так, что открыть журнал с какого-то момента, который называется чекпоинтом или контрольной точкой, тоже к этому обсуждению не имеет значения, как мы определяем, где оно находится. Мы с какого-то момента открываем журнал, идем по нему, там записи. Мы находим запись, к которой к какой-то странице применим. Мы обращаемся к хипу, берем оттуда страницу, применяем к ней эту запись. И вот так вот, проигрывая журнал с чекпоинтом до конца, мы накатываем изменения в базе данных до последней версии, и у нас база приходит в константное состояние. Кто мне скажет, почему это нифига не будет работать? Если мы будем каждый раз брать страницу из диска, у нас есть несколько обращений к странице. Это что-то такое, наверное, да? То есть, наверное, нужно проверить, нет ли страницы или это считает, что мы в торне не читаемая из диска. Давай для простоты эксперимента скажем, что записи в журнале, их применение, оно идемпатентно. То есть, мы можем несколько раз применять одну и ту же запись. Я про другое, про то, что типа, если мы взяли страницу из диска, применили изменения, потом снова взяли страницу из диска, применили изменения, то предыдущее примененное изменение будет потеряно. Нет, считается, что ты когда делаешь рекавер, у тебя тоже работает buffer manager. Если ты взял страницу из диска, ты положил ее в пул, применил данное изменение, второй раз ты ее не будешь читать из диска, понимаешь. У нас есть чистый снапшот, да? Мы начинаем с чистого снапшота. Ну, я не уверен, что ты называешь чистым снапшотом. Ну, в смысле, он нормально закончился без всяких проблем. Чекпоинт, ты имеешь в виду? Ой, да, сорян, чекпоинт. Ну, да, да, да, у тебя чекпоинт успешно завершился и все такое. То есть, потом система нормально работала, у тебя вот ты, ну, buffer manager работал по своей логике, что если там страница грязная, она вытесняется в диск, там если место кончается и так далее. Я не уверен, что в вул записи, в случае пазгреса, можно применять ровно в том же порядке, в котором не написано диски, потому что наш же комит может быть, по-моему, в отдельной вул записи, нет? Ты прав в общем случае, когда у нас есть тема с undo и redo логами, но не прав в случае с пазгресом, потому что пазгресу все равно, у него undo лог в хипе и ты, ну, то есть, ты можешь применять записи прямо в том порядке, в котором они есть, более того, реплики так и делают. Да, это так. Ладно, давай я расскажу, почему я дурак. Рассмотрим сценарий, когда у нас система работает, у нее есть shared buffers, в ней есть страница, место в shared buffers кончается, нам нужно одну из страниц вытеснить, новую прочитать, логично. Если страница грязная, она помечена, что в ней были не сохранены изменения, мы должны сходить в кучу и записать эту страницу. Проблема в том, что запись в 8-килобайтной странице в кучу, она не является какой? Атомарной. Атомарной. И мы можем записать данные частично и испортить хип. И потом мы не установимся. Это та самая причина, почему я пишу херату в своих блогах, а вы меня не отправляете. Поэтому, поэтому, ride-ahead-log в пасгресе работает совершенно не так, он работает немножко не так. Оказывается, что я узнал, потому что мы, казалось бы, Энди и Павла обсуждали сначала Intro to database systems, advanced database systems, потом я несколько книжек про внутреннее устройство пасгресса, японскую, русскую, и там еще была. А, собственно, database systems concepts. Потом ты пишешь пост и разбираешься по исходникам, и все равно вот оно, только потом приходит понимание. Оказывается, что после чекпойнта, успешного чекпойнта, когда мы первый раз меняем страницу, мы пишем в журнал ее полную копию. Как раз для этого случая. То, что если ты упадешь, пока ты менял страницу в хиппи, ничего страшного, у нас после чекпойнта есть ее копия в журнале. Вот это называется full page writes. Оно в пасгресе по умолчанию включено, и очень не рекомендуется это выключать, потому что тогда система будет терять данные в силу названных причин. Тут возникают еще разные интересные моменты. То, что когда ты узнаешь, что ага, в журнале есть полный копий страницы, они там не просто так. Возникают вопросы. Сейчас у меня здесь помечено. Вопрос номер первый. А пишем ли мы исходную версию страницы, а потом к ней обычную RedHead Log запись? Или мы пишем, типа мы изменяем страницу, пишем ее первую измененную версию? Это первый вопрос. Интуиция подсказывает, что было бы логично писать первую измененную версию, потому что, ну иначе это избыточно. Ты пишешь чистую копию, а потом за ней дельту. Зачем, когда ты можешь просто в первой записи записать нормально? Опыт подсказывает, что в пасгресе не обязательно все починять. В пасгресе некоторые вещи сделаны вопреки интуиции, и на то есть хорошие причины, поэтому теперь нужно снова открывать код, снова разбираться. Я на данном этапе не знаю, как она на самом деле работает. Если нас слушают эксперты, вы, пожалуйста, попросим. Второй вопрос. Сейчас я прочитаю. Блин, я себе сделал какие-то пометки в понедельник, и теперь сам не могу по ним разобраться. Ну и ладно. Все равно у меня есть запасная карточка на своей личной борде, поэтому буду в другой раз разбираться, и потом вам расскажу. Фактически это изменение, это небольшое. Ты все правильно знал, просто деталью уточнил. Оно небольшое, но потом начинаешь задумываться, еще знаешь, про разные вещи. Что вот у тебя есть это правило, про то, что страницы из хипа пишутся на диск строго после записи в журнале. И сделано так для того, чтобы, если делать наоборот, ты можешь сначала вычислить страницу, потом попытаться записать в журнал, но не успеть, и упасть раньше этого. Это значит, что когда ты запустишься и начнешь рекавери, и начнешь смотреть на свои записи из журнала, у тебя вот, ты встретишь запись, у нее есть LSN, Locked Sequence Number. Это несмотря на то, что это такое, но смысл в том, что она посмотрит на эту страницу и поймет, что это страница из будущего, и ты эту запись не можешь применять к страницам из будущего, и твой рекавери обломается. Это в наивной реализации. Но если мы сказали выше, что на самом деле у нас есть полная копия страниц в журнале, то, может быть, нет никакой разницы. Может быть, мы можем писать в любом порядке страницы из Shared Buffers и Walls Apsi. Ну, какая разница, если мы пишем страницы в Write a Hardlock? Логично? Нет, нифига не логично. Потому что есть граничный случай, как раз вот касающийся первой записи после чекпоинта. Когда ты первый раз меняешь страницу после чекпоинта, ты не можешь записать страницу сразу в HIP, а потом ее копию в журнал. По тем же самым причинам, что ты можешь упасть, пока ты писал в HIP, и у тебя HIP просто будет испорченный, а в журнале не будет копии. Поэтому ты должен в журнал записать сначала копию страницы, потом менять HIP. И возникает вопрос. Ну, хорошо. Первую записи после чекпоинта мы договорились, что ее нужно сделать сначала в журнал, но потом-то уже нет никакой разницы, в каком порядке писать. И как будто бы, когда ты первую записи после чекпоинта сделал в журнал, потом, вроде как, нет разницы, в каком порядке ты выясняешь данные из shardbuffers, а в какой момент пишешь волл. Но есть другая проблема. А как ты будешь трекать? Ты после чекпоинта писал или не писал? И выясняется, что трекать это не так-то просто, поэтому проще всегда проверять, что ты сначала пишешь волл, а потом в HIP. То есть, как бы, изменение, оно простое, но оно тянет за собой портянку других вопросов. Понимаешь? Не только вопросов, но еще и пониманий и, как это сказать, возможно, все подобные вещи нужно записать в качестве каких-то гарантий. То есть, мы гарантируем то-то, поэтому куча выводов. Наверное, список гарантий будет слишком большим для позгресса. Еще там интересные вопросы уровня. А что если мы работали с full-page rights, но потом при рекавери мы выключили full-page rights, а должны ли у нас аллеритмы рекавери отличаться в зависимости от настройков? Не должны, наверное, не должны, чтобы наверняка восстановиться. И чего-то там еще. Я много всякой фигни после этого выписывал. Но одно я могу сказать вам точно. Восстановление после рекавери — это нифига не простая штука. А в позгрессе оно еще и относительно просто для мира с УБД в целом, потому что нету андул записей. И этим существенно... Одна из причин, почему так сделано — это существенно упрощает реализацию. То есть, казалось бы, у нас реализация так уже упрощенная, но она нифига не простая. Вот. Пожалуй, мораль из этого — не пишите свои базы данных, особенно не пишите свои, которые с райдом и дологом, потому что вы умрете, ну, точнее так, вы накосячите, но вы не будете об этом знать. Все сложно. И под конец я даже запутался. Поэтому давай быстрее перейдем к следующей теме. А ты потом открой мою статью. Знаешь, как классно написано «теперь-то в ней точно нет дефектов»? Точно. Или есть? До следующего раза. Так, следующая тема моя. Я притащил опять небольшой paper, который я хотел на прошлой неделе обсудить, но мы не успели, поэтому будем обсуждать на этой неделе. Поэтому я, возможно, какие-то детали смогу уже забыть. Уж простите. Итак, paper называется «Taming Google Scale Continuous Testing». Вкратце это про проблемы с CIM внутри Google. Мне было очень интересно почитать, потому что, когда я много работал с CIM в разных компаниях, и мне всегда было интересно, когда становится компания размера очень большой, каким образом правильно расчислять тестирование. Потому что даже на маленьких объемах тестов может начаться, не знаю, большая головная боль. А на огромных объемах кода и теста, и количество разработчиков, эта головная боль увеличивается многократно. И вот как раз именно про это и написана статья. Во-первых, давайте я вкратце прибегусь по своим заметкам. Во-первых, в Google система тестирования называется TAP, Test Automation Platform, то есть платформа автоматизации тестирования. И в средний день, статья была от 17-го года, смотрите, уже пять лет назад. И вот пять лет назад, в средний обычный день, TAP тестировал больше 13 тысяч проектов, требуя 800 тысяч билдов в день и 150 миллионов запусков тестов. Это, скажем так, дофига. И это потребляет огромную гору энергии, времени, цпу на всех этих кластерах. И очевидно, что возникает вопрос, а нужно ли все это делать? И этот вопрос, не знаю, стоит ли погружаться в историю, но когда я работал в НЦСТ, мы с Лбрусом запускали тестирование. Для процессора Лбрус, я был в компиляторном проекте, у нас было много идей тоже, как оптимизировать тестирование. И одно из самых лучших тестирований, которое мы придумали, это выделить самые нужные кусочки тестов, которые часто падали, которые часто показывали какую-то ошибку, в так называемое оперативное тестирование. И вот это оперативное тестирование, оно запускалось и работало в течение 9 часов. То есть это самые лучшие, самые часто падаемые, самые хорошие тесты, которые мы можем выделить для того, чтобы хоть как-то хоть немножечко хоть чуть-чуть покрыть компилятор. И вот он запускался 8-9 тестов, представляете, да? То есть как бы вы сделали какое-то небольшое изменение проекта, чуть-чуть что-то поправили, а повлиять оно может на кучу всего, особенно если вы делаете какие-нибудь, не знаю, там оптимизации в компиляторе, которые влияют на кучу других оптимизаций, там куча эвристий, и так далее. И чтобы все это покрыть, нужно прогнать всего 8-9 часов тест, и это будет маленький маленький тест. Потом у нас было ночное тестирование, которое называлось ночным, потому что оно запускалось вечером, часов там, я уж не помню во сколько, 8-9-10 во сколько-то. Вот. И заканчивалось оно, конечно же, не на утро, потому что за ночь оно обработаться не успеет, а заканчивалось оно там хорошо, если за сутки успевало. Вот. То есть у нас, я помню, была задача как-то сделать так, чтобы оно хотя бы каждые вечер запускалось, а не раз в две ночи, потому что оно употреблял там кучу цпу таймов, цпу тайма тайма тайма, и невозможно было прям уменьшить никак, мы пытались изо всех сил уменьшать объем тестирования. Вот. И это на, не знаю, на тестах, которые мы сумели насобирать, а у нас там было в команде, в компании, я не знаю, сколько, меньше тысячи человек. А у гугла там, я не знаю, сколько, там пять городов можно построить и заселить их сотрудниками гугла, разработчиками, и я не знаю, из томов напечатанных кодов можно построить огромные башни. Вот. И понятно дело, что у них эти же проблемы есть. И вот статья как раз приводится, что да, у нас есть большая проблема. Вот. И в среднем код коммитится каждую секунду, и поэтому, когда люди приходят в гугл и ожидают, что вот на мой коммит кода, и когда вот я запушил что-то в репозитории, произойдет сборка, получается, что на каждый коммит кода запротестировать и собрать всего практически нереально. Вот. И как оказалось, по статистике, исходя из этой статьи, со временем происходит квадратичный рост необходимых ресурсов для тестирования. Квадратичный, потому что происходит линейный рост по количеству коммитов. Я так понимаю, что к 2017 году гугл таким образом рос в количестве людей, и соответственно, чем больше людей, тем больше коммитов, вот он, линейный рост. А во-вторых, количество тестов, которые создавались и которые необходимо было тестировать, тоже увеличилось линейно. Ну, логично. Вот получается квадратичная зависимость. Интересно. И, соответственно, это постоянно увеличивало количество размера кластеров и приводило к тому, что со временем эти размеры всегда заканчивались очень быстро. И, соответственно, стратегией вот этого всего департамента, который занимался этапом, было создать какую-то новую идею. И в качестве этой новой идеи они придумали майлстоуны. Майлстоун это такая идея, что ты каждое сколько-то времени делаешь как бы срез текущего состояния всех репозиторий, компилируешь это все, запускаешь тестирование этого всего и показываешь всеми результаты. При этом, насколько часто ты это делаешь срез зависит от того, как много у тебя ресурсов, как много, как быстро прошло предыдущее тестирование. И в 2017 году еще раз средний срез был каждый 45 минут в пик тайм. Когда больше всего комитов делается. И, соответственно, конечно же, очень часто было так, что большое количество ошибок приводили к каким-то проблемам. То есть, не хватило памяти или машина упала или еще что-то. И можно было добиться того, что подобные срезы и до 9 часов растягивались. И это, конечно, большая была проблема. Соответственно, у них была цель уменьшить вот этот вот либо объем тестов, который необходимо тестировать, либо тестировать под множество, а потом регулярно проверять все. Они пока не пришли к выводу и вот начали придумывать новую идею. Вот как раз бумага об этом. Оказалось, что все тесты совершенно не одинаковые. И вот интересная идея. Из 5,5 миллионов тестов, которые они создали, всего 63 тысячи когда-либо падали. 5,5 миллионов 63 тысячи. Это получается один процент тестов, когда-либо вообще падал в их тестирование всегда. Все остальные тесты никогда не падали. Вот и поэтому их, конечно же, глупо одинаково как-то трактовать. Их надо по-разному трактовать. Затем, соответственно, вторая идея, которая с которой они пришли, это то, что после накопления статистики и после того, как у них есть результаты, собранные за какое-то время, они могут дать ранее фидбэк человеку. Ты знаешь, что ты закомитал в Java Code и куда комитала в течение последних двух недель еще 15 человек. По нашей статистике с вероятностью 90 процентов у тебя там есть ошибка, которая приведет к какому-то падению. Ты подумай на всякий случай. Ты точно хочешь закомитовать или там может что-то исправить. Вот этот ранний фидбэк на самом деле дает быструю связь обратно и программисты чаще проверят еще на всякий случай что-то и исправят ошибку еще до того, как тестирование покажет, что там была ошибка. Мне кажется, это вообще-то вот это классная тема. Ранний фидбэк. Что думаете, пока я тут смотрю записи, скажите мне свое мнение. Ранний фидбэк всегда хорошо. Чем раньше, тем лучше. Да, вот. Пошли дальше. В Google понятие теста вообще тоже размытое, потому что очень сложно сравнивать разные языки, разные организации тестирования и где-то тестом является, не знаю, unit-test внутри файла, где-то тестом является запуск какого-то собранного бинаря, а где-то тестом является запуск shell-скрипта, который в какую-то отдельную папочку логи посылает. То есть, это все совершенно разные уровни, их надо как-то по-разному трепетовать. Иногда вообще сложно понять, где происходит ошибка. Особенно если на разных языках программирования в разных средах написаны тесты и кто-нибудь навоял свой собственный shell-скрипт, непонятно откуда брать эту ошибку в общем виде. Конечно, у каждого человека или отдела есть понимание, что где происходит, но когда ты пишешь саму систему тестирования, ты должен какую-то унификацию вести. Вот эту унификацию надо либо протаскивать через всю компанию, либо сказать как-бы best, подход, что потратим меньше времени и сделаем что сможем. И соответственно, очень сильно им мешали flaky тесты, которые портят вообще всем и всем. Во-первых, flaky тесты чаще всего зависят от окружающего мира, то есть это не проблема в коде и не проблема в том, что там два потока между собой как-то неправильно соревнуются, а это еще может сильно зависеть от окружения, от памяти, от того, что сейчас есть на диске, от того как запускались предыдущие тесты, база данных и так далее и так далее. И поэтому очень сложно начинать работать с flaky тестами, с мигающими тестами этими. А что самое плохое, мигающий тест очень сильно портит всю статистику, потому что большинство систем тестирования пытаются собирать статистику вида, вот у меня тот тест отлично работал, потом сломался, а потом вот этот комит его починил. И отсюда можно делать какие-то выводы. А flaky тест он может так себя вести, а потом окажется, что он нисколечко не починил, просто временно начал работать снова. И это приводит к тому, что единственный способ бороться с flaky тестами, это перезапускать эти тесты в чистом виде, где-то еще отдельно тестировать те пакеты, которые показывают вот такие мигающие результаты. И это еще больше увеличивает время тестирования, ресурсы и так далее. И поэтому они решили не полагаться на, изо всех вот этих вышеописных проблем, они решили не полагаться на какую-то очень узкую информацию, сконцентрированную про отдельно взятый тест, ну например там кто создал, когда он работал, когда он не работал и как бы от чего он зависит и так далее. Вот и вместо этого они разработали эмпирический подход. И вот после этого мне стало сразу неинтересно читать. Да Валер, ты не намнешь, если что. Как кротик. Это он говорил фу-фу-фу-фу, не надо так делать. Вот так вот не надо делать эмпирические подходы, потому что эмпирические подходы очень тяжело повторить и уж тем более проверить. Итого, они взяли знания о том, как у них сделается тестирование и каким образом оно запускается и от чего он зависит. Не поясняется, что это имеется в виду, но я предполагаю, что у них там есть какая-нибудь база данных вида. Вот в этом пакете зависимо от внешнего мера, а еще мы запускаем там шел, а еще там зависит от версии библиотеки, там вот что-нибудь типа такого сильно зависит. Плюс они использовали физический анализ, плюс они создали специальную модель, которая состоит из названия теста или тестового пакета, разработчика, который сделал изменения и команды, которая сделала изменения. Соответственно, тот код, который они тестируют с помощью этого пакета, какие-то изменения, какая-то мета информация про изменения. И они все вот это вот запаковали как вот единый один, единую одну запись, картеж. И в дальнейшем они вот этот картеж использовали для обучения какой-то своей внутренней системы. Тут не поясняют, что. Я так понимаю, что какой-то они там статистически или там мл что-то на нее натравили. И соответственно, уже делали выводы на основании того, когда вот они протестировали кучу раз все, после этого они начинали уже какие-то изменения вводить и соответственно статистику использовать для того, чтобы что-то исправлять. Вот как раз здесь они увидели, что у них всего 63 тысячи из пяти с половиной миллионов вообще когда-нибудь упало. Вот. Да. Вот. И... Сейчас подождите. Да. Чаще всего отношение прошедших и упавших тестов составляло 99 к 1. И соответственно, если они как вывод, как бы можно не тестировать 98 процентов оставшихся, соответственно, положить то, что хотя бы иногда падает и то, что имеет возможность упасть в тестируемый пакет, а все остальное просто отбросить. Да. Соответственно, они после того, как они все это протестировали и когда они увидели всю эту статистическую, они внезапно поняли, что сама идея вот этого проекта должна как-то немножко поменяться для того, чтобы найти... Не для того, чтобы лучше сделать тестирование, а для того, чтобы понимать лучшие тесты системы и соответственно делать какой-то анализ тестов и что необходимо тестировать. То есть у них больше... Изначально была идея, давайте напишем лучшую систему тестирования. А в итоге они написали лучший анализатор тестов. Это немножко другое, хотя и сильно связанное. Вот. У них очень много в статье описано, я вообще в это погружаться не буду, информация о том, как мерить расстояние между пакетами, которое может привести к проблеме. Ну, к примеру, у вас пакет А использует пакет Б как библиотеку, пакет Б использует пакет С как библиотеку и в пакете С произошло изменение какой-то функциональности. Вот. Повлияет оно на С? Ну да, повлияет. Повлияет ли оно на Б? Ну да, скорее всего повлияет. Повлияет ли оно на А? Да, повлияет. И вот это расстояние, оно здесь два. От А к Б, а от Б к С. Они провели очень много экспериментов, они прям тут кучу графиков нарисовали для того, чтобы показать, что похоже, что больше чем 10 вот эта длина зависимости не должна тестироваться. То есть изначально идея была то, что вот как бы, если у тебя есть полный граф зависимости и любое изменение в этом графе, нужно запускать тестирование всего, что может зависеть от того изменения. Вот. А здесь они сделали вывод, что при уменьшении длины до 10 происходит очень большое уменьшение количества необходимо запускаемых тестов, но при этом количество найденных ошибок почти не меняется. Они везде используют слово почти и это приводит нас к пониманию, что как бы у них не стопроцентная вероятность того, что как бы они все поймают, но это значительно уменьшает количество используемых ресурсов. Они пришли к выводу, что некоторые типы файлов чаще ломаются. Вот такое удивительное открытие. Некоторые утилиты или пользователи или департаменты чаще ломают свои пакеты, как бы их изменения чаще ломают тесты. А да, и вот они нашли очень классную зависимость, которые они говорят, что скорее всего у всех компаний будет разное, но файлы, которые изменяются более тремя или более людьми в течение короткого времени приводят к большему, к очень большому количеству проблем по сравнению с двумя разработчиками. Они не указывают, что значит очень большое, в чем разница. Вот. Но они говорят, что как бы, если у вас два человека копаются в коде, то это вызывает, почти не вызывает проблем. Если три человека копаются в коде, то это вызывает намного больше проблем. И это все ерунда, ерунда. Да, про это я рассказал, что почти, как-то у них не стопроцентная точность попадания, но они окей с этим. И соответственно, как следствие, они очень сильно смогли уменьшить количество тестироваемой базы за счет как раз сокращения, за счет сокращения длины зависимости до десяти и за счет того, что они смогли выкинуть часть тестов из постоянного тестирования, то, которое никогда не падало. И они регулярно это проверяют, но как бы поддерживают свое оперативное тестирование, как мы это называли в Эльбрусе, на очень низком уровне. Они смогли значительно снизить ресурсы, необходимые для тестирования. Мне очень не понравилась эта статья по тому, что они очень много скрывают и не говорят деталей. В частности, мы смогли сильно снизить тестируемую базу. Мы смогли сильно снизить ресурсы или ЦПУ необходимые для того, чтобы провести тестирование. Что значит сильно? Куда? К чего? Какие-то... Ну, как бы, скажите хотя бы график, я не знаю, там мы в 5 раз снизили здесь, в 10 раз увеличили здесь, и у нас соответственно происходит такое изменение. Они еще ничего не говорят. И все вот эти вот, как бы нам почти удалось или сильно тестируем, мне очень не понравилось. Вот. Есть в статье много графиков на тему того, как правильно определить дистанцию, которую нужно тестировать. Если кому интересно именно этот вопрос, статью стоит почитать, потому что они прям хорошо подошли к этому вопросу. Они и графики построили, и количество ошибок показали там и так далее. Но статья очень часто употребляется сноска вида, то, что мы нашли для гугла, для компаний, для остальных компаний скорее всего работать не будет. И поэтому в целом, но интересная статья почитать, но советовать я ее не буду. Вот. Вопросов, я так понимаю, нет, потому что скучно. Да нет, просто я понял, что все скрыто. Да, да, да, и все скрыто. Вот именно потому что скрыто, поэтому... Туман гугловойны. Гугло-туман, гугловойны, да. А вот что вовсе не скрыто? Да, что можно даже посмотреть, не только почитать. Это видосики про Postgres, про что же еще вы могли подумать. Видосики с конференции PGConf New York City 2022, доступные на YouTube. Я посмотрел по списку, что там есть за видео, выбрал одно, оно называется database disasters and how to find them, читает Кристоф Петус. И я надеялся, что это обновленный доклад, у него... Я в свое время, в 17-м году, посмотрел его доклад, называется Corruption War Stories, про то, как СУБД теряют свои данные. И вот судя по названию, я надеялся, что это что-то очень похоже. Оказалось, что это другой доклад, который я тоже смотрел, но он про другое. Он про... Как бы это объяснять? Как хендлить инциденты? То есть на... Чего не делать, не паниковать, на какие метрики смотреть, на какие не смотреть и так далее. Доклад не очень интересный, на мой субъективный взгляд, но может быть вам он лучше зайдет, может быть он мне не понравился, потому что я его уже когда-то смотрел. И более того, мне почему-то есть такое ощущение, что он даже был в DevZen. Ну-ка давайте быстренько проверим, вовремя записи. Ну, по названию не находится. Ну что ж, так или иначе, там есть еще много докладов, помимо этого. Ознакомьтесь, это бесплатно, не скрыто. Отлично, ну раз одно видео мы обсудили, давай может другое видео обсудим. Да, давайте, друзья, поговорим с вами про нетворкинг. Все знают, что нетворкинг очень важен в работе программиста, особенно если вы узко специализированный программист, тогда нетворкинг особенно важен. И это одна из причин, почему людям рекомендует пойти учиться в УЗ, даже если вы, может быть, не получите какие-то важные хард скеллы, по крайней мере вы осилите нетворкинг. Как вы поняли, речь идет про реальную работу с сетью, про протоколы сетевые, и это 11 лекция в серии Advanced Data Bay Systems, которую читает Энди Павло. Подождите, что база данных использует нетворкинг? Да. Боже мой. Вот, и даже база данных использует нетворкинг, а ты, дорогой слушатель, все еще нет. Доклад не такой, чтобы полно открытий, поэтому это будет краткий пересказ. Из-за интересного, что я узнал, оказывается, есть JDBC, и у JDBC у него есть разные способы, как прицепить его к разным базам данных. Можно взять фишный драйвер, например, через JNI, по-моему, называется, прелинковать к вертолем машине Java и вот прямо через него сходить, как пример. А можно написать нативную реализацию на Джавера. Опять скребется котик в дверь, вы, пожалуйста, игнорируйте это. Но, что представляет наибольший интерес, так и сейчас, простите, надо пустить кота, это очень бьет по ушам в секунду. Скажите, по правде, я вообще не слышал, как у него, кто-то там бьет котик, что-то куда-то скребет. Я тоже ничего не слышал, но я с другой стороны понимаю, потому что когда у меня кто-то там, не знаю, обычно скребется или ходит или что-нибудь еще за спиной, я это в мониторинг слышу гораздо лучше, чем это потом слышно на записи. Да, да, да, да. Я говорю. Да, да. Обсуждали, как у тебя котышки будут. Это в основном мне давит на уши. Вот. Кошечка села в дверях и такая и смотрит на меня типа, а че это ты дверь открыла, че надо? И не пошла. Так вот, оказывается, у GDBC у него есть свой сетевой протокол, и ты можешь, если хочешь, написать к своей суббоде middleware, в которой GDBC будет ходить по сети, а уже этот middleware сходит там в твою базу данных как надо. Я этого не знал, но этим на практике, разумеется, никто не пользуется. Обычно реализуют либо позгрессовый протокол, ну, в некоторых системах протокол MySQL. Это не так просто, что вот просто реализовать сетевой протокол, потому что обычно ты хочешь, чтобы с тобой еще и всякие сторонние тулы работали вот-вот прям просто. Для этого тебе нужно реализовать еще и соответствующий диагнет SQL, и кроме того, тебе еще нужно реализовать каталог, системный каталог, то есть суббода, которую ты выбираешь. Но если ты вот как-то поднажмешь и постараешься, тогда все сторонние тулы будут думать, что они работают с позгрессом, но и с MySQL и представлять весь свой памятежий функционал. Я как человек, который ходил обоими путями, утверждаю, чтобы пути покляты на самом деле. Ты писал middleware для GDBC? Я не писал middleware для GDBC, я работал в проекте, где люди с одной стороны вначале пытались, помните, когда работал с Apache Coresight? Внутри кусок Coresight есть такая штука Avatica, она позволяет писать GDBC драйвера к Coresight подобными штукам. А потом мы бросили это гибло дело, занялись другим гиблом делом и стали делать посреди совместимое нечто. Оба дела гибла. Первое, очень легко заставить работать, в смысле, когда ты пишешь свой собственный GDBC драйвер, но если на том диалекте никто не разговаривает, и твой GDBC драйвер, как бы ни у кого его, по-моему, обычно нет, то большие проблемы с совместимостью. С вами будет работать только те, кто с вами очень хотят работать. Если вы предполагаете, что на другом конце может быть какой-то популярный софт, лучше так не делать. Вторым путем ходить более, как это, можно более инкрементально, потому что далеко не весь софт проклят. За 5 человеком месяцев можно заставить все более или менее работать с 85% муталлов, потом еще спустить несколько человек лет вам придется, чтобы покрыть все остальные чкейсы. В общем, проблема с тем, чтобы пытаться быть совместимым с Muscle или с G-Scroll, я не пытался быть совместимым с Muscle, но это все несколько проще. Проблема с попытками быть похожим на Muscle, в том, что тулы сторонние, они очень любят ходить в каталог Muscle. И каталог очень часто может вести себя каким-то определенным для определенной версии образов, особенно P-SQL, вот он, особенно проклятый. Наша реализация P-SQL протокола умудрялась, я помню даже про это в подкасте рассказывал, умудрялась в секволт вываливать P-SQL, потому что P-SQL был написан на самом деле с ошибкой, но из-за того, как себя вел каталог P-SQL определенных версий, этот секволт настоящий P-SQL не триггерил, а мы триггерили. Ну и в целом, другие клиенты тоже могут делать какие-то предположения о том, какой формы у вас PgCatalog, и в общем вам придется скорее всего PgCatalog на самом деле делать для нескольких версий, как будто бы по SQl, чтобы это все нормально работало с разными тулами. В общем, развлечение то еще, но повторюсь, это по моему скромному опыту можно быстрее, когда можно пойти к большему успеху, но это требует больших труд затрат. Я с пользовательской стороны, у нас на проекте мы пытались, нам было все равно в чем конкретно хранить данные, и делалась поддержка, там был Badger, это KeyValue Storage с ACID для Go, там была поддержка Postgres, и там была поддержка CockroachDB. В Cockroach сделано интересно, у них Postgresовый диалект и Postgresовый протокол, но как будто бы не заявлена прям 100% совместимость, и вот конкретно в этом проекте мы каталогов вообще не использовали, я не уверен, есть ли он там, я не удивлюсь, если окажется, что в Cockroach нет Postgresового каталога, с моей перспективой это будет абсолютно логично, и некоторые функционалы там в принципе отсутствуют, и его там не может быть, ты приходишь в Cockroach и говоришь, я беру advisory log на всю Subd, а тебе Cockroach говорит, чего, и ты такой, ах, ну да, это же Cockroach, откуда в нем advisory log на всю систему, вот, ну то есть это логично, что их там нет, поэтому в зависимости от того, кто ваши клиенты, что вы для них пишете, иногда это может быть не слишком безумным мероприятием, ну и того, что ваши клиенты ожидают. Это не очень безумное мероприятие, кстати, вот у нас, к счастью, никто не пытался брать advisory log, потому что мы писали продукт для аналитики, но зато во всяких аналитических продуктах типа Tableau, Microsoft BI, какой-нибудь Alteryx, ClickView, еще их миллион разных, у них у каждого этого продукта есть свое уникальное видение того, как нужно разговаривать с подсказкой с QL, и каждый раз вскрывают какие-то потрясающие кроничные случаи, про которые ты никогда не задумывался, будучи просто пользователем подсказки QL. Я правильно понимаю, вы пытались быть практически drop-in replacement? Для запросов. Писать у нас было вообще нельзя, но для select statement мы пытались быть drop-in replacement. Мой паем был только в том, что некоторые продукты, они изначально и не пытаются быть drop-in replacement, им главное, чтобы драйвер работал, а дальше уже клиент разберется, что он на самом деле хочет, ну то есть тебе не придется PsychoPG2 перезабритать. Ну да, это тоже на самом деле важно, но это была одна из причин, потому что, когда вы пишете, когда вы идете путем написания своего JDBC драйвера, очевидно, что все, что не умеет JDBC, сразу нужно изобретать новый драйвер, или делать еще один C-шный драйвер, что тоже реализуемо, но типа это 2х работы. Вот, а для тех, кому интересно, advisory log это офигенная тема, чтобы прогнать миграции на приложении, ну в некоторых приложениях это нормально. Уходите, я вас прогоняю. В некоторых системах это нормальная история, заложить базу данных, пока ты вот в одном инстанте приложения гоняешь миграцию, потом ты лог отпускаешь, и у тебя все остальные клиенты могут что-то делать. В таких сценариях advisory log это офигенная штука, а в как руче тебе приходится делать миграции лениво, либо брать снапшот на всю систему, что тоже не дешево, начинается сложная история. Ну вот, но мы говорили про JDBC и его middleware, я вот в принципе не знал, что так можно, и я такой еще слушаю и задумался, как прикольно у JDBC свой сетевой протокол, а почему же никто так не делает? Я такой сижу, сижу и думаю, а кто мне ответит, почему так никто не делает? Я уже не помню деталей, но там было что-то проклятое, я не помню что. По-моему, из-за разряд начинается N plus 1 запрос, какая-то такая херня. Я не помню почему проклятое, если честно. Там есть некоторое количество проклятости, это называется JVM. Нет, слушай, ну JVM само по себе, с ним можно жить, страшнее, когда есть какие-то нерешаемые проблемки. Я имею в виду, что если ты пишешь с УБД, то ты ожидаешь, что в тебя не только из JVM ходит. Ну да, я уже про это сказал, что это как минимум 2x работы. То есть у пазгоисквеля, к частии пазгоисквеля, у него довольно простой и понятный протокол. Реализация пазгоисквеля протокола, типа Y-протокол, она не очень большая была, мы дольше с реализацией типов разбирались. Сам все протокол довольно помещающиеся в голову. Более того, на GitHub чуть ли не несколько готовых реализаций на ГОВА. Да, под разные языки, да. Так что в этом плане там бояться особо нечего. Опять же, много чего можно сам как роче посмотреть, если у вас ГОВА или в Крейт ДБ, Крейт АЙО, если у вас Джава. С реализацией типов чуть большие проблемы, тоже можно довольно быстро совсем разобраться. Самые большие проблемы — это совместимость по каталогу. Этому очень долго, как это, при помощи какой-то матери, ваершарка и кучи разных тестирований разных кейсов в разных софтах, софтинах учились встречать на наиболее популярный запрос к каталогу. А были случаи, что приходили приложения, ожидавшие, что у тебя есть расширение и стандартной поставки? Да, конечно, PostGIS регулярно хотят. PostGIS понятно. Нет, я имел в виду что-нибудь для аналитики, чтобы в кишки заглядывать. PageInspect. Я прихожу и такой, а где твой PageInspect? Во всяком случае, такого никакой готовый софт не хотел. Обычно много какой софт пытается в feature detection, если он что-то дитин, такой «ок, какой-то старый PostGIS, такого нет». В принципе, по-моему, с PostGIS тоже самое, что «о, PostGIS нет, ну ладно». Но в другом случае, что у нас был клиент, который хотел, чтобы PostGIS поддерживался. Но в целом чаще какие-то эзотерические запросы к стандартному каталогу. Еще часто хотят PG Stat Statements. Возможно, но опять же мы делали продукт для аналитики, не выскакивало. Пг Stat Statements он часто не включен, он всегда зашиплен, но часто не включен. Еще в этом докладе нам говорят про стуки, которые позволяют ходить в приложение в обход ядра. Первая штука называется DPDK, Data Plane Development Kit. Мне кажется, пару раз в подкасте мы его вспоминали. Да, было дело. И согласно этому докладу на 2020 год, похоже, что единственная СУБД, которая серьезно его использует, это ScillaDB, которая как Кассандра, но на C++. Энди говорит, что с DPDK проблема такая, что чтобы им серьезно пользоваться, нужно переписать большую часть СУБД. То есть он естественно не так, что замена с ОКИТом. И тебе нужно вот прям сильно хотеть DPDK, чтобы его использовать. Еще он дает ссылку на... Я так понял, кого из разработчиков ScillaDB в твиттере. Это просто очень смешная аналогия, что использовать DPDK это примерно как пытаться согреться, пописыв в себе в штаны. Первое время это работает отлично, но потом ты понимаешь, что совершила ошибку. Мне понравилось. Я думаю, что совершила ошибку, заперев котика снаружи. Вот это сильно слышнее, чем было раньше. Котик очень сильно хочет внутрь, но ему скоро перехочется. Другая штука, как альтернатива DPDK, называется Remote Direct Memory Access, RDMI. Я так понимаю, это немножко праприетарная штука, потому что вот мне она не так часто встречалась, как DPDK. Раньше точно было праприетарно, сейчас, по-моему, стало чуть менее праприетарно. Она используется в Oracle RAC, это как мультимастер, и Microsoft Farm. Я вот просто по названию брендов понимаю, что это должна быть немного праприетарной. Нет, просто RDMI, он же по-разному может быть реализован. Когда я впервые про это услышал, он был реализован в первую очередь в InfiniBand. InfiniBand, очевидно, праприетарная хрень, и ты в свое приложение добавлял тем, что ты линковался с какой-то библиотекой, которую Mellanox, производитель InfiniBand, тебе поставлял. Сейчас, насколько я понимаю, есть какой-то RDMI поверх просто Ethernet. Я не помню, он так называется, RDMI Over Converged Ethernet, RoSI. И по-моему, RoSI может быть, я не знаю, но я бы ожидал, что он есть какой-то не совсем вусмерт-праприетарный, хотя нужно смотреть. Я этим ни разу не пользовался, просто раз Ethernet не праприетарный, я ожидаю, что и RDMI Over Converged Ethernet тоже не праприетарный. Там обычно проблема не в самом Ethernet, а в производитель сетевых карт. Так ты знаешь, любая сетевая карта со своей прошивкой праприетарная, хз. Я имею в виду, что, насколько мне известно, DPDK он только для карточек от Intel. Это соответствует действительности? Я не уверен. Раньше было так, сейчас я не уверен. Если вы эксперт по DPDK, обязательно приходите к нам в выпуск. Также технология, с которой было бы интересно поиграться, попробовать, это к вопросу, куда развиваться. Я не знаю, откуда про Intel взялась, вроде страница википедии ничего такого даже близко не утверждает. Мне кажется, это какой-то у нас коррективный BrainFart случился про Intel. Вот в этом накладе он чуть ли не Intel DPDK называется. По-моему, Intel первое начали отпилить, но сейчас это часть Linux Foundation. Возвращаюсь к RDMA. Это штука, которая позволяет читать память другого сервера в обход операционной системы. Или писать в другой сервер. Но у этой технологии, как я понимаю из доклада, в отличие от DPDK, есть такая проблема, что клиент должен точно знать адреса, откуда читать или куда писать. А во-вторых, СОБД должна как-то узнавать, что из нее читают или в нее пишут. И конкретно в RDMA этого нет. Тем не менее Oracle для мультимастера это использовал. Я подозреваю, что это делает так, что ты... Не хочу врать, но ты можешь или флажки ставить через RDMA, или ты можешь через RDMA большой объем данных прогонять, а через классическую сеть говорить «Эй, чувак, я там тебе написал». Ну вот да, последнее наиболее правдоподобно. Дальше уже мое дополнение, которое в докладе не было. Но по мере популяризации NVMe дисков у нас будто лучная горлышка уходит из диска и перетекает в сеть. И вот поэтому становится все больше интереса к DPDK и RDMA. Но на данный момент рабочая версия, что как будто бы они наибольшую ценность представляют для кишок с OBD, для ее внутренней реализации той же репликации или того же мультимастера. То есть это не что-то, что ты хочешь пробрасывать на клиента обычно. Надо смотреть, что у тебя за нагрузки и так далее. Но опять же, для той же репликации это звучит как технология, которую стоит изучить. В принципе, это все интересное из этого доклада. Там было много воды про то, что как же мы будем сервизовывать строки, а как же мы будем сервизовывать колонки. А если мы выбрали пазгрессовый протокол, а у нас колонки на базу данных, а давайте просто дадим один огромный картеж.",
    "result": {
      "query": "Google continuous testing challenges"
    }
  }
]
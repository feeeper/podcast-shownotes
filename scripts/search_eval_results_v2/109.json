[
  {
    "segment_id": "01c82dc3-1808-4b62-a732-e84da87ae3ba",
    "episode_id": "ec91d519-754b-406e-b140-868dcfaab322",
    "episode_number": 109,
    "segment_number": 2,
    "text": "Такая у меня мысль про сторидж будущего, который я развиваю. Я надеюсь, что я до конца этого года каким-то прототипом чего-то все-таки разоружусь. Так, Валера, что-то не торопится тебя поправить, но в чат об этом пишет у тебя. Иногда пропадает звук ненадолго, то есть, похоже, ты либо по Wi-Fi, либо не поставил галочку TCP. Ты можешь это поправить. Я думаю, мы с Астасом пока можем ответить на вопросы из чата, они довольно простые. Тут, например, слушатель dbf256 спрашивает, сколько человек в подчинении находится. Я не думаю, что это большой секрет. Во всей компании порядок примерно такой, что человек 50. 60 примерно, и компания как бы из двух юрлиц состоит, то есть, непосредственно в разработке половины. Ну да, то есть, порядок такой. Саша отвечает за ту половину, которая за разработку. А вот еще интересный вопрос, я думаю, на него Стас может ответить. Слушатель nkartashov говорит, что а вот в сообществе Хаскеля за определенную фичу обещают ящик пива. Мне интересно, есть ли прецеденты, чтобы в сообществе Postgres давали такие баунти за фичи? Несколько раз такое наблюдал в конкретных тредах в почте. Народ на что-то там спорил. Конкретно, чтобы как в Project Policy такое было, я этого не видел. Есть чуть-чуть другие традиции. В релиз цикле 9.6, например, голосовали за самый страшный патч. То есть, вот из того, что уже в Merge'е народ устроил выбор, что кажется, что было самым страшным, что может вызвать больше всего проблем потом в продакшене. Выбрали и подумали, стоит ли нам как бы откатить это, или действительно мы там готовы с этим жить и фиксить. Там было названо парочка изменений. Не помню, что именно выбрали, я не помню. Там был Snapshot To Old. Snapshot To Old и Parallel Scan тоже были где-то там на втором месте. Если Parallel Worker, это все равно понятная, что нужная штука, и с этим нужно делать, вот Snapshot To Old было не очень понятно. Я могу сейчас прямо рассказать, что это такое. В базах данных, в версионниках, если у тебя есть открытая транзакция, то у тебя не чистится лог до какого-то момента. И это может стать проблемой. И надо бы административно как-то на это повлиять. Можно было бы, есть один из подходов, запретить транзакциям, которые очень долго открыты, что-то заново, я думаю, писать. То есть вот эта ошибка Snapshot To Old, может Саша меня сейчас поправит, она вылезет, если транзакция, которая там месяц висела, она пытается... А, не, не так. Нет, это именно про... Если будет чтение из вот этих очень старых данных, устаревших, то выдастся ошибка. Если долгоиграющая транзакция не будет читать вот свои там эти древние данные из старого Snapshot, то все нормально и завершится, и никому ошибки не будет. Вроде вот так вот. Ну да, то есть раньше в Postgres было так, что старые данные, они держатся, остаются в базе до тех пор, пока не закончатся все те кешины, которые могут их увидеть в SAC. Но при этом база может распухнуть. И сделали Snapshot To Old, это значит, что если ты слишком долго держишь Snapshot, то тебя через некоторое время убивают. Но при этом эту фичу, ну вначале была там простая реализация, потом ее сделали более умной, что даже если твой Snapshot устарел, то ты прерываешься только тогда, когда ты реально увидел те данные, которые успели поменяться. То есть, например, если есть какая-то редонная таблица, и ты на ней висишь, например, очень долго, но в нее никто не писал, то ты все равно устоятно отработаешь. А при этом уже вакуум начнет чистить те данные, которые появились в процессе жизни такой транзакции, и все будет нормально работать. А сам патч этот стал таким уродливым из-за того, что он довольно сильно покарабкал интерфейсы, и они стали выглядеть достаточно страшно. Но уже после Комита провели определенный рефакторинг, и все стало выглядеть не так уж плохо. За самый страшный патч, если я правильно помню, предложили подарить мышь. Да. Потому что это такая, как сказать, это не игра слов. Нет, это... Это прикол на тему слонов. Да, чуть глубже, да, это же опасная вещь для слона. Интересно. Ну, вообще-то, изначальная идея была в том, что все-таки самый страшный патч таки откатить. Там оказалась некоторая проблема в том, как эту всю процедуру устроили. Там назначили Release Management Team, то есть это те люди, которые от ИПС, за то, чтобы у нас вовремя вышел релиз. И в качестве критерия мы откатим патч, уже закомменченный, выбрали то, что весь Release Management Team проголосует за то, чтобы его откатить. И, разумеется, ни один из патчей просто не набрал всех голосов, и ничего не откатили. Возможно, просто в следующем релизе как-то по-другому сделают. Нет, ну это, по-моему, нормальная тема, как раз голосовать консенсусом. Это ООН, совбез ООН голосует именно так, по некоторым вопросам, и действительно что-то иногда имеет смысл делать только когда все согласны. Любой может заблокировать, почему бы нет. Откатывать хорошие патчи, хорошие в том плане, что они дают какой-то функционал. Продолжая с Сашей и Алексеем вопрос про какие-то такие традиции, эти бутылки пива, на ежегодном собрании разработчиков Postgres есть, я так понимаю, уходит это десятилетие уже этой традиции, что проводят благотворительные аукционы, и на этих благотворительных аукционах продают всякие достаточно ненужные вещи, типа фотографии подписанные, какие-нибудь игрушки. На последнем девелопер-митинге Косте книжника Слоник, который ему шили дети, жена при помощи детей, такая игрушка Слоник, он ушел, по-моему, доллара за 400. Это был один из лотов, который ушел почти за максимальную цену. Еще Олег там создал фильмец и постер в стиле Звездных войн с разработчиками Postgres, с их стайлинговыми фотками из 90-х. Да, это было все приурочено к 20-летию Postgres. А деньги куда идут? Деньги идут в Atava Mission, то есть в благотворительную организацию, которая, я так понимаю, помогает бездомным городам Атавы, где проводится эта конференция. А давайте пройдем по фичам 9.6, потому что мы некоторые уже назвали, параллельное сканирование, то еще. То есть я смотрю на страничку на Вики, параллельный джойн и параллельный агрегат, это все появилось в 9.6? Да, еще я уже назвал оптимизацию буфер-менеджера. А ты рассказал, в чем она заключается? Я так вкратце рассказал, но я повторю. Там суть в том, что в буфер-менеджере был спинлок, там была определенная структура данных, защищенная спинлоком. И при этом как раз для самой простейшей операции, которую нужно сделать, чтобы прочитать какой-то буфер данных, нужно было взять этот спинлок и отпустить потом спинлок, ее просто заменили на атомарную операцию. А там с помощью каса менялось состояние буфера. Это дало очень существенное рение. А кстати, там еще забавно после этого вылезла определенная опция С с выравниваемым покэш-линием определенных структур. И в принципе для меня это было не срок удивления, то что выравнив определенную струку покэш-линием, можно получить ускорение на 50%, хотя я думал, что это все не такие кардинальные вещи, где процентов 5 ты получишь, но не больше. Слушай, извини, но я тебя снова хочу отправить чей-нибудь интернет, тебя очень тяжело бывает слушать, практически догадываться не хочется, о чем ты говоришь. Окей, хорошо. Я могу тогда продолжить про список изменений. Вот как бы ты перевел вот пушдаун? Пушдаун, пропихивание. Под пушдауном обычно имеется в виду, есть такой Postgres интерфейс foreign data wrappers. Это интерфейс позволяет подключить какую-нибудь удаленную базу данных, возможно, Postgres, возможно, все что угодно, включая просто файл или LDAP, или еще что, и она отобразится в таблицу. Но если вот эта база, которая где-то далеко, она умеет, например, в джойны, и ты делаешь по этой табличке джойн, то в некоторых случаях, у тебя есть 2 foreign таблички, между ними джойн, ты можешь либо выгрузить их полностью себе, либо сделать действительно вот этот джойн, отправить в этой foreign базе, она у себя сделает и вернет это обратно. Соответственно, вот эту штуку сделали. Еще один чатик Катя Абрамова пишет. Как ей интересно это слушать. Простите, отвлекся. Это ваш в этот модный телеграм, что ли? Да, в этот модный телеграм. Привет всем, кто слушает нас в телеграме. Нам надо завести параллельно еще. Нет, заходите в гидр. Окей, так вот, если там у вас реальная SQL база, то это важная штука. Я знаю несколько стартапиков, которые активно начали этим пользоваться и сидели еще на мастере из-за того, что появился pushdown. Вот я тут видел Саша, он mute делал, он наверное что-то хотел добавить. Ну ладно, появится. Да, я появился. Ты хотел что-то сказать по поводу pushdown? Или нет? Я неправильно интерпретировал. Нет, ты вроде уже все сказал. Да, pushdown, собственно, это возможность что-то посчитать на удаленной стороне, а не на своей. То есть, например, можно привести такой пример, что у вас есть какая-то большая табличка, вы ее разделили на несколько серверов удаленных, все их подключили по FDV, например, хотите просчитать какой-то агрегат. Вот, и агрегат pushdown, он позволяет отправить на каждый сервер свой агрегированный запрос, а потом просто вам выдать общий результат. Ну, в общем, как-то так. Вот, дальше можно пройтись по списку изменений. Вот про parallel в SIGSCAN сказали, но можно чуть подробнее. Вообще, в Postgres появился, Postgres сделан на процессах, то есть каждое соединение – это отдельный процесс. А не треды. Поэтому с тем, чтобы сделать какой-то запрос во много потоков, с этим возникают определенные проблемы. И сделали целую инфраструктуру background-воркеров, она еще была в 9.5, но ее, может, даже раньше, но в 9.5 точно была. В 9.4 уже была. Правда, они тогда были, по-моему, не динамические. Были только такие, только те, которые запускаются вместе с Postgres. Вот, сейчас сделали динамик background-воркеры, и, например, через них сделан parallel SIGSCAN, то есть вы делаете какой-то запрос, стартует несколько процессов, и каждый из них, они делят между собой табличку, каждый из них бежит, соответственно, это может, например, вам поломать порядок, в котором оно возвращается, если у вас лимита нет. Но что ожидаемо, собственно, от parallel сканирования, но оно издает все процессоры, и в ожидаемое количество раз быстрее происходит, что важно, когда вы делаете какую-то аналитику по базе. Я нахожу очень полезными фичи про репликацию синхронную, во-первых, поддержка нескольких синхронных реплик, и, во-вторых, это возможность убедиться, что реплика применила к видимым данным вот эти изменения в коммите, то есть Remote Apply режим. Да, это вот одна из таких. Я напомню слушателям, мы вроде упоминали, извини, что я перебил, это вот когда ты сделал коммит, потом сходил на чтение на реплику, и ты уверен, что ты прочитаешь вот то, что закоммитилось, потому что раньше этого не гарантировалось. На самом деле, по-моему... А, ты сейчас говоришь про Remote Apply, правильно? Да, про Remote Apply. А, да, тогда все правильно. Ну вот я сталкивался с тем, что есть такой достаточно популярный сайт, cold.com, и Миша, который там был техгером, вот они как раз именно на это наступали и долго ругались, что они ходят на реплику, а потом они периодически данные не находят, а в один постгресс они по нагрузке не влезают, ну то есть они там много с этим плясали, но в итоге все-таки ходили в один постгресс, и это важная фича. При этом тут вот такой нюанс, что можно очень хитро настроить, ты можешь объявить, например, три синхронные реплики и указать, что мы дожидаемся коммитта на любые две из них. Ну то есть фактически Quorum Commit. Да, да, да. И при этом вот сейчас в релиз цикле 9.7, которую назовут 10.0, NTT, ребята из Японии, Masahiko Sawada, они начали делать честный Quorum Commit, и в основном половина этого честного Quorum Commit это то, как конфигурацию задавать, так что она была обратно совместима, про это как всегда больше всего разговоров, но будет, да, в 10.0 уже будет Quorum Commit честный, скорее всего. Еще хотел добавить, что в принципе такую вещь, как прочитать гарантированно на реплике то, что записали на мастер, можно было при желании сделать и раньше, но из серии «Закат солнцу вручную», потому что отгрыз предоставляет такие функции, как узнать, какую позицию лого записал мастер на текущий момент, а на слейве можно всегда спросить, какую позицию лого он применил. То есть в принципе можно перед тем, как что-то прочитать, проверить, действительно ли мы уже накатились, а если еще не накатились, то подождать. Но это безусловно усложнит логику приложения, и сейчас, когда для этого есть отдельный режим, стало гораздо удобнее. Меня вот в релиз нотах удивило индекс онлесканы для частичных индексов, то есть раньше этого не было. Да, не было. Там какие-то внутренние сложности оптимизатора, которые я даже сейчас не могу назвать, но в итоге их просто зарешали. Так, а вот про кайнен, это что? Вопрос скорее всего отправляется Стасу. Кайнен, а, ну вот я сейчас искал по релиз нотам, тут есть 8 упоминаний Саши Короткого и 3 упоминания меня. Вот одно из них кайнен ты, видимо, нашел. Это вообще, вообще начну издалека. Как я попал в Postgres? Когда-то я работал в конторе, вообще говоря, в своей конторе, в стартовике, и нам нужно было искать по куче параметров с кучей условий типа bitwin. И вот я тогда нашел в Postgres, что в Postgres добавили кайнен фреймворк, который почти никакие типы данных не использует, но он вроде там внутри есть. И нашел Sashan patch, который не применили, я его дописал, который реализовывал для типа данных куб, вот как раз поиск ближайших соседей. То есть вы можете, куб это такой тип данных, который задает N-мерный параллелограмм, в частном случае точку. То есть если у вас там левый, левый, left, right, corner совпадает, там, ну в общем, в общем понятно, параллелепипед может выродиться в точку. Вот, и вы можете по какой-нибудь метрике, просто можно по Euclid искать ближайшие. Вот, я этот патч поправил, и так я познакомился с Сашей, с Олегом и участвовал. Да-да-да, я как раз хотел добавить, что именно так мы и познакомились, что Стас нашел мой патч, а я потом нашел, что Стас нашел мой патч. И так потом мы связались. Да, и оказалось, что мы сидим в одном институте, ты на третьем, я на четвертом этаже. Да, вот, соответственно, я тогда, потом ребята меня позвали на Google Summer of Code, Саша был моим ментором, я тогда сделал сжатие вот этих кубиков в случае, когда эта точка, потому что там раньше хранилось, он хранился как куб, то есть если точки, если куб выродился в точку, то он хранил два раза, два корнера. Я там сделал, чтобы этого не происходило, добавил битик, это закоммитили. И еще я сделал кнн, который не приняли сразу, ну там были с ним проблемы, и я его сразу не доделывал. При этом он в мейлолистах оставался, и внезапно его достаточно много кто применял себе на Postgres, и его использовали. И мне периодически народ писал, просил его поребезить на новую версию Postgres, а что я делал, и так вот, у меня есть какое-то количество пределей, которые мне просто по этому поводу писали. В конце концов, я уже в Postgres Pro начал работать и доделывал его до нормального состояния, его закоммитили, и вот да, и там все эти чуваки. Вот, например, один из, кстати, интересная штука, один из примеров, один из людей, которые мне писали по поводу кнн, это мужик с очень популярным в Америке сайтом про выборы, то есть ты можешь к нему на сайт зайти, ответить на какое-то количество вопросов, и тебе скажут какой-то типа партии ближе всего, какие-то политические взгляды, у него очень большой трафик на этот сайт. И вот они как раз ищут там таким кнн-ом близость. Вот они долго использовали этот патч в Prod, что достаточно забавно. Вот у них сейчас опять там гигантская нагрузка на их сайт в связи с выборами. Я тут вижу, народ пишет в чатик, что мы уже этот топик обсуждаем больше 40 минут, поэтому мне кажется, надо по остальным фичам пройти достаточно кратко. Поддерживаю. Могу еще рассказать про инфраструктуру расширяемости для аксесс-методов. Сейчас расшифрую, что это такое. Аксесс-метод в Postgres, это по сути тип индекса. И в Postgres на самом деле так все сделано, достаточно расширяемо, что, например, тот же B3 можно применить к любому типу данных, просто задав другую функцию сравнения. Но есть еще более обобщенные типы индексов, такие как GIST и SPGIST, с помощью которых можно вообще делать почти что угодно. Но тем не менее, если смотреть, что было заложено в Postgres еще на этапе его создания, то там вообще Stonebreaker, он говорил такую фразу, что является императивом то, чтобы пользователи могли вообще создавать свои методы доступа для того, чтобы искать в нетрадиционных типах данных. И по сути, да, действительно, в Postgres изначально была такая возможность заложена, в системном каталоге была табличка PGM, где можно взять и запилить свой тип индекса. Но с развитием Postgres эту фичу, скажем, не то чтобы удалили, но ее потихоньку замяли, потому что не было команды к рейду аксесс-метод, в самом интерфейсе были определенные шероховатости. И плюс к этому еще и не было возможности писать валзаписи. То есть сделать, чтобы оно там реплицировалось, было надежным и так далее. И для релиза 9.6 я проделал определенную работу, чтобы это все преодолеть. Во-первых, там был проведен рефакторинг интерфейсов, была добавлена команда CreateAccessMethod, был добавлен generic интерфейс для валзаписи, то есть такой интерфейс, с помощью которых можно с транзакционной лог писать. — То есть я правильно понимаю, что теперь аксесс-методы можно будет из экстеншонов создавать? — Из экстеншонов создавать, да. И в качестве примера запилили contrib.blue, то есть просто blue в качестве индексного метода доступа. — То есть подожди, в 9.6 оно уже будет, вот 9.6 выйдет и оно уже будет как бы здорово. — И для 9.6 мы уже пишем расширение, которое называется room, это улучшенный gin, который нам не надо обязательно проталкивать с postgres, который у нас живет как экстеншон. — Вот давайте отключаемся от hardcore и поговорим, почему все индексные методы, которые написаны русскими командами, называются gin, room, водка, какие ваши комментарии? — Значит, gin изначально задумывался как? Ну, он имеет generalized inverted index, изначально задумывалось, что это gin, который из бутылки, вернее, из лампы трешь, влетает gin, исполняет желание. Но со временем это все переигралось в сторону именно алкогольного напитка и решили эту тему дальше развить, поэтому придумали водка, который имел сложную расшифровку, но он, правда, застрял в виде прототипа, потому что сейчас мы больше ориентируемся на enterprise фичи и на такой хардкорный рисочек, который назывался водка, сейчас, к сожалению, времени не хватает. А room, собственно, тоже продолжение темы алкогольных напитков, ему, по-моему, придумали тоже какую-то расшифровку, но она не такая, скажем, значимая. — Russian useful method я слышал одну версию. — Да, Russian unified method. — Russian unified. — Да. Но что-то не настолько обладающее техническим смыслом, как gin, но зато прикольно. — Вот, ну ты расскажи в двух предложениях, что это такое, потому что фича room очень крутая штука. — Ну, gin позволяет искать, в том числе полнотекстовый поиск осуществлять, но суть в том, что он просто находит подходящие под запрос документы, но не ранжирует. И для того, чтобы отранжировать, вам нужно взять, вытащить все из самой таблицы, из хипа, посчитать релевантность, отсортировать и уже получить свои топ-10, топ-20 результатов, то довольно медленно, потому что если результатов много, их надо все из диска поднимать. А room, он хранит внутри себя координатки, и можно прямо в индексе посчитать релевантность и возвращать уже из индекса прямо в порядке релевантности, и это намного-намного быстрее. Ну, в общем, про room я вроде рассказал. — Есть что-нибудь еще про выпуск слонов, или мы пойдем дальше? — Много всего, можно остановиться, думаю, мы все самое основное рассказали. — А, да, сейчас, давайте еще. Коротенько еще про полнотекстовый поиск, что закоммитили фразовый поиск. Ну, то есть, грубо говоря, полнотекстовый поиск в возрасте был такой, что можно указать, что там присутствует лексема А и лексема Б, а лексемы С нет, но нельзя было указать то, чтобы они стояли рядом. А теперь вот в полнотекстовый запросы добавили такой синтексис, с помощью которого можно указать, что слова должны находиться на расстоянии не более чем таком-то. И еще, кстати, опять вернусь к room, благодаря тому, что в нем есть координатки, можно как раз такие запросы более точно обрабатывать в индексе, меньше потом перепроверять по табличке. То есть эта штука, которая была достаточно долго уже в эластике, и ее не было в Postgres, и вот сейчас она есть. Да, я даже когда-то специальный стелик сооружал на эту тему для одного из своих проектов, даже на GitHub его вложил, но теперь это уже все стало неактуально, потому что есть в Postgres коробки. Окей, давайте выкопаем стюардессу. Вот мы тут много говорили про замечательный баз данных Postgres, а вот на самом деле есть такая хипстерская баз данных, которая до сих пор есть, что для меня удивительно, собственно, до сих пор развивается. Для меня первой хипстерской баз данных, которая не RDBMS, стала CouchDB в далеком 2010-м. Она в принципе работала отлично на одной машине, даже как-то реплицировалась, но не умела ни шардироваться, мастер-мастер репликация была такая, что нужно было разрешать конфликт руками, но… Позволь, я все-таки скажу слово в защиту CouchDB, она была не для этого. То есть она была про то, что у тебя есть куча мобильных приложений, они там типа не очень нагружены, нужно время от времени их снять. Это позже сочинили. С лэптопом, например. Это позже сочинили. А изначально как было? Изначально, ну в смысле изначально просто хотели документно-ориентированную базу. Вот, с синхронизацией. И там действительно были всегда эти очень классные ченджфиды, но классные ченджфиды не могли вывести… То есть там, не знаю, хочешь положить в нее блок, вроде поддерживается, но лучше не надо. Хочешь там… То есть там из коробки были офигенно работающие материализованные вьюхи, но там не знаю, хочешь поменять что-то во вьюхе, но у тебя большая база. Лучше не надо, потому что вьюха пойдет пересчитываться и съест, ну не положите продакшн, но съест половину или 80% от спу продакшна. И такие вот всякие детские болезни были. Но тем не менее база заинтересовалась IBM. В какой-то момент купили стартап, который как раз делал шардированный CouchDB as a service. Он назывался Cloudant и сейчас до сих пор называется. Но Cloudant как-то развивался, он даже был оплансорственным. И вот наконец вышел CouchDB 2.0 и то, что так давно обещали пролетариату, свершилось, Cloudant был вмержен в CouchDB, в основную ветку. Собственно, тут статья в их блоге о том, как это в итоге все работает. В частности, в общем, получился такой динамо поверх CouchDB со всеми вытекающими. С одной стороны, прикольно, с другой стороны, у меня есть некоторые… CouchDB уже иногда отдавал сибелинги, мол, у тебя 2-3 версии документа. В принципе, я думаю, с этой точки зрения менять пришлось немного. Что точно изменилось, это change feed, потому что если раньше feed был такой, что у нас какую-то чиселку пишем в feed, и он дает все, что было после этой чиселки. Теперь же там какой-то Apache Term. Ну, в общем-то, всегда рекомендовали эту чиселку трактовать как некий Apache Term. Вот теперь это всегда Apache Term. Мне очень интересно, как работают эти change feeds, потому что если посмотреть на то, как сделала, например, межклассическая репликация в React, которая на самом деле закрытая, но про это был доклад, то там магия вокруг обмена Merkle-3 и прочего взаимодействия по системе антиэнтропии. Там есть, на самом деле, нетривиальные проблемы, связанные с тем, что если у нас динамо-стайл база, и мы изменения с точки входа плюнули в 3 узла, и они до кого-то долетели, до кого-то не долетели, до кого-то долетели позже, или там read-repair пришел, или что-то вот такое. Всегда потом может быть ситуация, когда при чтении, или особенно при подписке на такой фид могут возникать дупликаты, или чего-то может не появиться, появиться в другом порядке. Здесь ребята честно говорят, что да, происходит, но вот мне интересно, может ли быть ситуация, когда обновление change feed не появляется вообще. И прочие такие не очень консистентные вещи. Я, понятное дело, из блока-поста ответ на этот вопрос не получить. Но в общем, если кто-то еще интересуется проектом CouchDB, вот, наконец-то, завезли CouchDB, который... Не занесли еще. Ну да, почти. Его пытаются начать заносить. Ну, 2.0. Когда он будет, да. Да. И... Ну, так понимаю, он будет скоро. Я так понял, что он был чуть ли не на финишной прямой. Для скажечного недоступен, значит, еще нет. Окей. Что я хотел сказать-то? Да, хотел сказать, что мне интересно было бы сравнить его с этим... Боже. Вот как второе, но тут CouchBase. Там тоже есть change feed. CouchBase развивался за это время сильно бодрее. Там деньги крутились какие-никакие. По идее, CouchDB должен иметь более хороший фейловер, но иметь все эти причуды с необходимостью мерджить данные. Хотя, с другой стороны, между дата-центром и репликацией в CouchBase, насколько я знаю, там тоже иногда необходимо мерджить ручками. В общем, интересная ситуация. Будем посмотреть, куда она дальше полетит или не полетит. Мне кажется, ты вот сейчас сам себя загнал в ловушку, потому что, не знаю, в одних выпусках говоришь, что там не сравниваете ЦП и АП, в других выпусках говоришь, что не называете их ЦП и АП, а в этом выпуске давайте сравним ЦП и АП. Я не говорю, давайте сравним. Я говорю, интересно, посмотри, как они вот... Как это... Блин. Есть ли две базы, выросшие из одного, так скажем, корня. Интересно посмотреть, во что они разные развились, посмотреть на их разные поведения. Не сравнить в смысле, вот это лучше, это хуже, а в смысле посмотреть на это, посмотреть на то и посмотреть, что где как применимо. Хотя они в какой-то момент начинались как один проект. Все это не нужно и надо закопать, потому что, когда оно ломается, это невозможно починить. С CouchBase наступали несколько раз. Ну вот, в частности, интересно посмотреть на этот параметр, у CouchGT 2.0, когда он выйдет, насколько он ломается, до состояния невозможно починить. Ну то есть, по идее, динамо-система должна ломаться меньше. Вот интересно, а как он вообще репейлит несогласованные изменения? А вот знаешь, мне тоже интересно, потому что у React есть, во-первых, read-repair, во-вторых, антиэнтропия, то есть ноды в Merkle-3 обмениваются. Здесь про это ни слова. В код я, понятное дело, не смотрел пока что, и, возможно, никогда не посмотрел, то есть я не то чтобы большой фанат проекта теперь. Если кто-то из слушателей знает, что там внутри, приходите, расскажите, потому что я вот не знаю. Я подозреваю, что там должно быть как минимум read-repair, как в любой динамо-системе. Насчет Merkle-3, ну, если им было не лень, они, наверное, это сделали, если было лень, наверное, не сделали. Но, в принципе, Cloudant – проект не новый, он развивался довольно долго под койлом IBM, может быть, там все не так плохо. Я просто мониторю эту тему немного с другой стороны, со стороны научных статей. Я часто встречаю такие довольно забавные штуки. Давайте, там серия статья, которая говорит, давайте мы придумаем такую модель распределенную consistency, которую можно будет там коммитить в одни ноды без согласования с другими. А потом дальше идет ряд обсуждений, потом говорит, давайте мы, если у нас две транзакции с пересекающимися изменениями встречаются, то из неё просто одна перетрет данный другой, и мы будем считать, что это consistency. Ну нет, в общем, вот такое, это очень длинной подход, за такое, мне кажется, надо бить палками по ногам, или как там ещё наказывают. Не, ну это, я тоже влезу, это, собственно, подход CRDT. Нет, вот не совсем. Нет, это именно, ну, то, что я имел в виду, но CRDT работает так, ты просто чуть-чуть меняешь понятие, что у тебя такое consistency, после этого ты действительно можешь в split-brain ситуации писать в каждую, но потом они у тебя смёрдятся, и вот в твоём определении consistency ты его не нарушишь. Ну да, и при этом они все придут к тому же состоянию. Да, да, да, там не то, чтобы данные прям затираются, именно что если там у тебя и CRDT, то у тебя именно что тип данных, он должен немножко знать семантику того, что у тебя происходит, у меня есть два числа, и ты знаешь, что тебе нужен максимум. То есть ты не просто одно число затираешь другим на основе чего-то, ты берёшь два числа, сравниваешь, что это меньше, а это больше, и берёшь из них максимум. Потому что ты знаешь, что для этого поля семантически всегда нужно выбирать максимум. Или у тебя там есть set какой-то значений, и ты всегда знаешь, что тебе нужен union этого сета. Или если у тебя там multi-set, в общем, у тебя union с инкрементом каунтеров. Ну и такие-такие вещи. Если у тебя там каунтер хранится, то у тебя там в зависимости от этого типа CRDT-штва каунтер, у тебя может каунтер, который, например... Ну то есть есть grow-only каунтеры, а есть каунтеры, которые умеют вычитание, потому что на самом деле это два каунтера, и один показывает, сколько надо вверх почитать, другой сколько нужно вниз почитать. Ну там по одному максимум берутся, по другому минимумы. И потом эти вычитаем, считается разница. И тому подобные вещи. А как раз с CRDT всё хорошо. Там есть более такая пропортивная проблема в нижележачьих системах. То есть даже до того, как мы взяли CRDT, есть системы типа Cassandra. Ну я не хочу сейчас сказать про плохого про Cassandra. У Cassandra хорошая система для некоторых условий использования. Особенно там immutable данные или данные, когда мы там внутри одной колонки не пытаемся никаких апдейтов делать. Но вот если у нас есть апдейты внутри по одному ключу, по одной колонке, то победители будут выбираться просто на основе того, просто по таймстэмпу. И это печально. Системы вроде React и CouchDB, они отдадут оба значения. Ну если не сказать, а так не делать, то по умолчанию они отдадут оба значения, и уже пользовательское приложение будет выбирать. И в React как раз сейчас CRDT уже встроено в саму базу, и даже можно не давать пользователю выбор, можно просто сказать, что вот это CRDT такого типа, сделай выбор за меня в соответствии с теми правилами, которые я попросил указать, за которые я хочу отменить структуру данных. Ну и больше того, сейчас есть CRDT как... То есть вложенный CRDT уже придумали, как делать примерно года два назад. Как раз ребята из Basho. И вот буквально, по-моему, две недели назад вышла статья про то, как JSON можно моделировать в виде CRDT. Я еще ее не читал, но вот мне интересно. Будет почитать, я может быть дочитаю, и расскажу про нее. Вот такие дела с моей точки зрения. Да, но это все достаточно на низком уровне лежит в плане того, как тебе нужно дизайнить свое приложение, и если у тебя задача что-нибудь типа взять забронировать билеты в зал, в котором есть места, то вот такая штука не делается. На самом деле иногда делается. Ну... Ну то есть бизнесу чаще лучше овербукнуть, а потом возместить деньги, чем, в общем, не продать. Ну то есть тебе нужно задизайнить так, чтобы потом появилась задачка... Если такая ситуация возникла, что оба забронировали одно и то же, то автоматически появилась задачка менеджеру разрулить эту ситуацию. Не, ну может быть, да. То есть может я очень математично подхожу к этим задачам классическим, которых нужна строгая сериализуемость. Вот, ну... Ну, наверное. Или вот другая еще, как составлять расписание. Тоже вот... Тоже из того же. Ну тоже задачка менеджеру. Не, ну на самом деле надо понимать, что... Как это... В общем, CRDT, это... Как это, они стали популярны во многом благодаря тому, что есть вещи, которые... Где консистентность прям стопроцентная не нужна, зато нужно быстро сервить котиков, потому что если мы котиков сервим не быстро, то мы теряем деньги. Вот, не знаю, типично Twitter-лента на CRDT может быть, потому что, ну не знаю, там... Ну, как-то... Притом там важно, чтобы были все посты в порядок, не очень важно. Важно, чтобы реплай появлялись после твитов, а не до. В каком порядке реплай между собой, опять-таки, не очень важно. И тому подобное. То есть, не знаю, комментарии к фоточкам, фоточки, котят. Другой пример, где CRDT хорошо работает, это... Если не имеешь отношения к котикам и потеря денег за минуты простоя, это коллективное редактирование документов. Вот у нас был гость, наверное, выпусков 30 назад, может быть, больше уже, который как раз занимается тем, что делает протокол для... Ну и, собственно, редактор, который этот протокол использует, да, Swarm. js называется. Swarm.js, да. Это было не так давно, это был в 90-х какой-то выпуск. Вот, для обмена между несколькими разными клиентами, которые редактируют документ, и там какая-то, поэтому это построено поверх CRDT, специализированных. И понятно, что здесь вообще конфликт разрешается людьми, они документы смотрят. И делать там строгую синхронизацию, это было бы... Можно просто долбануться было бы. Ну то есть это просто... Лейтнесс возрастала бы настолько, что с этим было бы тяжело работать, если у вас не сверхбыстрое соединение с интернетом. Вот. Еще. Еще. Поскольку мы начали говорить про CRDT, а до этого мы говорили про Postgres, появилась в Postgres тоже какое-то количество времени назад такая штука Logical Decoding. Ты можешь свой журнал транзакции Postgres декодировать в логический формат, ну типа вот insert в такой-то idшник, update такого-то idшника, и там есть Decoding плагин, например, можно в JSON. Так вот, Bottled Water устроен, который из Postgres в Kafka репликацию делает вот гипотетически. Вот сейчас реализовать что-то типа CRDT подобного мерджа транзакций достаточно легко в плане того, что можно не влазить в глубины Postgres. А в BDR же, по-моему, можно делать свои хендлеры для обработки конфликта. Да, но только там есть очень простые полисы, типа FirstWin, LastWin. А свою можно же написать, нет? Можно, да. Вот можно дальше пойти и написать свою, и вот репликацию упаковать во что-то такое. Да, но разговор у нас был про что изначально? Про CRDT, потом мы ушли к странным моделям консистентности, а потом, я не знаю, как мы вышли на Kafka и выливание в него Postgres и мердж транзакций. Ну да, это про то, как можно было бы сделать в Postgres что-то подобное. Но зачем? Я думаю, почему бы и нет? Ну не знаю, для меня Postgres все-таки система, то есть если в системе уже есть понятие транзакция, если система уже построена на основе некоторых предположений, то наворачивать на нее сбоку вещи совсем с другого мира, мне кажется, не совсем здорово. Ты только что, Валер, доказывал, что в некоторых случаях это может быть полезно. Это может быть полезно, мне просто кажется... А теперь ты говоришь, что в Postgres это не нужно. Да, просто в Postgres это не нужно. Для этого есть другие системы, которые тоже делают. Есть интересный use case. Наши коллеги, господа SecondQuadrant, у них есть такой BDR, про который Саша сказал, какое там основное использование, что у тебя есть банки с отделениями, и в основном отделения, ну не в основном, а в основном, вот много софта банковского, банком, которым они продают, написано так, что отделение пишет только в свою базу, а отчеты оно должно считать глобальные. Вот это вот случай их мультимастера, и если вот там произошел какой-то врайт в глобальную таблицу из разных отделений, то там они разруливают. Но вот point в том, что эта штука реально юзается, реально нужна, и на нее есть спрос, и постепенно они перетягивают это в Postgres. То есть это как контраргумент к тому, что это странно и не нужно. Вот у тебя консистентность внутри базы – это одно, а что ты делаешь между базами, когда реплицируешь, и что тебе делать, когда сеть потерялась, это другая штука. Ну да-да-да, это действительно так. Два чая этому оратору. А давайте рассмотрим следующую тему. Ваня, ты с нами? Да-да, давайте. А я с вами. Меня слышно? Да. Я тут с настройками звука проиграл маленько. Эту тему добавил Валер, но мне тоже было интересно ее почитать, поэтому я надеюсь, Валера мне поможет. Но в целом это первый пост из серии из четырех постов, и автор обещает, что у каждого поста будет своя тематика, данная тематика – это на реальном примере, на реальном эксперименте посмотреть и доказать, что скорость доступа к памяти – это не константное время, то есть не O1, а в Big O нотации O от корени Z. И он это доказывает с помощью небольшого теста, то есть он делает большое количество элементов и в зависимости от количества элементов нормализует скорость доступа к одному элементу, то есть без разницы, сколько элементов в списке, в двусвязном списке, он показывает на отдельном графике, сколько на секунду тратится на доступ к одному элементу этого списка. И он показывает, что хотя должна быть константа, то есть должна быть прямая линия, то есть скорость не должна зависеть от количества элементов, она растет. И аппроксимация этого роста – это корень квадратный из количества элементов. Ну и чуть подальше он объясняет, что на самом деле все понятно, что это все из-за кэшей, кэшей большое количество, то есть там в процессоре кэши, оперативная память, потом на SSD, и потом в комментариях он отвечает, что еще будут кэши следующих уровней, там, я не знаю, если вы хотите в сети где-то локально, HD, потом сеть, потом какая-нибудь S3 и так далее. Но в целом он говорит, что аппроксимация верная и работает, можете это проверить, все-таки такого. Вот, я читал, статья вообще крутая, зачет, только непонятно, зачем все-таки корень из N проводить, как вот аппроксимацию, там можно все-таки было все что угодно провести, мне вот этот корень из N напоминает шутку про то, как физики доказывают, что все нечетные числа простые, вот там примерно такой же корень, это какая-то возрастающая плавная функция, почему обязательно корень. Он корень, потому что у тебя кэши, ну то есть если посмотреть, то получается, что при увеличении каждый кэш в целом увеличивается примерно около 100, ну в смысле порядок следующего кэша, он на два порядка больше, чем предыдущий кэш. Ну я бы тогда уже сказал, что логарифм, если уж так говорить, что ты экспоненциально, ну то есть каждый следующий на десяток отличается, тогда это все-таки логарифм, а не корень, но тоже как бы плавно растущая функция. Ну да, то есть грубо говоря, если бы у него был другой размер памяти, я не знаю, или другой скорости диск, то почему бы у него не получилось, с тем же успехом у него могло бы получиться на другом железе, N степени 2 третих или еще что-нибудь. Да. Меня вот больше беспокоят эти наносекунды, потому что у чувака, у него явно PC, у него системный таймер, он тикает 100 раз в секунду, то есть у него погрешность измерения 10 миллисекунд. Он когда получает наносекунду, он явно делает очень много измерений и потом делит на их количество. То есть он как бы строит свою аппроксимацию еще и по среднему. Ну почему бы и нет. Действительно, что может пойти не так? Нет, ну... Это единственная возможность, на самом деле. Это явно одномодовое распределение. Если инженеры Intel не пошутили как-то смешно над нами, то скорее всего это все верно. Но еще есть... То есть то, что он получил график, который правильно согласуется с размерами кэшей, а он провел эти линии, то это доказывает, что его подход сработал правильно. То есть он получил у себя экспериментально размеры кэшей. Ты лабораторно его институте делал по физике? У тебя сходилось? Да. Сходилось, я и делал. У меня тоже сходилось, но это не значит, что я... Пять семестров. У меня недавно один знакомый устроился работать. .. Он закончил пищевой институт и устроился работать на заводе, который делает сок. И он там оператор кого-то девайса, который прозрачности этого сока меряет. И ему действительно нужно было посчитать косвенную погрешность по формуле. С чем он подошел к трем-четырем разным людям, к косвенным техническим образованиям, попросил, а выведи-ка мне формулу для косвенной погрешности. Ему все вывели и все по-разному это сделали. То есть ответ как бы все равно, он порядок погрешности получил правильный, но формулу получил совершенно разную. Возвращаясь к данной статье, я считаю, что вообще бред написал человек. Почему? Потому что когда у тебя идет разговор о количестве элементов, ты все равно говоришь о количестве элементов, которые укладываются в какой-то определенный кэш. То есть если ты говоришь про, скажем, то, что у тебя помещается в оперативную память, то ты не имеешь в виду, что у тебя скорее всего будет она свопиться на диск. Если ты свопишь на диск, то ты не имеешь в виду, что ты будешь свопить его в облако. Дело все-таки ведь не в том, что... Подожди, дай закончу. А внутри твоей ступеньки, когда ты умещаешься, скажем, только в память или умещаешься только в кэш-процессор, у тебя на самом деле происходит как бы линия прямая, то есть у тебя не отличаются друг от друга, если ты в начале этой ступеньки или в конце этой ступеньки. Ну да, а в чем проблема? Так я как раз и говорил, что чувак бред написал. А в чем в плане бред? У него там действительно ступеньки показаны. Ну потому что он ступеньки не... Он смешивает понятия. Он с одной стороны говорит, что у нас скорость доступа, сложность, с точки зрения Big O нотации, прибегание по линейному, по связанному списку будет у нас n корней из n. Хотя на самом деле все это от n, а не n корней. Это ступеньки, но если ты хочешь как-то в уме прикинуть, и ты не знаешь модель процессора и все, то есть плюс-минус километр, он прав. Но вот мы к чему придирались, что именно корень от n пошла бы в любая другая функция между нулем и y равно x. Подожди, я хочу с тобой более фундаментально поспорить. Смотри, вот есть теория вычисления сложности, она не из ниоткуда взялась, она взялась из того, что нужно было оценивать, сколько алгоритм будет работать таквиз, в зависимости от длины входа. И вот эта абстракция, что вводится сложность по памяти, сложность по времени. И мы выговорим функцию, будет работать залинейное от входа время. И вот это все было в предположении о том, что у нас память, у нее uniform access к ней. Поэтому это было допустимое приближение, что если у нас n элементов в списке, то мы список пробежим за n операций. На самом деле, если мы возьмемся считать не операции а цпу, например, такты цпу, которые прошли, то внезапно время становится нелинейным. Подожди, оно становится нелинейным, если ты начинаешь сравнивать один элемент и два миллиарда элементов. А если ты начинаешь сравнивать от десяти тысяч элементов и до двух миллиардов, то что укладывают у тебя в оперативную память, то у тебя будет все так же n, а не n корней из n. И это более логично. Ну вот нет, смотри. Ну как бы да. У тебя в том-то и дело, что у тебя вся эта симптотика, она в частности должна тебе показывать, как у тебя будет вести себя алгоритм на всем скейле, а там график, если ты не заметил. Подожди, на всем скейле тебе не интересно, потому что у тебя скейл ограниченный. Он у тебя ограниченный. Он у тебя хоть как ограниченный размером. Ну как ограниченный, он же от n зависит. Вот у тебя скорость, доступ к элементу листа, он n. Да, ну давай, посчитай мне n для десять в сотой степени. Никак не посчитаешь, у тебя не хватит памяти. А если мы говорим, что скорость… Это неприменимо. Оно же вообще в окрестности, в бесконечности как раз. То есть O большое, оно как раз тебе говорит о том, как оно будет на очень больших n-ти навести. А здесь оно у нас ограничено в любом случае, поэтому это неприменимая теория в принципе. Смотри, у тебя там вот эта штука, график, ступеньки, они логарифмические. То есть если тебе кажется, что вот эти ступеньки, их можно аппроксимировать прямой линией, тебе кажется, если ты график сделаешь не логарифмическим, а линейным, то ты ожидаешь, что какая-то функция на бесконечности ведет себя как какая-то прямая, а чем бесконечнее ты идешь дальше… Да в том-то и дело, что у тебя нет бесконечности, ты всегда рассматриваешь локальную окрестность какой-то точки. Локальную оккрестность оперативной памяти, скажем, всё, ты не идешь на слоп, ты не идешь… Окей, отвечаем, локальную оккрестность оперативной памяти, возьмём локальную оккрестность оперативной памяти. У тебя там локальная оккрестность оперативной памяти, то что должно вести себя как прямая, внезапно ведёт себя как какая-то функция, которая немного начинает быть похожа на степенную. Это где это, но у тебя так будет. Ещё раз говорю, у тебя график, который с степеньками, который нарисован… Валера, что тебя смущает? Я вот слушаю уже сколько, пару минут, я не могу понять твою мысль. Я пытаюсь с Ваней поспорить, Ваня говорит, что это бред. Я говорю, что это не бред, потому что абстракция теории сложности на текущем поколении процессоров очень противным образом течёт. Не, ну я так понял, Ваня говорит, что «О, большой, это вообще бред». «О, большой, бред для данной статьи». Почему? Нет, смотри, как ты применяешь «О, большой?» Тебе есть алгоритм, тебе нужно оценить, как он будет себя вести в разных условиях, так? Вот смотри. Вот типичный пример, ты написал код. Погоди, погоди, я согласен с тобой, давай просто конкретно для одного. А давайте вы перестанете друг друга перебивать, и, например, Валера закончит таки свою мысль. А почему Валера, а почему не я? Ладно, Валера, давай заканчивай. Я так и не понял, что он, вот он начал с чего-то, и я до сих пор не пойму, что он хочет. Давай, давай, давай поймём, что он хочет сказать. Мне интересно уже. Я хочу сказать, что типично мы применяем «О, большой?», так что вот мы, не знаю, написали код, протестировали у нас 100 элементов. В продакшн у нас там от 10 тысяч до сотни тысяч элементов. Нам нужно оценить, вот то, что мы написали, вообще имеет смысл туда или нет. Больше того, у нас могут быть случаи, когда у нас там не 100 тысяч элементов, а у нас пришло больше пользователей и стало, не знаю, почти миллион. Оперативной памяти всё ещё хватает. Но вот при смене вот этих, казалось бы, вещей, которые всё ещё в масштабах оперативной памяти, наши оценки, которые вот мы там сделали, не знаю, протестировали на до 80 тысячах, они почему-то перестают работать, потому что мы оценили рост как линейный, а он там не линейный, он там степенную функцию превращается. Где он превращается в степенную функцию? Посмотри на график. Вот я смотрю от 10 мегабайт до 1 гигабайта и даже до 5, наверное, гигабайт, вообще почти прямая линия. Где там степенной рост? Секундочку, открою ссылку ещё раз. В общем, практический вывод в том, что если ты не учёл то, что у тебя данные могут вылезти за какой-то угол За пределы оперативной памяти. Ну ладно, за пределы оперативной памяти, это обычно все как-то более-менее понимают, но то, что данные вылезли за кэш процессора и всё внезапно стало намного медленнее, действительно, может быть для людей сюрпризом. Или чуть менее очевидный из-за NUMA-ноду, например, в нелокальную память. Да, или из-за NUMA-ноду, но то, что для понимания таких вещей нужна Big-O нотация, и тем более с коренью из N, я не уверен. Получается, что чувак как-то совместил несовместимые. То есть Big-O нотация вот у тебя на оперативной памяти. Если ты начинаешь NUMA-ноды, кэш процессора, или, не дай бог, ещё swap в S3, например, ну ты не можешь здесь Big-O нотацию вообще использовать. Она неприменима в данном случае. Можно небольшое наблюдение на эту тему? Люди вообще часто... Извини, Саш, я тебя перерываю всё-таки. По-моему, всё-таки в эфире я этого не озвучил, а это важная мысль. Люди очень часто забывают, что такое вот эта большая нотация, да, и что их там бывает ещё, сколько, 4, да, по-моему, ещё нотации, а обычно его большую всё-таки используют. И что она именно значит? А значит она, что для достаточно больших N, при этом что такое достаточно большое обычно как-то опускается, остаётся за скобками, время работы алгоритма, оно ограничено там константа умножить на какую-то функцию, да, то есть, например, O от N2, это значит, что у нас есть константа умножить на... Какой пример привёл? С логарифмом или... N2. Окей, на N2, да, и алгоритм, он работает не дольше вот этой функции, да, и люди, например, ну я слышал, как они возмущаются, например, а почему у меня, например, есть кэши, и в некоторых случаях моя там функция начинает работать быстрее, потому что она вот эскэшка быстренько взяла и отработала там за константное время, а не за N2, как я ожидал. Как бы, ну, чувак, у тебя вот этот случай, это всё ещё O от N2. Просто оно как бы оказалось сильно меньше, но оно не противоречит. Это немножко другая история, мне кажется. Это другая история, я всё это к тому, что люди, они неправильно используют вот эту, вот все эти O от N, и вот начинают их использовать в статьях, вот смотрите, у нас есть очень маленькие кэшики, и мы применим к ним теорию про очень большой N. Да-да-да, плюс один. Ну да. Применимость. При этом понятие очень большого, оно тоже очень относительно, то есть у тебя вот твой маленький кэшик может оказаться очень большим, а может оказаться, что у тебя твой очень большой диск, как у нас, маленький, и это, что не детализируется, у большого обычно, что считается достаточно большим. Окей, давайте всё-таки... Это может оказаться неприменимо. Я что хочу, как бы вот, я всё-таки ещё раз попытаюсь объяснить свой point. Есть у нас какой-то алгоритм, мы его написали. Ну и допустим, у нас наборы данных, там вполне реальная ситуация, у нас дейтасет может быть от одного мегабайта до 100 мегабайт. Ну мы как-то оценили, что то, что мы написали, будет работать. Допустим, мы там попали в то место, где график линейный, в среднем линейный, где график как прямая линия, как констант, то есть вот алгоритмический, мы попали в то место, где он себя ведёт как... В общем, где у нас скорость дейстатиса по памяти одинаковая. И мы, что да, вот у нас действительно, оно работает, там скажем, немедленнее, чем алгоритм. Внезапно мы запустили код, мы начали вбрасывать данные, вбрасывать, вбрасывать, вбрасывать. С какого-то момента оно начало себя вести медленнее, чем та алгоритмическая функция, которую мы оценили худшей перформанс нашей программы, потому что оно начало лазить в кэш. Точнее, оно... Лазило в кэш и стало лазить в память. Да, то есть у нас данные стали не локальные, и оно начало туда-сюда лазить. И, то есть, там даже проблема не в том, что оно полезло в память, в том, что там, как только у нас данные становится больше, чем в принципе может поместиться в кэш, их приходится дальше туда вбрасывать, выбрасывать. И вот именно что человек там как раз.. . Он же сделал патологический пример, когда список не подряд идёт, а он перебросан по всей памяти, и указатели каждый раз в рандомное место идут. То есть вся бегонотация и многие другие вещи, они до сих пор работают, потому что люди стараются массивы класть плотно. Поэтому когда итератор бежит по массиву, умная система памяти процессора, она возьмёт и сделает префеч в кэш из-за того, что там дальше жит в оперативке. И там наш код этого даже не заметит. Ты как-то очень резко перешёл. Мы померили скорость кэша, потом удивляемся, что память работает медленнее кэша, и от этого перешёл куатен. Окей, ладно, я попробую это ещё раз. Слушай, ты пытаешься? Это уже раз в третье. Давай мы это как-то в другом выпуске. Когда ты меряешь что-то и пытаешься прикинуть скорость работы чего-либо, там, не знаю, линейность, нелинейность, да? У тебя предположение о том, что у тебя всё-таки у нижележащего медиума константная скорость записи и чтения, так? Что у тебя не меняется? Вот внутри твоей вот этой оценки, твоей функции, что, мол, немедленнее? Первое правило построения бенчмарка. Знай, как работает твоя система и понимай, что именно ты... Я не говорю про бенчмарк сейчас. Я говорю сейчас о большой, это такая теоретическая оценка. Нет, подожди. Я говорю про теоретическую оценку. Ты начал свой пример с того, что мы померили и построили поэтому линейный график. Плюс один. Валер, ты несёшь фигню, и я предлагаю это обсудить потом. Сострелили меня, да. Мы не сострелили, Валер. Мы не сострелили, ты просто говоришь странные вещи. Блин, Бего, это не штука про бенчмарки. Никто не выражает бенчмарки в Бего-аннотации. Бего-аннотация это штука, чтобы оценить, а потом мы померили, и наши результаты эксперимента не сходятся с нашей оценкой. Вот о чём я говорю. Разумеется, они не сходятся. Так вот смотри, а вот ты берёшь, вот нет, ты берёшь алгоритм из книжки. У него написано, вот Бего этого алгоритма такое. Ты берёшь, кодишь этот алгоритм, берёшь бенчмарк, и он не сходится. Потому что я константу не посчитал. Умножил на маленькую константу. Ну разумеется, оно не сходится с книжкой, поэтому мы используем сортировку. Что значит не сходится с книжкой? У тебя характер роста, он либо линейный, либо нелинейный. Твоё понимание, потому что неправильное. Ты прочитал книжку по диагонали и думаешь, что ты её понял. Ты не оценил, что ты недостаточно близко подобрался к окрестности плюс бесконечности. Да-да-да. Я понимаю, что у квиксорта у него худший случай – O от n квадрат. Да, знаю. Все его используют, потому что на практике померили, оказалось, что лучше, чем пирамидальная сортировка, которая всегда O от n лог n на практике. Вот так получилось. У меня на самом деле основная претензия к этому O от корени Z, то, что функция, которую они аппроксимируют, ведёт себя очень скачкообразно. Практическая польза от этого к корни Z может получиться не очень большой. Это всё равно, как, я не знаю, человек шёл по улице, и вдруг его раздавила машина. И мы возьмём и какой-нибудь гладкой функцией аппроксимируем то, насколько он был жив каждую единицу времени. Мне вот это напоминает. Ну вот да, я тоже, у меня к этому было больше вопросов, чем к тому, что, мол, это бред. Но я всё ещё считаю, что статья не бред, потому что оценки стало применять тяжелее, скажем так. Стало проще применять разделяемую транзакционную память. И нам Ваня об этом рассказывает. Разве Ваня? Мне кажется, это как раз моя тема, нет? Ну, Ваня тоже отмечен. Я в подскачках только. Подскачки, окей. Подскачки в подсказке. Подскасте... Боже, нет, не буду пытаться. В общем, я на самом деле пытался эту тему затронуть в темах слушателей в прошлый раз, но я тогда не успел её нормально прочитать. В ITCD 3, как мы уже упоминали больше одного раза, появилась возможность делать транзакционные операции больше, чем с одним ключом. Понятное дело, что она оружие торчит через какой-то хтпшный конец и имеет какой-то... Ну, я не буду никак характеризовать, какой-то API, который выглядит как if-then-else, ну, и всякое такое. Там с операциями, условиями, то есть, ну, if-условие-условие, then-operation-операция, else-операция-операция. И вот эта штука, её, значит, можно отправить гулять в ITCD, и она там либо применится, либо откатится. Это, конечно, здорово. И, в общем, ребята рассматривают классический банковский пример, который на самом деле не отражает банковскую реальность, но хорошо подходит для иллюстрации того, как писать транзакционный код. И, значит, классический пример с переводом с счета на счет. Значит, пишут его просто вообще без всякой, ну, там, на старом ITCD-шном API и говорят, что ага, вот он и ломается на самом деле, потому что нет нифига никого изоляции никаких транзакций. Потом говорят, ага, давайте мы возьмем вот этот наш новый API и напишем всё на нём. Смотрите, работает. Классно. Конфликты откатываются. Одна проблема. Получившийся код страшен как ядерная война. Никому и таким пользоваться хотеться не будет. Мы хотим, чтобы нашими ITCD пользовались, попользовался каждый хипстер в своём новом проекте. Поэтому мы хотим гладкий интерфейс и шелковистые волосы. И действительно, ребята, следующий кусок кода, который они показывают, выглядит практически как Haskell на STM. В смысле, так же приятно. Вне зависимости от нашего отношения к Haskell, я думаю, многие должны согласиться, кто вообще видел Haskell на STM, что там действительно мало кода и понятно, что происходит. Вот. Здесь, конечно, нет какого-то защиты благодаря нам на уровне системы типов от того, что в STM, то есть в Haskell-стм-монаде ничего плохого произойти не может. В смысле, там не может произойти эффектов, которые там не должны происходить. В Go это, ну, при желании можно выстрелить себе в ногу. Но дело не в этом. Дело в том, что если написать код, который вот действительно что-то делает с транзакционной, с объектами в транзакции, он будет маленький, в нём будет только то, что, собственно, имеет отношение к коду, к тому, что там должно быть. Все моменты, связанные с откатом, перенакатом, конфликтами и вот этим всем, они аккуратно завёрнуты в красивую обёртку, которую нам не видно. И дальше рассматривается имплементация этой обёртки. Я, в принципе, вдаваться в детали сильно не буду. Кому интересно, может пойти почитать статью, чтобы, так скажем, TLDR – классический способ реализации транзакций на основе MVCC, когда у нас строится readset в writeset. Дальше при комитте, собственно, условия, которые там конфирмируются, что у нас в readset ничего не поменялось, ну и в writeset как бы, да. По-моему, абсолютно всё, что должно быть в writable, должно быть ещё и в readset, потому что я не помню, что там делали дополнительные условия. А, нет-нет, там так. Делается так, что, да, по-моему, условия на то, что ключ, который мы пишем, не менялся. Да, writeset не менялся, а readset тебе наплевать, потому что у тебя снапшотик. Ну вот нет, там нет снапшотов. Там то дело, что у нас же не snapshot disillusion здесь. Тогда, наверное, это не MVCC, а просто optimistic concurrency. Да, это optimistic concurrency. Да, да, это статично. То есть мы берём просто каждый прочитанный ключ, кладём себе локально на клиенте прямо, кладём свой readset, получаем такой локальный снапшот на клиенте. То есть любая следующая операция о чтении на самом деле пойдёт в этот снапшот, который мы сделали с... Как это? С ключа, в момент, когда мы читали. На самом деле в данном примере они там обеспечивают repeatable read. То есть на самом деле, если вдруг... То есть там есть эти... Если будет там выборка по ренжу два раза, то там в ренж может попасть какие-то вещи, которые мы в прошлый раз не видели. Они утверждают, что у них в полной реализации, если я не плеваю, здесь в примере есть также и полностью реализабл. Я туда в код ещё не смотрел, но я догадываюсь, что они там делают. Да. В общем, классическая имплементация вот такого рода транзакции на клиенте, если у нас есть примитивы необходимые для этого в базе. То есть в базе есть, собственно, вот этот вот conditional put, conditional get в виде вот этой транзакционного API. Есть обычный get. Дальше они показывают график перформанса, говорят, что, мол, работает всегда лучше, чем distributed log. В принципе, может работать медленнее, чем read committed. Притом внезапно repeatable read оказывается медленнее than serializable, потому что serializable делает, в общем, более честный, получается, снапшот, что ли. Ну, то есть там перечитывать и переходить в базу приходится в итоге реже. Поэтому repeatable read, он оказывается быстрее только на очень большом количестве ключей. А, нет, наоборот. Repeatable read лучше оказывается, когда у нас мало ключей, а когда много ключей, serializable начинает его рвать, потому что в итоге происходит просто меньше retry и меньше перечитываний. Можно вопрос? Да. Вот я читаю текущий код, и насколько я понимаю, вот этот optimistic concurrency в данном случае значит, что если у тебя вот этот commit, который здесь в коде прошел, вернее, как, ты сперва считываешь и строишь рецепт, а потом, если любой ключ из этого рецепта поменялся, то ты уже не можешь, твоя транзакция не проходит, и ты заново все делаешь. То есть заново прочитываешь, и все пошло заново. Насколько я посмотрел код, у них здесь нет никакой защиты. То есть представь, что у тебя там 20 одновременно, не знаю, запросов, которые пытаются что-то поменять, и у тебя есть большая транзакция, которая трогает 10 тысяч ключей. Получается, она будет висеть практически всегда и никогда не сможет закоммититься, потому что... Это классическая проблема STM. То есть там есть такая проблема, по-моему, в библиотекаре, когда у нас есть... Библиотекарь пытается отсортировать библиотеку по, скажем, по алфавиту, и в это время нам приходят ученики и все время сдают книги, и берут книги. И в общем получается, что библиотека никогда не завершит свою работу. Это классический такой пример на то, что у нас в принципе optimistic concurrency и STM. Он имеет свои граничные случаи, которые патологически плохо работают для него. Также есть вещи, которые плохо работают с локами. Дело в том, что в большинстве случаев мы хотим STM, на самом-то деле. Но STM же не обязательно делать на optimistic concurrency. Мы хотим его сделать и на МВЦЦ, и тогда эта проблема может быть решена. То есть еще одно промежуточное состояние. Ну да, в принципе. Ну там нет, подожди. То есть тогда у тебя ученики, которые приносят книги, есть возможность их затормозить, если ты вот для того сета книг, которые ты уже отсортировал. Слушай, да ты, наверное, можешь сделать его на optimistic concurrency, если там как-то исхитрится. И в принципе, я так понимаю, этот же API, вот их транзакционный, он поддерживает 4 режима. Локи, repeatable read, serializable и read committed. То есть в принципе, если у тебя эта проблема, ты можешь, наверное, просто откатиться на distributed log и вообще всех строго последовательно исполнять. Ну да, но при этом, по-моему, это в принципе особо не имеет решения проблемы, если кто-то хочет поменять очень много и идет много параллельных транзакций, которые хотят поменять что-то по чуть-чуть. Но тот, кто хочет поменять очень много, он затормозит на какое-то время всех. Но это, видимо, неизбежно. Либо наоборот никогда не закоммитится. Да, либо наоборот никогда не закоммитится. Я так понимаю, у них даже контроля этого нет. То есть оно будет висеть реально, и ты никак не сможешь потом это не отменить, ничего сделать. В случае, если это именно через serializable или repeatable, то действительно так, но на самом деле надо понимать, что это etcd. etcd используется как такие группки ключей, которые связаны с отдельными объектами. Мне трудно представить ситуацию, когда в etcd нужно сделать выборку по существенному массиву ключей и еще при этом захотеть с ними что-то поменять. Ну то есть это же не база данных общего назначения. Это вполне конкретная штука. Кстати, они даже пишут, для чего это используется. Это уже используется в Kubernetes, это уже используется, по-моему, в Torus. В смысле это новая STM API. Ну да, STM это штука, которая реализована просто для го-клиента. Это не какая-то штука самого etcd, что, мол, просто etcd позволяет вот такое реализовать в вашем клиенте.",
    "result": {
      "query": "CRDT vs CouchDB replication"
    }
  }
]
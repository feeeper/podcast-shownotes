[
  {
    "segment_id": "4b9074e9-0ae8-48c0-a72e-ef0d22525275",
    "episode_id": "736c0b0f-9d3a-436d-b30d-41a765c825eb",
    "episode_number": 5,
    "segment_number": 2,
    "text": "Я слушал некий подкаст, я не буду его называть, потому что не хочу его рекомендовать, потому что я хотел написать там гневный отзыв, меня автор этого подкаста очень расстроил наличием политоты в его подпиасте, и я хотел было написать там комментарий на код FM, и я не преуспел, потому что там предлагается там, подключите свой Twitter по AUS, и там, типа нажмите кнопочку, и ты ее нажимаешь, долго-долго ждешь, и ничего не происходит. И, ну, не знаю, если чуваки в третьем тысячелетии не могут написать комментарии, то я боюсь даже узнавать, что у них там еще не работает, то есть под FM я даже регистрироваться там не стал, платформа не вызывает доверия совершенно. Ну вот, стал смотреть, на чем живут другие подкасты, и какие есть другие варианты. Есть сервис libsyn.com. Там, например, живет замечательный подкаст «Разбор полетов», у них там довольно неплохие тарифы у этого сервиса, но дороговато. То есть там за 20 баксов в месяц можно нормально захоститься, это нормальные деньги, но можно дешевле. Да, я по ошибке не туда посмотрел в Amazon, не туда посмотрел в прайсинг у S3, и какое-то время подкаст жил на S3, пока Ваня не указал мне на мою близорукость. Ну конечно, я сижу в таких тяжелых роговых очках с такими линзами в виде бутылочных горлышек. У тебя просто калькуляторы с маленькими кнопочками, ты не надо кнопочек. Ты знаешь, это же Amazon, у них же всегда такие странные тарифы, и понять, что там и как это. Нет, у них там честно написано, что вот это гигабайты, которые вы храните, а вот это гигабайты, которые вы передаете. Я посмотрел в гигабайты, которые хранишь, и решил, что это то, что передаешь, и умножил соответствующим образом. Короче, на S3 там совершенно конские цены, там 0.12 центов за гигабайт трафика. Ну казалось бы, гигабайт, да, дофига трафика, но если вы возьмете средний выпуск, даже вот на такого никому неизвестного подкаста, как DevZone, и умножите там, не знаю, на количество, типично на количество скачиваний, то там сотни гигабайт трафика. А там много спонсоров. Нужно больше спонсоров. Ага, ну как там, нужно больше золота, да? Золота, золота. Да, да, да. Ну вот, короче, выходит совершенно на конские цены, хотя если подкаст не, ну, так только начинает свою жизнь, то на S3 вполне можно хоститься, и я знаю даже довольно популярные подкасты, которые, оказывается, хостятся на S3, например, CogniCast хостится на S3. Вот, так что, в принципе, это вариант. Мне, кстати, вот интересно, Вань, ты как большой специалист по Амазону, скажи мне, вот допустим, я такой классный залил подкаст на Амазон, на S3, потом приходит умная девушка Света и решает меня задосить. И начинает там с тысячи компов бесперебойно лить мой подкаст. Вопрос номер первый. Амазон, он меня спросит, перед тем, как деньги с моей карты виза снимать или не спросит? Слушай, это хороший вопрос. По-моему, там есть какие-то ограничения на сколько они должны с тебя снять месяц, больше они не возьмут, но у меня нет уверенности в том, что это работает. Слушай, хороший вопрос. В общем, карту лучше... Так вообще, там есть какая-нибудь защита от ДОСа, вот этих вещей, либо это все на твой откуп? Вот в чем проблема, действительно, то, что там есть логи, в логах есть айпишники, но ты с этими логами и этими айпишниками особо ничего сделать не можешь, по крайней мере, в первом приближении, я совсем не знаток Амазона. У нас пока нет дотеля, поэтому я не знаю. Как начну, так мы все узнаем. Мы дали всем идею, да? Ну вот, в общем, какие еще варианты этот модел? Есть Rackspace, но там цены тоже такие же конские, те же 12 центов за гигабайт, а потом я решил попробовать Digital Ocean. И у Digital Ocean, у него там хороший тариф. Вообще, вот чем мне понравилось после Амазона? Амазон, ты туда заходишь и у тебя там куча разных сервисов, там S3, EC2, и там Road 53, и вообще куча-куча всего, и если ты с этим никуда не работал, у тебя просто глаза разбегаются. И на фоне всего этого Digital Ocean. Там вы, коллеги, регались в Digital Ocean? Да, конечно. Мне не приходилось. В общем, ты просто создаешь тачки, друплеты, и тачки, они самые дешевые, они самые простенькие, и самые дорогие, они самые крутые. И у них у всех растут число ядер в процессоре, растет количество оперативки, растет количество трафика допустимое и так далее. И там написано, что если, например, за 5 долларов ты получаешь друплет с терабайтом трафика, и если ты превысишь этот лимит, хотя мы его вряд ли когда-то превысим в обозримом будущем, но если превысишь, то 2 цента за гигабайт еще доплатишь. Да. Ну вот, в результате DevZen переехал на Digital Ocean и замечательно там живет уже несколько выпусков. Денег пока они не заносили. Да. Но мы ждем. Но мы не возражаем. Кстати, мы, наверное, прилепим в ShowNotes реферальную ссылку, кому интересно. Вам она даст 10 долларов, а нам она тоже даст какие-то доллары, если вы останетесь на Digital Ocean и будете там пополнять счет в течение какого-то времени. Вот. Если вы хотите попробовать Digital Ocean, ссылка будет в ShowNotes. Ну, хороший сервис, я правда рекомендую. И, кстати, вот касательно DDoS, у тебя вот реальная тачка под Ubuntu, у тебя рутовый доступ и ты поднимаешь Nginx, например, и все у тебя под контролем. То есть ты можешь по логам посмотреть, по IPшникам, кто тебя DoS'ит, забанить, ну, в смысле, там, пофильтровать его трафик и все. Ну, то есть понятно хотя бы, что делать. Что делать в случае с S3, я вот не понимаю. Ты забыл добавить еще мощный API. Сам отговаривал нас перед выпуском. Не надо, не надо. Я не смог заряжаться. Ага. Ну да. А еще в Digital Ocean, что лично мне понравилось, ну раз уже заговорили, там есть готовые образы друплетов. Ты можешь их сам создавать, ну, то есть берешь виртуал, ну, у них, да, это, ну, виртуалки, но KVM, KVM виртуализация. Ты можешь там что-нибудь настроить, потом сохранить образ и склонировать его. Ты можешь, ну, поставить столько виртуалок, насколько тебе нужно. Есть готовые образы, то есть ты, например, в один клик можешь поднять блогжик с WordPress, или там поднять PHP, MySQL, Apache, такую конфигурацию. Вот. Ну, то есть, а, там то же самое GitLab, например. То есть, ну, удобно. Ну и на самом деле быстро. То есть вот то, что в рекламе говорят 45 секунд, я смогу сейчас за 45 секунд поднять. То есть там на самом деле очень быстро и понятно. Тебе сразу говорят, вот твой айпишник, начинай работать. Ну, справедливости ради, они на этой неделе, у них там были какие-то технические проблемы, они несколько дней долго устанавливали Connect, по-моему, так. То есть там, типа, секунд 20 ждешь и опа, по SSH смог зайти. Они как-то предупреждали тебя перед этим? О том, что работы будут? Это, похоже, было не у них проблема. Они там в Твиттере писали, что типа, да, мы разбираемся и там где-то у Амазона есть похожие проблемы, как-то так. Вот. Ну и раз мы говорили о Digital Ocean, то у них в блоге недавно появилась новость о том, что они сделали новую зону в Нью-Йорке. Чуваки расширяются, это здорово. То есть, если вам, например, нужно два дата-центра там где-то в Штатах, то вот, пожалуйста, New York 2, New York 3, в New York 1, по-моему, там сейчас нельзя завести друплет, типа, спрос очень большой. Я тоже сделал два дата-центра, они были там независимы. Вот. Интересно. Все это очень интересно. Я раньше с облаками не так, чтобы слишком много работал, потому что обычно этим занимались отдельно OBS. Не, ну они молодцы. У них, по-моему, сейчас самая быстрая скорость прироста аудитории. То есть, это, они реально рвут и мечут. Еще интересная тема насчет подкастов. Ну, давайте добьем и да. Идем. Интересно, как построить статистику по прослушиванию подкаста, имея только, например, логи Инжен Икса. Ну, нам как ведущим, разумеется, интересно, да, сколько людей нас слушает. И действительно, это не так просто посчитать, потому что если ты начнешь считать просто количество скачиваний, ты получишь ерунду. Если ты будешь считать количество уникальных IP или там пара IP-юзер-агент, ты получишь ерунду, потому что, ну, не трудно придумать кейсы, когда там человек зашел браузером, послушал первые две минуты, потом добавил подкаст через iTunes и скачал его целиком через iTunes. То есть, получается, вроде как два прослушивания, на самом деле одно. И простое решение, которое я нашел, и оно показывает что-то более-менее правдоподобное, это, как вы думаете, в чем оно заключается? Оно внешнее или твое собственное? Мое собственное. Я могу дать подсказку, это там скрипт на перле, там типа в 10 строк. Ну, даже не знаю. Первые регулярные выражения, они же все решают. Да, полные по теории рынка, как мы помним. Да-да-да. Вот, ну, на самом деле я просто посчитал объем трафика по одному выпуску делить на размер выпуска. А, ну да. То есть, если, например, там выпуск 80 Мб, а скачали 160 Мб, то понятно, его там примерно 2 человека послушало. Это все равно получается немного завышенная цифра, но она завышенная на 10%. По их константу, да. Да-да-да. То есть, если, например, тебя послушало 120 человек, ты можешь сказать, что ну, у меня около 100 слушателей. Подожди, оно же не учитывает iTunes? В смысле? Ну, у тебя есть трафик от iTunes, либо это тот же? iTunes, он просто хранит, насколько я понимаю, он просто хранит ссылку на твой RSS и больше он ничего не делает. То есть, когда ты получаешь подкаст, ты идешь в iTunes, говоришь, дай мне ссылку на RSS, получаешь фид, в фиде видишь, что появился новый mp3шник, и идешь за этим mp3шником. А он уже идет дальше на DigitalOcean, правильно? Ну, да. Ага, окей. Вот, такой интересный момент, мне кажется. Да. Ладно, а теперь мы, наконец-то, переходим к нормальным темам. Жди, Вань. Ну и первая нормальная тема, она не вполне нормальная. Да, появился блокпост на Google Cloud Platform о том, что они начинают работать с Мезосферой об управлении облаков, как будто бы это у вас одна большая машина. Общая идея в том, что в Мезосфере есть такой концепт, что все ресурсы, которые у вас есть в кластере, объединяются в одно большое подножество, и вы этим подножеством большим управляете. Можно такую аналогию провести, что у вас есть один большой вычислительный центр, одна большая машина, один большой компьютер, в котором все эти мощности в одном флаконе все присутствуют, и вы по очереди их вызываете, используете, аллацируете каким-то образом. Причем в самой статье я не нашел никаких ссылок на технические детали, я перешел на сайт Мезосферы и не нашел там тоже технических деталей. Я вообще не понимаю, какой смысл на таком техническом блоге ввести такие вот... Ну, не совсем, согласна. Смотри, Мезосфера – это, скажем, такой комплекс либо объединение других продуктов. Вот здесь написано о том, что оно включает, оно по сути базируется на фреймворке Apache, который называется Мезос, и по сути это то, что предоставляет нам непосредственно объединение машин в кластер. Да, я Мезос тоже читал. Вот, это вот одна вещь. Я думаю, где-то исходники ее должны быть. Мне хотелось бы какое-нибудь техническое введение, что это такое. Ну, смотри, дальше есть ссылки на Marathon и ссылка на GitHub. Это аналоги. Such as those from Marathon, Kronos и так далее. Я думаю, по сути идея будет те же. Ну, блин, если вы делаете какой-то продукт, надо хотя бы техническое описание писать, что вы сделали. Если кто-то использует Мезосферу, пожалуйста, напишите в комментариях, потому что я из их статьи мало что понял, как мне с этой штукой работать. То есть, идея хорошая, да, то есть у вас есть объединение, вы не знаете ничего о кластере. Конечно, тут сложности возникают всякими спартишнингами, то есть, когда у вас сеть разъединилась внезапно, как вам разделить ваш компьютер теперь на две части, непонятно как. Но мне хочется побольше. Побольше мяса. А его здесь не было. А чего еще не было? Я могу сделать переход? Да, давай, давай. А чего еще не было и нет? Я недавно с этим столкнулся, это Bayanis, ты Bayan, но как выяснилось, не все о нем знают. Не было и нет в Java возможности использовать алгоритмы шифрования, например, AES, с длинными ключами, например, 256 бит. То есть, AES, вы знаете, он может работать в нескольких режимах, например, у него может быть ключ 128 бит, может быть 256 бит. И если взять обычную Oracle JVM, поставить ее и запустить приложение на Java, которое ты скажешь, там, зашифруй мне в режиме CBFC или CTR, неважно, блок с длинным ключом, то он бросит исключение. Invalid key exception, illegal key size. И очень интересно, как это лечится. То есть, у Соединенных Штатов, вы знаете, у них там есть всякие идиотские законы на тему экспорта криптографических алгоритмов. И у Oracle, у него нет легальной возможности экспортировать JVM, которая позволяет шифровать данные с длинными ключами. В данном случае длине 128 бит. И получается, чтобы тебе в твоем приложении использовать нормальные длинные ключи, тебе нужно скачать JVM, а потом ее пропатчить. Каково? Ну, это жесть какая-то. То есть, для того, чтобы сделать побольше защищенность, нужно патчить JVM. Ну, или довольствоваться 128 битами. Это в принципе нормально. Ну, да, конечно, кому понадобится больше 64 килобайт. Это два раза уже в подкасте у нас. Ага, Свет, да. Но при этом, это же не на всех машинах проявляется, правильно? Это только на винде. Нет, проявляется везде. У меня проявилось под Ubuntu. Интересно. Ну вот, то есть, да, Java, она такая кроссплатформенная, но чтобы в ней работал заявленный функционал, нужно ее пропатчить. Здорово, да? Вот, но это я так, изливаю душ. Отлично. Ну, скорее, это особенности законодательства. Ну, да. В общем, есть такая особенность, если вы с ней столкнетесь, то теперь вы знаете, что делать. У нас в шоу-ноутах будет ссылка на Stack Overflow, где описано, куда идти, чего скачивать. Ну, просто как раз-таки по этой ссылке написано, что на Mac Pro все ок. Отлично. А что еще отлично, это консул. Да, консул опять жжет. Они именно сегодня добавили новую функциональность, они добавили Watcher, которых так не хватало, все очень сильно хотели. Вань, ну ты прям сразу угурёшь. Расскажите, что такое консул.io. А, то есть, надо вот так начинать, да? Пожалуй, да. Да, консул.io – это подделка от автора Вагранта. Он сказал, что нам не хватает функциональности на рынке распределенных систем, и написал новую систему консул, которая нужна для больших систем, которые хотят строить сервис Discovery, которые хотят иметь распределенную key-value-storage для этого, которые хотят иметь удобный многокластерный конфигуратор какой-то. И вот для всего этого они написали достаточно простую и понятную модель вот консул.io. То есть, продукт называется консул, его сайт – это консул.io. Они позволяют делать много вещей прямо из коробки, в основном для сервиса Discovery все это делается. И очень хорошая документация, очень приятный сайт, очень хорошо сделанный. То есть, посмотрите, нисколько не пожалеете. И вот именно сегодня они добавили watcher, это возможность иметь внешний какой-то процесс. Нет, скажем так, вы хотите добавить обработку случаев, когда у вас какое-то значение поменялось, было одно, стало другое, и в этом случае должен выполниться какой-то callback. Вот эта фишка была в зоокипере, и всем ее не хватало в консуле, и вот ее сейчас добавили. Я не знаю, когда она попадет в стабильную версию, но сейчас ее смерджили в мастер сегодня. Но говоря простым языком, они сделали триггеры. Да, только там непонятно, как пока управление, то я не нашел пока в документации, надо в код смотреть, в код я не успел поглядеть. Ты говоришь, что это чем-то похоже на зоокипер? Правильно, если я понимаю? Да, и у них на сайте прямо есть информация. А чем она лучше? Чем зоокипер? Чем зоокипер? Ну просто зоокипер, смотри, это такой стандарт уже де-факто для распределенных систем. Почему я должна использовать консул, а не зоокипер? Я выберу зоокипер. У них есть статья на эту тему, чем она лучше зоокипера. Она большое количество экранов. Я могу рассказать основное. Основное это то, что в зоокипере вам необходимо, и помимо того, что вы будете работать зоокипером, вам необходимо на каждом клиенте писать небольшую, но достаточно емкую функциональность на тему, как работать зоокипером, как смотреть, как делать в очереди и так далее. И в первую очередь сложности возникают с проверкой жизнедеятельности данного сервиса. То есть зоокипер, он фактически это просто QWL. Для того, чтобы обратиться в зоокипер... Ну там по сути как файловые системы что ли нахранить, можно так сказать. Да, да. И если у вас сервис умирает, то этой файловой системой есть TTL для данного сервиса, и она автоматически стирается, если он через какое-то время не приходит и не говорит ничего. И для того, чтобы этот TTL... Во-первых, сам TTL достаточно большой получается. То есть у вас сервис умер, скажем, минуту назад, у вас только сейчас стирается информация об этом сервисе, до этого времени все пытаются достучаться. А во-вторых, вам необходимо самостоятельно писать на каждом приложении код, который будет в зоокипер обращаться, обновлять эту штуку. Причем вот этот health check, он должен быть достаточно емкий, то есть это не просто то, что у вас процесс поднят, и он работает, а вам всякие штуки типа, вот он не съел слишком много памяти, а он не заиспользовал слишком много файловых дескрипторов, а он... Ну там еще можно... Ну вот вся логика, которая нам нужна. Как это в консоле будет? Они сами это делают? В консоле там есть прозрачный механизм. Во-первых, на каждой ноде будет запускаться свой собственный агент консольский, который достаточно легковесный, чтобы он не мешать всему остальному. А с другой стороны, он прямо на этой ноде следит за ее жизнеспособностью. То есть он сам может следить, отслеживать какое состояние ноды. Плюс в удобном интерфейсе вы предоставляете ему, вот смотри сюда, и если ты получишь не код 200 на этот http-запрос, то значит я умер. Или смотри сюда, и если ты получишь сюда значение меньше пяти на данный http-запрос, то значит что-то пошло не так. А если этот агент умрет? Ну, видимо, предполагается, что он не будет умирать. Тут еще нужно отметить, что консол, как я понимаю, я не специалист, это AP решение в то время, как Zookeeper таковым вроде бы не является. Да, нет? Не знаю. AP это что? Ну, как это, ну, ESCAP теорема, который… А, все, понял. Ну, работает он, кажется, по RAFT. Вообще у этого, у консола тоже, сервера консола, они полный аналог Zookeeper, то есть они тоже AP, тоже у них он работает по GASIP и все такое. То есть, ну, можно считать, что это практически аналогия. А Zookeeper DNS умеет? Вот консол умеет? Консол умеет, Zookeeper нет. И плюс консол еще умеет, когда у тебя два кластера, скажем, в разных availability зонах, и эти два кластера будут тоже между собой по внутреннему протоколу договариваться. Причем тоже, я так понял, что по GASIP, хотя может и нет. На самом деле, тут есть… Какой-то агент запускается, что представляет собой этот агент? Какой-то демон? Да, какой-то демон. А есть ли какая-то штука для визуализации всего? Для Zookeeper я знаю, что есть. Есть штука для визуализации, но я так понял, ты имеешь в виду интерфейс какой-то. Есть замечательная демонстрация, есть видео, оно идет 8 минут. Я прикреплю ссылку в шоу-ноты. Очень хорошая демонстрация, там чувак поднимает докер-контейнер, поднимает в нем консул, три экземпляра на трех… Да, он использует друплеты в Digital Ocean, и говорит, что вот смотрите, у меня там три нода, они друг друга увидели, теперь я сохранил туда значение, теперь я его могу получить. Хорошая демонстрация, я советую. А между нодами они по HTTP обращаются? Это информация скрыта. Слушай, я не помню. Я сомневаюсь, что там HTTP, потому что если у тебя большой объем данных, то его не очень эффективно по HTTP, конечно. Надо посмотреть. Штука интересная, все-таки я посмотрю. Я была уверена, что Zookeeper это то, что нам нужно. Zookeeper он просто старый, давний, всем известный. Консул появился не так давно, то есть они в Production Ready вышли меньше года назад, меньше полугода назад, не помню точно даты. А кто-нибудь уже его использует? У меня знакомая в Production пытается его вывести, в ближайшее время должна узнать результат. Вот наш хороший друг Никита Прокопов рассказывал про Zookeeper, всякие страшные вещи, то, что он там, не помню какой объем, типа 16 МБ данных не может нормально держать в каком-то небольшом дисковом пространстве и там все плохо.",
    "result": {
      "query": "консул vs zookeeper сравнение"
    }
  }
]
[
  {
    "segment_id": "efd59119-57ee-41ea-815a-c7124824e7ae",
    "episode_id": "fe6e8d44-6dae-4f56-aaab-9d789dbabf16",
    "episode_number": 114,
    "segment_number": 5,
    "text": "Греб решает все проблемы с Big Data. Особенно вот тот быстрый греб на Rasty. Да, да, да, тот самый, ускоренный. А что еще ускоренное? Так это бенчмарки железа для Deep Learning. Мы немножко затронули эту тему, какое железо выбирать и как вообще решать, что использовать. Я хочу просто добавить небольшую ссылку, которая показывает бенчмарки для разных типов GPU и для разных библиотек для Deep Learning. Кстати, я оттуда узнала, что есть такая библиотека, называется Neon Nirvana. Я об этом впервые слышала. Это написано на питоне библиотека, но не знаю, ты ведь слышал про такую библиотеку или нет? Про Neon нет, даже не сталкиваюсь. Я слышал про Nirvana, возможно, это та же Nirvana, которую купила Intel недавно. Да, точно, вот. Но я раньше не слышала про эту библиотеку. Это небольшая статья про то, что просто бенчмарки показывают, как оно работает и какую карточку вам лучше брать. Возможно, кому-то это будет полезно и интересно. Я бы тут еще добавил, что этих консумерских карточек, одну из которых использую я, Titan X, их вполне достаточно. Если у вас обычный компьютер, если вы не будете его пихать в серную стойку, где он будет занимать много места, то вполне можно этим обойтись. Допустим, моя карточка раз в 10 быстрее, что до последнего месяца предлагал Amazon. За что они брали какие-то сумасшедшие деньги. Если сравнивать с теми же Tesla от Nvidia, то по затратам противопроизводительности она получается гораздо лучше, эффективнее. Я добавлю, наверное, еще потом ссылку в статье о том, как строить Deep Learning Box и гайд по части железа. Что выбирать, как делать, особенно когда вы устанавливаете несколько видеокарт. Еще интересный момент по поводу хардвера. Тут как раз был человек из Nvidia на последнем Deep Learning Summit. И они рассказывали про какой-то их сумасшедший бокс, который стоит 180 тысяч долларов за штуку. Но который все равно является гораздо более эффективным по цене, чем вы бы покупали в Амазоне. Он в себе сосредоточивает мощь 45-ти каких-то машин, которые они приводили. Я не помню уже точно, что они приводили. Но рынок, мне кажется, для этого начинает расти. У Амазона сейчас больше условия. Ажион тоже предоставляет какие-то машинки для машинного обучения с GPU. И такое чувство, что Nvidia получается одни на этом рынке сейчас. Будто у них вообще нет конкурентов. А ты сказал, что у тебя карточка Titan Titan X Maxwell, правильно? Нет, у меня Titan X Pascal. Pascal, ага. Тем временем мы двигаемся дальше по темам. Следующая тема у нас Андрея. Я сразу скажу, что я ее принес. Но я решил сказать. Сейчас скажу, как его зовут. Николас. Это код пишет парень из Мозилы. Про то, как он ускорял компилятор Rasta. Николас известен тем, что несколько лет назад много-много работал в Мозиле над тем, над перформансом JavaScript. В частности, над выделением памяти в браузере, над garbage-коллектором. То есть его блог, можно почитать какие-то старые статьи, как они там работали с ГЦ.",
    "result": {
      "query": "GPU Deep Learning benchmarks"
    }
  }
]
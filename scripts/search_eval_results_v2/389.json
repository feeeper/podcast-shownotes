[
  {
    "segment_id": "cdbce893-ba46-49ca-a44c-946488868b8b",
    "episode_id": "9e0613ee-9b18-4f1d-aa68-bec8a6ffdf04",
    "episode_number": 389,
    "segment_number": 4,
    "text": "Взражения, вопросы, комментарии. Ну, что ж, тогда мы переходим к следующей теме. Это тоже про базы данных. Правда, Валер? Ну, не от меня. В общем, тут такой... нынче разговоров очень много, потому что прошла конференция Юзин-Икс, и на ней, кроме прочего, появился пейпер про DynamoDB, который, кроме прочего, в частности, раскрывает историческую связь с Dynamo, который как раз был прототипом Cassandra и React и всего этого. Раскрывается немножко там историю про челленджи, которые они вынуждены были преодолеть, пока они эту систему делали масштабирно и production-ready. Одна из вещей, которая, в общем-то, привлекла мое внимание к этому пейперу, это серия твитов и некоторые такие вводные слова в самом пейпере о том, что предсказуемые системы для DynamoDB сильно ценнее перформанса, как бы сырого перформанса. Можно еще раз подожди, что ценнее перформанса? Предсказуемость. Предсказуемость ценнее перформанса. И вместе с тем, что у тебя не должно быть хвоста во время этого. Что, грубо говоря, вот то, что у тебя там 99.9 и 99.5 процентиль, лучше они все будут одинаковые, чем очень быстрая медиана, но очень плохой или какой-нибудь внезапный выброс на, соответственно, более другом персентили. Ну, я бы не был так категоричен говорить, что это всегда верно, но я думаю, что это справедливо для многих систем, да. Ну, в смысле, как я повторюсь, мой глаз зацепило, что их пейпер с этого начинается. То есть я не утверждаю, что это для всех систем хорошо, просто это такая вещь, от которой я последнее время медитировал, потому что у нас есть в текущем проекте похожего рода проблемы. Ну и в целом, как бы, я в своей жизни, наверное, большинство систем, которые я оперировал, имели или могли потенциально иметь то, что называется бимодальное поведение, когда у тебя есть поведение системы, когда с ней все хорошо, и поведение системы, когда что-то случилось, и там, не знаю, кэш вычистился, или не успели подобрать какой-то мусор, или затупил диск, не успели подобрать мусор на диске, или не успел джавный гробчик, не успел мусор продобрать человек от фигня, система входит в такое деградированное состояние, и очень сложно выкрепиться без перезапуска. Конкретно в DynamoDB таким элементом был кэш метаданных, про то, где... это кэш, в котором написано, какой ключ с какой таблицы, на каких нодах искать. Я не буду преподаваться в подобную стерилизацию, но смысл в том, что раньше у них каждый роутер запросов имел локальный кэш, который он там по довольно грубым правилам обновлял, и как только этот кэш... как только вы деплоуете новый роутер, у него пустые кэши, ваш система начинает непредсказуемо отвечать, как только вы... например, не знаю, вас роутер начал обслуживать нового клиента, опять же, он ничего не знает про таблицы этого клиента, опять-таки начинаются непредсказуемые скачки, и так далее. То есть, как бы... что еще хуже, что если у нас несколько роутеров перезапустили, ну, прямо как бы, скажем, регион, то у нас вообще может случиться катастрофический рост нагрузки на... как бы, систему, которая является авторитетной, потому что... если у нас перезапустили целый регион, там начнется просто такой, как бы, сметающий все на своем пути поток запросов к исходной системе. И исходной системе станет тяжело. И при, наверное, совсем грубом каком-то таком происшествии мы можем и исходную авторитетную систему положить, чего бы, наверное, не хотелось. Вот. Собственно, как поступили разработчики, они сделали отдельную такую подсистему, которая сама по себе является распределенным, реплицированным, иммемори-хранилищем. И в него уходит всегда. То есть, ну, на каждый запрос мы в него в любом случае послаем запрос. Почему это... то есть это как бы немножко менее эффективно для случаев, когда у нас мы могли бы это уже локально все закашировать. Но это, к моему, есть какие-то локальные каши все равно, но если мы прям совсем повторные запросы посылаем. Но в таком, скажем, среднем случае мы ходим в эту распределенную мемори-систему, и это дает такую гарантию, что сколько мы не деплой новых запросов, соответственно, это как бы мы, ну, авторы системы, сколько не нужно задеплойть новых роутеров, или сколько не нужно их перезапустить, поскольку паттер нагрузки всегда довольно один и тот же, не возникает ситуация, когда они набегают на исходную систему. Соответственно, сама in-memory каширующая система, она сама вся распределенная и реплицированная, соответственно, если там какая-то одна нода отвалится, она, видимо, зафейловерится на другие реплики. Ну, то есть это напрямую в пейпере не написано, но вот из того, что она реплицированная или распределенная, я предполагаю, что она реплицирована именно для того, чтобы при отваливании отдельных узлов к этой in-memory каша, чтобы оно не деградировало так же, как старый каш. Вот, это довольно интересный паттерн, то есть, я такие же штуки вот из похожих, то есть это не обязательно должно быть про каши, очень похожая ситуация, может быть, с позгрессом, например. В позгрессе есть такой механизм автовакуум. И, ну, то есть, для те, кто не знаком с тем, как позгресс в этом плане устроен, позгресс данные почти всегда пишет, пишет, пишет, пишет. Когда мы что-то обновляем, в большинстве случаев мы просто старые данные поменчаем как мусор, по столку на них никто больше не ссылается. И есть подсистема автовак, вообще даже мы не то, что их помечаем, Саша меня поправит, мне кажется, что мы просто, на них просто перестают ссылаться, они даже как-то специально не помечены. Нет, они продолжают ссылаться. У тебя, когда ты удаляешь данные, то, что происходит, то, что происходит, что происходит, они в них просто пишут метк о том, что они были удалены в такой-то транзакции. Да, окей, да, да. Тмакс, Тмин. Да, более того, вообще не факт, что вот эта транзакция, которая удалила данные, она еще успешно завершилась, она может быть заоборсилась. Поэтому ее состояние нужно проверять. Получается, что просто в какой-то момент у нас есть у тупла Тмакс, и этот тупл больше не… и транзакция, которая в Тмакс написана, она завершилась. И все, которые были до нее, тоже завершились. После этого тупл становится невидим никому. Ну, там чуточку сложнее. В целом у тебя условие такое, что не должно существовать активной транзакции, способной видеть этот картер. И тебе нужно проверять и Тмин, и Тмакс для этого. Потому что, может быть, ты вот очень давно начал транзакцию и не комиссил ее, а она все еще видит этот тупл. Справедливо. В какой-то момент тупл становится никому не виден, потому что все транзакции, которые могли бы увидеть, они все закончились. Или откатились, или закомитились. И после этого есть специальная система, которая ходит и переписывает немножко страницы. Если у нас на страницах много мусора, нам нужно те туплы, которые там живы, записать куда-то в другое место. Все остальное, я не киснил, как автовакуум работает. Он страница говорит, что здесь теперь свободно? Или он... Автовакуум, вообще вакуум в позгрессе, он многоуровневый. Самый лайтовый вакуум. Он просто ходит по страницам, он лочит одну страницу, проверяет кортежи на этой странице. И если они больше никому не видны, вычищает их из страницы все. Он супер лайтовый, он... Ничего не перемещает? В индекс он не ходит, насколько я помню. Есть вакуум фулл, сейчас поздно, сложная и не помню. То есть есть более сложные вакуумы, которые лочат всю таблицу. И вот сейчас я не готов это пересказывать. Но поскольку в том, что есть более тяжелый вакуум, есть более тяжелые вакуумы, которые будут лочить таблицу целиком. И как перестраивается, вычищаются индексы, я вообще не помню. Окей. В любом случае, возвращаясь, вы же по тому, что я... К чему я это вообще вспомнил, что очень часто ради перфоманса вакуум делают очень неагрессивным. И он там приходит, не знаю, раз в сутки, что-то там подчищает. И типа у нас большую часть времени все прекрасно, а там вечером в нерабочее время приходит, значит вакуумы все вычищает. У такого подхода, ну то есть да, мы по сути работу откладываем на потом. И то есть сейчас у нас все быстро, но когда-то потом должно стать медленно. И если у нас нагрузка не какая-то особая, оно так может годами работать и все будет нормально. Но потом случится день, когда нам много записали. Или диск затупил вечером и вакуум не справился. Или еще почему-то, и у вас потом начинается время, когда нужно обслуживать клиентов интенсивно, а вакуум еще не закончился, и у вас, во-первых, вакуум все еще кушает ресурсы. Во-вторых, все эти страницы, которые не вычищены, любое действие с ними приводит к тому, что, то есть грубо говоря, вам нужно прочитать и обновить много строк. И они из-за того, что у вас в страницах много мертвых туплов, так может оказаться, что вам по два-три живых тупла на страницу и куча мусора. И вам просто ради каждого тупла нужно поднять всю страницу, там сколько она? Четыре, кажется, или восемь килобайт, отливать один аптейд, положить на место, опять же добавить туда количество мусора, потому что даже если там update был in place, может быть даже не добавляя мусора, но тем не менее. Потом пойти со следующей страницы, то же самое сделают у вас, получается read amplification, write amplification, еще и вакуум в это время где-то работает, то есть вы отложили очень много работы и сделали системе хуже, и если не дать ей времени потом провакумиться, она будет деградировать, деградировать и деградировать. Альтернатива – это настроить вакуум очень агрессивно, чтобы он просто постоянно прибегал и почищал. Да, это возможно замедлит ваши текущие бенчмарки, которые вы сейчас гоняете, текущие какие-то показатели, может у вас немножко вырастет время ответа, зато вы сильно уменьшаете риск попасть в эту ситуацию, когда у вас настолько неотвакумленная таблица, что вы попадаете в такой просто death spiral, когда нужно отключать клиентов и провакумливать все настиж, гоняй настиж как-то начисто. Вот, и не знаю, это просто то, что вот в моей практике была похожая ситуация, и мне кажется, можно много таких примеров привести, и вот эта идея о том, что предсказуемость, она часто может быть важнее скорости, она со мной как-то очень срезонировала. А сам пейпер будет попозже, я так понимаю. Да, сам пейпер будет попозже, я хотел его к сегодняшнему дню успеть, но не успел. Ну да, но я думаю в этом, знаешь, когда, если это теоретически, объективно, да, пытаться рассуждать, то не факт, что это всегда верно, но вот на практике, я думаю, верно почти всегда, потому что человек так устроен, если что-то случается редко, они об этом перестают думать, а потом, о, господи боже мой, у нас в пасгрейсе, оказывается, бывает вакуум и транзакцион рап-араунд, и там А-бекапы мы делали, инвестировали, вот все эти истории, поэтому да, я согласен, что в реальности намного предсказуемости, короче, все, что сказал, правда. Я бы хотел добавить, что это же легко как-то понять, даже новичкам объяснить, нет смысла бороться за производительность, если ваша программа работать не так, как вы хотите. Нет, но прикол в том, что она будет работать не так, как ты хочешь потом, ты сейчас об этом не знаешь, сейчас она работает очень быстро. Кстати, это является критерием, наверное, что если ваша программа работает долго, прямо долго, ну, система, не обязательно отдельная программа, вам хочется предсказуемости, если ваша, если у вашей системы есть какой-то горизонт, после которого ее точно перезапустят, то предсказуемость может быть чуть менее важной характеристикой, может быть важнее именно throughput, то",
    "result": {
      "query": "predictability vs performance database systems"
    }
  }
]
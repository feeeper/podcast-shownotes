[
  {
    "segment_id": "772afc59-0d4c-42cb-b5ea-ad490e5206bb",
    "episode_id": "cbf3ad33-328a-49ba-b691-9033ab448ecf",
    "episode_number": 375,
    "segment_number": 5,
    "text": "А еще для анализа проблем с разными штуками и вообще тестирования проблем с разными штуками, бывает полезно использовать property-based-тесты. Моя любимая тема. Я уже, кажется, выпуск назад или два выпуска назад, в 73-м, в 37-м, говорил, что, ну то есть я там бурчал на Jason B. У меня вот там была тема. Я 15 минут недовольно бурчал на Jason B. И вот, в общем, я в качестве... как это... для своих целей я писал, напоминаю специализированную хеш-функцию, которая хеширует Jason B так, чтобы два Jason B, которые равняются друг другу, как бы вот семантически с точки зрения базы данных PostgreSQL, чтобы их хеши тоже равнялись друг другу. А если они разные, хеши друг другу не равнялись. Что тоже, на самом деле, важное свойство, которое не для каждой хеш-функции выполняется. То есть, например, в PostgreSQL есть встроенная функция JasonBHashExtended или как это так она называется, не помню точно. И вот она одинаковый Jason B. Семантически одинаковый, даже немножко по разному записанное напоминаю. Там есть особенность тем, как чиселки хранятся в PostgreSQL, потому что номер очень точный тип, слишком точный тип. Вот. Они... в общем, он с точки зрения того, что два равных значения по разным записанных, они будут захашированы одинаково. А вот при этом есть ситуация, которая мне, собственно, помогли найти property-base-тесты, когда он для двух разных Json-ов отдаст одно и то же хеше значение. Почему так? Потому что... ну, да. JasonB, он позволяет хранить... то есть, вообще, сам все форматы JSON, он, по-моему, не позволяет хранить просто отдельные значения. То есть, как это довольно... то есть, не каждый парсер благосклонно относится к тому, что вы берете, записываете единичку или просто строку в кавычках и говорите, это мой JSON. Насколько я помню... Насколько прости, что я снова перебиваю. Насколько я помню, сканификацию в Json-е, опять же, поспеть, это может хранить только объект. То есть, даже массив, это не... вот без ничего, это неправильный JSON-объект. Ну вот, в общем, JasonB, он, на самом деле, позволяет хранить куски. Ну, то есть, например, вы можете записать просто единичку или просто now. Искать JSONB и хранить это в стадце, в строке благосклонной. Однако, это будет очень интересно записано. Это с точки зрения формата JSONB, это массив из одного элемента, который помещен специальным образом, типа массив из одного элемента, который представляет собой только этот элемент. Я не знаю, это, видимо, какие-то особенности формата, но, в общем-то, так. И если наивно с этим работать, то можно не заметить, что там есть специальный флорок у массива, который говорит о том, что это массив из одного элемента. Я думаю, что Postgres-овая hash-функция специально это не замечает, потому что там, типа, она используется для того, чтобы класть вещи в hash-таблице и коллизии потом руками резолвятся. А мне нужно было, чтобы коллизии не было. Вот, и, собственно, мне нужно, как бы, я, когда написал свою hash-функцию, я, в принципе, хотел ее как-то протестировать, ну, я какое-то количество кейсов руками, конечно, придумал, но руки это руки, но они очень часто не совсем из плеч. Или, даже если они из плеч, они не могут предусмотреть всех возможных хач-кейсов, типа, вот того, что я сейчас описал, и, по идее, еще догадаясь, что нужно протестировать, что значение, как бы, что hash от значения равен hash-у, или, точнее, не равен hash-у от того же значения, но, типа, взятого в массив. И, собственно, вот в таких случаях property-based-тесты просто идеально помогают, и, собственно, я догадывался, что что-нибудь такое у себя найду, какую-нибудь такую богулинку. И, собственно, я начал искать библиотеку для того, как бы, вот, как мне в моем расте навертеть property-based-тестов. Нашел две библиотеки. Одна называется QuickCheck, вторая называется PropTest. QuickCheck, не знаю, как бы, я не могу сказать, что она похожа на хатт скельфский QuickCheck, чем-то, кроме названия. PropTest очень сильно похожа на питонячий hypothesis. Собственно, из них двух я всем настоятельно рекомендую использовать PropTest. Я попробовал QuickCheck. У него, в-первых, шутка неудобный интерфейс. Написать, просто описать генератор для курсивной структуры, вроде JSON, это то еще удовольствие. Она вроде как быстрее работает, ну, то есть она действительно быстрее перебирает варианты. Но эти варианты довольно бестолковые. То есть она одна из важных, одно из важных свойств многих property-based-тестировающих библиотек, потому что они перебирают не просто какой-то рандом, оно старается перебирать какие-то минимальные, как-то минимальные интересные кейсы или как-то, не знаю, то есть ходить по всяким граничным случаям. Во всяком случае так были устроены большинство библиотек, с которыми я лично работал. А как бы перебирать просто огромные JSON, это не очень интересно, потому что, ну, как бы, там много ли этих, в смысле, много ли там среди среди больших всякого интересного, как раз вот обычно вот какие-нибудь структурно интересные случаи важны. Если библиотека даже не позволяет эту структуру описывать, то, наверное, там можно руками со всеми руками это сделать, но вот именно у prop-теста есть прям удобные примитивы, которые позволяют это собрать, и библиотека достаточно умная, чтобы понять, что, ага, вот здесь у нас структура меняется, значит, вот здесь нужно, здесь есть интересная граница, вокруг которой нужно походить, перебирать варианты. И, собственно, prop-тест нашел у меня багу, quick-check не нашел. При том, я в начале даже когда не знал, что есть бага, я просто выбирал библиотеку, я плантил тривиальный баг, и вот, опять же, quick-check его не нашел, в смысле, утерастовский quick-check, quick-check prop-тест нашел. Соответственно, если вы хотите использовать property-based тестирование в Rust, рекомендую библиотеку prop-тест. Я закончил. Вопрос в дополнение или переходим к лактозе Зен. Я предлагаю перейти к лактозе Зен, тем более, смотри, у нас еще куча тем, а мы уже наговорили на полчаса. Непереносимая как лактоза тема, потому что мы обсуждаем видео из серии vaccination database talks, сезон под названием Booster, непереносимая, потому что на следующей неделе будет уже следующее видео, поэтому эту тему перенести нельзя. В этот раз доклад посвящен УБД, даже не так, системе под названием relational.ai. Валера, скажи мне, пожалуйста, тебе доводилось когда-нибудь использовать relational.ai? Впервые слышу. Я понял. Сразу скажу. Начало у доклада немножко затянутое, я послушал там первые 20 минут и воспринял его как поток всякой маркетинговой фигни от VP. Доклад читает VP компании. Я вот серьезно думал, что надо выключать, но решал отколись пивой и внезапно все стало таким интересным. Значит, утверждается, что они пишут с УБД для релиционных графов знаний, для relational knowledge graphs. Это мы говорим про терминологию из мира экспертных систем, искусственного интеллекта. В этом домене очень большая сложность представить факты, которые тебе известны, потому что часто они не очень хорошо структурируются. Одно из популярных представлений это либо на графах, либо на чем-то, что очень похоже на графы. И забегая немножко вперед, вот конкретно relational.ai работает не с RDF, как в прошлом выпуске, в 37-47 мы обсуждали систему stardoc. Stardoc это чистая RDF-система. Relational.ai, они используют, у них как RDF, но они могут не только тройки хранить, они могут хранить четверки, пятерки и так далее. Кстати, не хотелось бы там говорить с самим собой на протяжении какого-то долгого времени, поэтому если есть какие-то вопросы, снова перебивайте или дополнение, все что угодно. Валер, ты послушал предыдущий выпуск? Я послушал, да. Хорошо, то есть ты в контексте. Я рад. Опять же, забегая немножко вперед, у них собственный язык запросов, который называется rel. Он по синтексу похож на Python, но на этом все сходство заканчивается. В языке запросов rel очень много язык из datalog, который из того, что я смог понять, очень похож на Prologue. То есть это такой язык, который pattern-match'ит то, что ты у него спрашиваешь. Я не смогу это объяснить под запись, если вы особенные числа никогда не, ну вообще в Prologue глаза не видели, но это очень мощная штука. Это язык декларативный, языкологическое программирование, не путайся функциональным, который тебе позволяет определять термины и потом переиспользовать их в функциями. Вот в concreate.frl называют definitions и на основании этого задавать системе вопросы почти как на естественном языке, но очень близко. То есть к тому, что ты спрашиваешь, к нему можно еще дописать сбоку припеку parser с естественного языка на rel или на Prologue или на datalog, и у тебя будет прям экспертная система типа alisa или чего-то, к которой можно прямо на естественном языке обращаться, и она будет что-то отвечать. Вот, если вы никогда Prologue не пробовали, очень рекомендую. На самом деле я бы хотел добавить, что он сложен в понимании в самый первый момент, как и вообще любой декларативный язык, потому что ты не понимаешь, как можно программировать на языке, не записывая последовательность действий. Ты фактически идешь от цели. Подожди, ты же в SQL тоже не записываешь последовательность действий. Ты как не записываешь, ты говоришь select, join by, goodbye. Но это не последовательность действия, ты множество описываешь на самом деле. Это то, за что я очень люблю SQL, потому что это язык, который тебя обманывает. Ну, не то, что обманывает. С любыми декларативными языками это относится к SQL, к Prologue, ты резко начинаешь их понимать, когда ты не просто как бы синтакс ботаешь и что он тебе возвращает, а начинаешь разбираться, а как оно будет реально работать. То же самое с Prologue. Я нифига не понимал Prologue, потом я сейчас уже напрочу забыл, но в свое время, когда разбирался, я читал только книжку, только какие-то статьи и дошел до места, где рассказано, как оно реально будет исполняться, и тут я как понял Prologue, я вот так понял. Но потом я все забыл. И также с SQL, как только ты понимаешь, что где-то там есть планы запросов, которые состоят из таких-то узлов, и твой запрос оптимизатором, планировщиком преобразуется в это дерево исполнения, и его ты видишь в Explained, то все становится резко более понятно. Да, тогда они поддерживают SQL, SQL у них реализован на основе DaggerDB, про DaggerDB у нас был какой-то из выпусков, поищите по сайту, у нас есть поиск. Он говорит, что будущее за Cloud Native в базе данных, он премьерс устарел и не может обеспечить такие очень важные вещи, как бесконечное хранилище, full-managed system и так далее. Эту часть я слушал в полухо, но они пытаются себя делать как именно Cloud Native решение, соответственно оно совершенно закрытое, совершенно в облаке, но у них есть какие-то там открытые кусочки, про которые мы поговорим дальше. И вообще хочу сказать, что этот докладчик, он очень много говорит про то, что не поддерживают, а на вопрос, как отвечают ссылками на вайфпейпер. Поэтому в рамках своего... С звучит как так себе докладик, потому что ты хочешь послушать доклад, чтобы сэкономить себе время и понять, хочешь ли вы вайфпейпер читать или нет, а тебе рекомендуют на нем посчитать вайфпейпер. На самом деле я почерпнул некоторую интересную идею. В целом я хочу, опять же забегая вперед, сказать, что мне доклад понравился, это один из лучших докладов, которые я видел в этом сезоне. Но у него очень странное начало и я хотел бы чуть-чуть больше узнать про детали реализации, но в общем-то докладчик и так вышел за определенное ему время, спасибо хотя бы за пейпер и объяснение, ну, о чем они. Поэтому мы сейчас перейдем. Про РДФ и то, что эта система поддерживает больше, чем просто РДФ мы поговорили. Мы поговорили о том, что это система для датасатанистов и тех, кто занимается МЛ. В отличие от датадога, то есть напомним датадог это штука про поиск, куда ты вгрузил свои инструкторированные данные, а потом по ним ищешь. А здесь очень похожая система, по крайней мере… Мне кажется датадог это что-то не то. Не понял. Датадог мне как оказалось это вообще всегда DAT.SAAS для того, чтобы в него метрики выгружать. Мне кажется ты что-то другое хотел сказать вместо датадог. StarDog. StarDog. Система, которую мы в прошлом выпуске обсуждали. Дурацкие похожие названия. Я себе в пометках прямо написал DATADOG. Я осуждаю такие похожие названия. Да, система очень похожа на StarDog, но StarDog это штука про поиск, а это очень похожая концептуально. Но внутри она устроена совершенно наше. Система для тех, кто занимается датасатанизмом. Среди разных фичей они поддерживают инкриментальные изменения в своих… То есть у них есть в юхе, по крайней мере, как я понял из доклада, и они умеют инкриментальные изменения. То есть когда ты где-то что-то поменял, у тебя в ю пересчитывает только то, что нужно пересчитать. И потом упоминается в том контексте, что они за open source сели штуку, называется SAAS. jl. JL это расширение у джули, юзот программирования джули, который напомню, как питон, только с g-tone. Ну и совсем не питон, но вы поняли. Мне стало интересно, что… И он как-то это так вскользь запоминает. Ну, кстати, у нас там есть SAAS.jl, который мы там за open source и продолжать дальше. Вот я пошел подчеркнуть, что это такое. GitHub говорит нам, что это фреймворк для инкриментального вычисления и мемоизации по требованию, как-то вдохновленная фреймворком SAAS на языке Rust. Ну, как бы мне это не дало понимания, что это за штука, я пошел читать про SAAS, которое на языке Rust. Там GitHub говорит, что… Точнее, не так. GitHub тоже не очень понятно объясняет, но у SAAS есть книжка. Она бесплатно лежит в интернете, ее можно почитать. Вот и его книжка уже там введена или где-то. Она уже нормально объясняет, что это фреймворк на языке Rust для написания инкриментальных программ, которые работают по требованию. То есть программ, которые непрерывно производят новый выхлоп, новый аутпут по мере изменения инпута. Звучит как что-то прикольное. Еще раз, да. Еще раз я не очень понял. У тебя есть программа, у нее есть вход и выход. Вход большой, ну это типа база данных, да, например, это твой вход. И твой выход – это сложная функция, сложная в вычислительном плане от входа, правильно? Так. Ты один раз вычислил выход, ты его запомнил. Потом ты говоришь, а я во входе делаю update trawly-valley set x == 1. То есть ты поменял значение в своей базе данных, ты поменял вход. Вот сальса – это фреймворк, который он не будет вот тебе глубинкой пересчитывать все с нуля. Он умненько пересчитает только то, что нужно. Все понятно. То есть у тебя есть функция от всей базы данных, а пересчет всего не будет, она поймет, что надо и как обновить, и будет пересчитывать только то, что нужно. Это как makefile, который, если поменялся один файл в проекте, то он пересоберет эту ветку до самого верха, но не будет все остальные ветки пересобирать. Я не осилил пока книжку. Я сильно подозреваю, чтобы для достижения этого тебе нужно там неслабо поиспользовать их примитивы, их фреймворк. Я не знаю, что у них там язык, не язык. То есть я вообще ничего не знаю про сальсу, но она тебе это сделает не просто так за бесплатно, тебе придется для этого немало попотеть. Я вот что хотел сказать. А возвращаясь к relational.ai, они взяли и пересняли это на джули, потому что у них все на джули. В смысле не вся суббда, но у них в заключательной части системы полагается на джули. Дальше нам дают некоторые подробности о том, как они хранят свои данные. Они используют для сокращения relational.ai, они используют сокращение RAI. Я сначала на слайдах увидел RAI, и я прям залип. У меня ассоциации с RAI в C++ или к каким-то бизнесовыми метриками. Это что за RAI? Короче, у меня заняло время понять, что речь идет про relational.ai, саму систему. Так вот, базы данных в RAI неизменяемые, и включая каталог суббда, то есть ты дописываешь имутабельные данные, которые ссылаются на данные, которые были до этого. Напомню, это графовая база данных, поэтому у тебя не обязательно происходит большое write amplification на произвольную запись в базу данных, но тебе нужно обязательно менять компаринс веб, некую структуру, которая указывает на текущий снапшот базы данных. Отмечается куча плюсов этого подхода, и у них есть garbage collection для данных, которые никто больше не видит. Отмечают такие преимущества, что нам больше не нужны локи, мы можем клонировать базу данных за 1, но я не очень большой эксперт, но мне кажется, что в такой структуре будут некоторые проблемы при интенсивной записи в много потопов, на что докладчик говорит, что они используют beta sigma деревья, и есть отдельный папер, который привлекомый в show notes про beta sigma деревья, я никогда в жизни не слышал про beta sigma деревья, но утверждается, что они write optimized. Вот такие дела. Теперь мне придется прочитать папер про beta sigma деревья. Читай, приноси. Или я могу положить на это хвост и не заниматься но будем посмотреть. У меня есть предложение, Валер, давай мы будем разделять труд. Я буду смотреть доклады, а ты читать и пробовать все дна. У меня там уже список всякого разного, я уже там пытаюсь оселить статьи. Количество статьи, которые хочу прочитать, оно растет быстрее, чем я хочу прочитать и осмыслить. Тем более, что некоторые из них, в общем-то, знаешь, бывает прям хочется прочитать, потому что они еще и входят в область моих рабочих интересов. Это такое, ну, то есть хочется же сесть, прочитать, а проанализировать, а сложно прям вот много времени выделить. Да, да, да. Хочется еще ядро подгросов подписать, а когда ты не пишешь, хочется еще и отдохнуть. Я все это прекрасно понимаю. А еще и GMZ есть. Вот, и в том же вы, существо, они в среднем стремятся избегать более дискомфорта, поэтому я, как нормальное живое существо, даже не планирую читать этот пейпер, чтобы не испытывать более дискомфорта по факту того, что я на самом деле не прочитаю. Ну вот, дальше докладчик рассказывает нам про джойны. Джойны у них тоже не как у всех. Они используют Worst-Cast-Optimal-Join-Algorithms. Это прям целая семеста алгоритмов, сокращенно WCOG. Простите, у меня, наверное, неправильно выписано, наверное Worst-Cast-Optimal-Join. Это имело бы намного больше смысла. Это класс алгоритмов. К ним относятся такие алгоритмы как LeapProc, TryJoin, LFJT, и ЯнашилПейпер. Он будет полинкован в шоу-нотах. А также еще два алгоритма, про которые я не смог найти пейпер. Подожди, подожди, стой. А ты расскажешь про этот пейпер или ты уходишь от него? Меня интересует… Ты длинное, страшное название сказал. И чем он отличается от не таких джойнов? В чем ты делаешь? В чем сила? Это отличный вопрос. Сила, как мы помним, в правде, а не в деньгах. А ответ на твой вопрос он находится в пейпере, который всего на 12 страниц. Окей, понятно. Я к тому, что, ребят, слушатели, если вы все это найдете, прочитаете, приходите и говорите, типа, нам вот это понравилось, мы можем даже с вами это обсудить в подкасте, если что. Видите, мы не успеваем все это читать. Для каждого джойна есть отдельный пейпер, но с ума сойти. Большой минус этого доклада, что этот конкретный докладчик пытался объяснить на картинках какие-то принципы работы этого Worst Case Optimal Joins. Я посмотрел на эти картинки, я ничего не понял. Там просто квадратики, стрелочки, ничего не понятно. Надо читать пейпер, разбираться. Вот, это Lipfrog TryJoin, это вот один из этих алгоритмов, по которому есть пейпер. Еще один называется GenericJoin, и вы можете представить, почему очень сложно найти пейпер по такому названию. Вот, и еще один называется DovetailJoin. Я узнал, что Dovetail, это когда у тебя, короче, просто погуглите по этому слову, когда у тебя брусья особым образом соединяются при строительстве дома или мебели, чего-то такого. Докладчик отвечает, что вот этот Dovetail, это алгоритм, изобретенный в январе 2019, и возможно, что пейпер еще в процессе выкладывания. Представляете, в январе 2019 он был изобретен, опробирован и всякое такое. В 2020 году ты, может быть, сел писать пейпер, а сейчас он на ревью в какой-нибудь конференции, может быть, его по этому и нет в интернетах. Это мои догадки. Вот, плюс он, докладчик приводит несколько других ссылок на другие пейперы. То есть, например, есть пейпер про WCLG алгоритмы применительных языку Spark и разные другие пейперы. Это все, все, все вы найдете в шоунотах. Если вас вот пейперы интересуют, я их все, по крайней мере, вот те, которыми показались наиболее важными, я их все выписал из доклада. Вот. Возвращаясь к языку Джулия, почему они так на него активно полагаются? Потому что они поддерживают компилируемое, это первое и второе, векторизуемое исполнение своих запросов. Они поддерживают и первое, и второе, и умеют их вместе. То есть, один и тот же запрос, он может быть частично скомпилирован, частично векторизован, и они это исполняют на своей системе. Про то, как это у них внутри работает, ничего не известно. Но они говорят, что это могут. Еще, Realational AI умеет семантическую оптимизацию. Это такая штука, что, ну, как пример, у тебя есть запрос на даталог, который, ну, переводя на человеческий язык, говорит, вот, найди мне определенные графы, графы базы данных, определенные структуры, там, по определенному критерию, а потом найди из них граф с наименьшим количеством узлов. На даталоге это будет выглядеть как некоторая декларация интересующих тебя графов, из которых ты вот, о которых ты берешь минимум. И семантическая оптимизация, вот эта фича их, означает, что, глядя на этот запрос, система может протолкнуть этот минимум ниже, в запрос на даталоге, тем самым сократив ресурсы, необходимые для завершения этого запроса. То есть, тебе вместо того, чтобы вот прям найти все-все-все-все-все графы, загрузить их в память, потом там из них найти какой-то минимум или, как бы, опять же, по одному их выгружая и сравнивая с последним, вот он там меньше или больше, вместо каких-то этих алгоритмов ты можешь сократить пространство поиска. Опять же, как это у них работает, я ничего не понял. Может быть, даже были какие-то ссылки на paper или 2 paper, но на этом этапе я перестал их выписывать. Ну, потому что их и так немало, и уж про семантическую оптимизацию на графовых базах данных это уже что-то, что я точно не буду читать. Вердикт по докладу. Очень много полезных ссылок, очень много клевых идей. Ребята разрабатывают на кровоточащем острие науке, но, к сожалению, очень мало деталей про то, как это именно работает, но зато много ссылок. Вот такой интересный доклад. Мне здесь было бы интересно почитать про пейтеры с графическими базами данных, мне это в целом почему-то любопытно, но я чувствую, что там так тяжело. Простите, я уже забалтываюсь. Да, в графовом, конечно, но нет. Это мое воображение или с графовыми базами данных прям какой-то ажиотаж?",
    "result": {
      "query": "relational.ai database review"
    }
  }
]
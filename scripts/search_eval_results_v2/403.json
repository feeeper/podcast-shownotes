[
  {
    "segment_id": "5dacde30-3383-4a53-9718-8889e80e75cc",
    "episode_id": "bcf9cf96-7230-4a7e-b197-ae906cf7713e",
    "episode_number": 403,
    "segment_number": 12,
    "text": "Мне кажется, что это такая правильная мысль, то есть движение в правильном направлении, если они достаточно много метрик собрали и увидели, что это работает, по-настоящему работает. Мне кажется, что подобную систему реализовать не так уж и сложно, потому что метрики чаще всего есть уже в системе, и максимум, что надо сделать, это какую-то небольшую бизнес-логику написать сверху для того, чтобы описать, что я хочу с этими метриками сделать это, а потом покажи мне результат, покажи мне ноды, которые больше всего ломаются на основе этих метрик. Вот такая вот идея. В чате Алекс пишет, что в автоматическом режиме такая система может привести к каскейдинг фейлор, если не быть очень осторожным. Я упустил немножко, то есть они не просто уведомляют о проблемах, они автоматически пытаются их решать. Ну вот эта вот размытая часть в пейпере, которую я не до конца понял, они позволяют, в основе их идей, да, они позволяют делать рестарт сервиса, рестарт виртуальной машины или рестарт хоста, или остановку виртуальной машины и хоста. Но они в самом пейпере не говорят, что мы выбрали это или мы делаем одно с другим, или еще что-то такое. Насколько я понял, они делают все-таки рестарт сервиса и email каким-нибудь админом. И я полностью согласен, что это нельзя включать в автоматическом режиме, чтобы оно само чинило, пока не собрано достаточно данных. Потому что, во-первых, даже сами авторы пейпера делают сноску вида, вы знаете, мы тут вот эту систему придумали, но вот эти коэффициенты, которые мы здесь указываем, коэффициент номер 2, 15, 78, они подобраны нашей системе по историческим данным. То есть мы просто их таким образом подогнали, чтобы на самом деле было минимальное количество аутлайеров, которые на самом деле с ними что-то не так. Эти коэффициенты, скорее всего, вам не подойдут, но вы попробуйте, но скорее не подойдут, чем подойдут. И запускать это вслепую сразу у себя, я вообще бы побоялся, это первое. Второе, системы, которые могут в автоматическом режиме влиять на продакшн, выключая, перезагружая и так далее, это очень опасная вещь. Я полностью согласен, можно убить свой продакшн просто из-за того, что это будет еще одно действующее лицо, которое внезапно без разбора начнет кого-то дубасить, выключать, перезагружать, это реально опасно. Но если вы в аккуратном режиме, скажем, не чаще, чем раз в час делать какое-то действие, и это действие – это рестарт какого-то сервиса или запуск какой-нибудь процедуры для того, чтобы какую-нибудь Амазонноду вырубить и вместо этого запустить все то же самое на другой Амазонноде, мне кажется, это достаточно безопасно, особенно если вы будете иметь какой-нибудь список разрешенных сервисов для рестарта. То есть какую-нибудь Кассандру или, не дай Боже, какие-нибудь большие стейтфул системы я бы не трогал, а вот какие-то небольшие, которые мало стоит внутри себя содержат могут спокойно рестартоваться, я бы, может быть, и поставил в автоматическом режиме. Да, я согласен. Тут Алекс еще пишет, что вот это переключение между неработающим и работающим состоянием, и оно может влиять на историю и на то, что неправильно будут рассчитываться коэффициенты, то есть как бы вот машина включилась, у нее 0 таймаутов, а она не работает. Но у нее 0 таймаутов просто потому, что к ней еще запросы не приходили. Там это тоже обсуждается, и там делается окно, 10-минутное окно предыдущих данных, на основе которого делается расчет, там немножечко про это касается они. Но да, конечно, мне в этом смысле как раз статья показалась немножко поверхностной, потому что очень много подобных крыльевых случаев, которые надо учитывать, я их не вижу в статье. Взываю к Валере. Валера, Валера, приди. Ты хочешь, чтобы я тему сменил, или ты хочешь, чтобы я какой-то комментарий дал по поводу происходящего? И то, и другое, но только в обратном смысле. Я тогда статью меняю. Все, поздно, ты меня вызвал, я пришел и закрыл вечеринку, какой я плохой. А дальше снова Саша на тему. Ха-ха-ха. Да, что ж, давайте поговорим о базе данных. Но эта тема будет короткой. Рубрика «Саша смотрит записи старых докладов с PidgeCon», в этот раз доклад 2019 года, называется «Inter to Postgres Planner Hacking», читает Мелани Плэйджман. Мелани – это широчайший, известная в очень узких кругах разработчица, изначально Greenplama, теперь уже в Майкрософте. И она рассказывает, как ковыряет планировщик в Postgres. Из доклада мы узнаем, что в Postgres есть отладочные ручки для парсера, планировщика и rewrite rules. Их можно включить командой set debug.print.parse.to.on, и также есть debug.print.plan и debug.print.rewritten. И еще нужно поменять лог-левел, который выводится, чтобы вам в лог-файл не смотреть, а прямо из PSQL все видеть. Меняем лог-левел на, он называется client-min-messages, на уровень log. И у вас прямо в PSQL, когда вы запросы исполняете, будет выводиться дерево пропарочного запроса, дерево плана и так далее. В принципе, в X-Plane есть нечто похожее на планы, поэтому, наверное, это полезно в основном разработчикам. Выводятся структуры в мне незнакомом формате, то есть он ни на что не похож, это ни JSON, ни XML, ни CSV, это какой-то очень мне незнакомый формат. Было бы удобно, если бы это был сразу GraphVis, чтобы по нему строить картинки. В этом докладе используются картинки, построенные по выводу отладочному, но я так понял, что они были сделаны в докладе часы вручную. Если кто-нибудь знает, что это за формат такой и как его перевести в картинки, вы, пожалуйста, расскажите. Я не знаю, честно. Дальше Мелани рассказывает, что она посмотрела на патчи, которые предлагались в планировщик с 2014 года и посмотрела на причины, почему они отклоняются. И у нее есть топ-4 причин. Это правила имени Мелани. Во-первых, трансформации должны быть семантически корректными во всех случаях. То есть если вы придумываете какие-то правила преобразования запросов, они должны не менять семантику вообще во всех случаях. Как своего рода подпункт, но вынятим его отдельно, что вот эти оптимизации не должны препятствовать дальнейшим оптимизациям. То есть это не должна быть такая финальная ветвь на итеративном процессе оптимизации запроса. Пункт третий. Нужно учитывать само время, которое уходит на планирование, потому что оно складывается со временем исполнения запроса. Если вы придумали оптимизацию, сделать которую медленно, то она не очень полезна. И плюс четвертый пункт, что если вы придумали оптимизацию для каких-то редких случаев, которые очень редки, до которых большинству людей нет дела, то вряд ли сообщество примет от вас патч, который предлагает огромный развесистый фреймворк на 10 тысяч плюс строк-коды, который решает вот эту маленькую проблему, до которой никому нет дела. То есть в целом изменения в планировщике должны быть универсальными, быстрыми и решать проблемы, до которых есть дело больше, чем одному или двум людям. Дальше она описывает сценарий. Сценарий такой. В Puzzle Gratia у тебя есть оператор Any. Ты можешь сделать select что-то откуда-то и взять это все в Any. И семантика такая, что ты можешь вот это Any от select сравнивать со значениями. Получается довольно удобно.",
    "result": {
      "query": "Postgres planner debugging tools"
    }
  }
]
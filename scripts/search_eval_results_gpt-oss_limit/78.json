[
  {
    "segment_id": "74d113a8-49cd-493f-944c-4699245c7007",
    "episode_id": "b2b29131-bec9-4209-ba74-3b776e8cd208",
    "episode_number": 78,
    "segment_number": 5,
    "text": "Так что... Не знаю, может быть что-то не так настроил, конечно. Ну, я могу еще попробовать. Не, как бы я не настаиваю, я просто говорю, что он в принципе довольно няшен и, ну, возможно, что-то ты действительно не так сделал. Слушай, давай расскажи, я немного отходил, вы уже поговорили про вот этот Dynamic Time Warping? Нет. Давайте обсудим, может. Ну, это такой метод... Метод, посчитать, схожий с двух временных рядов, по сути. Ну, примерно как и в клидовое расстояние, только немножко сложнее. Вот. Извини, я перебью, меня всегда волновал, знаешь какой вопрос? То есть я примерно знаю, что это такое, но мне всегда было непонятно, вот можно взять, там, не знаю, при помощи этого метода найти куски тайм-серии, которые похожи, не зная при этом заранее, где они расположены? Да, то есть у тебя должен быть какой-то паттерн, заранее известный, вот, какая-то форма сигнала, например, и ты можешь ее искать по своей базе данных. Но вот по сути это такая очень классная фича, которая должна быть в нормальной базе временных рядов, потому что, ну, ты можешь выполнять запрос, ты можешь выполнять запрос в KMM... Давай уточним, в нормальной General Purpose базе временных рядов. Ну да, для мониторинга это не очень нужно, это нужно для всяких промышленных вещей, там, для, ну, не знаю, мониторинга чего-нибудь. Ты можешь заранее определять всякие кондишены, когда у тебя что-то ломается, например, потому что ты знаешь, что при этом у тебя фронт временной ряд выглядит определенным образом. Резкий обрыв, потом какой-нибудь скачок, не знаю, все что угодно. На ЭКГ, насколько я знаю, тоже форма вот этой волны, сердцебиение, пульс, там тоже каждый пик, он что-то значит, и определенные болезни, определенные нарушения, они вызывают искажение вот этого временного ряда, по сути. И с помощью этого алгоритма можно искать эвкалидовым расстоянием, банально. Расскажи подробнее про детали этого алгоритма. Он довольно сложный, ну, я, пожалуй, не буду его расписывать. Он решается методом динамического программирования, но там, по-моему, сложность квадратичная в итоге получается. Его решают, есть алгоритм fast dynamic time wrapping, там есть lower bound, то есть создается какая-то ошибка, которую можно получить, ну и считается это все за линейное время, точнее, по-моему, даже за n log n. Что такое? Ну, в общем, я не помню точно. Ну, в общем, это одна из фич, которую я планирую добавить обязательно. Мне почему-то кажется, что если будет существовать база данных временных рядов, которые будет уметь читать DTV, это будет очень круто, и это позволит создавать какие-то новые приложения, которые сейчас создавать нельзя. С текущего посторснина DTV. На самом деле, это много где используется, просто довольно сложно описать, зачем это нужно. Мне интерес, скажем, немножко полупрофессиональный, можно ли этот метод, и вот в частности этот алгоритм, либо какие-то его моменты использовать для определения похожести цепочек ДНК? Либо это абсолютно никак не применимо? Вот, скажем, почему я интересуюсь. Цепочка ДНК можно элементарно представить в виде временного ряда. И, естественно, если у тебя есть реализация Dynamic Time Wrapping, есть такой запрос, ты можешь гонять Nearest Neighbor запроса в своей базе и получать похожие цепочки ДНК. Вы подобную штуку делали в Грэй Сити для того, чтобы определять, нали ту причину проблемы, которая происходит сейчас на продакшене? Для мониторинга это можно использовать для того, чтобы искать корреляции, например. То есть где-то что-то сломалось, ты смотришь на одну серию и пытаешься понять, что еще себя ведет не так. Ну и, естественно, если у тебя скакнул ЦПУ как-то странно на одном графике, он может быть точно так же скакнул где-нибудь еще, и ты можешь сделать такой запрос, получить все временные ряды, которые в этом интервале времени вели себя похожим образом. Ну, в принципе, даже для мониторинга это может быть полезно. Я знаю, даже есть какая-то консортная система мониторинга, я не помню, кто ее делал, они делали нечто похожее. Там, правда, не Dynamic Time Wrapping, но там они преобразовывали временной ряд в текст и хранили его в эластике. И потом в эластике искали корреляции. Ну это довольно прикольно, но проект уже сдох, к сожалению. Я, честно говоря, забыл, кто это и как называется. Расскажи про Saks, это тоже одна из фичей, которые ты собираешься добавить? Ну это одна из фичей, которые я добавил уже, у меня есть такой запрос, только у меня нет такого индекса. По сути, Saks это метод преобразования, это расшифровывается как аббригатура, символик Aggregate Approximation, то есть это метод преобразования временного ряда в текст. После того, как вы преобразовали временный ряд в текст, по сути, множество слов фиксированной длины. Там можно задать размер алфавита, например, можно использовать только 4 символа или 8 или 10. И длину сквозящего окна, то есть у вас все слова будут одной длины. И дальше вы это все можете индексировать и так далее. То есть использовать все методы Information Retrieval, использовать инвертированный индекс, использовать TF и DF. Для того, чтобы это все искать. Ну и по сути это тоже метод гонять NearSnaper по своей базе. Но тут нужно заранее все это как-то заиндексировать и где-то сохранить. У меня есть такой запрос, он позволяет преобразовать временной ряд в Saks представление и выдавать его. Но я еще не реализовал индекс. Помимо этого на основе Saks можно сделать детектор аномалий. Я тоже над ним начал работать, он тоже еще не закончен. В принципе, довольно просто все. Вы считаете Saks для каких-то интервалов времени, допустим, 10 минут. Потом считаете похожесть этих двух регионов, соседних. Если они сильно отличаются, можете сказать, что это аномалия. Можно как-то все параметризировать. Круто это тем, что это можно сделать так, что не нужно будет задавать параметры никакие. То есть это детектор аномалий, который работает сразу из коробки. И он не на статистических свойствах работает, а именно на форме сигналов, на форме данных. То есть он может... аномалии могут быть, то есть какие-то точечные или статистические. Могут быть аномалии, которые... Сигнал находится в абсолютно нормальном диапазоне, но форма сигнала какая-то такая, какой никогда не было. Вот, например, для данных ЭКГ это очень клево и вообще ничем не заменимо. Для мониторинга, мне кажется, тоже полезно, потому что просто настроить. .. Точнее, вообще не нужно настраивать. Круто. Есть еще другие применения. Можно считать... Блин, у меня вылетело слово. А, мотив. Ну то есть какой-то отрезок серии, который постоянно повторяется. Можно найти его, можно кластеризовать временные ряды. То есть похожие временные ряды сгруппировать вместе. Если заранее неизвестно, что означает тот или иной временный ряд. И, например, хочется гонять Хольт Винтерс, Хольт Винтерс можно гонять только на похожих временных рядах, которые ведут себя одинаково. Одна и та же сезонность, ну то есть одна и та же природа, по сути. Таким образом можно найти такие ряды. Ты перегрузил лично меня, например. И я имею ощущение, что я подкаст буду потом переслушивать. Просто что... Извини. Да нет, ну если это не то, то хорошо на самом деле. Потому что редко у нас получаются настолько хорошие, насыщенные выпуски, когда все-таки с хардкорчиком и этим всем. Поэтому на самом деле это хорошо. Я просто перечитал здесь ресерчи за последние не знаю, несколько лет. Ну все самые такие пейперы популярные. Так что я могу долго продолжать. Нет, на самом деле это просто с моей точки зрения это потрясающе. Практически на голом энтузиазме пилить проект, настолько ресерчуемкий. Ну то есть я видимо даже недооценил, сказав, что ты один из немногих людей, которые занимаются темой. Но ты не просто темой хранения занимаешься, ты темой вообще всего занимаешься. Это похоже просто уникальная опенсорс штука пока получается. К Сашиному вопросу о плюсах. О плюсах? Ну то есть Саша в начале подкаста спросил, есть ли какие-то уникальные вещи, которые у других нет. Ну вот это все. Ну это все пока еще не очень работает. Ну хотя бы пилится. Детектор аномалий работает. Все что работает нормально. Жень, расскажи давай уж как-то добьем тему. Ты добавил еще ссылку на Nonvolatile Storage. Что это? Ну это просто интересная статья, которую мы перечитали. На самом деле мы тут в позапрошлом выпуске с гостем, я попытался его вывести на Nonvolatile Storage базы данных, но он сказал, что не имеет глубокого ресерча в этой области, поэтому он пока не будет комментировать. Я статью не читал, Евгений ее читал. Евгений, расскажи мне о чем статья. Статья о том, что... Ну на самом деле это кстати тоже можно связать с Akumul. Просто у меня основная идеология заключается в том, что в принципе для большинства применений достаточно одной машины, потому что на современном сервере можно обрабатывать огромное количество данных, огромные объемы данных временных рядов. Они довольно легко обрабатываются, то есть там какой-нибудь музыковой речи посчитать для миллиона временных рядов, вообще ерунда. Там все будет ограничено скоростью чищения из диска, наверное. Вот. Статья о том, что возможно скоро это все будет ограничено скоростью работы CPU и количеством памяти, потому что сейчас появляются, эффективно начинают эксплуатироваться всякие клевые штуки, которые называются Storage Class Memories. Ну по сути это SSD, ну это флеш, накопитель, который работает через PCI Express. Он может быть порядка, ну примерно в тысячу раз быстрее работать, чем жесткий диск. И в принципе, большая часть статьи посвящена тому, что современный стэк, операционная система и приложения, и база данных, в принципе, к этому не готова. Потому что там может быть порядка 100 тысяч операций чтения в секунду и очень мало времени у одного процессора на обработку каждой страницы, которая оттуда прочитает. Ну, в принципе, с чем-то похожим. О чем-то похожем я даже говорил, у меня в проекте скорость записи базы данных ограничена процессором. Не скоростью записи на диск, который еще очень далеко. Где-то я процентов 10 пропускные способности использую на записи. На такой машине с таким девайсом, с таким, я не знаю как назвать, это уже не SSD. Ну, в общем, все будет еще хуже. Ну, примерно что-то похожее происходит с сетевыми контроллерами. Сейчас появились очень быстрые сетевые контроллеры, которые, в принципе, могут поставить колом любой сервер. То есть обычная машина, обычная операционная система не в состоянии утилизировать такой сетевый контроллер на 100%. Люди сейчас пишут всякие сложные штуки, там, kernel bypass и так далее, чтобы в процессе обработки пакетов не участвовало ядро. На самом деле мне казалось, я видел какую-то срывающую с покрова статью с kernel bypass, но я, к сожалению, ее не прочитал еще. Какой-то известный хостер, у них есть блог, и они там написали несколько статей на эту тему. Там название было что-то в духе как «отправить или передать миллион пакетов в секунду». И они там передавали миллион юдапакетов. Да, да, мы обсуждали эту статью. И настраивали Linux таким образом, чтобы все прерывания там опрабатывались на разных ядрах и так далее. Вот такие дела. Мне кажется, что-то подобное должно появиться и для таких жестких дисков. Плюс еще незагоральные времена, когда появится... Ну вот Intel недавно что-то там публиковали по поводу технологии новой 3DXPoint. По сути там скорость чтения записи сопоставима со скоростью работы обычной оперативной памяти. На самом деле мне интересно, когда это все появится в наших обычных продакшенах, потому что я верю, что все эти офигенные блиггин-эйдж технологии, что они действительно могут поставить на колени современные CPU. И я понимаю, что современные CPU проблемы со скеррингом, но с другой стороны, не знаю, года два назад проблемы со скеррингом были у жестких дисков и SSD. А сейчас они, получается, обгоняют CPU. И вот мне интересно, когда они у нас окажутся в нашем реальном продакшене, и будет ли это все еще проблемой в тот момент. Слушай, такие вот SM они уже продаются и их нужно купить. Ну, за сколько денег? За много денег. Ну вот. Есть вариант дешевого селфхоста-железа, дорогого селфхоста-железа и Amazon. Большинство людей выбирают Amazon, несмотря на то, что сравним с дорогим селфхоста-железом. Там даже еще 64-ядерных серверов нет, там по-моему 32 ГБ, это предел, который можно купить. А селфхоста-железа, которая совсем селфхоста-железа, ну там, допустим, можно делать фэнси конфигурации в плане размера оперативоньки и CPU, но ничего даже близко к nonvolatile memory, то есть если ты сам не поедешь, не купишь плашку и свой собственный дата-центр не доставишь, то никто тебе это не поставит. Нет, но SSD тоже не быстро возникло, оно плавно развивалось, увеличилось, сейчас это уже везде. Ну да, сейчас это даже на Амазоне есть, вот я про то и говорю. На самом деле в статье есть страшная цифра, там написано, что SSD начали появляться 10 лет назад. Я понял, какой я старый. Мне кажется, что это недавно началось. Ну, сам я помню свой первый ноутбук с SSD, это было лет 6 назад. Ну, у меня примерно так же. Я не помню точно момент, когда это все начало появляться, но наверное да, лет 6-7 назад. То есть появилось в мире еще раньше, до простых смертных, оно докатилось лет 6 назад. То есть в случае с SSD оно вначале попало именно на консюмерское железо, а потом на сервера, потому что на сервера долгое время боялись ставить. Ну, кстати да. Я помню еще была новость где-то в 2009 или 2008 году, когда Google стал заменять обычные жесткие диски на SSD дата центра. Это было вообще ого, никто такого не делал. Все боялись. Окей, я предлагаю ехать дальше на самом деле. У нас тут Александр побывал на интересном... Ну, кстати говоря, я уже слышал полярные мнения об этом мероприятии, но тем не менее, поскольку у нас там был Александр, я дам ему слово. Полярное мнение, это интересно, да. Я слышал, знаешь, что собрались импортозамещатели и замещали импорт, и мол ничего интересного не было. Ну, понятно, да, всегда будут недовольны. Ты знаешь, если вот читать наши комментарии, то подкаст говно и вообще слушать не надо. Вот из этой же серии. В любом случае, да, эту тему я готовил последние три дня. Я сходил на APG.conf, был там на первом дне с мастер-классами, и потом еще два дня конференции. Нас просят говорить поменьше про конференции в подкасте. Мастер-классы? Мастер-класс. Постараюсь кратко рассказать. Я выделил три доклада, по одному на каждый день, которые, на мой взгляд, самые интересные. Буду их рекомендовать. Из мастер-классов мне больше всего понравился доклад Ильи Космодемьянского из компании PostgreSQL Consulting. Говорят, он часто выступает с этим докладом, и, ну, собственно, по докладу видно, он такой отрепетированный, хороший. Доклад про настройку операционной системы и железа для PostgreSQL, так, чтобы у него было все круто с производительностью. Вот, по-моему, доклад совершенно огненный. Идет он, поскольку это мастер-класс, часа три. Но мне просто... я очень сильно радовался, потому что там прям ответы на все. Какие сервера, каких производителей брать. Если вы там хотите арендовать сервер, то у какого провайдера. Спойлер, производитель хороший Dell. А провайдер Webzilla. Как он там? Блин. Нет, нет, Webazilla или как-то так называется. Ты лучше знаешь, что скажи, чтобы слушателей, и в частности те, кто не имеет возможности сходить. Это где-нибудь видео есть или это нужно... Да, да, да, я хотел об этом вообще сказать. Смотри, видео будет, обещали, с одной оговоркой, что некоторые иностранные докладчики могут иметь долбанутый трудовой договор, который запрещает публикацию видео, докладов этих сотрудников. Если не будет таких странных участников иностранных, то видео будет все рано или поздно. Если будут, то, соответственно, таких видосов не будет. То есть, по идее, все видеоматериалы должны быть доступны. Так, собственно, это, наверное, все про доклад. Я его всячески рекомендую, мне он больше всех понравился. А, да, кстати, я тут говорю про доклады, которые понравились лично мне. Там, например, были интересные доклады, содержание которых я немного знал, скажем так, и поэтому я их здесь не называю. Следующий доклад, который мне понравился со второго дня, ну, в смысле с первого дня конференции, который не мастер-класса, доклад Юрия Соболева «Постгрэс, Елька, Кедро, Биржи, Интернет, Реклама», при том эта биржа — это Edster.com. Мне он понравился тем, что ребята за очень короткие сроки, за пять месяцев, используя фактически один только постгрэс, сделали готовый продукт, наверное так надо сказать. То есть, сделали биржу интернет-рекламы, которая там работает быстро, работает хорошо. Я не помню уже точно деталей, которые меня так зацепили, но доклад оставил хорошее впечатление, я его обвел кружочком специально. И еще один доклад — это Грегори Старк «Сортировка. Прошлое, настоящее, будущее». Он на самом деле не то, чтобы там срывает покровы про новейшие изменения в области сортировки за последние пять лет или что-то в этом роде. Он такой хороший исторический доклад, как в 1995 году в PostgreSQL была реализована по книжке Кнута сортировка. По-моему, она сначала была даже без варианта, чисто в памяти, то есть сортировалась только на диске. И как ее в последние 20 лет, 1995, ее улучшали, какие баги находили. Например, там был забагный баг, из-за которого использовалась только половина доступной оперативной памяти, из той доступной, которую ты в конфиге указал. Но никто на это не жаловался, года до 2008, потому что ни у кого не было так много оперативной памяти, чтобы это было прям реально большой проблемой. И самую большую ценность представляет последний слайд, на котором идей по тому, куда двигаться дальше. Интересен он тем, что речь идет про то, что сортировку можно распараллеливать, она еще не распараллельна. И вообще ее можно делать на OpenCL, на CUDA и на подобных вещах. И вообще там можно половину PostgreSQL при желании ее переписывать на OpenCL, можно прям всю жизнь этим заниматься и следовать. Мне, кстати говоря, всегда возникает такое ощущение, что мне где-то наебывают, когда говорят про OpenCL. Потому что, насколько я помню, он хорошо работает для очень хорошо векторизуемых вычислений, а сортировка не звучит как очень хорошо векторизуемые вычисления, и джойны не звучат как хорошо векторизуемые вычисления. При этом очень много говорят про BD на CUDA и BD на OpenCL, и то ли оно все стало сильно лучше с тех пор, в чем я сомневаюсь, потому что железо видеокарт не сильно менялось. Ну, слава богу, оно теперь скорее всего поддерживает гораздо больше, но не то, чтобы это было прям колоссально быстрее, чем CPU. Или я чего-то очень не знаю про то, как они собираются это делать. Я сам не могу сказать, что большой специалист в этой области. Там была какая-то ссылка на один пейпер, когда будут слайды, слайды. Я, кстати, думаю, уже давно все лежат где-то на слайдшере, а видос будет позже. То есть там реально есть какой-то пейпер, в котором речь идет про реализацию сортировки на OpenCL. Я еще в минуту всегда задавался таким вопросом, а вот у нас клауд-провайдеров, то вообще кто кроме Амазона дает железо с GPU? Ну, подожди, есть, конечно, клауд, но что тебе мешает арендовать именно железки? А там примерно то же самое, проблема, в том же дата-центре тебе привезут такой сервер, или тебе придется самому заказывать и везти в дата-центр? Скажу тебе честно, не задавался таким вопросом. То есть, ну, как-то не было нужды. Еще хочу отметить, это были три доклада, которые я рекомендую. Если не знаете какой посмотреть, хотите посмотреть один, то смотрите мастер-класс про оптимизацию постгресса, тем более он довольно длинный. Хочется отметить, что кормили много, кормили вкусно, и был даже вариант, есть салатики, такой диетический вариант, хотя, конечно, много из еды было, всякие пирожки такого рода. Сообщается в группе в фейсбуке, что 602 человека пришло, и 60 выступали с докладами, не считая близ докладов. По-моему, в Москве собрать 602 человека, которые интересуются постгрессом, это, ну, не знаю, успех. Было два доклада чуваков из Хироку. Честно говоря, они мне не очень понравились, потому что, ну, они такие, типа, ну, мы делаем Хироку, Хироку живет в Амазоне, Амазон говно, все время все ломается, и мы от этого сильно страдаем. Ну, как бы, используйте Хироку. Подожди, а они не сказали при этом, как они со страданиями борются? Потому что вот как раз страдания постгресса на Амазоне, такая тема, которую лично я бы хотел послушать. Ну, как они борются? Они все автоматизируют так, чтобы оно самоочинилось, чтобы им клиенты звонили. Ну, вот так. Ну, они не выложат в open source себе? Нет, ну, может они хотя бы какие-то такие вот общие методики рассказывали, что у них работает. Мы здесь поставили звуки, вот написали скрипт, который уходит в звуки, там вот это все. Или там, не знаю, не звуки, а etcd, whatever. То есть они даже до этого не спустились. В этом проблема, да. Они сказали, ну, мы короче все автоматизировали, и теперь оно самоочинится. Вот, ну и там еще, по-моему это в их докладе они упоминали volley, это инструмент для заливки write-ahead-log в S3. Если я ничего не путаю, может быть это было вообще в другой презентации. То есть это, может быть я не совсем правильно помню, ты понимаешь, да? Три дня это так много информации. Можно будет записи делать. Я вот когда на Кореолу не ездил, специально прям записи делал. Вот, мне очень понравилось, они сказали интересную вещь про MySQL. Ну, поскольку у чуваки вообще много ездят по конференциям, да, и общаются с разными тусовками, у них такое есть наблюдение, что MySQL и его форки, там всякие MariaDB, вот это все, они вообще потихоньку умирают, потому что все либо с них валят, либо просто не используют. Очень много пользователей именно у Postgres, его особенно любят, ну, со слов чуваков из Хироку, очень любят в сообществе Ruby программистов. То есть это прям такая, когда Ruby программисту нужно на что-то поставить рельсы, да, вот прям все поголовно берут Postgres, говорят чуваки из Хироку. А еще есть очень большое сообщество программистов на Node.js, которое пока не очень большое, но оно зато растет очень быстро. Самое быстрорастущее сообщество программистов в мире. У них другой дефолт, они прям все любят мангу. Сюрприз, сюрприз. Да. Мне кажется, я знаю, куда бомбы сбрасывать. Куда? Я тоже хочу знать. Ну, в смысле, берем тусовку Node.jsеров, сбрасываем бомбы и там, короче, одновременно погибают сразу все мангарасты. Ну, они, я боюсь, децентрализованы, то есть тебе, наверное, нужно все-таки вирус, который их в зомби превратит. Они же уже нет. А, то есть не заэффектят. Так, так, так, я сказал про доклады. Еще, например, был мастер-класс про то, типа, итак, ты хочешь стать коммиттором в Postgres, тогда тебе нужно сделать следующие шаги. Но поскольку, ну, то есть мне по понятным причинам был этот доклад не очень интересен, но слушателям он может заинтересовать. Еще был интересный доклад про устройство индексов в Postgres и какие там работы ведутся. Доклад Анастасии Лубенниковой. Вот, очень интересный, ну, может быть нашим слушателям. То есть я, в принципе, узнал не слишком много нового для себя. А я его, кстати, может быть, даже и послушал бы, потому что я, в принципе, интересуюсь устройством всяких разных индексов в разных местах, и, наверное, даже послушал бы. Я думаю, он тебе понравится. Там есть про две фичи, которые только появятся в 9.6, может быть. Вот доклад следующий, вот точно для Валеры. Костя Книжник рассказывал про то, как он со Стасом делает распределенные транзакции для Postgres. Вот проблема у этого конкретного доклада, что Костя, он очень умный, даже не скажу парень, он скорее дядя. Но он как-то не очень удачно изложил, представил идею, как мне кажется, что они в сущности делают. Как там потом еще в кулуарах я уточнял. Берется Postgres, берется Raft. Ты на Raft выбираешь лидеры, в которые идешь с транзакциями на чтение, на запись, в основном на запись. И к этому прикручен еще дополнительный обмен сообщениями, который тебе делает, как это называется, Serializable. Уровень, да? Так это произносится. Подожди, а зачем, если ты выбираешь лидера, зачем тебе еще отдельный дополнительный сообщений для установления Serializable? Для сериализации, да. Ну а зачем тебе при этом, если у тебя уже есть лидер, выбранный Raft, зачем тебе еще что-то делать? Или все-таки у тебя шардированные... Валера, выслушай, нет, там шардинга нет пока. Там проблема заключается в том, что у тебя на всех нодах одновременно должно... Либо ты ни на одной ноде не видишь изменения, либо ты их видишь сразу на всех. Тебе вот чисто Raft из коробки, вот просто с репликацией этого не дает. А, подожди, то есть оно без шарда, но типа мультимастер? Да, мультимастер и пока без шарда. Мультимастер, но с выбором мастера. С выбором лидера, который хранит некую служебную информацию для... Ну, там... То есть по идее, если ты выбрал лидера, то в моей точке зрения обычно лидеры сериализуют. Так ты ходишь с запросами не только на лидера. Да, да, это так. Но у тебя лидер занимается сериализацией, если у тебя лидер просериализовал, то ты потом... Или типа что они должны запремениться на одновременно на всех, ты это имеешь в виду. И это тоже, то есть ты можешь пойти с чтением вообще на другой мастер, понимаешь. Да, ну вообще это интересно, это было бы интересно послушать, у меня в принципе есть идеи, как это можно было бы сделать, но да, это очень интересно. Вот, вот, вот. Так, наверное про Костю Книжника это всё. А, да, был ещё круглый стол и, наверное, вот сетел. Подожди, а Костя Книжник, он тоже... это микро доклад был или доклад уже есть в видео и слайдах? Я думаю, что слайды уже где-то есть, видео, я думаю, будет сильно позже, потому что его надо смонтировать. Кстати, Саш, мне знаешь, что такое вопрос? Оно у них сериализуемое или линеаризуемое? Я не знаю, честно. То есть обычно про термин реализация, термин линеаризация вообще никто не использует, так говорят про, типа, это snapshot isolation, это read committed, вот, по 4 уровня. Да, я знаю, но фишка сериализации в том, что сериализуемое не обязано быть линеаризуемым. То есть, грубо говоря, с точки зрения здравого смысла, сериализуемый уровень изоляции может давать довольно безумные штуки. Окей, да. Так, и что я ещё хотел сказать? Да, был круглый стол и там, наверное, вот больше всего на нём людям бомбануло, и они пошли в Твиттере писать всякие негативные вещи, потому что там действительно собрались не очень технические люди и говорили разные странные вещи, а потом из аудитории ещё более странные люди задавали вопросы из разряда, почему, блин, Рудцентр мне до сих пор не сделал российского Амазона на конференции про Посгресс, они спрашивают, это, не знаю, Наталья Касперская, например. Да, и, кстати, вот Наталья Касперская, она на удивление интересные вещи говорила, то есть, ну, не знаю, я вот прям прислушивался и радовался. И очень интересный рассказ у неё был про сервера Хьюлет-Паккард, я вот хочу поделиться этой информацией с слушателями, потому что для меня это стала новостью. Оказывается, у Хьюлета есть такие интерпризные сервера, ты их когда покупаешь, ты там подписываешь бумажку, что типа у тебя должна быть техническая поддержка, ну, типа раз в год приходить и смотреть на этот сервер. И оказывается, в этих серверах есть очень специальное ПО, в смысле прошитое в прошивке у сервера, который вот этот инженер, который делает техобслуживание, должен время от времени вводить серийники. И если ты пропустил случайно по любым причинам, мы помним, да, импортозамещение, вот это всё, если по любым причинам ты пропустил техобслуживание, то у тебя очень быстро твой сервер превращается в очень дорогую тыкву. Ну нихрена себе, я, честно говоря, прихванил бы, то есть покупаешь железо, оно типа моё, но нет. С ума сойти. Ну, да. Вот такие оказывается есть сервера. Я реально этого не знал, я реально прифигел. Ну, прифигел это очень мягкое слово для того, что испытываю сейчас я. Это прям нужно каждый год вводить, либо первых 5 лет, а потом всё? Я честно не знаю. Ну, то есть я так понимаю, что у этих серверов есть SLA, что он не ломается очень много времени, при условии, что на него сможет специальный инженер. А если серийник не вводить, ну, кто знает, может этот сервер украли, например. То есть я понимаю, что оно может быть не обязательно с очень злым и умысленно сделано, но сделано по-пидорски. А человек будет сам приезжать к тебе, либо ты будешь его ещё и привозить? Нет, ну региональное представительство какое-то есть. Ну, надо, наверное. Вот, ещё я развиртуализировался с Аней и Женей, помните, к нам приходили, они это ребята, которые делают хэппидэв в Омске, которые за Solid Principle и вот это всё. Да, и внезапно я сделал близзадоклад, там была секция близзадокладов на 5 минут, я рассказал, почему NoSQL это более унижение, и что его как основную базу данных не нужно использовать точно, а для неизменяемых данных и всякой аналитики, ну, может быть. Ну, ты же не прав, это же всё очень специфично от проекта. Ну, давай вот выложат запись доклада, и ты мне потом скажешь, что я сказал неправильно, окей? Ну, ты же сам всегда любишь говорить, что нельзя, что только ситхи всё абсолютно возводят. Я сказал, что по моему опыту оно работает, вот знаешь, из разряда вот мы возьмём и в качестве основной базы данных возьмём Кассандру, и будем там хранить всё, и нам не нужны транзакции, и мы можем иногда чуть-чуть терять, потому что Last Strike Wins, это работает плохо. Согласен, но с другой стороны, вот у нас основная база данных это React, и мы счастливы. У нас есть транзакционное хранилище, там где нужна транзакция, но основная база данных для юзер-стейтов, которая трогается на 100% запросов, это React. Основная это с точки зрения объёма данных, наверное, да, ты имеешь в виду? Ну, да. То есть у нас точно так же было, да. Ну, и понимаешь, что очень специфично твои доменные области. Опять же, и что касается рекламы, которые работают, то у нас Aerospike прям рулит и бибикает прям везде. Короче, разбомбили твой доклад. Я бы послушала, конечно, аргументы. Я думаю, я рано или поздно напишу пост, как только мне станет не лень. 10 причин, почему не нужно использовать NoSQL. Ну, да. А потом следующая статья сразу 10 причин, почему нужно использовать NoSQL. А потом просто бегаем со сковородками и, короче, собираем жир. Нет, потом ещё 10 специалистов, которые любят SQL, потом 10, кто не любит SQL. Я не виноват, что людям нравится такое читать. Вот, Саша, буквально сегодня или вчера есть такой в Erlang-сообществе человек, Дима Демант, написал, что имел конверсацию в Твиттере с Франческой Черзарине по поводу свежевыходящей книги, которую мы уже обсуждали. И там туда ещё несколько людей присоединились, и потом там ещё пост на Medium случился. Суть в том, что все книги по Erlang, они, короче, как вот в той картинке, как нарисовать сову. Нарисовать там типа 4 окружности, потом вторая картинка, нарисовать остатки совы. Вот так и тут, что они все исследуют ATP, исследуют ещё что-нибудь. А как писать модные распределённые приложения никто не писал. Вот, Саша, ведь ты так любишь писать, то, что люди любят читать. Ну вот, напиши книгу. Я об этом подумаю. А, Света, тебе слово. Раз мы тут рассказывали про конференции, попросили нас сделать анонс одной конференции, которая будет в Минске нескоро. Это 16 апреля, конференция для фронтендеров. Внезапно, возможно, среди нас, среди слушателей, ещё таки найдутся все те оба фронтендера, которые нас слушают. И мы всячески приглашаем людей посетить это мероприятие. Нам пока что не дали бесплатный билет, но, возможно, у нас получится выбить что-нибудь для наших постоянных слушателей. Так что приходите, будут вас ждать. На этом всё. Я предлагаю к тем слушателям, возможно, передвигаться. Что вы скажете на этот счёт? На самом деле я бы взял по камере одну свою тему, потому что у меня буквально всего два слова. И дальше, как вот Иван тоже предлагает тему слушателей, поэтому ему виднее. Я бы хотел ровно про одну статью сказать, потому что саму статью по себе обсуждать не очень интересно. Есть такая известная в узких культурах личность, как эти макафри, которая всё время работала над бакендом Halo 4. Она же, насколько я понимаю, сайт релабилити инженер в Твиттере. По-моему, не СРЕ, она занимается распределёнными системами. Я не уверен, не хочу врать, может быть ты и права. Суть в том, что у неё вышла статья в ACMQ, Verification of a Distributed System, Practitioner's Guide to Increasing Confidence in Systems Correctness. Сама статья, для людей, которые уже всё это видели или знают, она не очень интересная. И больше того, она никаких особо деталей не содержит. Это офигенная обзорная статья. Если вас интересуют вопросы, как протестировать вашу распределённую систему, даже если вы не пишете свои распределённые базы данных, вам это скорее всего хочется знать, потому что у вас микросервис, вот эта вся фигня, это вполне себе распределённая система, это раз. Во-вторых, если у вас есть какая-то база данных, которую вы берёте, не знаю, Mongo какая-нибудь, и вы хотите проверить, работает ли она в вашем случае, вам тоже неплохо бы знать, как вот эти техники применять к тому, что вы делаете. Это отличная обзорная статья, я рекомендую её читать всем, кто не знаком с тем, на что она ссылается. Ну, давайте действительно к темам слушателей тогда, раз все хотят темы слушателей. Все же хотят темы слушателей, да? Да не то, что мы хотим. У нас просто все наши темы, которые мы дальше добавляли, они довольно объёмные. И нам ещё часа на два их тут обсуждать. Видите, да, Ваня не хочет вашей темы. Давай уже. В общем, нам тут говорят про наш постоянный слушатель Содин, он нам предлагает поговорить про Kotlin 1.0, релиз кандидат. Мне нечего сказать. Вы утомились своим котлином, релиз будет, поговорим. Вот, про InfluxDB, ну, то есть мы сегодня уже как раз поговорили довольно много, надо сказать. Притом там как раз вот о том, что в 70 раз быстрее вот это всё, то что 100 тысяч записей в секунду на диск можно сложить, это всё. Ну, я не знал, что эта версия вышла так недавно, но мы уже, мне кажется, обсудили, спасибо Жене. Тут где-то говорили про образование, ну, в общем, про образование лично мне сказать особо нечего. Там статья, скажем так, там статья конкретно про бугуир, вот к чему я веду. Возможно, Свете есть что сказать. Да, тот самый бугуир. Ну, статья очень спорная и вызывает много вопросов. Идея такая, что, как известно, бугуир отдаёт не самое качественное образование, такой, знаешь, сразу же вброс идёт в статье. И примером способа, как эту ситуацию пофиксить, приводится программа, рассчитана на 4 года, 8 семестров, в которой описано, что нужно изучать, чтобы стать супер-пупер-крутым программистом. Вот, в целом программа интересная. То есть, там полностью, вот вообще, подчистую убрали всё, что касается какого-то гуманитарного образования. То есть, там нет ни философии, ни психологии, ни педагогики, ни социологии, ничего вот этого. То есть, там такой технический исключительно курс. Вот, и дальше идут великолепные комментарии. Это просто, я очень советую почитать эту статью, особенно комментарии. Просто занятно чтило. Вот, ну, не знаю, что касается этой программы, она очень сырая. Это, знаешь, так, человек захотел просто набросать за часик-другой эту программу, даже, может быть, меньше времени. И вот то, что вот получилось. Хотя, конечно, идея интересная. Вот, в конце предлагается за это всё добро платить 50 тысяч долларов. То есть, опять же, по меркам Беларуси, это огромная сумма, на самом деле. Ну, если мы не берём именно зарплаты в секторе IT, это колоссальная сумма. Вот, то есть, если у нас там... Ну, у нас, конечно, много хуже ситуация, опять же, с долларом, чем в той же России. Вот, и смотреть на это, ну, интересно. Интересно, конечно, просто точка зрения, но не могу с этим согласиться и как-то поддержать. Вы читали вообще эту статью? Нет, я предлагаю двигаться дальше. Да, на самом деле, я увидел, что там Гуир, и подумал, что я там в словосвете, вот. И, в общем, я попал. На самом деле, я видел эту информацию, по-моему, от него уже, только где-то в другом месте он уже это предлагал, если я правильно помню. Ну, по крайней мере, я вот подобное разделение на несколько лет, на вот эти ближайшие пакеты, в смысле, как это сказать, ну, пакеты курсов в одном флаконе, которые немножко связаны и так далее, они, где-то я их уже видел. Но мне кажется, что там правильно пишут, что очень всё однобоко. С английским, с менеджментом, с, как ты правильно говоришь, гуманитарным образованием. То есть, они хотят готовить, знаешь, таких кодеров, и всё. Да, очень узко направлено. Окей, следующий вопрос. Сталкивались ли ведущие с таким заболеванием, как синдром сухого глаза, чем лечились? Я лично сталкивался. Ну, не знаю, был ли это синдром сухого глаза. У меня была такая проблема в какой-то момент, что у меня глаза после рабочего дня были очень сухими, и мне было очень неприятно. Во-первых, да, способ быстро закидать тапками – это капать себе жидкие слезы. Но вообще мне долгосрочно помогла смена освещения в комнате, где я сижу. То есть, в моём случае это был просто купить себе лампочку настольную и просить людей не включать свет сверху. Я сидел со вторым человеком, который страдал такой же фигнёй, и мы в итоге посетились настольными лампами, и не включали свет, который был потолочный, просто потому что те конкретные потолочные лампочки заставили мои глаза выкатываться из орбиты и быть сухими. Вот так эту проблему решил я для себя. У меня бывает такая проблема из-за того, что я ношу контактные линзы, и я обратил внимание, это очень сильно зависит от конкретного офиса и кондиционеров, которые там используются. То есть, например, в новом офисе, где я сейчас работаю, там очень увлажнённый хороший воздух. Я обхожусь уже несколько месяцев вообще никакой капли. Я просто одеваю утром линзы, вечером снимаю, и у меня всё хорошо. В предыдущем офисе был более сухой воздух, и я там лил капли просто водопадами, и мне это не особо помогало. Вот, может быть, имеется мысль, если у вас такая проблема, поставить рядом с собой. Сейчас делают такие девайсы, которые паром холодным пшикают и увлажняют воздух вокруг. Знаешь, я тоже могу здесь добавить по поводу линз. В то время, когда носила линзы и когда начала работать на фуллтайм, это было очень неприятно. Потому что, опять же, как работают линзы, комфортно себя чувствуешь в линзах только потому, что у тебя выделяется слеза. Когда ты смотришь на монитор, ты, в принципе, моргаешь реже. И здесь возникает проблема в принципе. Если ты носишь линзы, ты меньше моргаешь, и получаешь такой немножко дискомфорт. Конечно, это зависит ещё от помещения, от своей, скажем, особенности твоего организма. Но я не могла работать вообще за компьютером на полный рабочий день в линзах. В итоге я перешла на очки, чувствую себя хорошо. И ещё такой момент. Да, хорошая поговорка. И ещё момент. Если вы не высыпаетесь и вы носите линзы, то я тоже чувствовала, насколько сразу ощущается, что глаза очень какие-то сухие. И линзы вставлять неприятно было. И это сразу же заметно. Так что высыпайтесь. Может быть, и только у меня такая была проблема. Но если я не высыпаюсь, я чувствую, что глаза какие-то сухие. И бросайте уже бухать. Я свои 5 копеек добавлю. Можно ещё добавить естественное освещение, если получается. То есть шторы открывать, если сидишь у окна. И естественное освещение, как Валера объяснял, оно помогает. То есть вот эти лампы, они на самом деле иногда бывают либо плохого качества, либо лично вам не подходят. Я вот у окна сижу, открываю всегда шторы. И мне лампы, что есть, что нет, они не мешают, не помогают. Да, я удваиваю этого господина, потому что лампы, которые под дневного освещения, это ужасная штука. Потому что они сильные. То есть буквально, не знаю, вам вчера могли поставить хорошие лампочки, через год они изнасилевались. Или сколько они изнашиваются. А поставили другие, вам не повезло. За это отвечает не ваша компания, а люди, которые содержат помещение. И они что поставили, то поставили. И как бы страдаете. Поэтому пожелаю по возможности избегать этого. Остальные, по-моему, мало голосов имеют. Ой, дайте мне тогда рассказать тему, я обещал с прошлого вопроса. Пошли. Это про как раз Google Cloud Platform и объединение Red Hat OpenShift Dedicated. Это был вопрос слушателей к прошлому выпуску. Я не читал эту новость тогда, я ей прочитал сейчас. И что я имею в виду. Во-первых, вы знаете, что такое OpenShift, да? Это такая система, это такой паз, который может строиться на чем угодно. Начинает с вашей собственной железы и заканчивая любыми кубернетосами. Вот сейчас они интегрировались с Google Cloud Platform, но интегрировались не с той точки зрения, что они вроде и раньше могли это делать, они сейчас с OpenShift Dedicated позволяют делать. То есть это вы платите за обслуживание, вы платите кучу денег за то, что приходят люди, все настраивают и у вас проблем нет. То есть для меня это вполне логичный шаг. Я думал, что они это уже и до этого делали. Я с удивлением эту новость читал. А с другой стороны мне не очень понятно, вот этот OpenShift Dedicated, кто его использует. Насколько я читал их цены, там у вас в случае реального железа есть 4 ноды, и за эти 4 ноды, на которые установлен OpenShift, вы будете платить 48 тысяч в год. Еще за каждое добавление каждой ноды, там еще 12 тысяч. И ограничен еще трафик, ограничен жесткий диск и все такое.",
    "result": {
      "query": "Dynamic Time Warping временные ряды поиск шаблонов"
    }
  }
]
[
  {
    "segment_id": "e254e9ab-9490-4745-955e-249168879de0",
    "episode_id": "238e04da-da20-4232-ba7d-4c8c6b7ee1f9",
    "episode_number": 103,
    "segment_number": 7,
    "text": "не таким больным. Вот, я высказался. Неконсистентность API, она не на стороне терраформа, она на стороне Амазона. Просто, когда неконсистентность на стороне Амазона, приходится имплементировать с тем API для плагинов, которые есть у терраформа, возникают ошибки на стыке, которые, в общем, не удивительны. В общем, да, я высказался, я поделился своей болью. Нечего добавить. Ещё одна тема, которая совершенно не связана с предыдущей, это LRU кэши. Вам нравится LRU? Вальдер, тебе нравится LRU кэш? Почему мне это должно нравиться или не нравиться? LRU кэш это... Ну, ты его часто используешь, ну у вас есть Redis, да? Ты знал, что там есть LRU? Ну, что в Redis есть LRU, я не знал, как-то не заботит меня. У нас LRU есть в другом месте, которое отвечает за то, чтобы у нас было в игре одновременно пользователи были с разными конфигами. Конфиги, которые давно не использовались, они из памяти ноды вытесняются. А вот тут антирес, который автор Redis, он говорит, что LRU это на самом деле такой трюк, это не настоящий подход. Потому что LRU он удаляет у тебя из кэша элемент, который дольше всего не использовался, не запрашивался. Что на самом деле ты хочешь, это удалить элемент, который с наименьшей вероятностью будет запрошен в будущем. Как бы это не одно и то же на самом деле. И как бы основой на этом он описывает то, как реализация LRU была сделана ранее в Redis и то, как она сделана в версии, которая у вас сейчас разрабатывается. Мне очень понравилось, как сделано удаление. Там идея вот в чем. У тебя есть хэштабличка, да? У тебя в элементах есть лишние 24 бита, которые можно использовать под нужды LRU. Но видимо там от выравнивания они остались и предлагалось лишнюю память не выделять. Собственно туда интерес предложил сложить timestamp Unix округленные, понятно дело. Их хватает в таком представлении в 24 битах на 194 дня. То есть для нужды LRU кэша там более чем достаточно. Теперь возникает вопрос. У тебя есть хэштабличка. Если бы у тебя был список, то LRU реализуется элементарно. У тебя есть хвост, голова. Ты более используемые элементы кладешь в голову, а когда нужно что-то удалить, удаляешь хвоста. Когда у тебя хэштабличка, то никакого списка нет. И как удалять не очень понятно. И он написывает такой замечательный совершенно подход, как я считаю. Возьмем несколько случайных элементов из таблички. Возьмем из них тот, который дольше всего не использовался. И собственно его удалим. Почему так можно сделать? Потому что на самом деле у нас LRU это такая аппроксимация того, что мы хотим сделать на самом деле. Ну и почему бы при удалении тоже не аппроксимировать, удалять примерно то, что мы хотим удалить. Оказывается, это замечательно работает. У него в блоге приводятся различные эксперименты на эту тему. Плюс оказывается, это можно несколько еще оптимизировать. То есть, например, не каждый раз брать из 5 случайных элементов, из них самый худший выкидывается. А поддерживать еще и пул из 16 элементов потенциальных для удаления. И при описанном ранее удалении, если этот пул пустует, то добавляет туда элементы. Если он не пустует, то если я правильно помню, удаляется вот из этого самый наихудший элемент, который дольше всего не использовался. Следующее улучшение LRU-KSH заключается в использовании LFU, то есть List Frequency Frequent Use, по-моему, так это расшифровывается. У нас есть все те же самые 24 бита, но нам нужно не закодировать время, как раньше, а нам нужно закодировать число обращений к этому элементу. То есть понятно, что если элемент используется часто, в общем, он используется часто, но к нему давно не обращались, это не значит, что его надо выкидывать из KSH. Пока то, что я говорю, более-менее имеет смысл? Да, все понятно. Окей. Ну вот. Идея, как бы, проблема простая, нужно в 24 битах более-менее осознанно закодировать вот эту частоту обращений. Антирес предлагает разбить эти 24 бита на две составляющие, 8 бит и 16 бит. В 8 битах хранится так называемый логарифмический счетчик. Это... В 8 битах, понятно, много чисел не закодируешь. Поэтому что предлагается сделать? У тебя чем больше значение счетчика в этих 8 битах, тем с меньшей вероятностью он увеличивается при следующем инкременте. То есть там такая незамысловатая формула, что там ну, типа, в зависимости от значения ранд и значения счетчика, он либо реально делает инкремент, либо не делается. И там приводится такая оценка, что порядка... Ну, если ты сделал 100 инкрементов, то значение счетчика будет примерно 10. Если ты сделал 1000 инкрементов, то примерно 18. Если ты сделал 100 тысяч инкрементов, то 142. И если ты сделал 1 миллион инкрементов, то счетчик будет, как бы, ну, иметь максимальное значение 255. Вторая проблема то, что с ходом времени тебе нужно еще этот счетчик иногда уменьшать. Ну, то есть у тебя есть некоторое окно, в течение которого ты отслеживаешь число обращений к элементам хэш-таблицы. На этом у нас есть целые 16 бит. Прям раздолье. Туда пишется таймстэмп в минутах. То есть он несколько округляется, и в конфиге можно указать, что, ну, в стиле «делай декремент раз в n минут». Если ты при очередном обращении к счетчику видишь, что он декрементировался больше, меньше, не декрементировался в последние n минут, то ты его либо делишь на 2, если он большой, имеет большое значение, либо если он имеет некое небольшое значение, там тоже, я так понимаю, пороги выставляются, то из него вычитается какая-то константа. Потому что, напомню, счетчик алгоритмический. Вот. И если я правильно помню, то вот этот LFU работает намного лучше. Причина, по которой я обо всем там рассказываю, то, что я лично знаю про LRU, но я никогда не встречал такие стратегии выкидывания элементов из него. Не знаю, как вы. И мне обо всем этом было прочитать очень интересно. Плюс в статье есть ссылка на paper, называется «Тайни LRU». Вот, paper не читал, и интерес пишет, что он не очень применим в его случае. Честно не помню, почему. А, там в некоторых случаях можно из кэша в кэш можно то ли не добавлять элементы, то ли не удалять из него элементы. И вот считается, что так можно делать не всегда. Такие дела. Вопросы? Ну, я не вопрос, я добавлю, что в целом это неплохая стратегия, когда мы берем какую-то известную концепцию LRU и тыкаемся где-то рядышком с ней. Большинство народа использует и не понимает, что вот эта разница между тем, что у тебя наименее часто используемый, а надо на самом деле сохранять элементы, у которых максимальная вероятность их дальнейшего использования. Это совершенно разные вещи, просто мы достигаем таким образом. И подобные статьи, конечно, не помогают это увидеть. Особенно интересно, наверное, с этими с битиками, как он предлагает их использовать. Это классная у него идея.",
    "result": {
      "query": "LRU кэш Redis алгоритм удаление случайных элементов"
    }
  }
]
[
  {
    "segment_id": "d0ce4496-b4fd-4e7c-8ac1-e0989042dcd1",
    "episode_id": "b9efcd83-15ca-454d-a208-236e6b1ceb65",
    "episode_number": 436,
    "segment_number": 5,
    "text": "Вот. Надеюсь, мои работодатели не услышат этот выпуск. Вот. Но ремоута нигде нету, и это очень печально, и поэтому какие-то письма мне приходят, что sorry, не варик, либо сделайте тестовое задание, а я из принципа не хочу делать эти тестовые задания, я знаю, как они проверяются, и ну, такое. Вот. Но по поводу вот этого выпуска, это был хороший выпуск и хороший лайфхак, и еще в этом же выпуске, по-моему, вы обсуждали такую штуку, как AnyDesk, и я вот как раз-таки вчера или сегодня наконец-то его поставил, потому что TeamViewer поднадоел, он мне не особо нравится, но как раз была проблема, чтобы к сервочку своему подключаться, потому что он работает с GUI-интерфейсом, по SSH все-таки не получается какие-то вещи делать, и работаю через UI. Так что спасибо вам, спасибо за ваши выпуски. Рад, что полезно. Ладно, возвращаемся. Так не просто слушает, но еще и пользует. Возвращаясь к твоей работе, ты сказал, что BigData и Security. Я ничего не знаю про Security, но я, как это, имел неосторожность трогать BigData. Сколько у вас BigData, и почему вы считаете, что она big? Ты говоришь, что вы mute. Ой, Андрей. Если честно, проблема в том, что я услышал только вопрос, сколько. Сколько дата, видимо? Сколько у вас BigData, и почему вы считаете, что ваша BigData big? Да, смотри. Такое стандартное определение BigData для меня, по крайней мере, это то, что не помещается на один компьютер. Ну, по крайней мере, это для меня так. По поводу... На один компьютер. Чего один компьютер? Память один компьютер? Самый мощный, который есть. Условно, если там самый текущий мощный сервер, не знаю, сколько оперативки можно загрузить, я думаю, 200... Спокойно, гигабайт оперативки можно загрузить. Жесткого диска, я думаю, тоже не проблема загрузить 64 терабайта. Вот, если в день генерится больше этих данных, я так наугад примерно сказал, то это хорошо. По поводу BigData, почему мы считаем, что это big? В целом, хороший вопрос. Даже не знаю, как сильно его нормально прокомментировать. Если коротко, потому что мы не можем просто взять и использовать Postgres. У нас есть клиенты, у которых порядка, наверное, 3 миллиарда запросов в день. И мы это все должны обрабатывать. Если ровным пластом разложить 3 миллиарда запросов, то это получается примерно 10 тысяч, наверное, операций в секунду записей, что кажется, не так много. Но проблема в том, что бывают всякие DDoS-атаки, и спокойно может взлететь до миллиарда записей в секунду. И мы, ну, база данных особо не выдержит, если мы будем просто в нее пушить миллиард записей. И поэтому, наверное, я могу сказать, что да, у нас BigData, и мы стараемся, чтобы все это не падало. И если там DDoS-ит какой-нибудь условный eBay, то мы должны сделать так, чтобы мы не упали, и чтобы eBay не упал. То есть, получается, я так сейчас как-то, короче, на салфеточке прикинул, получается, что у вас где-то сотни гигабайт на кастомера данных. К сожалению, у меня опять пропала связь. На салфеточке прикинул, сколько у тебя получилось? Сотни гигабайт на кастомера. Сотни гигабайт? Вот смотря, сколько у тебя... Этого, наверное, не было. Ладно, сотни гигабайт вола в день на кастомера. То есть, если у вас столько записей, непонятно, сколько у вас... Размер записи. Размер записи, но я прикинул, скажем, десятки байт. Я прикинул, что он... Понятно, что я не знаю, сколько у вас всего история хранится, но можно предположить, что обновлений случается какие-то сотни гигабайт в день. Но это на каждого кастомера. Ну, ладно, окей, не на каждого, если честно, на самых крупных. В целом, да, но это же нужно еще и обработать. То есть сотни гигабайт, оно не звучит как супер много, если честно. То есть для базы данных сотни гигабайт, ну, это на одной машинке поместится. Но это в день, а мы берем промежутки года. То есть мы должны это хранить годами. Просто, как это, чтобы... Не с целью пофлексить, а с целью просто, ну, как бы сравнить бигдату. Как-то определение бигдатности. То, с чем я работал, я это не считал особо бигдатой, потому что оно, ну, как кластер Кавки, который это всасывал, это было больше, чем одна машина. Но в итоге данные помещались в одну машину, ну, опять же, с репликами Пасгреса, и там были десятки гигабайт вола в час. Ну, смотри, да, и я понимаю, про что ты говоришь. Я, наверное, даже не сильно готов с тобой на эту тему спорить, потому что, я согласен, звучит как не супер впечатляющие цифры, но проблема именно, что когда у нас идет DDoS, когда у нас идет миллионы запросов в секунду, которые мы должны обработать, сохранить и сделать какие-то выводы по каждому из запросов, то это не суперкривиальная задача. То есть называть это просто датой, либо бигдатой, ну, хороший вопрос. Мы, на самом деле, пользуемся облачными решениями, поэтому нам в этом плане проще. Вы пользуетесь чем-то готовым облачным, вроде Snowflake или, там, не знаю, Redshift, или вы просто разворачиваете на облаке что-то свое? Мы пользуемся готовым, вот сейчас конкретно Snowflake еще не пользуемся, но думаем про него. По крайней мере, постоянно обсуждаем момент со Snowflake, на текущий момент есть гугловые реализации, там используются где-то BigQuery, где-то Mongo, то есть используется различный баз данных. То есть, если я правильно понимаю, у вас есть какой-то входящий трафик, вы разбираете все, все-все-все входящие, не знаю, пакеты запроса, например, что вы по запросам работаете, и складируете это как логи, не логи в Mongo и, и Bigtable, и вам, видимо, на каждый запрос нужно гонять аналитику. Я верно понимаю, что происходит? В целом, да. То есть, наш клиент настраивает свою систему специальным образом, который для него наиболее подходит. Где-то можно разрешить какие-то запросы, где-то нельзя. И, да, запрос вначале идет к нам, мы анализируем, что с этим запросом все хорошо, что айпишник хороший, там, не дедосят с этого айпишника, что конкретно сейчас, этот юзер никого не дедосит, анализируем, что подходит он под запросы какие-то, и если все хорошо, то мы пропускаем этот реквест. Если нет, мы его помечаем, что для своей аналитики, для аналитики также клиентам, что с этим запросом есть проблемы, если хочет, ты его можешь заблокировать, если хочет, ты его можешь пропустить. И клиент уже сам решает, он хочет его пропустить, либо хочет заблокировать. Окей, за сколько времени, микросекунд, миллисекунд вы отрабатываете один запрос? Если честно, я не могу сказать, но там микросекунды, нет, сори, наверное, все-таки миллисекунды, блин, не могу сказать, но порядок очень низкий, там точно меньше 10 миллисекунд. Мы недавно как раз-таки обсуждали по поводу улучшений нашего сервиса, и мы думали использовать внешний API, чтобы кое-какой, какие данные проверять. И там была гарантия порядка 10 миллисекунд, не знаю, как эта гарантия могла даваться, в том плане, что API идет по интернету, понятное дело, и как они могли гарантии на именно на интернет, потому что они не предоставляли решение, чтобы мы у себя его развернули. Они именно через интернет API продавали. И для нас это, конечно же, много. 10 миллисекунд на каждый запрос, это много. Поэтому не могу сказать, извиняюсь. Вот у меня просто были эти же соображения. Я понимаю, что, конечно, Mongo или Bigtable отвечают меньше, чем за 10 миллисекунд каждое, но мне сложно представить, что вы даже, например, в оба этих места успеете сходить, обрабатывая один запрос, потому что если вам нужно принять решение, то есть запрос идет до вас, а потом от вас обратно к серверу. Если даже вы добавляете к нему 10 миллисекунд, а потом он еще будет сколько-то миллисекунд лететь к серверу, допустим, там он будет быстро лететь, я предполагаю, что вы, скорее всего, коллокидитесь с тем местом, куда вы контролируете запрос. Но все равно получается, что у вас очень даже честные тайминги. И вот мне интересно, куда вы реально успеваете сходить в реальном времени, а куда вы сходите, не знаю, как-то потом принимаете какие-то решения, которые вы запоминаете? Ну, на самом деле мы, можно даже сказать, что в каком-то смысле никуда не ходим, потому что, вот эти вещи, которые... Я просто еще думаю, насколько я могу сейчас рассказывать, как это устроено внутри. Это тоже хороший вопрос. Какие-то вещи нам нужно действительно сходить в базу данных и получить эти данные. Какие-то вещи мы можем просто загрузить в память, то есть, например, конфигурацию системы, мы загружаем ее просто в память, и сами конфигурации мы можем раз проверить, насколько там запрос соответствует конфигурации. Если мы говорим про, то DDoS там надо проверить. Например, на один IP-шник, если за последнюю минуту заходил, превысил порог, на DDoS-атаку, то мы помечаем его как DDoS и уже после этого отправляем в остальные базы данных, откуда остальные прокси подсасывают его и тоже понимают, что вот этот IP-шник, он DDoS-ит. Его надо блокировать. Не всегда обязательно идти прямо в BigQuery или в общий баз данных. Есть какие-то вещи, которые мы локально выставляем. Опять же, у нас используется Redis для таких данных, и мы очень много подсасываем непосредственно в оперативку самого приложения на прокси. Окей, ну я примерно более-менее понял. Я, наверное, представляю, что вы там делаете. У меня нет больше технических вопросов. Если ты хочешь рассказать про какое-то интересное техническое решение, с которым ты столкнулся, то вот был бы сейчас самое время, потому что если нет, я бы пошел дальше по другим вопросам. Наверное, можно пойти дальше по другим вопросам. Вот, тогда, поскольку я не специалист по безопасности, я передам слово Саше, потому что Саша у нас специалист по безопасности, в отличие от меня. А чего? Это надо карточку открыть? Нет, просто мы тут анализировали, значит, как бы стек BigData и вообще BigData ли у нас. Ну, как бы вопросы про BigData закончились, но ребята при помощи BigData делают тебе как бы аналитику, не аналитику, как это, они делают DDoS protection. И в защиту от инъекций и всякого такого. Поскольку у тебя, Саша, блог, ты спалился тем, что много раз писал про такие вопросики, а я в этом практически никак не разбираюсь, я делегирую тебе эту часть интервью. Позволь, пожалуйста, поинтересоваться. Когда я в блогике хоть раз писал про DDoS? Ты точно про шифрование, что-то писал. Про DDoS, по-моему, тоже писал. Так ребята не занимаются шифрованием. Ну, я понял, что, да, вы собираете... Опять же, сорянчик, я тут отходил ненадолго. Я понял, что вы собираете информацию о клиентах-посетителе и по их поведению делаете сегментацию. Это, ну, DDoS или не DDoS, например. Окей. Ну, да, по сути, обычный такой проект, защита от различных... Отличного типа атак. Если вам интересно Cyber Security, я могу рассказать про один из предыдущих моих опытов работы. Для меня этот проект, ну, изначально, когда я в него заходил, это какое-то... Какая-то магия была. Сейчас уже чуть меньшая магия. Это поиск security vulnerabilities в реалтайме. То есть в реалтайме работает аппликейшн, и мы в реалтайме анализируем, какие у него есть security security security security уязвимости. Уязвимости в безопасности. Чем это отличается от FAP Spider и подобных решений? Хороший вопрос. Решений, на самом деле, довольно много. Это не то... Это... Я работал там года два назад. Просто если мы говорим про security, могу тоже рассказать, как я там что-то делал, как мы там работали. Потому что мне кажется, это какая-то магия, что тогда казалось, так и сейчас кажется, что это какая-то магия, что поиски security... Вопрос в реалтайме, потому что некоторые вещи не всегда можно статическим анализом перехватить. Нет, реалтайм предполагает, что ты не разворачиваешь приложение где-то в staging environment, что ты это прямо в продакшене делаешь. Нет, это скорее предполагает, что ты разворачиваешь staging, допустим, для end-to-end тестирования. И на нем также запускаешь наш софт, чтобы найти также и security. То есть это скорее больше для этого.",
    "result": {
      "query": "AnyDesk вместо TeamViewer подключение к серверу GUI"
    }
  }
]
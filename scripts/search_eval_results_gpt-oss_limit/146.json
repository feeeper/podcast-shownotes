[
  {
    "segment_id": "a4379dfe-af7e-4ce3-92b7-e98e4a77ab64",
    "episode_id": "54ef6377-6a4a-4548-a44e-34056dba5494",
    "episode_number": 146,
    "segment_number": 3,
    "text": "Это правда. Но совсем закапывать подход в целом нельзя, он просто в другое место переместился, как где действительно сейчас есть и, скорее всего, всегда будет какая-то непостоянная связь. Возвращаясь к Rit'у, очень молодцы ребята из Хабрахабр, которые отмечали день рождения, 11 лет, что ни разу не круглая дата, но тем не менее. Они под шатром сделали концерт с живой музыкой и с крафтовым пивом. Мне больше всего понравилось пиво Тёмный Властелин. Вот, по-моему, самое вкусное было из всех. Он чёрный назывался, он назывался Чёрный Властелин. Чёрный, не тёмный. Я после того, как в Оттаве попросил девушку принести мне Black Beer, на всякий случай произношу тёмный, да, пытались сделать там митап, сколько людей там пришло? Это было очень смешно. На какой из? На первый митап. Пришло три человека. Один из них был мой брат, второй это... Случайно трехожий? Как он сказал, типа, я сам Дэвзен не слушаю, но узнаю того, кто слушает. Это было в палатке, в Сетре. Там было шумновато, поэтому мы стырили один столик и поставили его на улицу. Было очень весело. Но зато у меня сейчас есть чёткое подтверждение, что, во-первых, Света существует, и у меня сейчас сомнения только в существовании Валеры. То есть у меня иногда есть подозрение, что Валерины реплики пишут Саша со Светой вместе, и наняли актёра, который умеет их быстро произносить. На самом деле, все реплики записаны заранее и производятся на ускоренном... На скорости. Не генерируется нейронное съятие. Валера не возражает против такого. Просто нет записанной реплики. На этот случай. Я просто посмеюсь. Про автопатию с караоке я предлагаю пропустить. Да? Нет? Не знаю? Не будем. Что ж там было? Боже мой! Да ничего особенного, попили караоке. А на второй метап уже в лорикрафт пришло нормально человек 10-15. Где-то так. Был там Никита Прокопов, которого мы уже в выпусках 100 не упоминали. Были там коллеги с моей предыдущей работы. Кого ещё мы помним? Ну, ещё один наш участник подкаста с 58-го выпуска. Господин Кот Бегемот, да? Ты про него? Очень мило, душевно посидели. Я после всех этих метапов и Рита до сих пор измотан и немного сонный. Хотя вроде отоспался. Душевно измотан, понимаете. Да, Вань? Я вспомнил ещё одно выступление от одного из разработчиков Яндекса. Мне оно запомнилось тем, что он рассказывал про своё участие в Кегле, как он занял второе место по распознаванию снимков из космоса разных объектов. И он рассказывал, как их команда из двух человек выиграла решение, они заняли второе место, и он рассказывал пять первых мест, что они использовали. Запомнилось оно в первую очередь тем, что никто не задал ни одного вопроса, и мне кажется, во всей аудитории два-три человека поняли полностью всю суть. Он очень надеялся на вопросы, оставил 10-15 минут времени, но никто ничего не спросил, все похлопали, и он ушёл недовольный. Я имею в виду, что, возвращаясь к тому, что вы там говорили, что РИД, интернет-технологии и все дела, ваши нейронные сеточки никак не укладываются в интернет-технологии. То есть это всё-таки уже больше компьютер-сайенс. Как-то общая, получается, более общая конференция. Надо сказать, что там был отдельный поток, который рассказывал про IoT, про ML периодически, но не было очень много докладов по этой теме. И ещё я хочу послушать доклад, когда выйдут записи про нейрорисунки, как надо правильно решать магическим способом ваши проблемы с проектом. Никто не ходил из наших, мне его рассказали, и мне прям в чужом пересказе он очень понравился. Идея в том, что надо правильные рисунки рисовать из нужных примитивов. У вас есть там 4 примитива, отрезок, треугольник, квадрат и кружочек, и когда ты думаешь про твою проблему, ты просто эти примитивы перемешиваешь и в листочек формата А4 наносишь. А потом ты начинаешь всякие разные фрагменты, которые тебе хочется подчеркнуть, подчёркивать некоторые, обводить, скашивать углы и так далее. Этим надо заниматься часа два. Когда ты этим занимаешься часа два, магическим образом что-то произойдёт во вселенной, и твои проблемы решатся. Вот такая вот концепция. Мне прям очень хочется послушать. Звучит, как большая куча буллшота, честно говоря. Мне прям понравились формулировки. Не смог точно рассказать, я слушал человека сразу после этого доклада. Наверное, человек, обращенный в веру Егора. По-моему, тема себя временно исчерпала. Мы вернёмся к ней, возможно, чуть попозже, когда уже пригласим людей, а так... Согласен. Мне, конечно, хочется добавить, поблагодарить организаторов этой конференции, потому что она того стоила определённо. И я надеюсь, что мы будем продолжать с этого дня. Да, присоединяемся. И коль скоро заговорили про AI, машин-лёрнинг и так далее, я предлагаю рассказать про самодрайвящие сами себя машины от Яндекса. А вот, между прочим, прежде чем мы пойдём к Яндексу, я сегодня был на, извините, гоночке Формулы Е в Берлине, и тут я как-то эпически пропустил самоводящийся болид, который сам с собой ездил почему-то. Ну то есть это... Быстро? Я не знаю, я пропустил, но мне говорили, что он одиноко по треку ездил, ни с кем больше не. .. То есть в расписании значилась RoboRace, а по описаниям там машина просто нарезала круги сама, одиноко. Смотрите, как грустно и одиноко робо-машина. Давайте пожалеем их. А для тёмных отличие в Формулы Е от других формул? На это как бы болиды Формулы 1, только они без бензина и там ретродверители. Ага, окей. А скорости они развивают, надо думать, поменьше, да? Я бы сказал, такие же. Ну то есть так вот, я спидом прострелял... Но недолго. Почему? Нет, это 40-минутная гонка. Возвращаясь к машинкам. Во-первых, многое про это неизвестно, то есть Яндекс просто объявил, что они провели тестирование беспилотного автомобиля. Беспилотный автомобиль был создан на базе Тойоты и Киа, и он успешно прошёл испытание. Что значит «успешно прошёл испытание» — непонятно. Какие именно тесты были проведены — непонятно. Мне кажется, что они просто обозначились, что мы тоже ведём исследование, у нас есть команда для этого, и вот это всё. Слушай, я тоже читала эту статью, и в ней написано о том, что Яндекс сейчас использует Тойоту... Или, по-моему, Тойота Приус. Тойота Приус, да. Тойота Приус. И они катаются в таком загончике недалеко от офиса Яндекса, и они пока не выезжают на проезжую часть, где самое интересное творится. А они тоже одни катаются? Или у них хотя бы компания есть? Я думаю, там есть компания из таких же робомашин. Ну, по-моему, судя по видео, у них там только компания из операторов с камерами. Слушай, ну это уже неплохо. По крайней мере, они не боятся выходить, когда те машины рядом ездят. Справедливости ради, там были люди. Они сказали, что они научились обижать людей не на проезжей части, а в таком загончике. Зачем они людей обижают? Так что... Обижать людей. Да, поэтому пока что... Ну, пока что это пиар, согласись с тем. Пока что это пиар в основном, и они обещают в 2018 году выезжать на проезжей части, так что ещё не скоро до настоящих самодвижущихся повозок. Куда они будут выезжать? Ему ещё не разрешили, это надо прям согласовывать по закону. Ну, они обещают, что к 2018 году они смогут это согласовать. Но, к слову, они используют лидары, эти безумно дорогие устройства, поэтому мы не скоро увидим самодвижущиеся машины, доступные для обычных людей. Это вот та, что на крыше крутится, да? Да, такая пипка на крыше. Которая как радар, но только с лазером, умеет делать 3D-карту. И очень точно считать расстояние. Ну, как 3D-карту. До того момента, пока не встречается препятствие, которое бросает тень на всё, что за ним. А в остальном 3D. Кстати, а вы слышали, что Boston Dynamics продали японцам? Да, сотбанку продали. Это же ужас. Ну, там история была такая, что... Google купил кота в мешке, у них был только прототип, и они когда поняли, что проект выше прототипа никуда не полетит, они стали искать покупателя. Ну вот, нашли. Потыкали мешок, он не мяукал. К слову, у сотбанка теперь очень интересное портфолио, и там есть ARM, они им владеют, они владеют теперь Boston Dynamics, и они активно развиваются. Так что интересно. Последние роботы Boston Dynamics очень страшны. А когда их продают японцам, у которых есть фильмы про Godzilla, у них становится дважды страшнее. А когда еще машины оставляют ездить совсем одни, и они расстраиваются, это еще страшнее. Сейчас я прикреплю новость про Boston Dynamics куда-нибудь. Акции подскочили ведь в Яндексе, да? После этой новости. Как никто не следит? Постойте. Надо было бы посмотреть. Мы тут что, технари? Ну да. А пока Ваня прилепляет ссылку, я предлагаю Валере рассказать про timely dataflow, да и не просто, а на языке новомодном, хоть и ржавым. Вот. Я уже, да, тему принес, наверное, выпуск два назад, поэтому я уже ничего не помню. А у нас все темы в этом выпуске такие не новые, зато хорошие. Настоявшиеся. Да. В общем-то, на самом деле, как обычно в нашем любимом блоге, который мы все время тестируем Андреа Накойлера, вышла статья про... Слушай, когда он перестанет это делать, нам нечего будет в подкасте рассказывать. Нет, слушай, придется самим пейпер читать. Да это ужас какой-то. Может быть писать? Может нам ему платить денег? Слушай, патронов, давайте патронов ему будем частично отдавать. Не, на самом деле, звучит неплохо смотреть. У нас четыре ведущих, каждый пишет по два поста в неделю, потом обсуждаем 8-7 по, не знаю, 15 минут нормально. Да, только пейпер, я до сих пор, IC Train лежал в этом, если ты заметил, он лежал в темах, и я опять его не дочитал, поэтому я опять его вынес из тем. Плохой и негодный Валера. Вообще отвратительный Валера. Смотрит всякие гонки вместо того, чтобы пейпера читать. Да, собственно... Жизнь ужить задумываешь ты? Ты что, какая жизнь? Я что, думаешь, на гонку пошел? Гонку смотреть? Конечно же нет, у меня же что-то пропадало с собой. Кто же гонки ходит смотреть? Уходят фотографии. Здесь фотография. Да. Вот. Собственно, статья называется «Online reconstruction of structural information from data center logs». Как можно понять из названия, оно не про, в общем случае, машинлернинг, а про более узкую задачу. И timely data flow – это вообще такая модель, которую придумывали Microsoft Research для системы NAYAT. В 2013 году. И, собственно, ребята... То есть, они поняли, что они хотят для своей задачи что-то похожее на какой-то из data flow-подходов, типа Flink или, собственно, вот timely data flow. Но, я так понимаю, на NAYAT просто ее не пощупаешь в открытом доступе. А Flink они померили, ну и дальше про это. Им не очень понравилось. Они решили, что делать, просто систему обработки логов на глазок. Они не хотят, они хотят какую-то более-менее нормальную модель использовать. Да, чтобы было быстро и модно, и как это, молодежно. Подожди, Валер. То есть, они заранее не знали, какую они проблему решают, или что? Нет, они заранее знали проблему, они не хотели на глазок... То есть, как-то... Они не хотели писать код, просто, что-то типа фигак-фигак, они хотели взять какую-то foundation, теоретически, чтобы на основе этого уже строить. А можешь тогда проблему еще раз пояснить их, что они хотели решить? Ну смотри, в общем, есть у тебя... Как это, в общем... Сейчас, я точно знаю, что у вас в эфире такая штука была. В общем, у тебя есть... Да, у вас, короче, есть сервачье разное. Каждый кусок сервачья оставляет за собой множество логов. И сервисов много, они там еще и всякое пишут разное, пишут кто куда, пишут в разных форматах, вот это все. Единственное, что их объединяет, это у них есть timestamps и метка, как бы, origin запроса, которая породила все происходящее. То есть, каждая произведенная лог-линия, она ассоциируется с каким-то запросом, к чему оно вообще происходило. Есть, соответственно, какая-то система, которая должна все это отсюда вытащить, собрать в когерентную, осмысленную штуку. И у них сейчас здесь дополнительно написано, что они это хотели делать интерактивно, чтобы ты открыл какую-то страничку, консоль или что-то еще, и ты мог просто в real-time наблюдать, как у тебя что-то происходит, можно было отлаживаться максимально быстро и приятно. Вот, такая вот задача. Спасибо. Насколько я знаю, ты, по-моему, даже рассказывал про похожую систему у вас в эфи. Да, был. Вот, и, собственно, ребята в данном случае, у них утверждается, что то, на чем они тестировались, это 5 гигабайт в секунду логов, 50 терабайт в день, я не знаю, сжатых, не сжатых, не помню, уточняется, и собиралось 1300 серверов. То есть, ну, немаленький такой сетап. Ну, собственно, да, они написали вот такой, ну, в свете ближе всего, наверное, будет флинг, чтобы понять, о чем речь. Ну, они, притом, вместо флинга брали таймли, дейтофлоу из Наяни, он там модель немножко отличается, но, по сути, программируется примерно так же. У вас есть DSL, поскольку растый язык тоже такой, развесистая система типов, она тоже такая хорошо типизированная, выглядит просто как куча операций с коллекциями, а только это операция с стримом, они это побенчмаркали, и, в общем, что интересно, что оно флинг ровет просто сухую, то есть оно вот на этих безумных объемах логов обрабатывало, то есть оно может обрабатывать данные быстрее, чем они поступают. А флинг, там у него интересный график в одном месте есть, что он на одной машине совсем медленный, потом на двух-трех машинах почти приближается к этому, потом, когда его дальше большетабируешь, у него такой overhead становится, что он снова начинает отставать. Вот, а ребята на расте, у них просто стабильно, они успевали просасывать поток. На скольких машинах? Я сейчас на графике вижу написать 4 worker, 8 worker, 16 worker, при том, я так понимаю, самый приятный выглядящий график на 4-8, по-моему. Слушай, ну, в общем, я не помню точно, я боюсь соврать. Здесь есть какой-то график на количество хостов у worker, и тут количество хостов от 1 до 4, а worker от 1 до 16. Это у флинга. А, это у флинга, понял. Слушай, здесь вообще может быть даже на одном хосте, я чуть-чуть не очень понимаю, о чем речь, тяжело, я, говорю, читал достаточно давно, и так просто тяжело сказать. У этого есть очевидные минусы, то есть оно быстрее флинга, но ребята, поскольку они это делали просто для собирания логов, это best effort штука, оно если как-то разваливается, то оно разваливается. То есть флинг, он умеет в... При правильном настроении и правильном кодописании, он будет exactly one семантику давать, то есть если он потребляет из какой-нибудь кавки, там есть offsets, и он может знать, откуда он заофсатился, у него внутренний timestamp всегда будет связан с тем offset, с чем он прилетел. И, соответственно, если синг сделан тоже правильно, то тоже можно понять, до куда что-то было обработано. И, в общем, если все правильно построить, то на флинге можно построить exactly one систему. Exactly one — это такая интересная штука, там, как бы, она, понятное дело, что там может быть какой-то репроцессинг, но с точки зрения конечного результата оно будет выглядеть так, как будто бы было обработано в точности однажды. То есть если у вас есть какие-то побочные эффекты внутри pipeline, они могут в больше раз выстрелить, но поэтому не надо внутри pipeline пихать побочные эффекты. Ну вот, у флинга очень сильная гарантия в этом чему. Подожди секунду, а можешь пояснить, что значит exactly one при обработке логов? Я чуть не очень пока понимаю. При обработке логов, он-то и делает, что exactly one при обработке логов, наверное, быть и не может особо. Потому что у флинга, в принципе, при желании, можно на определенных задачах настругать exactly ones. То есть здесь оно неприменимо, они же логи обрабатывать хотят. Ну да, потому что здесь вообще гарантия гораздо слабее у системы. То есть у флинга, даже если не может exactly ones, его можно, по крайней мере, научить репроцессинг делать всегда. То есть если ты не уверен, что что-то долетело, всегда можно по меньшей мере перезапроцессить. Или там, если ты упал, то можно продолжить с того места, куда ты упал, а не с какого-то рандомного. Вот здесь, ребята, насколько я понимаю, ничего этого вообще нет. То есть то, что оно сильно быстрее, это может быть заслуга не только языка, но еще и того, что просто может быть где-то меньше overhead. Но они делают такое интересное заявление, что мы так не считаем. Ну ок. А в итоге они что добились с логами? То есть они в итоге что получают на выходе этой системы? Ты же говорил, что они хотят открывать какое-то место, где у тебя что-то происходит в системе, и ты можешь сразу... То есть они полноценно все сделали, все что хотели? Я имею в виду, что они... Насколько я понимаю, да. Просто к тому, что система, она не может считаться прям... Я увидел твит, в котором было, что таймли дейтафлоу на расти просто рвет флинг во много-много раз на много-много мелких JVM. Но все-таки это не те... Да, это очень похожие штуки, но их нельзя один к одному сравнить, просто потому что они совершенно с разными гарантиями работают. Я даже, честно говоря, не уверен, что вот этот таймли дейтафлоу на расти, что он вообще распределенный. Я вот как бы сейчас смотрю и не очень уверен, что... Да-да, ни одного слова подтверждающего это нет. Да, что там процессинг... То есть понятно, что там сбор логов происходит распределенно, но вот если там распределенный процессинг, мне не очень понятно. Но с другой стороны, в принципе, они могут в несколько воркеров, то, наверное, сделать распределение не то, чтобы... Ну блин, черт его знает, нужно смотреть глубже. Я уже, так говоря, давно читал. Вот, собственно, но хочется в очередной раз порадоваться за то, что раст развивается, используется даже в таких как-то суровых условиях. И насколько я знаю, автор этой штуковины пошел работать в Google. Могу ошибаться. В статье на сайте, ну в смысле в блоге, как раз очень много отсылок на подобные статьи. То есть Эдриан сделал ссылки на его разборы Dapper, Mystery Machine, LProf, Pivot Tracing, то есть все статьи, которые каким-то образом касаются темы, он их здесь перечислил. И тем, кто интересуется этой темой, можно прямо зайти в статью и начать оттуда, так сказать, по всем возможным научным статьям. Очень хорошая штука, то есть я уже полазил, посмотрел, мне понравилось. Потрясающе суперполезные вещи. Что еще потрясающе и суперполезно, это... Саша not excited. Восьми лет нет. Что, почему я... Нет, ну я молчал, потому что я совсем согласен. Что еще суперполезно, это оконные функции, процедуры. Все-таки они, наверное, называются функции, но меня немного коробит от этого. Оконные процедуры в PostgreSQL. Мне кажется, на них можно просто выкинуть весь таймлидейт дейтафлоу и просто на оконных функциях логикировать. Так ведь? Ну конечно, у тебя же вот, ну, самая лучшая очередь — это PostgreSQL, да? Вот у тебя очередь уже лежит, ну, то есть лог. Берешь и окном его так вжух, и все. Вот, на самом деле, тема про то, что в блоге Брюса Мамжана были започтены слайды, объясняющие, как работать с оконными функциями. И, ну, честно говоря, для меня это всегда было такой не очень понятной магией. Ну и для меня тоже остается. Не очень понятной области применения. Вот, а тут сколько там? Штук 80, по-моему, было слайдов. Все просто и понятно. 80 ровно, да. Вот. Ты, Вань, к этой теме присоединился, потому что хотел сказать, что? Я хотел поспрашивать и пообсуждать. То есть у меня вопрос такой. Насколько я понимаю, вот эти оконные функции, или процедуры, как ты их называешь, они появились не сразу в PostgreSQL, да? Да. Ну, то есть их начали делать из-за того, что не хватало функциональности или как? Что с их помощью можно сделать такого, что без них сделать не получится? Насколько я понимаю, с их помощью что-то сделать удобнее. То есть, разумеется, ты можешь написать всегда приложение, которое поделает туда селектов, сюда селектов, потом на своей стороне шур-шур-шур, и у тебя результат, да? Ну, то есть, доказать легко, в пределе ты выгружаешь всю базу и делаешь по ней шур-шур-шур. Гребан. Да, вот. Меня самого всегда удивляло, зачем люди это используют, потому что на моей практике мне не нужно было вообще ни разу. Но я поспрашивал, и вот со слов тех других людей, это нужно в задачах, когда тебе нужно что-то, ну, во-первых, у тебя есть выборка по какому-то условию, а потом тебе из этой выборки нужно что-то случайное. То есть, например, показать два случайных баннера, которые будут интересны этому пользователю. Или там показать, не знаю, ачивки игроков из соседних деревень, ну, какая-то такая странная фигня. Вот, и по ходу в этом случае окунные функции, они работают и быстро, и позволяют не гонять данные туда-обратно. Но, насколько я понимаю, подобные штуки можно сделать и просто, то есть ты делаешь первый селект, а потом функция average или выбираешь какое-нибудь число оттуда и какую-нибудь строчку вытаскиваешь. Можно и так было сделать, ведь нет? Ну, я повторюсь, нет ничего такого, что нельзя сделать без окунных функций. Ну, понятно. Я просто как бы... Вот я сейчас, наверное, в твоём состоянии, когда ты до того, как ты начал спрашивать у людей, зачем они это используют. Я до сих пор пока не вижу реально удобных применений, чтобы нельзя было совсем без них, а новую сущность почему-то ввели. Вот я пытаюсь разобраться, зачем это сделали. Валер, а у вас используются окунные функции где-нибудь? Мне кажется, да, но я не уверен на 100%. То есть в моём коде нет. В моём коде точно нет. Нет, ну ты-то просто им пользоваться не умеешь, а вот у настоящего гуру... Ну вот ещё раз говорю, у настоящего гуру я не уверен. Я бы не исключал такой возможности, вот так скажем. Я не помню, чтобы они где-то были, но я бы не исключал такой возможности. Но кому надо, пожалуйста, открывайте слайды и обучайтесь. Очень просто написано, прям с реальными примерами. Вот давайте мы сделаем это, это, это, и вот получается такой результат. И он получается таким, потому что вот смотри. Ты знаешь, просто написано, да, но у меня где-то на 20-м слайде мозг просто разрывает в чек и отказывается что-либо понимать, что происходит. Да, то есть вроде до этого ты понял, но вот сюда уже не хочется читать. Ну то есть просто в какой-то момент реально мозг как бы налетает на стену и понимает, что нет, дальше уже никак. Только можно просочиться через маленькие дырочки, вот через сеточку и в виде фарша пройти. Что ещё может пройти в виде фарша? Это Facebook, я так понимаю, FB. Плохой переход, я не одобряю. Почему? Мне кажется, в виде фарша будет ваш код на языках низкого уровня, если вы не будете перекладывать к нему подорожник и не будете его проверять всевозможными статическими чекерами. Мы здесь уже пару раз обсуждали Infer, как это правильно, чёрт возьми, произносить от Facebook. Я думаю, это Infer. Ну в общем, вывод от Facebook, который это такой тул для статического анализа кода. Я даже как-то рассказывал, по-моему, в районе сентября, как я пытался приложить его к QPQ, не очень успешно. Вот. То, что я пытался тогда делать в сентябре, это было что-то из разряда, давайте мы замоделим API QPQ, так чтобы он замоделил с точки зрения тех примитивов, которые предоставляет Infer. Но дело в том, что Infer предоставляет ограниченное количество эфиров, и... блин, эфиров, чёрт, что я несу. Ограниченное количество примитивов, ограниченное количество... А мне было интересно, ты реально думаешь, или это мы в чате с Сашей Бондаренко переписываемся и тебе кажется... Именно, именно. Замедлим Валеру, ну ты слишком сильно замедлился, понимаешь, это должно быть как-то пропорционально до скорости 1.0. Ну простите, у меня как-то сразу выбивает скалик, кто-то ещё, кроме меня, пытается общаться, так нельзя. Я не могу в 4 потока, или 2, даже 3 потока. Ты одноязерный или одноязерный с гипертрейдингом, это важно. Я с гипертрейдингом, да. Да что-то не похоже. Значит, мне наврали в магазине. Да, собственно, что завезли в инфер, давайте разберёмся. Можно простые чеки, которые основаны на регексах или ещё каких-то простых признаках, особенно это важно для языков типа objective-c, где очень много завязано просто на конвеншены, то есть если ты видишь, что что-то так называется, оно должно себя вести определённым образом. И все код пишут именно так. Или просто ты можешь сказать, что если какое-то ключевое слово в коде смачило, значит где-то должно быть обратное ключевое слово. В общем, подобные штуки теперь стало можно добавлять без расковыривания самого инфера. То есть то, что я пытался сделать, это как бы используя уже существующий, так скажем, вокабуляр инфера, писать какую-то новую библиотеку, а здесь по сути разрешили вокабуляр инфера расширять без ковыряния в саму инфере посредством специального языка. Да, это ограничено, да, внутри самого инфера можно сделать больше, но это первый шаг к тому, чтобы сделать его ещё более расширяемым, сделать его хорошо применимым за пределами фейсбука. Кстати, насколько я слышал, Spotify его начали использовать. Я посмотрел, у него самая интересная вещь, которая есть, это возможность работать с темпоральной логикой. И, соответственно, у него есть возможность доказывать что-нибудь с учётом времени. Слушай, слушай, слушай, инфер он вообще не про доказательства, он про то, что у тебя уже есть свойства, которые у тебя записали за тебя в инфере, ну или вот теперь при помощи твоего языка можешь записать, и самая база, что ты можешь сделать, если ты хочешь проверяться, просто зная, что у тебя есть стандартная библиотека языка, ты можешь просто натравить его на свою программу и посмотреть, есть ли у неё ошибки. Если инфер говорит, что они есть, значит, они, скорее всего, есть. Следующее, что ты можешь сделать, ты можешь замоделировать это, что я пытался сделать с LibDQ, ты можешь замоделировать какую-то другую библиотеку в терминах уже существующих примитивов, но, насколько я понимаю, ты не можешь особо использовать их темпоральную логику, чтобы что-то произвольное доказать, насколько я понимаю. Я там такого не видел. Ну извини, я что-то Ваню перебил, и я что-то не очень... Он пропал или он просто расстроился, что я его перебил? Чёрт. А ты меня... Я пропал, да? А сейчас меня слышно? Да. Отлично. То есть язык имеет темпоральный оператор, который позволяет описывать будущее, в которое ты пройдёшь в своей программе. И соответственно будет находить какие-то результаты. К примеру, можно будет использовать оператор вида, а вот эта штука никогда не будет иметь такого-то, или никогда не будет диалогаться раньше дирегистрации. Какие-то такие доказательства он сможет... Ну не доказательства, он сможет находить ошибки в твоих кодах, которые вот это свойство будут нарушать. Если я тебя правильно понимаю, это ты сейчас говоришь про язык расширения. Да, вот этот ALF. Но в том-то и дело, что он уже это всё делает, просто теперь ты такие штуки можешь описать для чего-то ещё. Ну я как раз про это и говорю, что это его большой плюс, что он позволяет это достаточно легко описывать на базе АЛФ-теста, твоей программы. Не, ну то есть раньше тоже можно было, что я пытался сделать, то есть если мне нужно было описать какую-то функцию API, которая делала аллокацию, а потом диалогацию, и мне нужно было соответствующие гарантии получить, то есть на самом деле просто внутри моей, так скажем, в кавычках модели, я просто в итоге вызывал встроенные примитивы, которые отвечают за соответствующую семантику. Но теперь просто можно новые такие вещи добавлять, которые не встроены в сам инфер, и было это возможно немножко другой семантикой. Ну как говорится, надо попробовать. Я сразу говорю, что для чистого С, не знаю, может они починили, но как я бы сейчас рассказывал, для чистого С работало плохо. Они говорят, что СС++ и Objective-C. Ну да, они так говорят, но я говорю, что для чистого СС работало плохо в сентябре. Но всё равно я всех призываю пользоваться, если уж не инфер, то каким-то другими средствами статического анализа, потому что он нас их спасёт. А кто-нибудь ещё может кроме инфера делать темпоральную логику? По-моему нет. Ну, я имею в виду именно статических анализаторов. Выбор небольшой. Ну то есть проверка... Мне очень нравится проверка вида, когда у тебя есть несколько объектов, которые обязательно должны выполняться в такой-то последовательности, да, и если мне кто-то будет говорить, что вот здесь у тебя нарушается вот это свойство, что оно должно там регистрироваться раньше, чем применяться, к примеру, это офигенно.",
    "result": {
      "query": "Rit 11 лет Хабрахабр концерт живой музыки пиво Тёмный Властелин"
    }
  }
]
[
  {
    "segment_id": "b59046cc-8057-4818-8582-06da05c0495e",
    "episode_id": "869db0dc-e45e-423a-aba4-8f4aca36b0af",
    "episode_number": 156,
    "segment_number": 2,
    "text": "даже не вендерлога, чтобы не хранить в Амазоне в КМС, к примеру. Подожди, а что плохо с Амазон КМС, или же КМС, это что-то какое-то тамошний менеджер всяких секретов, или я ошибаюсь? Нет, не ошибаешься, но я, честно, очень не люблю завязываться на одном облаке, либо на одном каком-то провайдере, потому что если вдруг клиент, или мне придется куда-то мигрировать, то мне все равно придется использовать какие-то сторонние тулзы, если я привязываюсь к конкретному облаку, вот почему, допустим, в Амазоне я стараюсь не использовать CloudFormation, а использовать Terraform, что если мне что-то вот приспичит, завтра сворачиваемся и уходим в Google, в Google Cloud, то я почти безболезненно смогу туда смигрировать. Ну, может, это лишний параноид, параноидальность, извини, пожалуйста, Алексей, потому что ты все равно пользуешься каким-то провайдером, у этого провайдера есть какой-то базовый набор услуг, который есть у большинства, ты же не пытаешься сделать абстракцию над OpenStack, хотя это тоже можно было бы сделать, потому что и Амазон, и OpenStack предоставляют тебе создание инстансов, то есть инстансы ты создаешь в Амазоне, а CMS-ом ты пользоваться не хочешь. Ну, у меня все равно инстансы в Амазоне Terraform создаются, они достаточно близки, получается, к OpenStack, к тому же, ой, извините, и если мне нужно будет смигрировать с Амазона на OpenStack, где примерно такие же API, ну, очень натянуты, ну, примерно, то с помощью Terraform это будет достаточно быстро, чем CloudFormation переписывать на HEAD. Это можно сделать, там есть один способ достаточно быстрый, но достаточно болезненно может быть. Нет, про CloudFormation я не спорю, но, скажем, тот же самый CMS, он позволяет тебе легко стартовать, то есть ты его сделаешь, там, я не знаю, ну, за день работы максимум, и все, тебе не надо ни с чем больше дремучиться, а тот же самый Vault разворачивать на OpenStack, скажем, ну, я не знаю. Да, с одной стороны это такой over-engineering, но с другой стороны это просто попытка, наверное, себя оградить от будущей боли, если такая, и перестраховаться, наверное, лишний раз. Переоптимизировать заранее. Да, вот, ну, уже было такое в практике, что, например, сегодня прямо вот нужно кровь из носа написать шеф кук-бук, который развернет там кластер конфлюенса, ой, извините, не конфлюенса, а джиры. Ну, окей, пишем, и тут на следующий день мигрируем все дружно на Ansible. Ну да, это понятно. Ну вот это, не знаю, уже, наверное, с годами такая паранойя просто реально начинает из собой, замечая, что паранойя берет свое. То есть мне непонятно, а такое действительно часто у вас бывает, что вы взяли в один день что-то на шеф и написали, на следующий день все побежали в Ansible? Ну, не только у нас, такое есть везде. Я вот до работы в компании EEPAM я работал в МТС и в «Большой тройке», вот, и было везде, было практически одинаково. Сейчас я живу в Санкт-Петербурге, я москвич на самом деле, я из Москвы, вот, и в «Большой тройке» то же самое было, что в компании МТС, достаточно крупной компанией в России, мы дружно пилили под OpenStack очень многие вещи, а потом мы просто начали мигрировать на закрытый продукт. Не, ну, все равно я имею в виду, что это было, даже в таких случаях это происходит настолько резко, что взяли одним днем и побежали. То есть, так сказать, одним днем я уже подумал, что там, не знаю, что-то случилось у вас такое, не знаю. Ну, тут накладывает такая специфика, что клиенту захотелось, мы клиенты ориентированные, если не смог переубедить, ну, тогда придется мигрировать. В текущий момент, вот, на текущем проекте я определяю инфраструктуру и архитектуру как тех лид, и такого не происходит, потому что, ну, сейчас вот у нас выстроена инфраструктура, это именно Terraform с одной стороны, с другой стороны у нас идет Puppet. И там куски Дженкинса местами, плюс местами даже есть лямбды, но они такие просто специфичные для Амазона. Ну, то есть вы все стараетесь довольно абстрактно писать, да? У меня есть как раз вопрос такой похожий, вот, как часто вы в реальности приводите продукты из Амазона в Google Cloud? В Google Cloud было на предыдущем месте работы мы перевозили, точнее, мы не то, что перевозили, мы использовали и Google Cloud и Амазон одновременно, потому что там паранойя была не у меня, паранойя была у Сива, и если Google Cloud, ой, этот Амазон умрет, то нам надо жить. Соответственно, у нас была такая вещь, что кусок жил в Амазоне в нескольких регионах, кусок жил в Google Cloud, и на основе этого там была балансировка именно на уровне DNS по зонам, по доступности, причем это даже не Route 53 использовался для геобалансировки и проверки хостов, жив или нет, использовал достаточно open-source продукт. А можно еще такой вопрос? Вот ты сейчас говоришь про свой конкретный отдел, а насколько их много? То есть я имею в виду, насколько то, что ты говоришь, сильно расстреляно вообще в целом в E-PAMA? Я не могу говорить за другие локации, потому что у E-PAMA, насколько мне изменяет память, больше 10 офисов по миру. У меня пул небольшой, мой отдел разделен на, наверное, 6 или 7 пулов, и как в других отделах, я честно не знаю. Пулы и локации – это то же самое? Нет, пул – это мелкая структура, но это команда фактически. Локации в Питере у нас 3 офиса в данный момент, большой офис в Беларуси, в Минске, и еще не помню, в каких городах, в Беларуси, на Украине, Польша, Германия, Америка и так далее. Понятно. Но и сейчас ты говоришь фактически свой опыт, то есть другие команды, занимающиеся подобным девопсом, они могут делать все совершенно по-другому? Да, это все зависит от конкретного проекта, от конкретной команды. У нас есть люди, которые используют… есть команды, которые используют Salt вместо Puppet или Chef. У нас есть команда, которые строят полностью… если живем в Амазоне, строим только на амазоновских тулзах, от код деплоймента, начиная и заканчивая полностью кастомными CloudWatch метриками. И вот есть команды, которые также живут на HashCorp. Тут уже все зависит от конкретного TeamLead, техлида, от конкретного проекта и что хочет заказчик фактически. Понятно. Ну и вот вопрос из чата. Ник Линкер спрашивает, используете ли вы Kubernetes? И, ну да, используете или нет? Да, Kubernetes используется на ряде проектов, есть такое. И что вы делаете со StatefulServices, базами данных, Elasticsearch, Redis, Cassandra? Так, Redis есть, используется, но используется как кэши. DynamoDB используется, но DynamoDB используется немного не по назначению, наверное. Она используется, DynamoDB, как лог-файлы, как блокировки для Terraform, чтобы реализовать RemoteState, потому что в Terraform есть проблема. Почему не в S3? В S3 тоже хранится, в S3 хранится State. А, понял, понял, видимо у вас команда большая, вы об этом стукаетесь, да? Да, мы стукаемся, да и плюс еще, если мы потеряем State, мы потеряем инфраструктуру, а это проблема. Terraform не безгрешен, как и любая толза, и если мы теряем State, мы теряем стэк полностью, и у нас начинаются проблемы. Они решаемы, но лучше перестраховаться. У меня один знакомый, он в Берлине в небольшой компании работает, State и хранит вплоть до двух или трех репозиториях отдельных. И это понятно. Слушай, а DynamoDB вы как лог-файлы используете? Это же… Ну вообще, как там получается логи делать? А там создается табличка, на которую в нее выгружается текущее состояние Terraform. У Terraform недавно это появилось, буквально, не знаю, месяца назад, наверное, три назад. И Terraform при следующем apply уже лезет, посмотрит, что у него есть ресурс у DynamoDB, лезет туда и смотрит, не суберядится ли он с кем-то. Раньше такое было у Terragrunt, или как так у толзы называлось. Это фактически абстракт, обвязка над Terraform. Возвращаясь к предыдущему вопросу, а Stateful все сервисы вы в кубернетике как с ними работаете? Я честно, я знаю, что у нас он используется, я в кубернетике не использую. У меня немного предвзятые отношения к докеру, и я его в продакшен не использую, потому что в моих условиях он немного неприменим.",
    "result": {
      "query": "Terraform миграция AWS Google Cloud"
    }
  }
]
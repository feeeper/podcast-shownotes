[
  {
    "segment_id": "2ef47594-10dc-41a9-8734-61d7d047070b",
    "episode_id": "863c3e7c-a34d-464c-a09a-ccaebed10810",
    "episode_number": 30,
    "segment_number": 2,
    "text": "То есть, там треть, что ли, всего интернета в Штатах, это на Netflix висит. Ну, понимаете, переплюнуть порнуху в этом плане, это очень большое достижение, мне кажется. Да, на самом деле. Его зовут Адриан Кокрофт, и вот как раз на ссылку на его лекцию разместил NGINX, и в том числе они, как сказать, краткие выдержки из этой лекции, из его соседних лекций. Я не знаю, кто писал статью, тут, по-моему, нет автора, по крайней мере, я не увидел. Есть автор. Тони Маура. Прямо рядом с датой, которая намекает нам, что статья-то на прошлой неделе была опубликована. Ох, черт. И в целом, вот эта вот вещь, Саш, я видел у тебя недовольство, на этой неделе было про метросервисы, а в целом мне статья понравилась. А ты наоборот? Я так понял, что у тебя это был сарказм. Нет, нет, нет, в оригинале фраза звучала так, что чем больше я работаю с Erlang-ами и ACA-кластерами, тем больше я начинаю любить микросервисы и типичную архитектуру, где есть бэкэнды без стейтов, где весь стейт в реализационных базовых данных, в манпишах, да, вот так. Она как-то лаконичнее была. Извини, а как микросервисы связаны с стейтом, хранящимся где-нибудь в базе данных? Обычно микросервисы как раз все стейтлес, в этом их фишка. То есть, вернее, как у них есть разделение на то, что у тебя есть стейтлес-часть, которая сильно масштабируется, и есть какой-то бэкэнд, который хранит данные и тоже позволяет масштабироваться. Ну, просто мне кажется, в любом случае, любой такой вот подход, рано или поздно упадется в масштабируемость базы данных и, с моей точки зрения, разумнее коллацировать сервис с данными. А почему он упадется в базу данных? Ну, в смысле, рано или поздно упадется, у тебя же не бесконечный capacity на машине, которая базу данных держит. Да, если бы только у нас была возможность как-то шардить данные или реплицировать. Нет, я тебе про то и говорю, что если у тебя на одну реплику базы данных идет 10 реплик микросервиса, то, возможно, ты можешь что-то так вот скукожить и иметь в 10 раз меньше процессов, запущенных в своей системе, и потреблять в 10 раз меньше ресурсов. Ну, это все спорно, я согласен с Валерой, то есть, иногда бывает так, что микросервис, сохраняющий какую-то шарду, это будет лучше, но иногда, Валер, бывает проще сделать стейтлес полностью машиной, которая... Я, безусловно, абсолютно ни про какие случаи не говорю, просто мне кажется, что здесь нужно от случая идти, а не говорить, что такая практика хороша, а такая нехороша. Так я не говорю, что такая хороша или такая нехороша, я про то, что когда у тебя приложение стоит из нод, и эти все ноды, они друг к другу ходят из разных мест, это не очень удобно поддерживать, отложивать. Намного проще, когда у тебя, просто и понятно, пришел запросик, ты сходил туда-туда, записал данные, и все, у тебя никакого стейта. Нет, ну подожди, при этом микросервис все равно один в другой ходит. Ну да. Я даже не очень понимаю, а стейт, если в сервисе есть стейт, он все равно за пределы самого сервиса не уходит. В чем разница с точки зрения потребителя? Тут дело не в стейте, а в абстракции, которую тебе дает микросервис. А то, что платформы типа АК и Ирланг замыкают на то, что у тебя получается очень-очень большой конгломерат непонятного, который там с собой внутри общается, ну я не знаю, в твоем случае у нас в Ирланге все поделено на такие микросервисы, если ты знаешь, вот эта система, которую мы пилили в экзанты, у нас была старая вертикаль, которая состояла из набора сервисов, мы перестроили блоки, добавили реаккор и получили новую вертикаль. То, что у вас, я примерно представляю, это не совсем те микросервисы. Я сталкивался с проблемой, что когда у тебя есть ирланговые ноды, которые с друг другом общаются, как в Ирланге принято, то у тебя там возникают всякие неприятности, что там конфликт глобальных имен в Ирланге, например. Или то, что ты пишешь кусочек кода, а потом выясняется, что в него-то кто-то откуда-то ходил, или у тебя кто-то присоединяет к кластеру старую версию приложения, где рекорды-то немножко другие. Все сильно зависит от соглашений. Это раз, а во-вторых, у нас местами были конкретно такие TCP концы, чтобы не страннулся Ирланг в Ирланг, а ходил через обычный TCP местами. Ну и ходит. Ну да, да. Я не говорю, что так не надо, ни в коем случае не используйте АК-кластер, ни в коем случае не используйте Ирланг с его распределенными актерами, но как правило, без них проще, намного проще. Ну, я об этом говорю уже не первый раз, я всегда говорю, что если у вас есть возможность писать что-то без АК или Ирланга, ну, вы счастливый человек, пожалуйста, используйте эту возможность. А в конце этой статьи на nginx.com они пиарят ту самую книжку, про которую я рассказывал. Building Microservices? Да, я ее, кстати, сейчас читаю. Ну и как тебе? Ну, так себе. То есть не очень, да? В смысле, там слишком много базовых вещей, которые все и так знают, что ли? Ну да, типа того. Единственная вещь, которая в тезисах мне удивила, nginx, ой, nginx, говорю, Netflix, оказывается, очень давно начал рассчитывать на контейнеры, и у них стандарт де-факто, что все должно работать в контейнере довольно давно. То есть я не знаю, как они начинали, скажем, без докера, они напрямую на LXC работали. Конечно, так вот, тот же самый Heroku на LXC работает. Я думаю, многие другие платформы, сервис-провайдеры тоже контейнеры так или иначе используют, потому что отличные средства изоляции встроены в систему. С одной стороны, когда ты делаешь инфраструктуру, это так, а когда ты делаешь, у тебя большая компания, сколько в Netflix тысяч человек-то есть должно быть, и у тебя должно быть очень четко, как сказать, тулзы вокруг всего этого LXC. Имея докер, это несложно построить, а пока докера не было, это же было достаточно непросто. Ну, не скажи, потому что, как правило, это решалось тем, что просто пишется какая-то своя собственная рулилка контейнеров. Свой докер. Даже не докер, гораздо более примитивная штука. Вот, например, я когда работал на своей, теперь уже получается, пред-предыдущей работе, там была такая рулилка LXC на крестах, которые были биндены к Langu, и это все, в принципе, работало нормально. Ну, то есть, все, что нужно было, выносилось в простенький интерфейс, а все остальные детали просто были статично забиты. Вот это для меня, если честно, удивительно. То есть, до сих пор еще индустрия постепенно перестраивается на использовании контейнеров, а это насколько надо сильно далеко глядеть в будущее, чтобы понимать преимущества, чтобы писать на плюсах биндинги к Langu, для того, чтобы использовать эти преимущества контейнера. Ну, то есть, оно реально должно давать большой плюс, чтобы вот эту технологию начинать издалека копать. Знаешь, честно, в той системе это не давало никого большого плюса, с моей точки зрения. То есть, были какие-то задумки, для чего это делалось, в итоге ничего из этого не использовалось. Смысл тогда? Не знаю, я эту систему уже на нее прихватили, я же рассказывал эту историю, что я пришел в компанию, которая, по сути, купила систему уже готовую, и она была на Erlang-е, Кристаха Перле, и в компании не было ни одного Erlang-иста, я стал первым. Отлично. Или второй, или что-то такое там было. То есть, так все стабильно работало, что не нужны были Erlang-исты? Нет, как раз наоборот. Ну, то есть, пока был контракт на поддержку с авторами, Erlang-исты были не нужны, как только там какая-то кошка пробежала, вот так, вот, понравились Erlang-исты. В целом, там три видео-лекции, возвращаясь назад к статье, первая и вторая, третья, это одно и то же, только на разных конференциях, плюс ответы на вопросы разные. То есть, фактически смотреть стоит только одну, а в целом, для меня, например, в Netflix, я уже несколько раз читал статьи нескольких разных людей, как устроена архитектура, у меня поэтому не было ничего нового, но я думаю, это может быть интересно тем, кто ни разу еще не читал, как они работают, на что они нацеливаются, про все эти хаусманки и так далее, там все это рассказывается. А вообще, в целом, по Кокрафту, вы сходите, посмотрите, у него на слайдшере висит основной его, как сказать, доклад, ну вот эти слайды только, чисто на 180 что-ли слайдов, что-то очень много, и там очень четко все расписано, можно даже не смотреть никакое видео, чисто по слайдам пробежаться, интересующие вещи, ссылку где-то найти в интернете. Вот такая тема. Следующая тема, давайте, опять же, я добавил, это то, что на этой неделе нашли ошибку в Java и Python, в Python реализация алгоритма TeamSort, нашли с помощью, как это, есть такой проект, который пытается искать с помощью специального, я даже не знаю, как это правильно сказать, то есть они же фактически неформально доказывают правильность алгоритма, они все равно делают что-то вроде QuickCheck, кто-нибудь читал еще? Я ее видел, почти поскипал, но, к сожалению, я не нашел времени ее полностью прочитать, все-таки переезд тут это все, но, сколько я понимаю, это что-то вроде ModelChecking, то есть это не совсем… То есть что-то посередине, то есть это не… Это не посередине, подожди, есть два подхода, есть таких прям используемых формальных подхода, первый это верификация посредством доказательства теорем, то есть ты берешь, строишь модель, как ты ее описываешь и дальше говоришь, что есть такое свойство, это свойство доказываешь прямо на ее, там, соответствующем языке моделирования. Ну или бывает система типа, не помню, как называется, где у тебя язык для описания, язык для доказательства разных языков, бред, конечно, но такое тоже бывает. Бывает ModelChecking… Медленно переборы. Не, ну это не совсем медленный перебор, там все гораздо хитрее, то есть никто, конечно же, не перебирает все полный State Space, потому что это бесконечно долго. Там есть несколько интересных трюков, я, к сожалению, сейчас их уже не смогу нормально вербализовать, там есть несколько интересных трюков, которые позволяют проверять темпоральные свойства на графике состояния программы. В данном случае tool называется Java Modeling Language, сокращенно JML. К какому классу это отнести? Ну это точно не QuickCheck, потому что это не генерация тестов на основе свойства, и не попытающихся фальсифицировать свойства, судя по тому, что, насколько я понимаю, и это тоже там есть. То есть у них есть доказательства на основе… Как это у них есть… Какой-то анализатор… Как там было сказано? В общем, ты пишешь дополнительно к программе, ты пишешь какие-то варианты внутри этой самой программы. Это подойдет вообще к любой системе моделирования, что к QuickCheck, что к ModelChecking, что к доказательствам. Ты в любом случае должен свойства написать, которые ты будешь доказывать. Да, да. И вот они делали не строгое доказательство теоремы, а они делали вывод на каждой итерации, они делали доказательство, что у тебя на каждой итерации сохраняется этот invariant с помощью какого-то своего статического анализатора. Это, наверное, на FromAC должна быть похожим, я так подозреваю. И они доказали, в общем, рассказываю тем, кто не читал статью, они доказали, что… Вернее, как они не смогли доказать, что этот алгоритм правильный. Они начали разбираться, думали сначала, что это, я так понимаю, что у них ошибка в их продукте, а потом поняли, что в реальности сам алгоритм неправильный, алгоритм сортировки, он не учитывает некоторых кривых случаев. И получается так, что вот этот весь код, который работает, скажем, в Андроиде, он в некоторых случаях будет давать неправильную сортировку. Они показали, как они это нашли, они показали, как это правильно пофиксить, они доказали, что то, что они пофиксили, уже правильно полностью, то есть они доказали с помощью своих тулзов, и они все это описали в своей статье. Как-то так. Мне кажется, это очень показательно в отношении нашей индустрии, как все говнекается, быстро, на скорую руку, типа, работает быстро, хорошо… Подожди, подожди, подожди, подожди, я не так говорил. Я тебя не перебивал, когда ты говорил, вот смотри, не надо. А потом багу нашли, типа, ну да, баг, окей, поправили, так, довольно забавно. У меня просто какой-то такой размышлизм в последнее время в голове крутится. Вот, Валер, тебе вопрос. Что такое AP-система? Это система, которая в случае, когда у нас пришел запрос, у нас часть системы недоступна, по крайней мере, с той точки, в которую пришел запрос. Часть системы, которая имеет отношение к обслуживанию этого запроса. И в этот момент мы можем сделать выбор, либо отказаться обслуживать запрос, сохранить консистентность, но зато потерять немножко доступности. Это будет CP-система. А если мы выберем, несмотря ни на что, обслужить запрос и возможно немножко временно потерять в консистентности, а потом в будущем эту консистентность как-то восстановить, потому что мы знаем, как мы это можем сделать. То это будет AP-система. Ну да, то есть это, который по Келк, ты сейчас рассказал, вот то, что касается части P, Partition. И получается забавная ситуация. Поскольку машин много, они могут время от времени падать, а упавшая машина, ну это можно считать частым случаем партишн. Ты согласен? Да. У нас есть выбор. Либо система будет три раза в день не работать, потому что машин много, они падают, и мы говорим, у нас консистенция, поэтому, простите, ребята, ничего недоступно. Либо мы можем отдать какое-то говнище и сказать, что это вроде как какие-то данные, они может не совсем верны, но вроде как они есть. И, то есть, фактически, что мы делаем в нашей индустрии? Мы делаем такие умные слова, которые оправдывают тот факт, что мы заставляем пользователей думать, что все хорошо. На самом деле, ничего не хорошо. Мы отдаем какую-то непонятную хероту, но мы говорим, что это АП решение, это нормально, все под контролем. Саш, ты лукавишь. Почему? Смотри, есть два момента. Во-первых, одна лежащая машина, это совершенно не значит, я специально оговорился, когда начал говорить, что тача системы, которая имеет отношение именно к обслуживанию этого запроса. Машина может не иметь отношения к обслуживанию этого запроса. Например, мы возьмем мой любимый React, в котором недавно появился React Ensemble. React Ensemble имеет паксус-энсамбль на каждую группу реплик. То бишь, лежащая машина затронет... Притом, одна машина вообще ничего не затронет, потому что у нас все еще есть кворум. То бишь, у нас есть две из трех реплик, мы все еще можем, у нас все еще есть большинство, мы все еще продолжаем обслуживать. Если две машины слегли, то недоступными станут только те ключи, которые обслуживались этими двумя машинами. То бишь, Саш, ты лукавишь, что ты сильно утрируешь проблему. Больше того, на самом деле можно с CP-семантикой иметь даже еще большую толерантность к падению машин. Подождите, давай разберемся. Валер, ты прав, ты полностью. Но Саша-то говорит про другое. Саша говорит, что введение самих, скажем, ну, решений, где АП ставится во главу угла и консистентность вообще не рассматривается. Нет, подожди, вот это вторая часть лукавства, потому что на самом деле это ни хрена пойми как. Есть довольно много решений, в частности, например, CRDT небезызвестные, в частности, например, рамп транзакции. И нас умными словами не грузи. Вот рассмотрим конкретный пример, который ты сам же привел. Три машины по одному ключу, да? Ты говоришь, что одна из них лежит. Ты считал данные из двух оставшихся машин и при помощи CRDT, например, отдаешь какой-то результат. Одна из машин недоступна. Но, допустим, у тебя на первой лежит какое-то одно значение, на второй какое-то другое значение, а на третьей то же значение, которое и на первом. Ты мержишь данные с помощью CRDT из какого-то непонятного состояния. Ты говоришь, что у тебя есть кворум, большинство, но у тебя есть большинство. Но те данные, которые они отдают, это все равно непонятная фигня. Непонятная фигня CRDT это очень детерминированная штука. Ты в любой момент времени по набору данных можешь знать, что у тебя будет. И ты не можешь потерять никакой информации, ты можешь временно не отдать информацию, но ты потерять ее не можешь. Ну хорошо, а если это не CRDT? Ну, дальше зависит от семантики твоего приложения. Классический пример с амазоновской корзиной, они мержат просто. Это еще другая часть лукавства с твоей стороны, потому что АП решения делают очень просто. Они говорят, что либо юзайте CRDT, либо, если вы не можете, то это не наша проблема, вы сами что-нибудь придумаете на своей стороне, помержите с помощью электронных часов. Не, ну а в чем проблема-то? То, что не все данные в CRDT можно засунуть. Нет, я имею в виду, что ты, когда выбираешь решение, где хранить, ты всегда видишь, что это система, которая, возможно, тебе даст неказнеценные данные. Да, да. Ты идешь сам на этот риск. То есть ты должен своим приложением это все решать и все. Если твои данные нельзя запихать в полу решетку, значит тебе не стоит брать АП решения, ты будешь очень неправ, взявший АП решения. Либо другой вариант, то есть твои данные должны быть иммутабельны. То есть твои данные либо должны упихиваться в полу решетку, либо должны быть иммутабельны. Значит ты не должен брать АП решения. Я неоднократно про это говорил и писал. Все это правильно, да. Но я говорю не с точки зрения инженерии, что там типа, если у тебя задача не решается с помощью CRDT, или ты всегда бишь иммутабельные данные, или еще как-то решает проблему. Я говорю скорее с точки зрения бизнеса. У тебя бизнес встает перед выбором. Либо не обманывать пользователя, давать им все консистентно. Но ты неправ, ты лук лавишь. Не ржешь? Да, ржешь. Вот представь, у тебя бизнес, у тебя два варианта. Всегда говорить пользователям правду. Но в этом случае ты очень быстро выйдешь из бизнеса, потому что у тебя система состоится из большого числа машин. Либо ты выбираешь АП решения, которые ты, разумеется, не будешь описать чисто иммутабельные данные, потому что это слишком дорого. Ты, разумеется, не будешь заморачиваться насчет CRDT. Ты выбрал АП решения. Понимаешь? Я не знаю, как другому описать мысль. Я, в принципе, не видел ни одного такого системы, которое ты описываешь серьезно. Кроме кэшей. Я видел кучу таких решений. Кэши, как всегда, Валер, ты говоришь, кроме кэшей. Кэши, они всегда присутствуют, они всегда входят в систему. А кэши, с другой стороны, они же строятся на основе кода консистентного стейта, который при том очень кратковременный. То есть закэшировали, что-то отдали. Я тебе, Валер, объясню очень доступно. Даже ты согласишься, что я в этой ситуации не докопаться и лукавства нет. У тебя есть, ну, скажем, я не знаю, система торговли ценными бумагами. У тебя в ней есть, ну, скажем, я не знаю, котировки. Допустим, у тебя порвалась связь между клиентом и стримом котировок. И у тебя два варианта. Либо сказать клиенту, что, чувак, система не работает, там где-то сеточка обрывалась, там дата-центр упал. Либо показать ему старые котировки. Как думаешь, что выберет бизнес? Подожди, define старые котировки. Смотри, что значит старые котировки? У тебя, ты же показываешь не одну котировку, ты показываешь графичек. И если ты показываешь графичек, ты рисуешь честную дырку. Если ты рисуешь просто, типа, дай мне последнюю котировку, ну, ты честно дуешь последнюю тебе известную. А если у меня упал мастер Postgres, и я даю данные из кэшика, то я честно даю просто закэшированные данные. Они неправильные, но у нас eventual consistency. Кэшик обновится в конечном счете. Понимаешь, кэш – это не eventual consistency. Кэш – это sequential consistency, это гораздо более сильная консистенция, чем eventual consistency. Ну, хорошо, окей. Но она все равно не дает достаточной гарантии. Понимаешь, достаточной для чего? Для пользователя, если ему очень нужны точно правильные данные, если реально пользователь, если они реально ему нужны, он уйдет из вашего сервиса. Если они ему реально не нужны, ну, это ок. Ну да, то есть как бы всегда получается так, что по-настоящему стопроцентно правильные данные для распределенной системы гарантированно отдать нельзя. А, можно. Нет, нельзя. Вот сейчас я объясню предельно просто, вот даже ты поймешь. Это вторая попытка уже. Еще более предельно. Я просто, понимаешь, я в пределе уже прям почти достиг предельного значения. Ну давай, давай. Это у нас же дзен. Конечно. У тебя есть, скажем, я даже не знаю, система торговли цеными бумагами. Что веришь? И в ней, допустим, есть котировки, да? Черт, я где-то слышал это. У меня сеть не рвется, но я в клиенте нажимаю «Купить», да? В этот момент с фида из там стойки где-то у контрагента ко мне в систему летит котировка. Но клиенты ее еще не видят. Она летит. И в этот же момент в систему летит запрос от клиента «Купить». Как ты думаешь, по какой котировке клиент купит свой инструмент, когда котировка придет в систему и запрос придет в систему? То есть ограничение скорости света, грубо говоря. Да, ты никак это не обойдешь. Я не знаю за биржевую систему в данном случае, я честно не знаю как это работает. Я могу сказать за игры, например. В играх, в таких ситуациях, то есть когда игрок, короче, стреляет, он же как бы пока он стреляет, у другого персонажа, тот другой персонаж мог раскрыться, например, за ящиком. Берется и делает следующая вещь. На клиент-сайде, который стрелял, рассчитывается коллизия и рассчитывается, что он действительно попытался попасть. Если клиент-сайд считает, что игрок попал, он шлет на сервер. Сервер честно отматывает время назад, на тот момент, когда клиент считает, что он попал. Сверяет своей физической моделью. Если клиент попал, то он засчитывает попадание и отматывает время обратно вперед. Отлично. Так происходит. Прицепь это для банковской сервер. Ну, я как бы, ну, то есть, серьезно, тут реально требования бизнеса. Ну, то есть, как бы, ребят, если вы в игре покажете игроку, что он не попал, когда он считает, что он попал, А теперь просто с точки зрения человека, который прячется. То есть он видит, что выбегает человек, а он спрятался за бокс. А вот как раз ему-то, он-то как раз не может контролировать, потому что в рамках ста миллисекунд он не поймет, успел он там или нет. Почему? Он же не смотрит в стреляющего. Подожди, у тебя все равно есть задержка между тем, что человек нажал на кнопку спрятаться за бокс, и тем, что тот на клиентсайде увидел, что он спрятался за бокс. И с точки зрения человека, который прячется за бокс, он точно так же мог успеть спрятаться за бокс, чем тот выстрелил. И на его клиентсайде будет уже неправильно, получается, решать. Да, да, это так, но просто видишь, в чем дело. Тут... Опа, все, аргументы кончились. Нет, нет, смотри, я Валера отвечу. А, нет. Алло, алло, алло, я просто переключил сетку. Обгони скорость Света, давай. Короче, смотри, получается, почему принимают в сторону стреляющего, потому что, чтобы заметить, что ты спрятался, а в тебя все равно попали, нужно смотреть лицом прямо в стреляющего, это редко бывает. Ну, я не знаю. А вот я смотрел прямо в него лицом, и что теперь? Ну, тогда ты, возможно, заметишь, но во-первых, да, а во-вторых, нужно иметь пинг больше 100 миллисекунд. То есть нужно играть по разной стороне Света, чтобы это заметить. Ну, то есть ты понимаешь, что это, опять же, не идеальное решение. Мы как раз Саше пытаемся доказать, что нет идеального решения, в любом случае кто-то страдает. Смотри, нет, ну, смотри, Саша более общую проблему сформировал, в той проблеме, в которой последний раз сформировал Саша, там действительно нет более общего идеального решения. Ну, кстати, нет, смотри, есть же еще, например, стратегии пошаговые и файтинги. Отлично. Они работают в так называемом локстеп режиме, это очень похоже на файтинг. А есть еще и нераспределенные системы, и там, там, рецепт сериализуется. Да, можно рассматривать какие-то кривые случаи, но мы-то рассматриваем современный мир. Нет, в современном мире сетевой файтинг и сетевая стратегия, реалтайм сетевой стратегии работают в локстеп режиме. То есть они, ну, представьте себе, такой паксос между, короче, ну, не совсем паксос, там немножко по-другому это работает, но представьте себе, похожая замороченность алгоритма между всеми, собственно говоря, играющими игроками. Это не быстро, но поскольку это стратежка, или поскольку это файтинг, там на самом деле важно реплицировать действие, а анимацию, то есть там важно не каждый фрейм анимации реплицировать, как в шутере, а реплицируется именно команда на действие, а дальше локально просто отыгрываются анимации. Мы же выясняли, что даже D-RAM работает с какой-то вероятностью, а ты говоришь, что нигде нет костылей и подпорок.",
    "result": {
      "query": "микросервисы стейтлес база данных"
    }
  }
]
[
  {
    "segment_id": "861c6b75-d03e-441c-b23c-875a1282fa7e",
    "episode_id": "771dbc75-7472-431d-acf2-2c2ffb3101d5",
    "episode_number": 72,
    "segment_number": 2,
    "text": "Про нее они уже давно рассказывали. И просто вот этот пост — это еще один классный-классный пример для того, чтобы показать, как эта система работает. Что они там делают? Это вместо того, чтобы просто взять и поменять, и потом посмотреть, как оно будет, они запускают две версии кода параллельно, в том месте, где они переключаются на эту фичу. И получается, что в продакшене не меняются обе версии, но как бы одна из них является боевой, а другая просто выполняется параллельно, но результат ее потом не участвует в основной логике. Вместо этого Scientist проверяет выход, выходные данные, выходные данные, что для одних и тех же входных данных они получили тот же самый результат. Соответственно, у них есть там система, чтобы это все там на графике показывать, есть ли какие-то отклонения и все такое прочее. И после этого они рассказывают, какие в результате баги и в Git и в libgit2 они смогли найти. Оказалось, что... То есть они запустили эту штуку, как я уже сказал, параллельно на основном коде, получили очень-очень много данных, потому что там у них происходит реально очень много merges за сутки. И стали просто смотреть на эти данные, постепенно отбрасывая какие-то случаи. И в результате за 4 дня они эмигрировали эту фичу с одной системы на другую. Такой вот хороший инженерный подход, когда вместо того, чтобы давайте попробуем, ой, не получилось, давайте откатим, они просто получают графики, и по этим графикам видят, что не так. И просто приходят к тому, что их система начинает вести себя так, как нужно. Очень интересный вопрос тем, кто просто почитать и будет интересно. Да, графики красивые. Слушай, а почему libgit2? Что случилось с первым libgit? Я так подозреваю, что первый libgit это, наверное, какой-то кусочек в самом Git. Я честно скажу, я не знаю. Или, может быть, кто-то пытался это писать. И, соответственно, они его так назвали. А еще, ты знаешь, Git же сейчас в второй версии. Может быть, был какой-то libgit, который работал с первой версией Git, а со второй работает вот этот. Слушай, а в итоге они хотели это сделать, чтобы было быстрее, да? Да. Оно стало быстрее намного? Они хотели это сделать не столько для того, чтобы быстрее, а чтобы сэкономить себе ресурсов. То есть, чтобы у них было меньше серверов поднято, чтобы у них под это дело меньше инфраструктуры было поднято. Я помню один из сайтов, который гоняется не на Амазоне, как большинство стартапчиков, а у них свое железо. Я не помню. Раньше они сидели на workspace, а сейчас на чем они сидят, я даже не знаю. Но факт такой, что они гоняются на железе без какой-то... без вот этой облачной фигни. То есть, они наверняка что-то будут использовать. Но вот так вот. Но быстрее это стало намного? Ты знаешь, наверное, да. А, вот здесь график есть. В вертикальное время в миллисекундах. И тут есть разрывы от 20 до 480. То есть, до 40 раз разница есть. Да, там же еще проблема в том, что вот этот алгоритм, который делает, собственно говоря, мерч, он же рекурсивный, и, соответственно, есть определенные случаи, в которых твой мерч будет занимать слишком много времени. И, на самом деле, внутри LibGit 2 есть какие-то эвристики на тему, как такие мерчи распознать. И вместо того, чтобы пытаться хоть как-то разрешить конфликт, просто говорить, ой, я не могу. И они нашли несколько случаев, когда у них вот эта функция, которая, собственно, делает мерч, зависала, и пыталась долго-долго искать ответ, вместо того, чтобы отваливаться по каким-то тайм-аутам и все такое. То есть, это одна из проблем, и плюс еще они не пишут, весь мерч происходит в памяти, то есть, они не пишут вот эти файлы на диск, то есть, они просто читают из репозитория собственные дифы, то есть, то, что лежит в точках Git, и больше никаких файлов им не нужно. Послушай, я... А, уговори. Нет, у меня два вопроса. Во-первых, я не читал еще GitHub Engineering Blog, он вообще хорош сам по себе, ты часто его читаешь? Довольно часто. Там местами бывает достаточно интересно, то есть, у них, например, был эпичный блокпост, говорит о том, что GitHub, это, наверное, сегодня самый-самый известный сайт, который до сих пор крутится на большом-большом приложении, на рубе Unreals, то есть, там есть еще Twitter, но Twitter там многие куски проносили в скалы и еще куда-то, и получается, что там у них, конечно, что-то крутится на рубях, но не так, чтобы сильно много. А GitHub, действительно, там очень-очень много всего крутится, собственно говоря, на рельсах, и они очень долго жили на каком-то форке Rails 2, и буквально, по-моему, то ли этим летом, то ли прошлым у них был большой-большой блокпост на тему, как они постепенно-постепенно съезжали с этого форка и все-таки оказались на последней версии рельсов. То есть, тоже примерно такой же подход, когда у них все вот эти переходы по фичам, они верифицировались, то есть, они получали метрики и по этим метрикам что-то делали. В целом, нужно понимать, что у них немножко специфичная нагрузка в плане того, что они работают с репозиториями, и, возможно, то, что они делают, не очень подходит каким-то другим компаниям, но, почитать, интересно. Наверное, до блога Netflix от какого-нибудь, наверное, не дотягивает, но довольно прикольно. А я бы не сказал, что у Netflix прям все посты такие, что огонь. Да, но, знаешь, с точки зрения влияния Netflix на индустрию, наверное, их блог гораздо более влиятельный, чем то, что делают. Но у GitHub время от времени несколько раз в год проскакивают такие длиннющие посты именно с хорошим содержанием. Вопрос. Я правильно понял, что они взяли и с нуля заимплементировали алгоритм мержа? Они не боятся, что оно разъедется когда-нибудь с тем, как Git работает? Да, потому что они заимплементировали тот самый мерж, который у них есть. То есть, они за 4 дня получили несколько миллионов этих мерджей и проверили, что их алгоритм ведет себя. Нет, сейчас ведет себя так же. Напишут там новый алгоритм, и у них разъедется. Если честно, я подозреваю, что наверное, все это привело к тому, что они написали кучу тестов, и в GitHub работают несколько сотрудников, которым платят именно за то, что они пишут Git Full-Time. То есть, мне кажется, что там... Скорее, они напишут следующую версию GIT. Не то чтобы целиком, да, но грубо говоря, что GitHub сегодня это один из основных вендоров, который Git, собственно говоря, и поддерживает. Поэтому такой опасности, скорее всего, нет. И плюс, ты же понимаешь, что это имеются в виду те мерджи, которые делаются мердж-кнопкой. Когда ты создал pull-request, и потом ты идешь на сайт и нажимаешь кнопочку. Я работал в нескольких компаниях, где было принято использовать только эту кнопочку, и в нескольких компаниях, где наоборот, эту кнопочку никто не любил. Потому что он делает мердж довольно специфично, в плане того, что он всегда создает вот этот мердж-коммит, а некоторые любят rebase вместо мерджа, а некоторые еще что-то любят. В общем, некоторые любят, чтобы не было вот этих лишних мердж-коммитов. То есть, если нет конфликтов, то просто у тебя ветки сливаются без лишнего консистенции. — Ну понятно, кнопку одобряют не всем. Я тут в тему про Git, я тут недавно свалил с платного GitHub. Точнее, не так, я и с Bitbucket свалил, и с платного GitHub. — А Bitbucket чем не устраивает? — Нет, он нормальный, а мне просто не очень нравится, во-первых, зависеть от стороннего сервиса, потому что в Bitbucket лежит и опа, а ты без репозитория. И как оказалось, у меня нету такой командной разработки в моих закрытых репозиториях, это для меня. И я сделал себе, точнее, даже у меня была машинка в DigitalOcean под VPN, я решил, а что я как дурак, плачу еще GitHub. Зашел по SSH, сделал репозиторий, сказал, GitKlone работает. Более того, оказалось, оно работает намного быстрее. Ты чувствуешь, оно работает реально быстрее, чем Bitbucket или GitHub, потому что они там все под нагрузкой, им нужно... у них там куча хоков на то, что нужно в интерфейсе что-то поменять. А здесь у тебя все прям летает. Так что, если лень переплачивать, то рекомендую... Ты переплачиваешь за DigitalOcean. Нет, я и так за него уже платил. А я сделал хитрее. Мне когда нужно было репозиторий, я брал какой-нибудь например Google Drive или Dropbox, в нем создавал репозиторий, потом с ним синкался из моей папки, где я проект веду. Ну, а потом они восстановятся из бэкапа, когда, ну не знаю, по какой-то причине, и у тебя все будет в криффе в коде. В смысле? Ну у меня же 2 копии получаются локальные. Один, который синхронизируется с Google, а второй... Ну, я понял, да. Но с другой стороны, я и по самби так делал. Так что... Ну, у меня тогда не было выхода. А я как раз плачу за GitHub. И во многом плачу именно потому, что есть вот эти дополнительные какие-то хуки и всякое такое. И даже в приватных репозиториях я часто первым делом цепляю Cycles CI, который тоже бесплатный. И он, конечно, тоже чуть-чуть тормозной. Кого цепляешь, извини? Circles CI. Это CI-сервер, типа аналог Travis CI или CodeShip. В общем, такая штука из серии. Ты пушешь, а оно тебе тесты гоняет. У него там бесплатно сколько-то тестов, сколько-то прогонов в месяц. И часто бывает, что мне хватает. Я, честно говоря, не помню, какой там биллинг, в плане того, что биллинг ли там по репозиториям отдельно, каждым, или там биллинг целиком. Но я еще ни разу за него не заплатил, но при этом периодически пользуюсь. Плюс я пушу не каждый коммит, а я делаю фичи бранчи, локально, даже если сам работаю. Или, например, если не делаю фичи бранчи, то делаю несколько коммитов, потом такой, о, примерно фичи готовы, я теперь пушу, и у меня теперь тесты прогоняются на других операционных системах. Вот и все. То есть там у меня локальный маг, там линекс, соответственно, прогнали тест, все окей. Чего ты хотел сказать? Я еще хотел сказать... Я понял, что у меня может сильно увеличиться количество закрытых репозиториев, потому что это связано с моим увлечением всем CIS-шным и тем, как используются сабмодули в этих проектах. Поэтому у меня могло увеличиться количество закрытых репозиториев и, соответственно, пабло, которое я плачу. Я вот сейчас плачу за 10, то ли 12, то ли чего-то там. И я уже думаю переходить на следующий день, потому что тоже надоело. И еще я хотел сказать, что у меня часто бывает, что репозитории закрыты, закрыты, закрыты, а потом в какой-то момент я его просто открываю. Это да, это понятный кейс, но это две команды в башу, поэтому я не вижу большой проблемы. Так, хорошо. Одному мне кажется, что у Dropbox такая странная ценовая политика, не у Dropbox, а у GitHub. Это как если бы Dropbox просил денег за папочки, а не за гигабайты. Да, да, да. Ну да, я поэтому вижу, что у многих сделано так, что есть какой-то один репозиторий, который они называют Playground, и в нем реально происходит все подряд. А зачем вообще при этом заносить денег на Dropbox, я не понимаю? Если это твой личный приватный репозиторий, в котором нет лабораторов, зачем он вообще на Dropbox? На GitHub, видишь. Ой, сори, блин, что-то у меня сегодня. На GitHub? Ну, потому что сегодня ты за одним компом, завтра за другим. Окей, следующую тему добавил я, и Ваня хочет к ней под... как это сказать? Подсесть. Подключиться. Подсоседиться. Пост называется «Как я написал self-hosted C-компилятор за 40 дней». Автор Руи... непроизносимое имя даже, не буду пытаться. Это при том... Ну, короче, чувак решил написать компилятор на C. Нет, он решил написать триллер, я так понял. А потом на тему триллера начал писать компилятор на C. Это как раз саморазвитие, но чтобы лучше понимать язык C. Понятная цель. И походу он делал себе заметки. Было это несколько лет назад, сейчас он решил эти заметки опубликовать. И читается действительно захватывающе, как Ваня сказал, как триллер. То есть, то из разряда «День 8-й у меня начало работать какие-то элементарные вещи с указателями, день 15-й я добавил оператор деления, условные операторы, оператор равенства, плюс-плюс, минус-минус». Вот в таком роде статья. И действительно очень интересно читается. Мне особенно запомнилось это тройные тесты так называемые. То есть, там идея вот в чем. Что ты берешь компилятор, компилируешь его самим собой, а потом берешь результат, то есть компилятор, и снова компилируешь компилятор и проверяешь, что у тебя тот же результат на выходе. То есть, ты таким образом у тебя двойной проверк, что ты правильно скомпилировал код, и то, что он после этого компилирует тот же код в то же самое, понимаете. И демпатентность компилятора. Ну да, вроде того. Это классическая проверка, когда у нас в универе те люди, которые защищались на реализации каких-то языков, их заставляли так делать. Ну, это круто. У нас был такой предмет, но он был такой, нибы хардкор, я бы сказал. Вот я о таком, наверное, первый раз прочитал. Или, может, читал когда-то очень давно. Я, можно, несколько выдержек оттуда прочитаю? Конечно, давай. Вообще, меня тоже очень порадовало. Во-первых, он несколько дней подряд ковырялся с препроцессингом и с тем, чтобы у него stdila.h скомпилировался. И, в конце концов, у него было так. Ну, я не помню точно, что же я там такое пофиксил, но теперь у меня он компилируется. И дальше объяснение вида, что я здесь сделал хак, там сделал хак, тут у меня почти не работает, это я вообще игнорирую. Типа такого. То есть, как бы, там очень реально много забот и бед. И он прямым текстом показывает, где проблема есть в языке, где недостаточно специфицирован, где вообще не специфицировано ничего. Вот. Потом, значит, следующая фраза. Я думаю, что я с языком C работаю уже почти 15 лет, но сегодня я чувствую, что наконец-то я до конца понял, что значит type syntaxes впервые в жизни. Типа такого. После того, как сам имплементировал. Type syntaxes? Там, когда ты определяешь новые типы и используешь их везде. Вот. А вот еще. Когда он делал вторую... Как это? Компилировал компилятор компилятором, а потом у него получилось, что этот компилятор с компилированным своим же компилятором не проходит те тесты, которые проходят, если с другим компилятором, каким-нибудь GCC, компилировать. И он говорит, что у меня нет никакой возможности отдебажить эту версию компилятора, потому что я не добавляю туда дебаг информации. Поэтому придется printfами делать. И мне это напоминает фильм Inception, что мы должны пойти глубже для того, чтобы воспроизвести эту ошибку. В общем, там довольно много веселых идей. Их прямо... На самом деле смешно читать. Мне по стилю очень напомнило Марсианин. Я не знаю, кто не читал Марсианин. Здесь то же самое. День такой-то, у меня, значит, кончился кислород. Ну, вот здесь. Я не смог откомпилировать stdio.h Прямо очень похоже. А ты кино пробудил, которое Марсианин? Ну, я читал его. Не смотрел. А, я смотрел потом тоже. Я смотрел экранизацию, и те, кто смотрели и читали, говорят, что фильм, он довольно обрезанная версия книги. Книга очень интересная. Фильм... Не смогли они туда запросить. Нет, мне он тоже понравился. Ну, видимо, потому что я не читал оригинал. Вы слушаете Kinozen Podcast. Да, мне очень понравился из этой статьи. Там, из разряда. У меня началось все сяк-холчиться. Я не понимаю, почему. Там, чувак три дня бился, бился, бился. Потом, блин, я лошар и я там читал документацию про АБИ на x86 системах. В смысле, на x64 системах. И, блин, я же стэк не выровнял до 16 байт. Вот я лошар. Вот. Еще очень много полезных ссылок в этой статье. То есть, я рекомендую ее даже если читать влом. Но она довольно длинная. То хотя бы посмотрите на ссылки. Здесь, например, есть как это называется? Final Draft C99 Final Draft C11 Почему именно драфты? Оказывается, что вот эти стандарты полноценные их версии они распространяются за 60 баксов за подаевку. Их прям очень трудно... Ну, их никто так не покупает. Потому что у всех есть бесплатные драфты. И поэтому нельзя найти этот стандарт где-то на торрентах. Ну, или я плохо искал. Поэтому вот все читают драфты. Так что, вот. Что дополнение? У меня не было опыта писания компилятора такого, чтобы он выдавал машинный код наружу и всякое такое. То есть, я писал интерпретатель. Но у меня была практика когда я писал дебаггер для одного языка в опере. И в какой-то момент мне приходилось дебаггер дебазить. Позвольте спросить. Он начинается на Java или на Visual? На желание языка? Нет. Компилятор я писал для языка своего, который там внутри придумали. И написал я его под Visual Studio и под Eclipse. Соответственно, он был и на Детонете и на Java. Но в какой-то момент мне пришлось Eclipse дебажить дебаггер, запущенный для этого языка в другом Eclipse. Это, конечно, тоже лёг мозги. И было, конечно, тяжело. Мы должны пойти глубже, да? Да, да. То есть, вот этот Inception эффект он, конечно, присутствует очень сильно. Пошли дальше? Видимо, да. Валер, дальше твоя тема. Окей, видимо, холд. На секунду задержу мысль. Я просто хотел сказать. Оказывается, вот этот драфт стандарта языка C, он страниц на 500 всего лишь. Так что можно прочитать вполне. А зачем? Это не много. Это очень много. На самом деле, нет. У людей, которые читали стандарт по джаваскрипту, он, по-моему, тоже 500-600 страниц, что-то такое. И я знаю одного человека, который знает чуть ли не от кроки до кроки. И, конечно, у человека память совершенно сумасшедшая. Он может столько всего вспомнить, что просто страшно общаться с ним. Я просто читал эти стандарты сам, в смысле, на C. Но я же разрабатывал компиляторы. И его очень сложно читать в том смысле, что вот у нас есть такое правило, а теперь рассмотрим 100 тысяч исключений, которые либо действуют не так, либо применяются немножко по-другому. Мы про C, не про C++, да? Да. Хорошо. Нет, я не говорю, что это прямо увлекательно захватывающая чтива, но вот так если, не знаю, страниц по 30 в день, так аккуратненько, я думаю, можно оселить. Просто смысла большого нет. То есть надо тебе кусок какой-то, ты его почитал, посмотрел. Полный стандарт читать всем. Нет, но если ты пишешь на C, разумеется. Мне кажется, это полезно в том смысле, что там есть какие-то вещи, и вот не помнишь, это undefined behavior, или оно там в стандарте как-то все-таки определено, что вот оно там вот так себя ведет. А, нет, ну это да, это обязательно. Я вообще-то не думаю, что ты это запомнишь после этого надолго. Ну, давай я прочитаю и запомню. Ну, в смысле и выясним. Валер, твоя тема. Извини, я тебя перебил. В общем, тут на следующую, на прошлой неделе, 7 декабря, вышла новая версия консола. Но меня не было, и мы не обсуждали. В общем, там есть интересные фичи и спорные фичи. Самая интересная и вкусная фича, это так называемая сетевая томография. Они впили в нечто под названием Vivaldi алгоритм, который расставляет ноды по network координатам. Я, честно сказать, еще ничего не читал про это Vivaldi, но в целом идея того, что консол, он в любом случае сидит на каждой машине, просто часть из них, 3 или 5 собраны в raft. Но так, в целом, консул-клиент, консул-агент сидит на каждой машине. И они периодически друг другу гостям шлют приветы. И состояние, кто жил, кто не очень. И раз они это все равно делают, вполне логично во время этого гостя точно так же измерять в среднее время раунд-трипа и прочие похожие характеристики. И вот красной основе этого они строят так называемую карту. Координат. На самом деле, смотреть на нее, я не знаю, можно или нет, но тут интересно, что во-первых, можно очень довольно легко запросить у консула, как дела в моей сети. То есть сейчас, лично мы на работе мониторим так, что у нас просто есть метрики просто снимаемые из каждого отдельного сетевого интерфейса. То есть если есть какие-то проблемы с сетей, мы максимум видим, что на каких-то таких сетевых интерфейсах почему-то TCP там прыгнул, скорее всего, потому что у нас реконнекты были. Или у нас retransmission TCP подпрыгнул. Так. Вот. Это все? Секунду, ты мне просто сказал про микрофон. Я не имел в виду, вот прямо сейчас бросай все и занимайся микрофоном, потом починишь. Ну, сори. Вот. А тут можно прям пойти и посмотреть, откуда, докуда у нас киппинги. В принципе, это крайне интересно, потому что даже у нас сейчас мы сидим как бы в одном дата-центре, у нас так получилось, что у нас там не совсем идеальная сеть, в плане того, что у нас там получается два сегмента, потому что машин многовато стало. И там уже бывает интересно, бывают интересные ситуации, и там как бы не так, что у всех резко latency одинаково выросла, потому что роутеру потеплело, а там бывают интересные ситуации, бывает интересно посмотреть, от кого до кого выросла latency. Больше того, он теперь позволяет, ну он в смысле консул, теперь позволяет делать сервис дискавери по принципу, отдай-ка мне что-нибудь, что мне быстрее всего ответит. И это вообще огонь, на мой взгляд. Особенно если у вас что-то по нескольким дата-центрам разбросано. Не обязательно консистентное, но зато быстро. А, нет, в смысле, как бы там запрос вида дай мне сервера такого типа, которые ближе всего к такой точке типа такого. Ближе в смысле... Не то, что тебя консул ближайший обслуживает. А ты у консула можешь спросить, кто тебе из серверов, в котором ты хочешь пойти, быстрее обслужит. Забавно, забавно. А статистика как раз на основе этого собирается. Раундрипа. Вот, вторая хитча, которую я считаю, ну то есть она идея для консула хорошая, но в целом она выглядит довольно спорной. То есть ребята, так понял, мне очень нравятся у них, до этого раньше была LMDB, Lightning... Что же с кем она расшировывается-то? Lightning Memory Map Database. На самом деле довольно интересный проект, если вы про него не читали, почитайте. Там автор довольно интересным образом biased в сторону... В сторону от LevelDB, скажем так. У него очень интересная критика в сторону LevelDB, я рекомендую ее почитать. Вот. Ну, как бы, на самом деле это немножко в сторону ушел. Подожди, что за критика LevelDB? Что его не устроило? Ну, как минимум, что скажем так, LevelDB это такая штука, которая опримизирована на запись. И у чувака интересный взгляд, типа что если данные некогда читать, то зачем вообще их писать? То есть, типа, если ваша база данных так написана, что ваш дисковый хранилищ так написано, что оно оптимизировано для операции записи до такой степени, что у вас могут очень сильно проседать чтения, вы уверены, что вам нужно такое хранилище вообще? Ну, что за дерзкие лепят? Ну, вот обычное такое приложение с такой странной нагрузкой, что 90% времени пишем, 10 читаем. Ну, нет, он не спорит, что такое может быть. Просто LevelDB это довольно универсальная штука. А в то же время, как большинство ворклодов, которые существуют, они на самом деле как раз про то, что пишем там и все-таки довольно таки пропорциональное время чтения. На самом деле, довольно много интересных всяких вещей, включая то, что типа LMDB, она ориентирована на встраивание, и LevelDB тоже типа ориентирована на встраивание, но он приводит довольно интересный аргумент, что то, как в ней происходят компакшены, то, как в ней происходят некоторые другие вещи, они на самом деле делают эту базу данных, то есть LevelDB, особенно ванильная, гугловская, она считает, что она король, и никого кроме нее рядом нет. Конкретно эти вещи подтверждаются тем, что LevelDB форкнули Facebook, Basho и Hyperdex, и у них у всех примерно одинаковые изменения, которые как раз направлены на то, чтобы сделать ее более дружелюбной по отношению к тому, что там еще кроме LevelDB работает. Или к другим LevelDB, которые работают на той же самой машине. Вот, как-то так. Понятно. Окей. На самом деле я рекомендую почитать этого чувака, потому что можно просто пойти на страничку LMDB и там, по-моему, по этому же сайту можно прогуляться и найти ссылки на его другие посты, если не ошибаюсь. Но если ошибаюсь, я потом в комменты занесу. Вот. Ты когда говоришь LMDB и LevelDB, ты их почуче приноси, а то я вот знаю, в чем дело, а слушатели, я думаю, запутаются. Ну простите, если я невнятен. На самом деле мы отвлеклись. Так вот, консенс на LMDB. У них с ним была пара проблем. Во-первых, LMDB сам по себе как просто обычный KVL, он не совсем оптимален для тех запросов, которые они к нему делают, им приходится немножко больше по нему шариться. А во-вторых, он на Cишечке написан. Поэтому им нужно было, у них как бы был весь проект на Go, и один такой ключевой депенд на Cишечке. Вот. Они сделали в итоге странное, на мой взгляд. Ну то есть, наверное, для консола это нормально. Но в целом, в общем, я сейчас скажу, а вы дадите ваше оценочное суждение. Они взяли и сделали in-memory базу данных, которая при этом необычная к KVL, поскольку они все-таки DNS в первую очередь делают, они сделали это на Radix 3. То есть там довольно эффективно можно делать запросы по префиксам. Вот. И... У нас есть Raft, с одной стороны. Он в любом случае, его лог Raft в любом случае пересисывается на диск. В любом случае, в какой-то момент Raft должен снимать снапшоты. Поэтому то, что баз данных у нас in-memory, он как бы на консистентность не влияет совсем. Ну и наконец, у нас просто реплицированная вся эта фигня. Поэтому тем более не так важно. Но с другой стороны, это довольно сильно ограничивает, например, с той стороны, что консол, он в принципе как бы как DNS, наверное, ну и оно влезет даже в памяти, ничего плохого не случится. Но если начинать его использовать как хранилище конфигов, я уверен, вот кто-то так пользует, и в классе дать там не одно значение, а там поключу сразу большую партямку JSON, то на достаточно большом кластере, мне кажется, оно может так произойти, что у нас количество данных, оно может как бы вылезти за пределы памяти, которую мы хотели бы выделить на машине, которая у нас отвечает чисто за за менеджмент кластера. Ну то есть у тебя больше 500 мегов, например, конфигов, серьезно? Ну, мы с тобой вместе работали в компании. Но там не было 500 мегов, там и 50. Там было больше. Там было больше? Нет. Было? Неа. Ну не знаю, я помню, что я помню, что у меня как-то раз память во время чтения конфига подрастала почти до гигабайта. Я не знаю, возможно, это был факт того, как его читали, собственно, что я в тот момент очинил, но я помню, что там было много данных, их нужно было оптимально читать, чтобы оно вот так вот не себя не вело. Здесь они про вот этот Radix пишут, что они перешли на него, чтобы избегать проблем с десертилизацией структуры и прочего. Ну я и говорю, что имерадикс 3, он подходит идеально для их запросов. Для основного паттерна запросов. У них не Key Value, у них DNS. DNS в данном случае так и получается. Он не Key Value, в том-то и дело, что он не Key Value нифига. В смысле, я имею в виду, он хорошо ложится на Radix, я вот что хотел сказать. Ну да, да. Получается, что у них основный функционал хранения конфигов, он стал, возможно, он, возможно, может пострадать для какого-то пользования. Ну вот Александр со мной уже спорит, ну вот я не знаю, у меня нет однозначной оценки этого факта. С одной стороны, в принципе, это хорошее решение. Просто в целом под их use case оно подходит лучше, чем ламбда-б, наверное. Но вот не пострадал ли при этом кто-то? Если пострадал, то откатится. Ну то есть чуваки теперь себя позиционируют как N-memory. Да, им просто важно быстро обслуживать DNS-запросы. А это на самом деле важная штука. Ну я имею в виду, если вы делаете сервис-дискавери, то у вас на одной машине может быть куча всяких вещей, которые делают постоянно запросы, и там с одной машины может идти несколько, я не знаю, сотен запросов в секунду. Ну если так надо внезапно. Ну и потом упер все это в память. Ну удвоить количество памяти там 10 баксов стоит. Ну да, наверное, ты прав в этом плане. Что еще ребята сделали в консоле? А вот подожди, вот относительно этого, они сказали, что это прям вот большая-большая фича уйти от C, и теперь все это на год. Они этому три абзаца посвятили. На самом деле вот такой вот больной вопрос скомпилировать C, если ты с Гошечкой что ли? Ты это сейчас у кого спрашиваешь? Не знаю, у кого-нибудь. Я могу тебе сказать, что вот как это сформулировать так аккуратно, прикладным программистам, которые вот пишут на го, на го, на го, а потом у них вот тут, не знаю, 2000 строк кода на C, условно говоря, им это очень некомфортно и неприятно и непривычно, действительно. Я по своему опыту могу сказать, что вот чуть-чуть есть C, и это вот сразу беда. Я по своему опыту, правда, с другими языками связки RLANG с C могу сказать следующее, что обычно проблема не в том, что у нас там кусок на C, в любом случае, как правило, его поддерживать-то не нужно, он скорее всего просто чужой, забил, как бы заимбедренный, ну или там кто-то, один или два человека в команде за это реально отвечают, а остальные просто смотрят. Проблема обычно в другом, в том, что этот кусок на C, он предполагает какой-то environment для сборки C. И его не всегда можно идеально одинаково получить на всех машинах, то есть, грубо говоря, пример жизни. Есть RLANG, есть биндинг к некой библиотеке на C, пропитарной. Вот. И например, разработчики, которые разрабатывали, они там можно сказать, долгое время кто-то, который раньше сидел на Mac OS, ушел, долгое время библиотека собиралась только на Linux. Потом прихожу я с Mac OS, и оно внезапно выясняется, что на Mac OS оно больше не собирается. Да, или под Windows, или, например, у тебя, не знаю, все работало-работало, а потом у вас появился армовый сервер. Ну да. Такого рода проблемы. Ну да, понятно. Да, и еще интересно, что эта замена база, там 26 коммитов всего, там файлики в пост вот так вот выложены, написали ее два чувака. И фактически по сравнению с LMDB это прям совсем-совсем маленькая штучка. LMDB тоже очень маленькая. Ее можно прочитать всю. Ну там явно больше, чем 20 коммитов. Ну да. Кстати, мне это напомнило, тот чувак с компилятором, он все это запостил на GitHub, и там есть история коммитов, то есть все прям очень интересно. Тут еще такой момент, LMDB, это очень широко используемая база данных, то есть, бэкэн, прощение, он используется в OpenLDAP, как минимум. Есть еще сборка, насколько я понимаю, с Кулайта, тоже с ним. А вот этот вот Radix3, я, конечно, верю в то, что ребята из HashiCorp, они не дураки, они умеют код нормально писать, судя по тому, что они до сих пор делали. Но все-таки набег часов, налет часов у вот этого их нового бэкэнда, он как бы все-таки значительно меньше. С другой стороны, они не пишут на диск, что сильно упрощает реализацию. О чем мы, кстати, поговорим чуть позже. Скажи мне, Валер, вот, ну как эксперт, мне срочно нужен вот как консул, что ты посоветуешь, консул, etcd или zookeeper? И почему? Ну, в смысле, вот, мне, как эксперту, сперва нужно знать, для чего тебе надо. Потому что я могу любого из них посоветовать. Очевидно, конфиги хранить. Конфиги хранить, конфиги хранить, ну, etcd или консул. Но бывают случаи, когда я могу с частой совестью посоветовать тебе zookeeper. Например? Ну, например, у тебя джавное окружение, тебе нужно именно что консенсус там, блокированьки, выбор лидера, или вот это все, то тогда zookeeper будет, наверное, более хорошим решением. Особенно если кто-то есть в команде, кто с ним уже работал. Если тебе нужно это все, но нету джава, мира, и там нету других вещей типа кафки, которым все равно нужен zookeeper, то etcd. Если тебе нужно что-то кроме консенсуса, то тогда консул. Ну, то есть, смотри, etcd и zookeeper, они оба про консенсус. И про какие-то примитивы, которые вокруг него можно потом построить. Но в особенности zookeeper, к которому есть целый куратор. Понятно. Но при этом zookeeper, они из чего кроме джавы использовать особо неудобно. Etcd удобно, особенно раньше было, а потом сломали. Но все равно все еще удобно. То есть, хотя бы вазовые вещи там можно делать. Ну и как бы в принципе можно... О, боже мой. Да, это я... Я не удержался, я занес немножко спецэффектов в подкаст. Окей. Надеюсь, они не будут сильно всех напрягать. Да, но честно говоря, я с трудом расспросил, что там сказали. Да? Тебе по-постарейски? Я понял, что это из Counter-Strike, да. Ну, повтори, повтори. Ну, сейчас. А, в общем. Сейчас было сложнее. Да. Продолжаем? Олег, давай следующий. Там у них еще были. Вот. Вкусная фишка, которой лично я просто тоже бы радовался, точно так как с сетевой томографией. Это, ну, можно сказать по-русски, запеченные запросы. Ну, то есть, бывает так, что нам хочется какую-то сложную запеченную? Ну, или как это? Ну, как в пирожке запеченную? Ну, или как это? Заготовленную. Короче, вот как бы бывает в пасгарю, короче, prepared queries. Ну, приготовленная, заготовленная, но не припеченная. Запеченная тоже используется, особенно когда говорят про какие-то текстурки или лайкмапы. Первый раз слышу, если честно. Ну, по гугле. Вот. Так, к чему это я? Да. Бывает так, что хочется у консола спросить что-нибудь эдакое, типа а дай-ка мне редис с фейловером такой, чтобы он был поближе, ну, с точки зрения этого нетворка томографии, да так, чтобы он был мастером и неэкспериментальным. И чтобы у него там DNS, короче, чтобы да, а, и чтобы вот это запросы в DNS было, типа там, time to live был таким-то. В принципе, что-то эдакое можно изобразить довольно легко на HTTP API консола. Проблема в том, что многие любят и пользуют консол, потому что он, как бы, торчит наружу DNS, и он может с HTTP API вообще не интегрироваться. Просто, ну, берешь, пишешь в конфигах, где тебе нужно вот DNS-адреса, которые в консолу резолвятся. А он дальше тебе будет подпихивать машины, которые тебе нужны. Прекрасно. Но вот такие сложные штуки на DNS делать раньше было нельзя. Теперь можно. То есть мы теперь можем, когда вот этот вот запрос с JSON-чиком плюнуть в консол, дать ему имя, потом по этому имени ходить в DNS. И получать радость от жизни и удовольствие. Офигенная штука. Да, я просто в восторге. Круче, чем в ETCD, да? В ETCD раньше такая штука была, ну, почти такая. Там не запрос можно было заготовить, там можно было прям небольшое расширение написать. У них на этом много что работало. Сейчас они, потом они поняли, что это все не совсем идеально ведет себя. То есть там были неочевидные моменты в использовании того, когда в ETCD было сделано. И мы пошли переделывать, чтобы это было, как это, очевидно пользовать. И чтобы там не было неочевидных проблем. А на время, пока не переделывают, они взяли и отломали то, что было раньше. Вот. Сейчас стало очевидно. В принципе, они уже выполнили свою цель. Ты про ETCD? Да. Они все удалили, теперь всем понятно, что ничего нет. Ну, там правда, у них там были расширения, которые делают довольно нетривиальные вещи. Когда в нетривиальных вещах есть неочевидные корнер-кейсы, ну, получается, сукки, по которым все равно накручивают сверху как куратор. Вот. Поэтому, а смысл делать неочевидные корнер-кейсы? То есть, ну, смысл тогда вообще делать это внутри ETCD, а не снаружи, как куратор для зукипера? О, окей. Но это еще не все про консол. Они еще тут фичей занесли. Они сделали модные ACL. Я, честно говоря, никогда в этой жизни ACL нигде не пользовался. У меня всегда ACL на уровне запрещено, и можно все. Потому что, ну, мне редко нужно... Постой, по-русски вот эта вот фича, это что вообще? Ну, ACL, access control листы. Ага, так, хорошо. Но наши слушатели это могли не понять. Окей, окей. Вот. Мне тоже непонятно, зачем они в консоле в данном случае. То есть, они предполагают, что консолом будет пользоваться больше, чем одна группа людей? Ну, то есть, наверное, да, если ты там его пользуешь вместе с кем-нибудь кубернетом, где у тебя типа в кубернете потенциально могут быть несколько команд сидеть, то есть, ну, ты такой девопс сидишь модный, вот, девопсишь себе вот эту инфраструктуру, на которую у тебя крутятся, не знаю, команда А и команда Б. И ты, значит, не хочешь, чтобы команда А могла, то есть, конечно, не по злобе душевной, а просто из людской ошибки могла сделать какую-нибудь бяку команде Б. Вот. И чтобы эта бяка не могла произойти даже в теории, вот, мы берем и делаем ACL. Нет, подожди, ACL не даст им что сделать? Прочитать из ДНС? Скорее, знаешь, мне кажется, скорее записать в ДНС. Ну, и прописать в ДНС тоже, наверное. Это уже более параноидально, но тот use case, который вижу лично я, это вот именно запретить писать в песочницу другой команды. Просто как бы тут разделять-то надо доступ к серверам, а не к ДНСу, который может быть закаширован где-то, схватить случайно там, не знаю, на чьей же машине. Да, но просто если ты заранее их разделил, например, то, наверное, все хорошо. Ну, еще есть особо параноидальные проекты, специфика у них такая, и они действительно хотят, чтобы ты не знал, где находится база данных. Но тогда не надо складывать в ту же самую подсеть на тех же самых серверах, вот и все. Согласен. Мне тоже, как бы, для меня, я никогда не понимал ACL в базах данных и ACL в таких конфигурационных менеджерах, потому что я в своей личной практике use cases, кроме как вот все можно или кому-то нельзя, а потом кому-то другому все можно, ну, или там еще use case кому-то только на чтение, а кому-то все можно. А прям access control листы, вот прям вот с разграничением, мне в жизни были не нужны. Ну, ты тоже интересный, вот тебе было не нужно, значит это не правда. Я не говорю, что никому не нужно, я сказал, что в моей практике, заметьте, сказал, в моей практике. Дальше они ввели TCP хелсчеки, докер-контейнер хелсчеки. Сколько же там у них фичей? Ну, на самом деле, это последнее. Ну, хорошо. Ну, на самом деле, это ничего, то есть, как бы я в заголовке все сказал. То есть ввели два новых типа хелсчека. Вот, ну и там еще немножко, там подкрутили, там улучшили, но это уже так, по мелочам. Ну, вот две главные хэчи, это заготовленный для нас запрос и network томография. Меня потом будет. Мне больше всего эта томография понравилась, мне прям сейчас хочется при Вальде почитать. Я вкратце посмотрел обзор, получается, что они строят евклидово пространство энумерное, то есть они сперва выбирают мерность этого пространства, а потом в этом пространстве каждую точку представляют в виде какого-то вектора.",
    "result": {
      "query": "GitHub Scientist параллельный merge проверка выходных данных"
    }
  }
]
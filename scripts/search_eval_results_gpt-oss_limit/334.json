[
  {
    "segment_id": "988dd870-8625-4778-ad84-1d99fc845dd6",
    "episode_id": "3cce3396-bb23-4d46-8b1c-cf87df3cb4df",
    "episode_number": 334,
    "segment_number": 3,
    "text": "Ну, то есть, ты начинаешь, перечисляешь, что возможно Impala и Presto. Да, берем рыночную нишу и начинаем ее постепенно очерчивать. То есть, какая вообще есть экосистема? Есть, например, коммерческие системы с закрытым исходным кодом. Есть системы, которые доступны только в облаках, их невозможно использовать on-premise. Есть системы, у которых нет у собственного движка хранения. А есть ClickHouse, который можно использовать и в облаках, и on-premise, который полностью open-source, с неограничительной лицензией, который работает быстро и все умеет. Напомню, какая часть. Так что вот эта ниша такая. Apache. Лицензия Apache 2. Вопрос-наброс был несколько тем, мы их, наверное, будем обсуждать, они не очень интересны, но в последнее время многие проекты, они внезапно меняют лицензию с Apache на какой-нибудь от GPL или что-нибудь, что в перспективе. Ты такой начал делать сас на ClickHouse, а потом раз, а мы теперь от GPL, ну типа вы можете развивать вы даже сами, если хотите. А будущие версии вы не сможете использовать. Есть ли такие риски или их по какой-то причине нет? Сейчас таких рисков нет. Вообще, кто знает, может быть, через годиков 5 или 10 что-нибудь изменится, хотя это сложный вопрос, потому что, смотрите, весь систему-то разрабатываем не только мы, не только Яндекс, и сейчас около половины, кстати, я недавно считал, 46 процентов, Contributions приходят снаружи. И эти Contributions тоже поступают под лицензию Apache 2. И хотя для большинства из них подписывается некая CLA, которая обозначает передачу имущественных прав, там все такое, это не всегда верно. То есть для некоторых из них нет простой возможности так вот взять и поменять лицензию для чужого кода. Ну, в принципе, мое понимание, что это всегда есть риск. Ну, типа вот, например, если ты используешь Postgres, там мало вероятно, что Postgres станет Agpl, потому что за ним нет корпорации, которая в этом могла быть заинтересована, по крайней мере одной корпорацией. А с проектами относительно молодыми, такой небольшой риск всегда есть, да, то что вы можете делать сервис на чем-то, что используется Apache 2, потом вжухает Agpl. Недавно такое вот было в новостях, но я уже убрал в архив, за графана это случилось. Графана, ну да, я видел все эти шоунотцы. Вы знаете, сейчас в последнее время очень много новостей про сменную лицензию. Вот самая громкая, наверное, была про Elastic. И на фоне этих новостей не имеет смысла в ту же самую, короче, идти, в ту же самую компанию. Это было бы очень странно. Наоборот, если туда не идти и сохранять максимально неограничительную лицензию, это получается таким конкретным преимуществом. Пусть все остальные поменяют, а мы не поменяем. Ну, кстати, так-то, наверное, раз мы же, ладно, ни что дальше вообще чего-то не будем, раз мы уже зашли в эту тему, получается, конкретно преимущество и так далее. Вот это же внутренний продукт Яндекса, вроде как. Тем не менее, он торчит наружу. То есть, вот какая здесь получается идеология зарабатывания денег, а тем не менее, идеология поддержки или это миджевая идея какая-то. Почему оно продолжит развиваться вообще в открытом состоянии? Во-первых, это нужно Яндексу, сама технология. Clickhouse используется где-то в 60 разных отделах в компании. Ну, начиная от крупных, баннерная система, метрика, маркет, браузер. Извини, я, наверное, не очень правильно вопрос поставил. Я понимаю, что Clickhouse очень хорошо используется в Яндексе. Почему он именно останется, почему он продолжит развиваться в открытом виде? Ведь ничто не мешает компании Яндекс оставить существующий, как бы Clickhouse, его существующие состояния в открытом виде. Какие-то дальнейшие патчи вносить уже в закрытом состоянии. Ты знаешь, тут ответ довольно простой. Это зависит от людей, то есть от нас. Ну вот, я хочу так его развивать и все это понимают. Я его развиваю. А если возникнет конфликт интересов? То есть, я имею в виду, если компания внезапно захочет делать по-другому? Конфликт придется решать и решение в те или иные стороны может быть. То есть, как бы ты топишь за эту идею и пока не думаешь сильно о том, что когда будет. Когда возникнет конфликт, тогда ты будешь его решать. Да, представьте, такая ситуация, что вы попробовали, я не знаю, какой-нибудь, допустим, никогда в жизни там, я не хочу обидеть вегетарианцев, но, допустим, вы никогда в жизни там не пробовали мясо, попробовали и все теперь, думайте, как можно по-другому. Вот, а я попробовал писать open source код и все, я теперь пишу только open source код. Уже обратного пути нет. Да, это действительно так. Мне кажется, как бы дискуссия немножко произошла в тупик, я предлагаю придерживаться технической части. Если только максим ты хочешь, чтобы дополнить, не отмолчивайся. Ну, да, я могу дополнить, наверное. Во-первых, у нас лицензия дает возможность делать fork и, скорее всего, если бы возникли какие-то не противоречия, в общем, конфликты, которые нельзя решить. В принципе, основные люди, ну, вот, например, Алексей, если посмотреть там по графикам, кто какие вещи делает, в принципе, мог бы сделать fork и с этим не возникло бы никаких проблем. Ну, да, разве что, может быть, назвать пришлось бы как было написано в чате creep house или creep house или что-нибудь типа того и продолжим. Замечательное название. Наверное, еще тоже хотел добавить, что в целом, наверное, можно посмотреть, что от контрибьюторов к нам залетают довольно большие фичи и эти большие фичи используются внутри компании и, наверное, очень много каких-то даже мелких фиксов от контрибьюторов все равно приходит. То есть, с Open Source много value или о компании. А вот это интересно. Расскажи, пожалуйста, про большие фичи, которые к вам залетали. Извини, пожалуйста, Леш, я тебе пишу в чатик. Ты не мог бы им это представить, у тебя идет шум и всякие? Да, легко. Я просто уже готов отвечать на все вопросы. Вот была одна интересная ситуация, когда нужно было определять долю трафика из разных автономных систем. Но автономная система это то, что относится к маршрутизации, можно определить там крупных провайдеров страны и так далее. Нужно это было определять по данным из Creep House. Ну что это за задача? Есть диапазоны IP адресов, списки этих диапазонов, их к ним нужно соотносить данные. Вопрос, как это делать эффективно. Ну и вот когда эта задача появилась, мы поняли, что где-то за месяц до этого нам закомитили фичу под названием словари типа IPTry, которая как раз позволяет решать эту задачу. То есть мы взяли, настроили и все работает. А IPTry? Да, IPTry. Ну Try это как структура данных, которая префиксная дерево. А расскажи подробнее про то, что происходит на закомитиле и как это помогает решить проблему с агрегацией трафика. В Creep House есть такая штука классная, называется внешние словари. Это возможность из любого внешнего источника, там внешняя база, MySQL, Postgres, ODPC источник, файлик просто на диске, какой-нибудь HTTP сервер, короче куча всяких источников подключить просто кивали отображения. И это кивали отображение используется для джойна в запросах или даже не для джойна, а как просто вызов функции. Вызываем функцию, получить какое-нибудь значение, поключу и все. Такой как бы более простой джойн. Типичное использование это скажем у вас в Creep House логи трафика, в логах трафика есть идентификатор рекламной компании, а названия рекламных компаний в логах нет. Но они есть где-нибудь в Postgres. Тут включаем это в виде словаря и теперь пишем просто запросе Select получить название рекламной компании из словаря. DictGet называется. В качестве одной из структуры такого словаря сделали вот этот IPTry. В нем ключом является IP адрес, значением что угодно, а для сопоставления этих ключей значением используются диапазоны IP адресов. И там написано что если там какой-нибудь провайдер допустим из Латвии с таким-то диапазоном, то написать что это вот автономная система номер такая, это провайдер такой-то из Латвии. Все, задача решена. А внутри как это устроено? Там человек написал префиксное дерево. Я ему сразу говорю что типа зачем, бессмысленно, давайте просто сортированный массив использовать. Может быть префиксное дерево для того чтобы это можно было обновлять по кусочкам. Но он говорит да планирую чтобы можно будет обновлять. В общем померзли все это, все прекрасно. И где-то за 4 года функциональность что обновлять так и не была дописана, зато 100 библиотекой, которую он подключил, были некоторые проблемы. Она иногда. Если записывать больше чем не помню сколько-то адресов, она крешилась. В общем дурацкая библиотека мы это переписали, стало проще и теперь все прекрасно работает. Слушай, это очень классная история. А у вас часто такие возникают кейсы когда кто-то приходит из комьюнити и вот такую лисьняшку добавляет. Мне интересно понять из комьюнити приходят такие скорее баг фиксы либо подносят какие-то реально новые фичи. Происходит и то и другое. Можно отметить что если возникает потребность в какой-то новый фиче, она обычно возникает одновременно и у Яндекса и у нескольких внешних клиентов среди которых есть крупные, у которых есть свои C++ разработчики готовые принять участие. То есть скорее это даже типичный случай. Иногда попадаются очень такие обскурные какие-нибудь фичи, которые никто не использует, но мы стараемся чтобы такие фичи по крайней мере не были самыми приоритетными. А вы не рассматривали возможность, ну ты говоришь, что там есть странные фичи, но наверное они кому-то нужны, но не всем. Может быть сделать фичу с расширениями для каликхауса не рассматривали такую возможность? Да, такую возможность рассматривали и рассматриваем. Это очень интересно и когда рассматриваем расширение всегда все упирается во-первых в интерфейсе, какие должны быть интерфейсы, чтобы эти расширения нормально работали, а во-вторых механизм их подключения. Скажем, есть один такой классический механизм подключения расширений, который использовать ни в коем случае нельзя, прямо противопоказано. Например, шаренные библиотеки. Ну скажем расширение для posgresа, это если я не ошибаюсь, шаренные библиотеки. Правильно, поправь меня. Нет, ты совершенно прав и похоже, но существующие разрешения себя относительно неплохо в этом планете чувствуют, а что не так с этим подходом? Почему? Потому что шарные библиотеки это подгрузка внешнего кода в адресное пространство процесса. И click house написан на C++, posgres написан на C, MySQL написан на C++ тоже. Особенность в том, что на C++ нормально почти никто не пишет. Мы пишем, но чтобы нормально писать на C++, нужно очень серьезно постараться. Очень серьезно уделить внимание именно инфраструктуре, то есть сборка со всеми санитайзерами статически, анализ фазинг, чтобы все это было. И даже если это есть, все равно будут проблемы. Если судить по тем реализациям, которые к нам попрощают, то далеко не с первого раза они достигаются достаточного качества реализации, а до этого это может быть таким минным полем, который нельзя использовать. Поэтому подключение именно стороннего кода именно на C или на C++ непосредственно в процесс. Это такая гиблая затея. Еще в качестве шамера.. . Я радикально согласен. Я понимаю твою точку зрения, но ты знаешь, такая история, ты же не шипишь расширение со своим продуктом куда-то кому-то. Обычно это расширение, которое нужно внутри какого-то бизнеса. Я работал больше чем в одной компании, где крутятся кастомные расширения пасгреса. Они написаны на C. Некоторые из них даже иногда не всегда были здорово написаны, потом у них находились баги. Но это обычно пасгрес, который не торчит никуда наружу. Это обычно пасгрес, в котором расширение делают какие-то абскурные бизнес-специфичные вещи. И не так уж и плохо, что там какие-то отдельные бизнес-специфические куски. Подожди, Валерс, ты не понимаешь. Наши гости ведут к тому, что они знают более правильный подход. Сейчас мы о нем узнаем. Как на самом деле нужно? Я еще на всякий случай скажу, что это будет только у отдельных клиентов. Если что-то будет глючить, это будет глючить у них. Но обвинять в этом они будут нас. Часто бывает такая ситуация, что я приезжаю к каким-нибудь клиентам, хотя сейчас не часто, но на другом конце света, они мне показывают их структуру данных и спрашивают, как что-то работает. И в этот момент приходится держать в уме большое количество возможностей. Если у нас в клик-хаусе есть какая-нибудь особенная настройка, которую никто почти не включает, если ее включить, все будет плохо работать. Ну, гипотетически. И вот это надо держать в уме. Смотришь на то, как работает система этого клиента и думаешь, они включили ли они вот эту вот необычную настройку. Если там какие-то необычные плагины, то всегда возникает вопрос, если нам присылают, скажем, stack trace какую-нибудь. И ты думаешь, а правильную ли сборку они используют? Какие у них модификации есть? А если я возьму адреса из этого stack trace, я смогу перевести их строчки в коде? Ну, смотри, твой аргумент рассыпается о том, что кому-то реально очень хочется, они берут исходный код click-хаус и записывают в него функции. Просто отсутствие механизма расширения, это история не про то, что никто не напишет плохого кода и ты сможешь просто по телепатически отладить их систему. Это скорее того, что теперь, чтобы иметь какой-то код рядом с click-хаусом, нужно не просто загрузить какую-то библиотеку, а нужно формировать click-хаус и регулярно поддерживать его в как-то синхронизированном сабстриме. Но как бы это больно, но если очень захочется, то так сделают. Нет, ну в смысле, так сделают, но будут очень сильно страдать. Я этим занимался, вы не хотите этого делать вообще никогда. Ну, хорошо, нет, ну ладно, у гостя своя точка зрения, у нас как бы своя точка зрения, мы может быть сможем друг друга переубедить, может не сможем, это не так важно. Я хочу узнать, а как на самом деле нужно делать расширение? Я еще скажу на всякий случай, что проблема с расширениями это необходимость фиксации интерфейсов. И если в коде интерфейсы, например, часто меняются, то вот вам придется либо выкинуть все старые расширения, они просто перестанут работать, либо очень аккуратно поддерживать обратную совместимость, причем это обратная совместимость не на уровне API, а на уровне ABI. А ABI это уже намного сложнее, как вы знаете для C более-менее стабильный API, а для C++ лучше на него не рассчитывать вообще. Это значит, что эти интерфейсы, если их делать именно в виде библиотека, они будут си-шными обертками. Но, кстати, для полноты я не думаю, что в Postgres кто-то реально гарантирует поддержку именно ABI. Там предполагается, что твой Postgres он собран тем же компилятором той же версии, которой ты и собираешь расширение на том же самом железе. Я нигде не видел, чтобы кто-то конкретно гарантировал ABI совместимость. Так как на самом деле нужно делать расширение? Мне вот что интересно. Несколько прошедших лет мы старались отложить этот вопрос как можно дальше. То есть как можно дольше избегать возможности сделать механизм расширений. Но сейчас, наконец-то, в roadmap на 2021 год, который публичный, есть пункт user-defined-functions и user-defined-types. И там рассматриваются пять способов, ну таких пять рабочих способов сделать этот механизм, из которых два обязательные и еще несколько экспериментальных. Из этих двух мы будем, в общем, будем пробовать. И один из способов он, может быть, не самый эффективный. Во-первых расширение просто живут в отдельных процессах. И взаимодействие с этими процессами просто через пайпы, сериализация данных. Это для user-defined-functions. То есть такой, может быть, не самый эффективный способ, но надежный и рабочий. Кстати, у Максима есть уже прототип, который это реализует. И там результаты на самом деле весьма классные. Сейчас Максим может немножко сказать про эти результаты. Да, то есть, как вот один из способов расширения сделать, то есть запустить какую-нибудь идею как саппроцесс и через пайпы туда-сюда перегонять данные в целом на моих тестах, которые я делал относительно недавно. Скорость была довольно большая, то есть у меня получалось где-то 10 гигабайт в секунду. Это просто перегонка данных. То есть скорее всего большее время там занимают не сериализация, десериализация, а какая-то бизнес-логика, которая будет функцией. И ее напишет пользователь. Так что скорее всего это неплохой результат. Потому что если пользователь отрабатывает UDF, только в очень небольшом количестве случаев, этот пользователь будет писать UDF именно на C++ или на C. Может быть ему нужно просто подключить какую-нибудь обученную модель для классификации данных. Кстати, такая возможность у нас в ClickHouse есть встроенная для одной из библиотек, а если другие библиотеки, вот можно будет воспользоваться этим способом расширения. Хочу добавить, что да, у нас когда мы в свое время для Erlang пытались понять, что мы хотим, насколько быстрое мы хотим расширение добавлять и каким образом его заставлять работать с Erlang стародавние времена, там 10 лет назад, мы уперлись в то, что мы изначально предполагали, что сервизация-диссервизация будет как ботлнеком, самым таким сложным и как-то дорогостоящим местом в логике. А потом оказалось, что бизнес-логика чаще всего гораздо дороже. И поэтому, особенно если вы что-то сложное пишете на каких-то непростых языках, то есть мы там писали на функциональных языках на Акамле, в частности, для того чтобы бизнес-логику сложную было делать легче и проще. И я полностью подтверждаю, это очень классная тема, особенно если вам нужно что-то сложное делать, дописывать в быструю хорошую систему сложную бизнес-логику, это офигенно будет работать. Ну давайте так аккуратно скажем, на мой взгляд, у этого решения есть плюсы и минусы. Конечно, конечно. Если ты реализовал какую-то кастомную функцию, да там сервизация, диссерсализация, все здорово, просто никто не знает в каком контексте она используется. Если я ее гоняю в цикле или там каждой из строке применяю, то недостатки очевидны. Конечно, не каждой строке будет инициироваться эта сервизация и забираться обратно значение. Конечно, все это поедет целым массивом. Аргументы функций сервизуются в виде такой таблички, как бы и значение обратно приедут. И это для ClickHouse довольно естественно, потому что там внутри обработка такими маленькими пачечками идет. То, что есть модный термин для этого, который недавно появился, называется morsel-based processing. Morsel это тоже недавно узнал слово английское. Это какой-то кусочек еды, как бы. Не знаю, как перевести. Знаете, что такое morsel? Мне кажется, Света у нас главный. Я впервые это слово слышу. Я с ним раньше не сталкивалась. Вот я тоже раньше не сталкивался, пока это не увидел в какой-то статье. Там написано morsel-based processing. Я прочитал статью и понял, что это про ClickHouse, но статья была не про ClickHouse. Я понял, что это используется в контексте в розы морить червячка. Ну да, я слышал. Так, ну что? Что там, про расширение? Давайте какой-нибудь вопрос такой провокационный или что-нибудь в этом роде. Ну я могу задать провокационный вопрос. Пока вы пишете column storage пазо данных, вот это вот все, в Postgres реализовали table access method. В том смысле, что ты можешь написать любой storage для Postgres в виде расширения, в том числе при желании и колоночной. Может, ну как бы повторюсь, вопрос набросовый. Может, стоило инвестировать время, вот как бы. Теперь у нас есть две системы. Могла быть одна система, к которой, ну которая как ядро, куда дописывают разные расширения, которые с друг другом очень интересным образом взаимодействуют в хорошем смысле. То есть не кажется хорошей мыслью работать над тем, над чем все работают. Интересно заметить то, что внутри своей архитектуры ClickHouse очень расширяемый. И так получилось неспроста, потому что в начале разработки очень трудно написать нормальное, нормальный табличный движок для хранения данных. Гораздо проще написать некоторый интерфейс для этого движка хранения данных. И сначала реализовать какой-нибудь игрушечный такой движок. Он, кстати, в ClickHouse сохранился, и многие его используют до сих пор. Это движки Log, TinyLog и Memory, которые для некоторых сценарий подходят, но в основном такие демонстрационные или в общем узкого применения. А затем уже реализовать полноценный Merge3, replicated merge3. То есть внутри ClickHouse очень даже расширяемый. И он относится, если сравнивать, скажем, MySQL и Postgres. В MySQL изначально был интерфейс внутри для движков таблиц, и там, соответственно, был MySAM и InnoDB. А в Postgres очень долгое время старательно избегали этой возможности из соображения того, что система просто должна хранить данные правильно и никаких альтернатив. Но, как видите, от этого принципы отошли. Да, но вопрос как бы наброса заключался же не в этом. Чтобы сделать интерфейс, люди смогли реализовывать движки во внешнем коде и подключать их к ClickHouse. Это очень интересно. И здесь на самом деле есть механизмы, тоже очень интересный механизм в виде табличных функций. Недавно, кстати, сейчас PullRequest есть в разработке под названием табличная функция Executable. Можно подложить скрипт пользовательский в специальную директорию и сослаться на этот скрипт в запросе, написав SelectFromExecutable имя этого скрипта и затем один или несколько подзапросов. То есть from табличная функция Executable, а в качестве аргументов этой табличной функции еще подзапросы. Эти подзапросы начнут пополняться и в режиме стриминг подадут данные на вход этому скрипту файловый дескриптор sd-in и еще несколько файловых дескрипторов, если есть следующие аргументы. И на выходе будут прочитать тоже стриминговым способом значения. На самом деле, то, что получилось, это такой недомап-редьюс, но его можно рассматривать как еще один механизм расширения. Я довольно уверен, у нас произошло недопонимание. Позволь, я переформулирую наброс. Ты говорил, что мы там работаем, мы там думаем, какой нам сделать механизм расширения. У нас в milestone есть возможность объявлять свои типы и свои функции и так далее. Я говорю, что в Postgres это все уже давно есть. Вы можете писать свои функции, вы можете делать расширения. И оконные функции, черти с дьяволом, я не знаю весь Подгрес, он огромный. К нему нужно только colon storage дописать. И это можно. Наброс в том, что может проще colon storage дописать, чем писать рядом, ну типа второй Postgres. Может быть, но примеры показывают, что нет. Если смотреть на разные прототипы, варианты, как люди писали colon storage для Postgres, это тянется уже больше, чем на 10 лет назад. Это и исследовательские прототипы, и продакшн прототипы, которые даже не прототипы, в общем решения, которые используются в отдельных компаниях. Есть и довольно распространенные. Это c-store, в общем, сайтус. Гринплан в некоторой степени. Да, Greenplan. Но почему-то там не получается так, что они попадают именно в основную кодовую базу. Greenplan был на основе довольно старой версии Postgres, они очень мучительно этот форк синхронизируют. Сейчас более-менее синхронизировали, и в общем-то все нормально, но возникает вопрос. Есть open source Postgres, есть open source Greenplan. Почему colon storage не в основной ветке Postgres? Почему они сейчас мучительно разрабатывают еще один? Потому что в сообществе не так много людей, а люди, которые могли бы написать классные colon storage, они пишут свою базу данных. Да, и вот у меня такое ощущение, что по крайней мере я недостаточно профессиональный разработчик, чтобы написать colon storage в Postgres. Дело в том, что я считаю, что я разработчик-любитель, не профессионал, и поэтому я пишу click house. Достойный ответ. Тогда сопутствующий вопрос. А вы не хотите было бы клевый фичой сделать в click house storage отчуждаемым? Ну, в смысле, чтобы я мог его измбедить в свой проект. Как у тебя такая мысль? И вот это очень интересная идея и гораздо удобнее с точки зрения кода. Это значит более абиблиотечить то, что есть, чтобы было проще подключаться в другие проекты. И в этом направлении можно двигаться. Здесь в качестве такого образца для подражания можно использовать LLVM. То есть есть там Clang, как компилятор, который отдельно можно запускать. Но любые компоненты, которые он использует, можно использовать как библиотеку. И это используется повсеместно. Вот если примерно такая архитектура, то это дает довольно большое количество преимуществ. И на самом деле совсем немного того, что нам не хватает, чтобы так было. В некоторых случаях просто неудобно. Да, еще можно в качестве примера рассмотреть Aro. То есть Aro – это именно что библиотека для обработки данных по столбцам и все такое. На основе Aro можно сделать некое подобие Click House, и в общем-то люди делают. Спрашивается, даже если посмотреть на внутреннее устройство того же Aro, какой там layout данных в оперативке, как устроены столбцы, то будет просто дежавил, потому что прямо точно как Click House. С точностью до значений константов некоторых. Спрашивается, а почему бы не сделать, чтобы те же столбцы, те же операции над ними, вычислительные всякие ядра отдельно и можно было использовать как библиотеку. Ответ на этот вопрос ничего не мешает, надо делать. Не сделали просто. Прикольно, конечно, что ты сейчас сказал про Aro. Я так подумал, что я бы такое запользовал. Притом не только движок хранения. В Aro пока все бедно, только совсем недавно вывали в более-менее рабочем состоянии минирацию запросов, сборку запросов из чего-то. В принципе, это прикольная тема. Я хотел немножко в другую степь отвести. Мы тут говорили про расширение, про какие-то другие способы взаимодействия с проектами. И вот упомянули скользь движок. Насколько понимаю, у Click House довольно специфичное хранение. Например, оно не просто колоночное, оно еще в Merge Trig это формируется. Что делает далеко не каждый колоночный хранитель, насколько я понимаю. И я не очень уверен, что у вас за компрессии данных используется. Потому что я с ходовой документацией нашел, жмутся ли строки как-нибудь. Конечно, все жмется. Кстати, в начале выпуска не очень хорошо говорили про строки. Но если вы говорили про строки, так не могло быть так, чтобы Click House не поддерживал строки. Я не имел в виду, что он их вообще не поддерживает. Я имел в виду, когда я впервые говорил про Click House, на дворе был 15-16 год. Я открыл первый проект и посмотрел, что это база данных, которая круто работает с большими объемами чиселок. Я скорее всего не имел в виду, что он вообще не умеет строки в себя загружать. Скорее всего, я имел в виду, что Click House не оптимизирован специально для работы с большими объемами строк. Потому что у меня тогда задача была ворочить большим массивом именно строк, а не чиселок. Я понимаю, что у вас, грубо говоря, юрой может быть... Какая-то ссылка может храниться вместе с кликами. Скорее всего, то, о чем я говорил, мне нужно было бы сделать групп-бай по большой строке. И уникальных ключей в этом групп-бай было бы сотни тысяч. Как раз типичные сценарии очень хорошо проработаны с самого начала. С самого начала, окей. Значит, я был неправ. Ага, вот, про сжатия. Сейчас расскажу. Смотрите. Во-первых, данные хранятся по столбцам. Каждый столбец в отдельном файле, за исключением некоторых компактных кусков, которые для свежезаписных данных. Но это такое исключение. Итак, каждый столбец в отдельном файле. Записываем некоторые данные, уложенные подряд. Скажем, если числа просто в бинарном виде, в native-формате. То есть это Little Indian. Пишем без всяких разделителей, без заголовков. Если строки, пишем байты этих строк. Размеры тоже отдельно пишем. И все это записываются в некоторые буферы для сжатия данных. Да, для строчки есть еще сжатие по словарю. Но это отдельная такая штука. В этих буферах данных разбиваем на некоторые кусочки, из которых формируются сжатые блоки. Эти кусочки по умолчанию от 64 кб до 1 мб. Как правило, сжимаются кусочки по 64 кб для кэш-локальности. Если 1 мб, там похуже будет с производительностью. И из них формируются сжатые блоки. Для сжатых блоков записывается чек-сумма. И файл записывается с сжатых блоков просто подряд. Один, другой. Их сжатие полностью независимо. То есть никаких хитростей. Дальше есть у нас индекс. Индекс должен уметь адресовать какие-то данные, чтобы мы могли переместиться куда-то и начинать читать данные с какой-то позиции. В индексе эта адресация – это два смещения. Смещение в файле с сжатыми блоками до начала сжатого блока. И смещение внутри сжатого блока до начала разжатых данных. Индексы разреженные в сортированных данных умеют адресовать не каждую строку. То есть одно значение достать нельзя. А каждое сколько-то там строк. Раньше было фиксировано количество, которое по умолчанию 8192. Такое магическое число. Типа каждые 8192 строки ставим такую засечку, с которой можно начинать читать данные. Сейчас адаптивная грунтарность. То есть если там какие-то толстые значения, там будет меньше строк на засечку. Если маленькие значения, больше строк на засечку. Ну, в общем, примерно так. Много всего. Спасибо, я потом переслушаю. Можно я спрошу вопрос из чата? По поводу обеспечения качества кода. Да, как и что фазится. Делали continuous phasing для статического анализа, что используется, как влияет внедренный статический анализ на код review. Вообще мне хотелось бы уточнить и расширить этот анализ. Когда ты сидишь дома, подпроцедуешь проект, который ты хочешь довести до идеального состояния. Это одно дело. Другое дело, ты делаешь open source внутри компании. И тут получается такой немножко с разных сторон. С одной стороны, ты в компании используешь. С другой стороны, ты пытаешься сделать... Все мы перфекционисты, пытаешься сделать это идеально для open source. Как ты для себя решаешь, что будет лучше? Какой будет лучший паттерн? Как ты для себя решаешь, что есть хорошее качество? И как ты добиваешься этого качества для open source проекта внутри компании? Да, сразу скажу то, что очень важно, что этот проект используется в гораздо большем количестве сценариев снаружи, чем внутри компании. Представьте себе ситуацию. Написали, сделали новый релиз. Там куча новых фич. Выложили на кучу серверов внутри компании. Все идеально работает. Оптайм идеальный. Ничего не глючит. Вообще никаких проблем. И это типичный случай, но этого недостаточно. Потому что именно то, что это open source, который используется по всему миру в тысячах разных компаний, приводит к тому, что люди будут пользоваться всеми сценариями. Все необычные фичи, которые разработаны, все необычные настройки, которые можно включить или выключить, будут включены или выключены. И было бы нехорошо, если бы в качестве фазинга использовать нашу пользовательскую базу, чтобы они нам сообщали об их проблемах. Гораздо лучше, чтобы нормально все работало, гораздо лучше такие сценарии уметь каким-то образом находить автоматически и проверять. Кстати, какие у нас присутствуют проверки, какой у нас присутствует фазинг, в том числе continuous, можно посмотреть прямо на гитхабе в списке проверок в комитах. Итак, ну давайте сначала про фазинг. Кстати, я недавно делал доклад на C++Russian, называется фазинг практически икейцев в кликхаусе. Можно найти на ютубе, набираете это название и там будет доклад. Там как раз рассказывано про 5 видов фазинга, которые у нас есть. Из них самый продвинутый это фазинг запросов на уровне AST. Это что значит? Есть у нас обычные тесты в виде SQL запросов. Берем эти SQL запросы, берем их AST и запоминаем всякие кусочки, которые там были. И пытаемся эти кусочки во-первых мутировать, а в качестве мутации идет постановка всяких необычных значений и постановка других кусочков AST, которых мы уже видели. Скажем сейчас будет какой-нибудь утурированный пример. Ну допустим где-нибудь в запросе было написано, я не знаю, в тесте было написано null умножить на null. Все нормально, тест проходит, это простой тест. Но мы запомнили, что там был кусочек AST такой дурацкий. А еще есть гигантское количество тестов, которые делают все что угодно другое. Например, создают таблицу, а у таблицы есть аргументы и фанитайзер возьмет это AST с аргументами и туда подставит тоже эту фигню, чтобы просто проверить что будет. И все это проверяется под четырьмя санитайзерами плюс дебажная сборка, это там assort и hardening. А санитайзер это address, memory, thread и undefined. Undefined behavior. И это все проверяется на каждый комит и на каждый pull request. То, что это на каждый комит в мастере, там идет запуск под каждым санитайзером один час, то есть 5 часов машинного времени на каждый комит. Типа continuous phasing. Это прям супер-суровый процесс. Это прям супер-сурово звучит. Пытаемся делать максимально сурово и если сравнивать с другими open source проектами на C++, то здесь можно сравнить, ну скажем, с Chromium. У него тоже есть continuous phasing, который сейчас нашел где-то 20 тысяч, ну вернее 20 тысяч открытых у них всяких срабатываний. Ну и у нас тоже довольно прилично, но где-то 300 штук, из них осталось исправить около 25. А бывает такое, что баголя проходит мимо этих проверок? Да, бывает, проходит в pull request, просто одного часа не хватило на phasing, а потом continuous phasing находят в следующие буквально дни. Ну не обязательно дни, иногда находим гораздо позже. К сожалению, это все не идеально. Но самое главное, это защититься от банальных ошибок, что off-by-one, error, buffer, overflow из-за аргументов, просто отсутствие проверки какой-нибудь аргументы, null pointer, dereference и тому подобное. Детские короче вещи, чтобы автоматически проверились и не надо было очень внимательно, постоянно мучиться на code review, хотя мучиться все равно придется. Мне не нравится, что Максим отмалчивается, я какой-нибудь вопрос хочу напрямую ему задать. Максим, ты вот прямо сейчас над чем работаешь? Прямо сейчас я внедряю ClickHouse NG для агрегирующих функций. То есть у нас у конкурентов, ну у некоторых можно сказать конкурентов, некоторые виды запросов работают в разы быстрее, так как для них генерируется код на runtime через LLVM например. Ну условно у тебя есть какой-нибудь запрос достать некоторые столбцы из таблицы, допустим с какими-нибудь числовыми типами провести над ними операции вроде там умножения, деления, какие-нибудь такие простые функции и получить результат. Тут есть две проблемы. Во-первых такие запросы часто используют конкуренты, чтобы показать как они бенчмаркуются с ClickHouse. Например есть некоторые системы, в которых в принципе особо ничего не поддерживается, даже запускается не всегда, но на некоторых таких типах запросов они работают быстрее, так как этот код генерируется на runtime. То есть весь этот запрос, который достаёт несколько колонок, делает с ними различные выражения, получается генерируется такой цикл и он уже хорошо оптимизируется. И для агрегирующих функций это тоже может быть полезно, когда например по какому-то ключу мы хотим запрать, хотим провести несколько агрегирующих функций. Например там посчитать количество, какое-то минимальное значение, довольно частые кейсы и вот на таких случаях в принципе должно быть существенное ускорение. А вот по поводу код-ребью хотелось бы добавить, то есть там человек спрашивал влияет ли это как-то на код-ребью, то что у нас так много фазеров и разных сианных инструментов. В целом мне кажется это упрощает код-ребью, так как ты некоторые вещи не смотришь, но в некоторых случаях это и ухудшает, так как ты посмотришь, что у нас проходит где-то суммарно довольно много проверок и скорее всего полар квест действительно работает. И в таких случаях мы не всегда смотрим на архитектуру, то есть хотелось бы этого избежать, но мы почти всегда в принципе этого избегаем. То есть такой аргумент, что если полар квест зеленый, то мы очень хотим его помержать и уже меньше времени тратим на код-ребью, если я правильно понял. А хотелось бы еще пояснить, да? Да, именно так. То есть например, когда к нам залетают какие-то полар квесты, мы довольно часто первым делом смотрим, пробуем все тесты и смотрим в целом проходит они или нет. Но если например все тесты проходят, то есть вероятнее всего каких-то именно проблем с кодом, не считая дизайна, нет. И в таком случае нужно именно посмотреть с точки зрения дизайна, все ли хорошо, не нарушаются ли какие-то абстракции, вот такие вещи. Мы это почти всегда делаем, но иногда, если например полар квесты огромные, не всегда получается все сразу вортить. Быстрый вопрос, а джит LLVM-ный или какой-то еще? Вот тут да, получается джит LLVM-ный. И вот я посмотрел какие есть реализации. Для начала посмотрел, что использует конкурент, так как в LLVM есть из таких доступных сверху быстрых вариантов два. Это MC-GIT и ORG. ORG расшифровывается как ONREQUEST COMPILATION. И в принципе нам такая синхронная компиляция ни к чему, это только тормозит код. Соответственно остается MC-GIT. И с ним возникло несколько трудностей, так как я в принципе залез внутрь, посмотрел как там все сделано, и некоторые вещи потребляли много памяти. И еще конкретный кейс в клик-хаусе, это когда мы например компилируем запрос, выполняем его, а потом мы хотим иметь некоторый кэш с компилированных запросов, так как вот эта компиляция запросов это такая побочная штука, и она нам скорее не всегда нужна. А используя MC-GIT интерфейс довольно сложно выгрузить уже с компилированной функцией. Так что у нас своя обертка написана для этого дела. Но да, мы используем LLVM. Давайте я еще немножко расскажу про этот GIT и вообще зачем он нужен. В клик-хаусе изначально то, что называется векторный движок обработки запросов. Можно привести множество аналогий, может быть кому-то будет такая аналогия актуальна, то что векторный движок обработки запросов похож на язык программирования APL или J или K, как они там внутри устроены. Ну, немножечко, не совсем с некоторыми деталями. То есть это интерпретатор, но интерпретатор, который все операции назначает не над отдельными значениями, а над маленькими массивчиками. Каждая операция над массивчиками, например сложить два массивчика, написана в виде достаточно эффективного внутреннего цикла, который в том числе может выполняться на процессоре с использованием векторных инструкций. Есть и другой подход, состоящий в компиляции выражений. Он состоит в том, что мы берем выражение в запросе, когда написано про селект A plus B внушь на C. И вот это вот выражение компилируем в виде функции, потом выполняем. Часто возникает вопрос, а что лучше, векторная обработка запроса или компиляция? Здесь ответ неоднозначный, потому что во многих случаях лучше векторная обработка запросов, но в некоторых лучше компиляция. Тогда возникает вопрос, а зачем же мы делаем JIT, если векторная обработка запросов может его превосходить или по крайней мере работать на равных. А делаем мы его для того, чтобы применить одновременно и то и другое. Мы будем компилировать не отдельные выражения, а цикл, содержащий эти выражения. То есть представьте опять пример A plus B внушить на C, и мы компилируем цикл 4, где вот эта операция. И у нас там на процессоре компилируется это не только в фьюст мальтиплей ад инструкцию, но еще и векторную инструкцию, которая будет с широкими регистрами работать. И вот это вот самый ультимативно лучший вариант. Ничего лучше просто не бывает. Ну, главное, чтобы в каши вовремя подвозили данные. Я хотел такой формат немножко переключить. У меня появилась идея, раз я про строки наврал, я могу какую-нибудь фигню начать морозить, а вы будете говорить, как я неправ. Давай. Вот, короче, в кликхаузе все очень сложно. Не то что не поддерживается, но сложно с распиленной установкой. То есть нужно довольно руками конфигурировать все, чуть ли не каждую таблицу для того, чтобы собрать репликацию. Сначала нужно звуки первую освоить вообще. Да, и звуки первую освоить. Это правда. Это обладает одновременно и преимуществами, и недостатками. А во многих сценариях это скорее недостаток, чем преимущество, но я расскажу, почему так. Представьте, вы настраиваете репликацию, скажем, в моей SQL или в Postgres. У вас будет реплицироваться целиком сервер или целиком база данных? С поправкой в Postgres не обязательно. Ну то есть там есть физическая репликация, есть логическая. Хорошо. Если логическая, вот тут я уже не в курсе, там что фильтровать, надо как-то по... к чему запрос относится или... понятно. Вот, а в кликхаусе система, она разрабатывается как бы снизу вверх. То есть мы делаем отдельные компоненты, а потом мы делаем компоненты, которые работают оверх них. И вот в самом начале в кликхаусе не было репликаций, были обычные нереплицируемые таблицы. И мы сделали так, что можно создать реплицируемые таблицы рядышком. Создаем реплицируемую таблицу, в другом сервере создаем тоже, указываем одинаковые там пути для координации. И эти таблицы реплицируются. И это удобно, то что дает довольно большую гибкость. Представьте, у вас есть кластер, состоящий там из шардов и реплик. И некоторые таблицы у вас реплицируются между, скажем, тремя репликами каждого шарда. А еще есть таблицы-справочники, и они реплицируются между... там уже сотней реплик. А еще рядышком можно разместить, скажем, какие-нибудь временные словарики от аналитиков. В таблице, которые не временные, то есть нормальные таблицы хранятся на диске и все такое, но они не реплицируются. То есть самые разные конфигурации, можно делать, это преимущество. Но недостаток в том, что... ну, во-первых, для репликации нужно сконфигурирует шарды и реплики.",
    "result": {
      "query": "ClickHouse репликация настройка таблиц"
    }
  }
]
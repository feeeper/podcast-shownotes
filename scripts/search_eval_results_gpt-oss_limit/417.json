[
  {
    "segment_id": "55ae9d88-efbc-4eea-b7cb-356220c3441c",
    "episode_id": "9fb08bcf-eaa9-4960-9c62-80bfb351bb91",
    "episode_number": 417,
    "segment_number": 13,
    "text": "просто потому что они выбрали такое партиционирование ну то есть очевидно что если у вас есть много сообщества как кажется есть много каналов то будут каналы и сообщества в которых говорят очень много и в общем такое партиционирование очевидно приводит к и приводило к горячим партициям и до какого-то момента вам удается масштабировать и размазывать нагрузку по большему большему большему количеству машин но есть такой предел а недавно в статье марка в блоге маркинг брукера я не принес ссылки но постараюсь найти как раз было такое рассмотрение теоретических пределов возьмем некоторые распределения и вот существует ли теоретический предел дальше которого бессмысленно масштабировать забрасывать железом проблему если у вас есть ваши ключи партиционирования распределены определенным образом и в общем у тебя да есть пределы вы не можете в принципе во-первых у вас деминишен ретерн очень быстро наступает даже без излога за пределы а потом еще у вас есть в принципе теоретический предел куда дальше бессмысленно масштабироваться вот я уже не помню у них кажется были сотни узлов да 200 узлов касандры я подозреваю немаленьких на этот кластер вот они там описывают некоторое количество страданий при том у них были забавные названия типа gossip dance как они там выводили если эта нода очень сильно начинает затуплять они ее там значит выводят из кластера дают ей просраться прокомпактизировать все данные все такое а потом значит вводят ее обратно в кластер ждут пока произойдут все хендов между узлами данных которые записались в другие места пока ноды не было а потом значит приходит время какую-нибудь другую ноду тоже дать другой к ноде просраться в общем бланкул как это мое почтение как они это решали они это решали двумя способами ну понятно дело что теперь перераспределить все данные уже наверное ну наверное поздновато ну я так понимаю у них возможно нету какой-то сильно более лучшей модели данных кроме как не знаю размазывать историю чата по всему кластеру каждого чата вот что скорее всего очень сильно как это нагрузку просто в общем это скорее всего будет другой плохой случай вот с одной стороны чтобы чуть меньше убивать узлы запросами они нашли вот паттерн который у них самый был злой это когда приходит значит куча народа открывает канал и они все как правило ломятся за вот недавней историей канала и они вот конкретно для этого сделали сервис на расте но на самом деле как бы без разницы они там типа во имя справедливости и мемов как это переписали все на расте то есть они сделали сервис на расте который по сути кэшируют недавнюю историю канала там чуть больше деталей в статье но смысл такой это им в принципе очень сильно уже улучшило ситуацию а вторая вещь которую они сделали они переехали на Сцилладиби там еще опять же повторюсь в статье много деталей она очень прикольно написана очень забавно как они там потом вводили в продакшн и мониторили в это время был чемпионат мира по футболу или супер кап по футболу нет по футболу в ворлд кап и у них там график на котором видны голы рэгби или сокер сокер ворлд кап по моему сокер который недавно был в 22 я конечно слежу за всеми спортсменами рэгби по моему супер боу называется ворлд кап по моему сокер в общем не так важно но смысл в том что у них там на графиках мониторинга были видны голы в общем я рекомендую статью она очень легко читается наверное самое главное такое что когда вы думаете какой у вас будет ключ партиционирования очень очень очень нужно следить за вашим распределением не думайте что у вас равномерное если как бы попытайтесь приложить все силы сколько у вас снается чтобы сделать распределение равномерным неправильное слово юниформ да вроде правильное в общем шардирование по каким-то вибакетам обычно решает проблема а так вон то дело что у них есть вибакет они не очень помогли мало вибакетов так нет в смысле я как раз тебе говорю что у тебя существует теоретический даже предел когда ты из-за наличия горячих ключей у тебя есть теоретическое количество вибакетов в которых тебе бессмысленно добавлять вибакет у тебя не станет лучше масштабироваться если у тебя изначально изначально набор данных каким-то неприятным образом распределено у него есть горячие точки то что помогает это именно что стараться так делать чтобы горячих точек не было не знаю например шардировать не только по пространственному чему-то но и по временному чему-то тогда у вас нагрузка будет чуть лучше размазываться между несколькими узлами например но все еще конечно же если у вас там если например вы шардируете по времени и вам нужна недавняя история чата оно всегда все равно будет в одну и ту же в один и тот же узел скорее всего пролетать если вы только не будете каждый не знаю каждый минут делать отдельным вибакетом не вибакетом короче ключевым протеционированием тогда у вас тогда запросы на вот это недавнее будут очень сильные по всему кластеру шарятся что тоже не очень хорошо так что тут нужно быть аккуратным но не понятно в какую сторону аккуратным в общем я предлагаю Саше перейти к рассказу про алгоритмы hash join рассказывать особо нечего следующего это еще один доклад из серии advanced database systems курс читает Энди Павла 20 кода курс и мне показалось что он большей частью является пересказом другого доклада который мы уже обсуждали из Basic курса снова Robinhood подход кукушечный подход вот это вся история возможно помните из чего-то что хоть немного зацепило в мере разработки с обд вечно ведется спор о том как лучше делать join с",
    "result": {
      "query": "пределы масштабирования партиционирования"
    }
  }
]
[
  {
    "segment_id": "6d0683c0-689b-4a1c-b13a-07f393b1f657",
    "episode_id": "fd99a757-43b8-4f15-81d9-fb29d6217bc8",
    "episode_number": 310,
    "segment_number": 19,
    "text": "плане, когда идет разработка, это, конечно, константное, дополнительное время, вот, особенно на старте, особенно на старте, когда там нужно, вот, первый раз, когда мне нужно было записать этот lifetime specifier, то есть, это что-то, невообразимое количество времени нужно потратить, просто, часами просто исходить все документации из такое airflow, но, впоследствии, в принципе, к этому привыкаешь, то есть, запоминаешь, как набор конструкции, да. Мои уши! Сори, там что-то у меня этот, гарнитура ездит. Ну, она, знаешь, в какой-то момент перевалила, гарнитура было больше, чем твоего голоса. Прости, пожалуйста. Сори, да, я может вот так попробую держать, не знаю. Да, в общем, в тот момент, когда то есть, я уже несколько раз это написал, там какие-то такие вещи, именно, с lifetime-ами, это проще, но кейсов, на самом деле, достаточно много, но не конечные, то есть, если их запоминать, набить руку, с этим можно жить. И да, оно помогает именно, вот, с memory-management достаточно сильно, то есть, если мы говорим про то, что мы себя ограничиваем от unsafe, то в этом моменте достаточно, как бы, четко работает Borrow Checker, да, он занимает постоянно фиксированное время от нас, отбирает при разработке, но при этом действительно он нас защищает от многих всех проблем. Вы на Rust, в итоге, пишите модуль какой-то для Node. js или это отдельный сервис, отдельно стоящий? Ну, куб-стор, в принципе, по сути, он будет упакован внутри kub.js, но если говорить технически, как процесс, это отдельно стоящий процесс, у которого будет, то есть, он будет поддерживать протокол MySQL, да, и, соответственно, он будет хоститься, то есть, в облаке, это как бы отдельно стоящий докер, и она локальная, это просто бинарный, который будет запущен как fork Node.js. Пока мы не делаем embed здесь, у нас нет такой необходимости, но в будущем, наверное, будет еще и embed-версия. Окей, Rust понятно, уже были такие упоминания Apache-R и Snowflake Architecture, и, наверное, я попрошу тебя начать со Snowflake и Architecture, потому что я сильно сомневаюсь, что мы про него не рассказали, потому что я помню, что я прочитал paper и в итоге, по-моему, решил его не рассказывать в подкасте, поэтому если ты дашь какую-то легкую вводную, было бы, наверное, здорово. Да, наверное, для слушателей, которые вот не знакомы с Snowflake, Snowflake это, собственно, cloud, база данных cloud data warehouse, который предоставляется по on-demand модели, очень похоже на то, что предоставляет BigQuery или Athena, и, соответственно, если говорить про архитектуру, наверное, одно из ключевых архитектурных решений, которое они приняли, сделали, и которое очень хорошо работает, это называется в общем, separation computing storage separation, да, то есть там separation разделения computing, разделение storage, а это на разных машинах хранится, то есть они как основной storage используют 3, при этом ноды, которые отвечают за процессинг данных, алоцируются on-demand, они используют локальный дисковый кэш, когда, соответственно, идет доступ на ноды, они выкачивают, соответственно, они так называемые микропартишены делают, это небольшие партишены вот этих вот колончных данных, они используют формат, который очень похож на паркет, но свой проприетарный, они скачивают их на каждую ноду, зеркалируют, и, соответственно, таким образом ноды могут полетать, ноды, в принципе, они могут гаситься, ноды могут алоцироваться пропорционально, соответственно, деманду, который идет на вход, таким образом очень большая динамика и дипка здесь достигается. А в чем параллель с CubeStore? Еще раз, в чем? Параллель с CubeStore? Сорри, да, параллель с CubeStore тем, что вот если посмотреть как раз на ClickHouse модель, в ClickHouse, соответственно, по классике, данные, когда инсертятся на ноде, они хранятся на ноде, то в CubeStore и в Snowflake мы используем подход, когда данные на нодах только зеркалируются, на самом деле, когда идет запись, они записываются на самом деле на удаленные диски, на удаленные файлы системы, это может быть S3, это может быть Google Cloud, MIO или HDFS, то есть любой распределенный storage, но он записывается удаленно, так что как бы computing ноды, они не зависят от, соответственно, storage нод.",
    "result": {
      "query": "Snowflake архитектура разделение вычислений и хранения"
    }
  }
]
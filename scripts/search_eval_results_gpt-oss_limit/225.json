[
  {
    "segment_id": "bb5a4338-6dca-4913-9c49-faeb15a914df",
    "episode_id": "0ca2cdd0-5259-4db5-9577-4f176ca897e3",
    "episode_number": 225,
    "segment_number": 10,
    "text": "Давай так. Я это запускал на другой машине, которую мы обсуждали в прошлом выпуске. Ага, всё, я понял, то есть Vulkan есть на Linux'е и Windows'е. Да. Окей, хорошо. На Mac'е он есть через Molten VK, если что, то есть как бы его можно через специальную библиотеку притащить. В самом Mac'е нет, но можно себе сделать свой совместимость. Вот, к чему это всё было? Да, может показаться, зачем вообще экспериментировать на каком-то старете, поторой кваке, но дело в том, что там всякие ray tracing, path tracing и всякие такие штуки, они не очень зависят от сложности геометрии, они зависят от количества пикселей на экране и там, ну так скажем, от того, сколько много у вас будет отскоков, но от собственно сложности геометрии, количества полигонов и там качество текстуры, оно зависит не очень. Поэтому, в принципе, всё, что в этой демке показано, несмотря на то, что оно выглядит немножко как очень красивый освещенный привет из 90-х, ранних 90-х, оно на самом деле, в принципе, если у вас есть ассет, то перекладывается на какую-то более современную графику. Что гораздо интереснее, то, что это не совсем, это и не ray tracing, и не path tracing, ну то есть у них YouTube-видео называется Quake 2 Real-Time Path Tracing Using RTX. Но если вы внимательно смотрите на картинку, если вы внимательно читаете то, что они пишут, это не совсем честный path tracing. Разница между ray tracing и path tracing в том, что когда мы делаем ray tracing, мы пускаем, я боюсь соврать, но вроде что-то помню. В общем, ray tracing мы пускаем лучше из камеры в сцену. Как только он сталкивается с геометрией, мы этой геометрией пытаемся трассировать его дальше, либо в другой источник света, либо... Да, собственно, мы просто его трассируем до источника света. И там, типа, если у нас есть какая-то преграда, то мы там соответственно рисуем тень, если у нас там полупрозрачная поверхность, мы там, допустим, преломляем, уменьшаем как бы яркость, что-нибудь такое. Если зеркало, мы это как зеркало делаем, а если источник света, мы просто делаем яркие пиксели и так далее. Это дает правильные зеркала, правильные преломления, сравнительно правильное освещение, но оно с жесткими тенями. Ну, в принципе, по-моему, если специально не заморачиваться, по-моему, даже без отскока будет. Path tracing – это гораздо более интересная штука, потому что он гораздо ближе к тому, что происходит в реальном мире. Мы пускаем не один луч, а много лучей с каждого пикселя, но при столкновении с геометрией мы его не в источник света бросаем, потому что у нас кроме источника света, на самом деле в цвет поверхности контрибютят еще многие другие штуки. Мы можем его бросать просто в соседние какие-то объекты, ну, то есть мы просто, типа, преломляем об этот кусок поверхности и пускаем куда-то дальше. Соответственно, это такой метод, который чудовищно долго, но достаточно правильно моделирует то, как ведет себя свет на самом деле. Собственно, чтобы это работало в реал-тайме, нужно как-то ухищряться, ну, соответственно, это нужно динозить. Это раз, а во-вторых, нужно делать как-то более стабильным, чем совсем рандом. Соответственно, плюсы в том, что будут вот эти вот color bleeding, то есть мы, не знаю, на белую поверхность поставим красный кубик, у нас, на самом деле, белая поверхность, она немножко цвета от красного кубика поймает, такого рода вещи. Каустики тоже, это такой феномен, который патх тресинг естественным образом просто производит. Каустика, если что, это когда у вас, например, есть водичка, вы в ней, в каком-то, например, не знаю, контейнере непрозрачном, и вот вы на нее светите каким-то источником света, а у вас такие как бы начинают блики играть на стене. Это называется каустика. Ну или, например, если вы посмотрите через стеклянный стакан на стол, у вас тоже на столе будет такой цветовой рисунок, это тоже каустика. Я бы уточнил, что вот именно там будет рисунок, и на нем будет такая линия, если ты через стакан на стол посветишь, такая линия, у которой есть излом. Вот сама вот эта линия с излом, она будет называться каустикой. Я не очень понимаю, а как можно, то есть каустика это чисто... А, ну хотя нет, это не волновое свойство, да, то есть тут волнового ничего не нужно, каустики получатся. Ну они и в рейтрейсинге должны же получиться, нет? Ну в рейтрейсинге и через хаки делают. Ну то есть рейтрейсинг пока в его самом базовом варианте, он полагает, что он трассирует не только до источника света, а вообще до чего угодно. А, то есть мы теряем каустики, потому что мы лучи трассируем только между глазом, только между камерой и источником света. Ну в смысле мы можем добавлять какие-то дополнительные хаки, то есть мы можем знать, что вот если этот материал может производить каустику, мы там просим специально отдельный луч, но типа это, короче, хаки. В рейтрейсинге он просто, как вот алгоритм описан, он так вот просто взгенерирует, но он очень будет долго сходиться, опять же наивный. То есть он типа еще дольше, чем рейтрейсинг. Бесконечно, ну то есть блин, тебе нужно больше одного луча запустить с каждой точки, ну то есть это чудовищно долго, на то, что используется в современном рендеринге, кинематографическом. И при этом все равно у тебя нет волновых свойств, то есть вот тени все равно будут. Почему нет, у тебя же... Диффракцию ты не получишь, вот. Там кольца Ньютона на полукруглой линзе ты не получишь. Я думаю, это через шейдеры делают, ну то есть у тебя шейдеры все еще никто не отменял поверхностные. Ну то есть, но автоматом это не получится. Автоматом, скорее всего, нет. С другой стороны, да, там в обыденной жизни диффракцию где-то заметьте, очень сложно. Вот, короче, да, продолжим к тому, о чем я. Собственно, это чудовищно долго работает, даже близко не к real-time, а здесь мы имеем... Речь все-таки о том, что хочется рендерить вот тут прямо сейчас, много кадров в секунду. Собственно, здесь применяются два трюка, ну один из которых, собственно, Nvidia рекламировала, но Nvidia про это мало, не говорила, то есть некий денойзинг на как раз тендер корс. Что такое денойзинг в случае вот этого патстрейсинга? Когда произносится слово денойзинг, первое, что мне лично приходит в голову, что денойзит конечную картинку. На самом деле нет. А вот тут в FAQ авторы пишут, что если пытаться денойзить просто конечную картинку, это дофига нестабильно получается, а они на самом деле денойзят как раз-таки вот результат патстрейсинга. То есть, типа, то, это, видимо, как бы обо что стукается луч, какой цвет он там получает, видимо, что-то такое. То есть, и они пытаются как-то переиспользовать то, что между кадрами у вас на самом деле, ну, скорее всего, то есть даже конечная картинка между кадрами отличается не очень, а цветотеневой рисунок, он тем более не очень сильно отличается, и то есть они пытаются, я так понимаю, сделать так, чтобы сходимость была еще и лучше за счет того, что у вас как бы в одном кадре так лучи упали, в другом кадре по-другому лучи упали, и мы между ними как бы общую информацию находим, и там еще какой-то хитрый денойзинг, я недостаточно в этом понимаю, но смысл в том, что они пишут, что они денойзят не конечную картинку, вот именно как бы вот сам патстрейсинг, что бы это ни значило. Во-вторых, они пишут, что они каким-то образом все-таки ограничивают то, что они трейсят, то есть все-таки лучи кидаются только до источников света, но источниками света здесь, судя по всему, является какой-то более широкий спектр объектов, чем просто источники света. Судя по картинке, у них есть мягкие тени, у них есть эре источники света, и все очень динамично, но например, чего у них нет, у них нет вот этого вторичного отскока света, то есть там, когда есть какая-нибудь поверхность код цвета на поверхности другого цвета, вот этого color bleeding не происходит. И вот мне интересно, это потому что вот они таким образом ограничивают то, как трясется, или потому что там просто поверхности, условно, достаточно близких цветов друг к другу. Вот это не очень понятно, и мне не очень понятно, насколько мне нужно быть впечатленным этим результатом. То есть, если честно, я ожидал несколько большего. То есть, когда мне говорят паст трясинг, я ожидаю еще более честно посчитанного света, наверное, так. С другой стороны, все равно неплохо, что у нас появляются какие-то технологии, которые могут утилизовывать вот это вот ускорение в железе. Может быть, мы через пару поколений игры увидим действительно полностью паст трясенные игры. У этого есть много хороших эффектов. То есть, не знаю, артистам можно будет наконец завязать. То есть, там много лет боролись за, так называемый PBR, Physical Based Rendering, когда у нас там в свойствах материалов используются какие-то реальные свойства материалов, и не нужно под каждую сцену тюнить текстуры, шейдеры и прочую всю фигню. Но до сих пор куча хаков в играх используется. То есть, это, во-первых, уменьшает количество хаков. Во-вторых, мы, как зрители, увидим, игроки увидим гораздо более прикольные, мягкие, реалистичные, не знаю, живые, динамичные картинки. Вот. В принципе, это, наверное, клево, но пока еще не совсем так. И в принципе, приятно, что оно работает в достаточно хорошем разрешении, достаточно хорошей скорости, и вот при этом Battlefield V тормозит, ну, или во всяком случае не очень быстро работает. Там просчитывается, насколько я понял, только отражение. И вот становится как раз таки еще интересно посмотреть, насколько специализированный написанный под это железо рендер будет круче, чем нашлепнутый отдельный эффект на традиционный рендер. То есть, как бы, я надеюсь, что мы еще увидим какие-то разработки нацельны чисто на это. Хотя, с другой стороны, вряд ли мы это увидим в коммерческих играх, потому что AMD пока ничего такого не выкатило. Так, отлично. Я тем временем посмотрел на тему слушателей и не наголосовали, поэтому, Сарянчик, надо голосовать за тебя. У меня еще есть, кстати, side note про ray tracing и path tracing. Давай. Какое-то время назад был достаточно удивлен, когда узнал, что, в общем, есть задача, есть фотки океана, снятые аэропотосъемкой с самолета. И нужно понять, то есть, если был ясный день, то попробовать по фотке океана восстановить, что было на небе. И, оказывается, эта задача практически идеально решается. То есть, если у тебя есть отражение от поверхности воды, по которой идут волны, то есть, это некая случайная структура, и по ней, собственно, ничего не видно. То есть, небо и облачность, и сам самолет в ней не отражаются. То есть, ты просто видишь какие-то волны. В смысле, вот прям волны воды. И из этой картинки можно практически идеально восстановить то, что отражение неба в ней. И при этом это не машин лернинг или еще что-то там сопоставляют, а как раз полностью обратный подход. То есть, задача решается на людские, типа там пишется дифференциальное уравнение, как бы свет отразился от случайной структуры, потом его можно, типа, развернуть, оно получается некорректное, но там его нормализуют, и получается просто вот формула. Ты вот прям берешь картинку со сфотанной водой, прогоняешь его через некоторое преобразование, и получаешь картинку неба, которая была сверху. И там видно и самолет, и облачность, и так далее. Просто вот этих баз с картинками аэрофотосъемки, их очень много, и вот там народ начал восстанавливать, а что было надо в этот момент времени. Офигеть. Звучит как фантастика, если честно. Можно ссылку? Я поищу. Да-да-да. Насколько я вижу, темы кончились. Возраст. На самом деле, Саша, не знаю, опять карточек добавил в бэклог. У нас, мне кажется, уже следующий бэклог, просто его на выпуск хватит. Давайте уж наконец разберемся с бэклогом. Давай, бери тему. Окей, я просто беру и отважно и храбро хватаю тему, которую Саша принёс, предлагал её обсудить. И мне кажется, я её скоро забуду в очередной раз. Саша пометил её как то, что он не прочитал этот пейпер. Но ты, если хочешь, можешь ему рассказывать. Ну так, я пейпер сам по себе, прям вот пейпер вообще не читал никогда, если я правильно помню. Может быть, читал, но уже забыл. Но, в общем, наша любимая тематика. Мы, значит, будем тыкаться в разные сториджи, базы данных, вот это всё. Есть такие ребята, Digraph.io. Если честно, я не очень в курсе, что они делают, но я знаю, что они в какой-то момент заопенсорсили гошную реализацию под названием Badger, которая как Honey Badger. Делают они графовую базу данных, как ни странно. Наверное, ещё для директинграфов или нет. Вот об этом история умалчивает. Ну, Digraph, я про это. Нет, ну интересно представлять в первую очередь их сторидж, который, Валера? Который, да. В общем, мы, как бы, многие слышали там про B3, наверное, даже в универе всем рассказали. В принципе, кто более-менее следит за, что сейчас модно на НЧЛСМ, блок-стратширт-мерч-3, оно вот, если вы когда-нибудь сталкивались с RoxDB, с LevelDB, оно в Cassandra тоже LSM. Ну, то есть практически везде сейчас LSM, за исключением, пожалуй, Postgres и самого классического... о, да, и, короче, в некоторых вариантах MySQL. То есть в некоторых вариантах MySQL уже LSM даже. То есть как-то так. MyRox или как это называется.",
    "result": {
      "query": "путь трассинг реалтайм denoising NVIDIA"
    }
  }
]
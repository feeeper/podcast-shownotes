[
  {
    "segment_id": "7f4b63be-cfe9-4032-8688-6e049e1f228f",
    "episode_id": "9201f683-5681-4fe1-b2e0-2c3e645a235a",
    "episode_number": 73,
    "segment_number": 5,
    "text": "Так только читай. Ты знаешь, я вот после того, как Apple купил FoundationDB, я полагаю, что вообще надо писать как можно больше баз данных, открытых, с хорошими тестами и с отличной производительностью. Вот реально. Слушай, они должны быть как, по-твоему, у нас есть каптеорема здесь в кавычках, да? CIP, как я не теряю. Вот мы, какая должна быть CIP или CP? Но мы уже обсуждали, что каптеорема, она неприменима для вот таких распределенных баз данных по-нормальному. Слушай, она, да, как бы CIP теорема, она сформулирована на самом деле для, как бы, для регистра, для реплицированного регистра, по сути. И на самом деле, как бы, как это, блин, по-русски. В общем, любая, сколько-нибудь осмысленная база данных, даже kvalue обычной, он уже может очень легко выйти за рамки прям вот совсем уже... Оно не может, они все выходят. Да, да, за рамки прям классического CIP, просто потому, что нет, ну как бы, если оно чисто AP, то оно, скорее всего, не особо выходит, ну, а не AP, а вот если оно CP, то оно уже, как бы, оно не то, чтобы прям недоступно, если хоть одна машина отвалилась, у тебя есть шардирование, и у нас отвалилось две машины внутри шарда, ну, шард будет недоступен, но все остальные шарды при этом будут доступны. Это уже, как бы, не полная недоступность, которую нам предсказывает, как бы, теорема, но просто у нас будет полная недоступность для тех регистров, которые... для тех ключей, которые на том шарде висят, где у нас два дверей пакет валилось. Как бы, на самом деле, моя точка зрения, то есть тот же самый REAC, опыт того же самого REAC, показывает, что, в принципе, можно иметь одновременно и то, и другое в обеих... В одной базе данных можно иметь оба подхода. Больше того, многие CP базы данных, например, позволяют делать dirty read, потому что, ну, вот нам, как бы, хочется... мы можем позволить себе где-то читать, там, как бы, немножко устаревшие данные, поэтому мы разрешим читать с любой реплики, неважно, откуда, насколько она up-to-date. Снова, это уже отход от CP в сторону AP. Такие трейд-оффы встречаются сплошь и рядом. То есть, как бы, для меня сейчас идеальная база данных, которая сейчас вот пилится, это как ROJ-DB. А почему? А потому что ребята, они делают все правильно. Я не знаю, как это сейчас значит, формулировать. Ну, то есть, я могу начать зачитывать просто все их технические решения, но у них, на самом деле, есть несколько очень классных, как бы, рядмишка классная, и там ссылки, как бы, дальше, если идти этот рядмишке, идти глубже по ссылкам, у них описано довольно хорошо их технические решения. И мне кажется, все, что они вот пока делают, они делают правильно, с моей точки зрения. Можно как-то кратко совсем. Ну, вот хотя бы одну самую ключевую вещь, которую ты сейчас вот... Смотри, во-первых, есть такой момент, что почти все распределенные базы данных, они во имя упрощения делают шардирование через консистент хэшинг. Либо как-то вот там HyperDeX, они немножко по-другому сделали, они попытались сделать какой-то умный хэшинг. Но это все равно не так здорово работает, потому что как только у тебя появляются джойны не по equality, а там, не знаю, в принципе, выборки не по equality ключа, а по какому-то range ключей, то есть если ты хочешь делать нормальные запросы в базу данных, которые ты привык делать в обычной свойской базовой базе, как только ты делаешь консистент хэшинг шардирования, у тебя вся эта штука перестает хорошо работать. Потому что тебе нужно либо индексы дополнительно строить отдельно, которые как-то иначе шардированы, либо вообще не шардированы, либо тебе нужно просто, как вот Кряк это делает в случае secondary indices, он просто берет, строит минимальное покрывающее множество, чтобы не все реплики тронуть, но такое множество реплик выбрать, чтобы хотя бы каждый кусочек кейспейса был покрыт этим множеством реплик. И в итоге шлет запросы гораздо на большее число реплик, чем можно было бы, если у тебя нет какого-то хорошего параметра ключа, по которому можно сильно судить. То же самое делают кассадеры почти все. Первое, что делают как роль чтебельника, это окей, мы пойдем по сложному пути, но который нам в итоге даст нормальный перформанс на такие запросы. Вместо того, чтобы делать фиксированное количество кусочков с консистентным хешингом, мы делаем типа просто вот балансинг по нашему кейспейсу, как он есть, альфа-нумерик. А дальше, если у нас какой-то кусочек шарда, если у нас какой-то шард становится очень горячим, мы его в динамике режем, если какие-то два соседних шарда становятся очень холодными, мы их в динамике мерджим. Так на самом деле делает, например, Google Bigtable. Это первая вещь, которую они... То есть это сложный путь, им сложно пойти, но они это сделали, они это делают правильно, это будет в итоге быстро работать. Второй момент, который они делают правильно, они делают нормальные транзакции. То есть сейчас есть хорошие сторажи, которые даже предыдущие пункты силили сделать правильно, типа RefinedDB. Но там другая проблема... А они с акцией гарантии? Вот эти вот промоучастия? Не, у них насчет дюрабилити не совсем понятно, а я думаю, что ACI у них точно есть. Окей. А нормальные транзакции сейчас нет вообще нигде просто. Сейчас нет ни одной базы данных распределенной с нормальными ACID транзакциями из коробки, как RochDB будет первый такой. Само собой. Ну потому что ACID транзакция это вот прям такой тяжелый... Ну не то, что... На самом деле, если у тебя есть база данных с CP, ты сверху можешь при помощи некоторых костылей навернуть ACID транзакции. Просто это будет костылить на твоей клиентской стороне, и это будет медленнее работать. Потому что когда у тебя транзакция драйвится клиентам... CP вопросов нет, но бывают кейсы, когда тебе очень важен AP. Очень важно, и здесь не вдавайся в подробности. И поэтому дело, что тебе придется здесь что-то придумывать. Ну, как бы насчет AP, существуют в природе AP транзакции, которые тебе гарантируют атомарность, но не изоляцию. Валера, у меня вопрос. Расскажи, пожалуйста, про тему. Про тему? Окей. На самом деле, меня просто тут увели, тут начался полусрать. Но ты не видишь, мы приклеили тролля, который нас постоянно отвлекает на всякие глупости. Вот да, я уже это понял. На самом деле, давайте сделаем вид, что это был офигенный переход. А еще ACID гарантии обещают на свежеиспеченной го-шавк или го-хаук, гос-хоук. Я не знаю, как это правильно читать. Наверное, гос-хоук. Хотя, может быть, го-шоук. Понятия не имею, как это правильно читать. Но, в общем, на изображении нарисован какой-то сокол или орел, поэтому будем считать, что это гос-хоук. DB, зарелижная версия 0.1. Ребята идут интересным путем. Они обещают full CP ACID, вот это все. Но при этом они говорят, что... Да, при том с транзакциями. Но при этом они говорят, что, короче, у нас будет object storage, вы, короче, вставите ваши объекты в наш storage, и у вас такие фигак объекты в storage распределенном. Это интересно. Я не очень понимаю, что они хотят добиться, потому что граф объектов засовывается в базу странно. Если там потом можно... Если граф объектов развесистый, то я не уверен, что у них там будет с перформансом. С другой стороны, у них интересная подходка к транзакциям. Они всю транзакцию гоняют на клиенте, потом пытаются все, что у них получилось, то видение, которое у клиента получилось, целиком засунуть обратно в базу. Если база с этим согласна, то типа у нас транзакция коммитится. Если база говорит, что что-то в это время поменялось, пока клиент свою транзакцию накатывал, он берет ее, потому что локально полностью накатает, потом снова результат пытается засунуть. Я у этого вижу... То есть подход, в принципе, очень здоровский с точки зрения производительности, но он очень сомнительный с точки зрения того, что получается, что каждый клиент должен реализовывать. Это довольно сложно. То есть у RethinkDB пришли похожим путем, у них меньше радикализма в этом плане, то есть они тоже много гоняют на клиенте, но не так много. У них уже проблемы с написанием драйверов. У этих ребят, может быть, еще больше проблем с написанием драйверов. Но в остальном, вещи, которые они обещают, очень здоровские, но надо понимать, что это версия 0.1, но они вообще пытаются что-то вроде Transactional Memory сделать. Такой вот... Вот, из прям таких совсем-совсем странных вещей, то есть они настолько 0.1 версия, что они еще пока не умеют даже элементарно добавлять нод в кластер. То есть вот мы кластер сконфигурировали, стартанули, вот все, работаем, бежим. То есть явно видно, что вот эта фигня, как она сейчас есть, она пока чистого прям бетка-бетка или даже альфа-альфа, и что они будут ее очень сильно пилить, и там сейчас очень много вещей, которые просто не поддерживаются, которые нужны реально в продакшене. Например, вышеупомянутые изменения топологии кластера, банальное удаление объектов по-человечески, более лучшее пакетирование, то есть больше клиентов для других языков, кроме Go, то есть почти все, что нужно реально в продакшене, там пока не работает, но нам обещают крутые фичи. Я буду пристально следить за этой базой данных, если она не сдохнет. Я надеюсь, что она не сдохнет, потому что в целом проект интересный. By the way, у них LMDB на бекенде. Пару фактов еще добавить. Во-первых, они написаны на Go, во-вторых, они хостятся на своем собственном сервере, на Меркуриэле, а на GitHub они только... Реплику. Реплику делают, да. А почему? Вот это вот тоже они прочитали тут манифесты и сдаются? Все? Может быть. Слушай, хорошо, у меня такой вопрос. Я же этот, как чувак из кровавого интерпрайза, вот это все. Мониторить-то это как? То есть мы вот так запили эту базу данных, и что дальше? Как мониторить? Ну очевидно, но как в любом кровавом интерпрайзе, забикс. Забикс. Слушай, а вы еще реально забикс используете? Не, вообще кто-нибудь забикс использует? Насколько я знаю, его используют вообще везде. Да, мы используем. Понятно. У меня на паре прошлых работ был реальный продакшен забиксу. Все, понял. Этот плавный переход был в сторону следующей темы, которая мне показалась немножко спорной. Про мониторинг? Да. Кто-нибудь что-то про меня прочитал? Я читала. Отлично. Значит, давай тогда обсуждать. Автор приводит историю, он говорит сперва про проблему, что нам тяжело мониторить быстроживущие контейнеры, и вообще контейнерный мониторинг очень сложен, потому что у тебя контейнеров может быть много, у тебя может быть большая сложная система, состоящая из большого количества сервисов, и на каждый отдельный сервис может работать небольшое время, и нам вообще в итоге сложно понять, как это правильно все мониторить. И он в итоге рассматривает историю установления мониторинга и говорит, что там было несколько классов. Первый класс смотрел текущее состояние, не смотрел больше ничего. Второй класс смотрел... Нет, подожди, первый класс смотрел текущее состояние какой-то характеристики. Класс 0, он это называет. Да, класс 0. Если у тебя значение характеристики вышло за пределы какого-то допустимого уровня, тебе шлется нотификация о том, что что-то случилось. И каждый раз, как только такая ситуация происходит, ты постоянно получаешь нотификацию. Я так и сказал. Про нотификацию не было, про пороговое значение. Любой мониторинг, он всегда пытается слать нотификацию, а пороговое значение – это текущее состояние для меня. То есть, он смотрит на текущее состояние, если там что-то не устраивает, пороговое значение, не пороговое значение или еще что-то. Фишка в том, что каждый раз, как только он пересекает эту черту, он будет постоянно слать тебе нотификацию. Хотя, по сути, у тебя там был какой-то спайк, и нотификация по-хорошему должна быть одна, но он тебе прислал их несколько штук. Хотя они об одном и том же сигнализируют. Ну, вот здесь тоже спорно. А что значит «одна»? Почему «одна»? Например, у тебя какая-то характеристика колеблется возле какого-то порогового значения. Это довольно легко решается. Есть такая тема гестерезис, и это решается. То есть, во-первых, гестерезис, во-вторых, вот, к примеру, у тебя шагнул этот спайк полчаса назад, и сейчас он до сих пор появляется. То есть тебе надо знать, что он полчаса шагнул назад, что он назад вернулся, текущее значение или как. То есть это все очень спорный момент. Это вот то, что касалось класса 0. О том, что они просто такие глупые системы, которые не имеют никакой памяти. То есть ничего не смотрят они за предыдущий промежуток времени. Стейты не имеют. Следующий этап – это системы со стейтом. Как только оно мониторит текущее значение твоей характеристики, но и смотрит, какие у тебя значения были раньше. Это значит, что если у тебя есть какая-то ситуация, например, ты раз в день делаешь бэкапы, и у тебя время делания бэкапов, ты получаешь сплех какой-то активности. То есть это какая-то, там, с точки зрения дня – это аномальное поведение. Но с точки зрения недели, например, это вполне понятная ситуация. Вот. И такие системы умеют понимать паттерны, и в паттернах они не будут считать это аномалией и не будут послать тебе нотификацию. Вот здесь у меня вопрос. Давай. Вот он сюда отнес Nagios, к примеру. Я не знаю, я, может, конечно, не очень много работал с Nagios. Я тоже мало с ним работала, и здесь у меня тоже возник вопрос, потому что с Nagios Nagios использовала как, не знаю, вещь, которая показывает графики, и всё. Но чтобы она имела такой разум... Да, вот прям... На Nagios имеет систему, что ты там пишешь какой угодно код, который анализирует текущее состояние, но я ни разу не видел удобного, по крайней мере, способа работать с историческими данными, что вот у меня по понедельникам в 2 часа дня у меня срабатывает всегда этот алерт, и теперь мне не надо никогда сигнализировать о нем. То есть как бы такого вот я в Nagios не видел. Я, может, конечно, его не так использую. И знатоки, кто слушает нас, пожалуйста, в комментариях придите, если это не так. Вот. К примеру, я, конечно, приведен к этому классу Datadog. Вот мы сейчас используем Datadog. В Datadog тоже такое есть? То есть я, короче, мне какой-то странный класс. То есть это, во-первых, сама странность причисления продуктов сюда, а во-вторых, вот, к примеру, у вас в понедельник всегда срабатывает эта проблема. Она вам точно никогда ничего не должна сигнализировать теперь? Ну, то есть, вот, к примеру, у вас происходит какой-то крипс базы данных, и у вас часть клиентов отваливается. Что, теперь вам этих отваливающихся клиентов не воспринимать как проблему никогда? Ну, то есть для меня это вообще спорный кейс. То есть ты должен... О-о-о, слушай, ну смотри. А вот какая ситуация лучше? Вообще полный отказ от обслуживания или то, что ты 10% клиентов не обслуживал? Для меня... Ваня, а в другом ты говоришь, что если у тебя проблема повторяется каждый понедельник, это не значит, что это норма. Да, согласен. Ну, то есть, как бы, а здесь он говорит, ну, как бы, по историческим причинам он все знает, и поэтому он не должен тебе ничего сигнализировать. Ну, судя по его блогу, так написано. То есть для меня это неприемлемо вообще. Тут смотри, есть нюанс такой, что порой, когда тебе система нотификации шлет слишком много алертов, ты начинаешь на них забивать. Относиться к алертам как ну, блин, снова пришло, ну, ладно, посмотрим. Пришло себе тысяча таких алертов, ну, значит, что-то плохое случилось. И когда тебе шлются алерты в таком режиме постоянном, то это тоже плохая ситуация. Слушай, ну, если у тебя алерт говорит, что клиент отвалился, он не смог ничего сделать, то, да, это, наверное, проблема, если они тебе шлются. Ну, то есть, как бы, я не очень понимаю, к чему ты говоришь. Давайте забивать на клиентов, которые отвалились, у которых проблема на продакшене? Не, я имею в виду, смотри, ты говоришь про конкретную ситуацию, вот, клиенты на продакшене, а я говорю тебе про историю, когда разработчики перестают обращать внимание на алерты, потому что их просто много. И они привыкли, что алерты посылаются по поводу и без, ну, ничего страшного. Ну, так это просто неправильно написано «алерты», тут система, которая используется, вообще ни при чем. То есть, первый, нулевой, второй класс. Я это точно рассказываю про совершенно другую ситуацию. Не, ну, как бы, мы сейчас обсуждаем разные классы разных мониторинговых систем. И он говорит, ну, теперь вот этот класс стал лучше, потому что он не шлет в случае, когда нам не надо слать. Я говорю, что таких случаев, когда не надо слать, во-первых, нет, чаще всего, если ты работаешь с реальным продакшеном. Во-вторых, это зависит не от системы, а от того типа алертов, который ты написал. То есть, если там тупой алерт, который тебе на всякий случай всегда пошлет что-то, ну, значит, это алерт неправильный. Ну, знаешь, я бы, знаешь, как сказал, я видел у нас на продаже, наверное, ситуацию, то есть, у нас был алерт, который был, как бы, он, скажем так, не звонил тебе через железную ленту, потому что он очень часто false positive, но иногда может быть true positive, просто потому что там зависимость от характера ступеньки. То есть, у нас реально пользователи ушли? Или пользователи ушли и не могут вернуться? Потому что у нас там что-нибудь отворилось. Но false positive зависит от алерты, а не от класса системы. Ну, да, я согласен, ну, вот да, это зависит от класса системы, но я действительно согласен с тем, что если что-то валится регулярно, какие-то алерты, то их начинают выключать, да, и они... С этим я согласен. Это, правда, плохо, но иногда бывает так, что, то есть, реально, тут система, которая действительно распознает паттерн, она бы помогла, потому что там, как бы, зависимость от характера ступеньки, там должно быть разное поведение. Я очень смутно себе представляю, как можно сделать генеральное решение, которое тебе такие паттерны будет распознавать. А вот никак, наверное. Вот я про то же. Вот, и, значит, возвращаясь назад к статье, там есть еще один класс систем, который, он говорит, должен скоро появиться, и он приводит даже одно из решений, как оно там называется, я забыл, RUTX, да, которое, значит, должны анализировать не какое-то отдельное проявление, а, скажем, вот у вас есть сервис, который состоит из разных контейнеров, которые могут, в том числе, быстро отрабатывать. Вы должны собирать информацию не по одному контейнеру, а по всем контейнерам данного типа, или даже всем контейнерам данного сервиса, и суммировать их проявления, и только вот эту агрегированную статистику показывать и каким-то образом анализировать. Это позволит вам, он там приводит сравнение с биологическими системами и говорит, что чаще всего оно в биологических системах работает, будет работать как бы и тут. Вот, но тоже как какой-то сомнительный факт, я его не очень до конца... Ты не рассказал про третий класс, или я пробуюсь? Я как раз про него сейчас и расскажу. Ну, как-то это очень странно, потому что все-таки мы не можем там оценить поведение всей системы в целом, потому что ну окей, когда мы приводим человека, у него теперь артур повышается, ну да, согласен, и мы считаем, что он болен, и нужно что-то с этим делать, да. Но причину этого мы сверху не понимаем. И нужна какая-то там диагностика, анализа, еще что-то. Если же мы говорим про какие-то распределенные компьютерные системы, то у нас уже сразу из коробки было бы неплохо иметь понимание, что вот здесь вот у нас на этой роли вдруг там грузка выросла, да, то есть здесь у нас есть возможность сразу получить информацию чуть более подробно, чем общая температура средней больницы. Я согласен, да, то есть как бы может быть стоит отталкиваться... У нас уже есть возможность, зачем? Нужна какая-то некая волшебная общая температура. Вот эта волшебная штука, она нужна, чтобы отделить, когда муха-котлет, когда у тебя есть проблемы, когда у тебя нет проблемы. Скажу, если у тебя контейнер отрабатывает за 20 миллисекунд, а ты собираешь статистику раз в секунду, то ты в принципе не поймаешь его. Вот тут очень такие моменты, потому что оказывается, можно влезу вот прям в наглую так, окажется, что это реально, как в том анекдоте, что у нас в морге там 0, в реанимации 40, в средней 36,6. Потому что мы же говорим не про отдельный контейнер, а про систему контейнеров. И эта метрика, какая-то десятая производная, она очень нерепрезентативна, на мой взгляд. А, тут история какая. В этой статье тоже интересный момент, уделяется много внимания, что вот у тебя есть какая-то ситуация произошла на продакшене, вот у вас какой-то сервис, он сбойнул. И это значит, что вот по наподобии с волной физической, у тебя получаются остальные сервисы, зависящие от этого, который сбойнул, тоже получат какие-то всплески активности. И в принципе, было бы неплохо, когда бы тебе твоя система альертинга понимала, что вот эти сервисы вообще связаны. И, например, строила такое, не знаю, дерево альертов, либо говорила, вот смотрите, это вот причина, а вот остальные тоже сбойнули, и от такой-то... Но первая причина – это вот эта проблема. То есть не просто так, что тебе в плоском виде прислали N-алертов, вместо того, чтобы структурировать их. Вот я в таком ключе поняла эту статью, и мне кажется, эта идея очень классная. Но ты не сможешь это вытащить ее никак. Я имею в виду, из суммарной статистики, когда у тебя суммируются все... Ну, к примеру, у тебя там тысяча этих сервисов данного типа, и каждый состоит из пяти контейнеров. Ты их просуммируешь, ты думаешь, ты сможешь вытащить эту информацию оттуда? Я вот думаю, что нет. То есть, может быть, она что-то покажет, но 36,6 по больнице оно ни о чем. Может быть, делать без интернта? Но это же не идея в том, чтобы суммировать твои характеристики. Это наглое прерывание и переход на темы слушателей. Хорошо, хорошо, пошли к темам слушателей. Уже? Так быстро? Хорошо. Давайте начнем с темы слушателей про Скалу Иго. Давай, давай, давай, отлично. Валера тоже читал эту статью, насколько я помню, да? Да. Ну, скажем, статья шикарная, на мой взгляд. Я читала просто вот за поэтом. Потому что фактически она повторяет ровно мои же мысли по этому поводу. Подожди, подожди, можно я прерву тебя? Слушай, смотрите, я пролетел по количеству голосов. То есть, чуть повыше стоит с пятью голосами тема, а это с 16 голосами. 16 человек проголосовали за, и как минимум 11 человек проголосовали против. То есть, это такая настолько неоднозначная тема. Давай, извини, Света. А почему против? Этим интересно. Да, да. Ну, тема какая? Что вот есть одна компания, называется она CrowdStrike, и они писали много на Скале. Много писали на Скале, и пришли к такому времени, когда разработчики стали матерыми и начали использовать всякие маргинальные библиотеки в своем проекте. Подожди, подожди, подожди. Мне кажется, ты уже сразу missing the point. Там не в том, что есть маргинальные библиотеки, а в том, что на Скале можно писать как с маргинальными библиотеками, так и без. Ты меня перебиваешь. Что ты лезешь, Ранша? Дай-ка мне рассказать. А что за маргинальные библиотеки-то? Подожди. Разработчики стали матерыми и начали тянуть в проект много чего интересного. И получилось так, что часть разработчиков, которая развивалась, скажем, в направлении FP, они притянули много чего интересного, и стал код довольно тяжелым для понимания человека извне.",
    "result": {
      "query": "согласованность CP AP распределенных баз данных"
    }
  }
]
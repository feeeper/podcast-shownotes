[
  {
    "segment_id": "6b250ce7-d7bb-4a01-af43-5e867d7b5dd0",
    "episode_id": "196dc153-c3ee-450c-a1f9-845eb613d7dd",
    "episode_number": 250,
    "segment_number": 3,
    "text": "Какая-то фантастика, вот реальная фантастика, я имею в виду, что такого не бывает, то есть, ну, какие последние проблемы вы имели с большими дата-флоу? Да блин, что-то кавка начала тормозить, ой, у меня там упало что-то в ней, реплика какая-то отвалилась, и у нее не хочет она подгружать последние изменения. А вы тут говорите, я вот хочу быстро и надежно запустить мне все остальное, чтобы работало, и чтобы дата-центр умер, а я восстановился. Слушай, у меня таких проблем, как у этих ребят, нету, но у нас есть другие интересные проблемы. Я буквально недавно смотрел ток, я не стал его притаскивать в подкаст, потому что это очень такая нишевая штука. Есть такие ребята, Dreamio, и у них был доклад в 2017 году про то, как они при помощи Apache Arrow и Apache Calcite, про которые я рассказывал в выпусках 5 назад, делали реляционный кэш. Я не буду рассказывать, что такое реляционный кэш, смысл такой, что, ну, мне кажется, да, наверное, придется рассказать вкратце, смысл такой, что мы, если у нас есть очень большой как бы массив данных, типа, ну, вот у меня в системе типа сейчас cold storage 18 терабайт, да, если вам интересно в этом работе, вы пишите на скале, напишите мне уличку, у нас еще нет пока вакансии, я не могу кинуть ссылку на вакансию, напишите мне уличку, я могу вас, наверное, попробовать как бы немножко раньше пропушить. Или как только вакансию откроем, сразу положить. Вот. И второй момент, что у тебя есть запросы, которые никакие, то есть люди давно придумали, что делать, если у тебя дашборд, один и тот же запрос, просто много раз, ну, там, делают LAP кубы или даже просто какие-то, ну, там, кэшуют этот ответ этого запроса, это просто. А что, если у тебя это какая-то BI-система с произвольными запросами, которые там вообще, может быть, какой-нибудь CTData Scientist и придумывает тебе какие-то запросы к этому, каждый раз новые или они, во всяком случае, эволюционируют, пока он его придумывает, он потом может быть превратится в дашбордный запрос, но пока он его придумывает, ему нужно с этим работать. Проблема в том, что ты все эти 13 терабайт, если ты начнешь кэшировать, тебе нужно кроме 13 терабайт быстрого хранилища, на котором они так уже лежат, нужно какой-то 13 терабайт еще более какого-то быстрого хранилища получается или там, не знаю, может, не все 13, но до хрена. Это, ну, очевидно, ограниченно работает, то есть ты не можешь просто взять весь файл, кэш положить, это, ну, не так это.",
    "result": {
      "query": "Кеширование больших дата‑флоу проблемы"
    }
  }
]
[
  {
    "segment_id": "855f95c5-a90d-43b0-bb94-d749edc4aa71",
    "episode_id": "ee7cc804-18cf-46fd-8263-4ad3fe3eb225",
    "episode_number": 125,
    "segment_number": 3,
    "text": "нас бранч-предиктор в процессорах не ломается, и мы получаем, в принципе, большой performance gap для рантаймов, это до 10%, что для рантаймов, которому 20 лет, это очень круто. А можешь пояснить? Я почему-то сейчас не понял. Окей, что такое стековые машины виртуальные? Все плюс-минус представляют. У нас есть какие-то байт-коды... JVM, понятно же. Ну, JVM, да, JVM, Ruby, Python и многие другие виртуальные машины построены на примере стековых виртуальных машин, потому что их писать гораздо проще, чем регистры виртуальной машины. В любых машинах у вас есть... сейчас большие кавычки такие, большое очень громадное упущение, есть аналог основных кодов, машинных кодов, это байт-коды. Вот эти байт-коды, это говорят, что мы делаем, мы там загружаем на стек какую-то переменную, мы там складываем переменные, которые лежат на стеке, мы там загружаем в память, берём со стека и загружаем в память, сделаем стор того, что есть на стеке. И тут у нас всегда есть вилка, что у нас оп-кода, который сейчас на стеке лежит, который виртуальная машина должна исполнять, либо есть какой-то аргумент, либо нет. Ну, допустим, просто сложение, сложить то, что лежит на стеке, сейчас две переменные, и там аргументов, казалось бы, нет. И эта вилка, она очень горячая, она постоянно крутится, и из-за этого в C-коде у вас постоянно ломается бранч-предиктор, бранч-предиктор в процессорах, я думаю, не стоит объяснять тем, кто хоть немножко знает, как устроен современный процессор. Или стоит? Можно сказать, что это важная вещь, нужно точно, ну хотя бы с большой вероятностью, знать, куда ты пойдёшь. Это понятно. Мне кажется, мы пару раз об этом говорили. Не стоит ковыряться. Бранч-предиктор мы не будем сейчас рассматривать, но да, это история про то, что процессор постоянно прикидывает, что вы пойдёте, скорее всего, туда, и он будет пытаться там вычислять, а если вдруг не получилось, то он будет сбрасывать весь стек, это очень дорого, это дорого, это тысячи циклов процессорных тактов, это безумная стоимость. Вот. Теперь если у нас всегда есть один, точнее, у нас есть сам обкод, всегда есть один аргумент, то мы просто избавляемся от этого ветвления, ИФа, и мы всегда крутимся, и процесс всегда просто работает без всяких бранч-предикторов, и это улучшило перформанс. Вот это непонятно. Почему? Как? Чем от сложения с первым аргументом улучшило бранч-предиктор? Не, не, смотри, не так. У тебя было, допустим, лоад конст какой-то, и у лоад конст, а дальше был константа. Это был байт-код лоад конст, и дальше констант, который мы загружали. И это был один байт-код, у которого был один аргумент. И были байт-коды, например, там, сложить. Сложить то, что две переменные, которые сейчас лежат на стеке, ну, там, аккумулятор. Вот у аккумулятора не было никакого аргумента. Логично, так? Теперь этот аргумент просто пустое значение. И вот в этом месте была ветка в интерпретаторе, когда мы либо шли в код, и интерпретатор постоянно проверял, что у нас либо есть вот этот аргумент на сложение, либо его нету. Понятно объясняю сейчас? В смысле, есть в стеке положенный, и надо его класть в стек, или не надо класть в стек, ты это имеешь в виду? Нет-нет-нет, если вы возьмете его и сделаете диз, ну, это мобильный питомецкий дизассендер, то вы увидите, там у вас есть лоад конст, тор конст, или какое-то умножение, или ещё что-то. Когда вы делаете, допустим, сложение, то у вас исполняется байт-код сложения, и складываются две переменные, два значения, которые лежат на стеке следующей. Так понятно? Ну, это да, я понимаю. Я не понимаю, а теперь у вас, ну, теперь ускорение за счёт того, что у вас условно считается внутри основного мейн, главного лупа, который крутит вот эти вот, берёт и декодирует байт-коды, он всегда считает, что у него есть один аргумент, и нет ветвления, что он проверяет, что если у нас нету аргумента у байт-кода, то мы пойдём налево и будем там что-то проверять, если есть, то мы пойдём каким-то, какая-то есть логика направо, то есть был очень неоптимальный основной луп декодирования байт-кодов написан в питоне, вот так вот. Это не связано с тем, что у нас как-то, то есть это та оптимизация, которая никак не трогает, как программист пишет код, вот самое важное, пожалуй, что стоит об этом сказать. Объяснил нормально, нет? Если честно, я так до конца не понимаю, ребят. Я тоже не понимаю, зачем... Давай я тебе поясню словами. У нас есть операция сложения, для того, чтобы выполнить операцию сложения, мы оба операнда должны положить на стэк, и так, мы кладём оперант 1 на стэк, мы кладём оперант 2 на стэк, потом мы говорим, всё, что там выше на стэке лежит, сложи. В смысле, взявайте два операнда и сложи. А теперь смотри, у тебя есть вот здесь дизассэмберный код, диз – это модуль питона, сейчас мы поговорим в контексте питона, то мы увидим, что у нас там есть load const, или какой-то load, или load global, а дальше мы видим, что у нас есть байткод сложения. Вот байткод сложения, если для load const там есть, допустим, load const – это сам байткод, а дальше стоит константа, это аргумент этого байткода, который он должен загрузить на стэк, то для операции сложения у нас этого байткода нету никакого аргумента, он пустой. Это понятно, да. То есть раньше его не было, а сейчас появился непонятный пустой аргумент. Да, а сейчас есть пустой, совершенно верно. И чем это помогает, вообще непонятно. То есть я всё равно должен сперва загрузить два аргумента на стэк, а потом сделать сложение, и почему у меня branch prediction должен понимать, что до этого не надо было, а сейчас надо, я вообще ничего не понимаю. Более того, теперь у тебя становится всё хуже в плане кэширования у тебя. Стоп-стоп-стоп, смотрите, а здесь интересно. Вот эти байткоды, в действительности это очень такая виртуальная структура, и они все распарсиваются и процессятся именно основным лупом виртуальной машины, то есть это вот тот самый цикл, который их декодирует и говорит, что вызвать или как сделать. И здесь... Я понял, ты говоришь о том, что луп самого парсера этого байткода, он имеет теперь меньше бранчей. Совершенно верно, он теперь имеет ровно... он имел раньше два бранча, либо существует какой-то аргумент, либо не существует, а теперь он имеет ровно один бранч, что всегда есть аргумент. И что, и прям сильно быстрее стало найти с помощью парсера? Самое интересное, что вот эта оптимизация, этот подход улучшил, допустим, перформанс в торнадо-шаблонизаторе, это прям совсем-совсем такой понятный клиентский и бизнес-аппликейшн на 10%. Для рантайма, который имеет 20 лет истории, 10% перформанс-гэп, это прям очень круто. Но он теперь разрядит больше памяти, как я понимаю. Ты знаешь, это несущественно. В реалиях память, это самое последнее, за что в питоне стоит волноваться. Там есть в 3.6 много чего, но если не извини, но по твоей же логике и скорость не главная, за что питоне нужно соревноваться. Сейчас, а вот мы до этого дойдём. Про скорость мы дойдём. Ну короче, давай я просуммирую. То есть получается так, что до этого питон был написан неоптимальный, были случаи, когда гранч-предикшн работал неправильно. Сейчас они, не изменяя ничего в клиентском коде, делают так, что оно стало работать лучше. Да, лучше и лучше сильно. Причём сильно, это прям для виртуальных машин, которые имеют очень большую историю, это очень круто. Потому что такие истории, они обычно рассказываются на конференциях, рассказываются где-то, и все говорят, ой, у нас там громадные достижения, мы на 10%, там на 10-15% ускорили, в принципе, ваш ворлд, и это всегда приветствуется. Здесь это как-то прошло очень тихо и почти незаметно, что очень удивительно. Да потому что это проблема питона, я имею в виду. Надо было поправить это в версии 1.3. Слушай, ну когда вот ребята в Яве сделали компакт-штринг, они на всех конференциях в течение 2016 года об этом трубили. Здесь такого нет. И вот это прям удивительно. Не опускайся до их уровня. Хорош. Я вообще ни за чьи уровни не опускаюсь, не подымаюсь. Здесь скорее подыматься надо, но в целом там и там и там грамоты инженера, просто вопрос подачи. Окей, с абвордами, об кодами как-то более-менее разобрались, я думаю. Согласен. Хорошо, про компактные дикты. Да, компактные дикты это то, о чём говорили, там даже были рассказы о том, что вот теперь у нас потенциально, может быть, код поломается, потому что компактные дикты принесли нам упорядоченность какую-то, а люди, которые не рассчитывали на то, что у нас теперь будут дикты упорядоченные, создатели библиотек могут теперь получить какие-то баги. Здесь хочется сказать несколько вещей. Первое – это то, что, во-первых, никто не обещал, что у нас будут дикты упорядоченные или нет. Ну вот, в семантике и в описании языка нигде не было сказано, что когда вы создаете дикт, он будет упорядоченный или нет. То есть тот, кто писал, рассчитывал, что дикт будет неупорядоченный или ещё какой-то, он сам себе злобный буратин. Правда. Согласны? Нет, но это всё логично. То есть вы не должны были до этого рассчитывать, не рассчитывайте и сейчас, и в будущем тоже. Огонь. Да. То есть у нас здесь пека языка, против которой мы кодируем. Я прошу прощения, но Лену Сторвольдсу не кодует сейчас. Почему? Потому что нельзя ломать пользовательский код, даже если он неправильно написан. А здесь нет лома пользовательского кода? А, ты имеешь в виду, что кто-то рассчитывал там чего-то куда-то, да? Конечно. Согласен, надо было в Верфи 4 выпускать. Тут сложный вопрос, потому что вообще есть в языках, кроме Ромера, есть там грамматика, есть семантика. Грамматика – это формально какое-то описание языка, а есть семантика – это описание, что будет происходить. Если в семантике не сказано, что будет так и так, то происходит такого... Линукс всё равно не кодует. Линукс может сколько год не додавать. Я начинаю подозревать, что гость не уважает Лену Сторвольдса. Я его очень сильно уважаю как создателя, я пользуюсь его продуктами, так или иначе по работе и в частной жизни, но я могу с ним спорить или быть частично несогласен в каких-то отдельных пунктах или разделах. Конкретно в разделе, что мы никогда не можем ломать обратную совместимость, здесь нам нужно определиться, что такое обратная совместимость. Если вам никто ничего не обещал, ну извините, вам никто ничего не обещал. Не согласны? Я согласен, но... Подожди, а мне ужасно интересно, атлайтики нужны или не нужны? Вот я тоже хотел бы помнить. В ядре? Вообще в мире. В принципе, в программировании. И мне ещё сразу вспоминается в этом, как и в Орланге, всегда был пример хороший, это пара трансформ, когда ты делаешь изменения АСТ на лету своего дерева, и оно всегда было не до конца документировано, и обратную совместимость не ломали в каждой версии. Я прямо каждый раз ругался. Отвечаю, я абсолютно верю и уверен, что кому-то где-то, когда-то зачем-то атлайтики в разработке нужны. Ладно, хватит наезжать на Гостя, давай пошли дальше, дикт неинтересная штука. Я извиняюсь, но Гостя он сам такой, как сказать, такой мотив задал. Да-да, подготавливает вопрос. Нет-нет, всё правильно, огонь, так и надо, я ничего против не имею. Мочи Гостя, кто-то пришёл тут нагло и говорит, я питон знаю, а здесь все такие клёвые программисты. Да-да. Мочи Гостя это хорошо, это надо запомнить. Ну правильно, не сношу двораш. Смотрите, там есть другие оптимизации, есть долгая вообще дорога, которую двигали, и это опять же прошло как-то мимо комьюнити. После того, как были сделаны вот эти компактные дикты, была сделана приватная версия диктов, которая позволяет трекать изменения в диктах, были сделаны специализированные функции с вардами, был сделан API для code transformation и был сделан API для транслирования фреймов на стеки CPython. Всё это открывает дорогу для очень крутых штук, то есть технически, если посмотреть на это, то в течение года комьюнити сверлил дырки в текущем CPython для того, чтобы потом можно было делать рантайм оптимизаторы, жидкомпиляторы, какие-то улучшения и тулинг вокруг текущего CPython.",
    "result": {
      "query": "оптимизация байткода без ветвления"
    }
  }
]
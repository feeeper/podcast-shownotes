[
  {
    "segment_id": "60eb823b-4b36-41ba-a1e7-4458d67bb69f",
    "episode_id": "40c6f19c-160d-4efb-9f81-15fb1a31bc50",
    "episode_number": 478,
    "segment_number": 11,
    "text": "Execution оно без jet, кстати вообще обновлении в ABB докладах, я так понимаю что нынче есть по этому поводу research, что хороший колоночный engine современный он не хуже или даже может быть некоторых случаях лучше чем джит не в последнюю очередь потому что очень хороший прям по-настоящему хороший джит очень сложно сделать и там уже очень маргинальные получаются 90 процентов выигрыша вы получите просто сделав хороший колоночный оператор для конкретного случая и собственно например если вы посмотрите как тот же самый кликхаус сделан у вас там опять же я как над кликхаусом не работал если кто-то придет в комментарии скажет что я дурак я уже неоднократно отправляли про мои высказывания про кликхаус вот в общем я жду возможно подобных комментариев насколько понимаю в ClickHouse многие операторы например шаблонизированы и они во время момента компиляции инстансируется для популярных типов как это того что у вас в колонке есть и поэтому у вас просто практически типа под каждую ширину колонки инстансируется шаблон плюс плюсный вот как вот эту колонку как батч колонки 64 просуммировать вот грубо говоря так и дальше уже непонятно что вы там накомпилируете как бы джетом такого что будет сильно оптимальнее чем векторизованный специализированный под конкретный тип колоночный сумматор В общем наверное что-то можно еще выжать, но это нужно прям очень сильно заморочиться. Во всяком случае мое понимание этого вопроса. Вернемся к Data Fusion и его экзекьюшену Он пул-based, по этому поводу я еще немножко дальше скажу. Они все активно сидят на Tokayo, ну и в принципе это проект на Rusty, про это не сказал. Проект на Расте и в принципе он по своей производительности весьма на уровне с другими похожими энджинами, то есть где-то помедленнее, где-то побыстрее, то есть из того что сейчас нынче именно в плане execution такого есть это метовский velax это я не помню с кем-нибудь там еще в докладе себя сравнивают, но их там несколько таких вот как то так на уровне того что такое патчи Error DataFusion есть вопросы? Будем считать, что нет вопросов. Что у меня в докладе отдельно хотелось для себя отметить такого, что я прям не знал и вынес для себя как заметки. Во первых и в рамках семью накладов и вообще в комьюнити есть такой а вспомни с кем еще себя сравнивали, они себя еще с dogdb сравнивали, dogdb местами побыстрее. Вот И в комьюнити и в частности на семью на кодах есть такая тема которая периодически всплывает, так как с джетом так и с тем у вас push-based или pull-based выполнением. То есть что такое что такое push-based выполняет это у вас оператор который делает какое-то вычисление он когда закончил он пропихивает дальше свои данные что такое pull это старая классическая vulkain model когда у вас есть оператор он когда закончил молотить и хочет следующую точку он своего как бы оператора выше по цепочке говорит отдай мне следующий тупол единственное в чем отличие современного pull based в том как он сделан в Data Fusion от того как он в Vulcain он не по ту пулу делает пул он делает пул по батчам и если опять же если я не ошибаюсь могу ошибаться ClickHouse по-моему тоже pool-based и тоже батчами Вот. DuckDB очень известно, что как раз таки, наверное, одна из наиболее известных, они очень публично об этом говорили, что они сделали push-based, это не единственная push-based система из известных, но они точно про это публично много говорили. Они сделали push-base, что вот они как раз таки на новейшем моднейшем ресерче это все обосновали и что у них на этом хороший перфоманс. В общем ребята из Data Fusion изначально все написали на pull based с батчами колонок и они используют в качестве shadler собственно TOK. Io и в TOK. Io есть worksteeling и в шейдере уже как бы написан он хороший и много для чего подходит. Кстати насчет того что он хороший я в интернетах видел разные мнения, но неважно он есть и он много чего умеет уже. В общем у Data Fusion был подход к тому чтобы попробовать сделать пуш-based и получилось как минимум не лучше, но очень сложно при этом. Вот они в итоге плюнули и не стали ничего делать а стали pushbased Погоди еще раз то есть pushbased сложнее сделать? Да это это в принципе даже не только это не только даже в data fusion pushbased в принципе сложнее хорошо сделать ну потому что у тебя очень много проблем возникает даже если мы не говорим про проблему архитектуры софта у тебя возникает проблема с тем что у тебя когда ты у тебя пустой система у тебя нет никакой необходимости в backpressure. Только ты начинаешь делать pushbase систему, у тебя сразу возникает история с backpressure. Ну да логично. И менеджментом backpressure распределенной системе между многими операторами. И это прям будет здоров проблема. И это даже сейчас не говорю про проблемы, которые возникают у тебя на уровне того, что у тебя интерфейс оператора превращается в из простого дай следующий тупол или дай следующий батч превращается в очень разясивству портянку. В общем улдэйст архитектурно проще и как бы с точки зрения проблем, которые нужно решать проще. В общем, в рамках всех этих разговоров Эндрю такую мысли высказывает, которая мне очень понравилась. Но на самом деле все архитектурные различия, за которые бьются академики, но он не совсем так это говорит, я переформулирую, они на самом деле могут влиять, но не столько влияют, сколько достаточно хорошая архитектура плюс просто количество ресурсов потраченных на инженерию в конкретном месте. То есть типа если у системы не совсем провальная архитектура, если у двух систем, у каждой из которых не совсем провальная архитектура, выиграет та, в которую просто больше типа вложено усилий. Это очень интересная и важная мысль и как бы с очень интересными примерами вроде pull и pushbased Я закончил про Data Fusion, есть еще второй доклад, есть ли вопрос на текущем месте? Я не очень понял, давай Саша. Коротко ты рекомендуешь к просмотру или нет? Если ты не знаком ни с каль сайтом ни с дата фьюжном то в целом рекомендую я не очень понял последнюю мысль то есть но это же же вроде такая очевидная вещь, что система, в которую вложено больше усилий, должна быть лучше, чем в которую вложено меньше усилий. Любому игроку в компьютерные игры очевидно, что красные бочки взрываются, даже если метнуть в них камень или нож. Это очевидно. Я просто сказал такое, что дополнительная информация мне не сложно. Мы сравним не просто усилия, а архитектура. То есть мы берем самый современный research и мы берем Data Fusion, который специально дизайнивался по принципу возможно не самый современный модный молодежный подход, но подходы которые уже работали в известных системах. То есть, грубо говоря, good enough. И вот good enough плюс усилия, оно получается не хуже, чем как бы самый-самый-самый современный research. Типа современный rocket science. Ну да. Пойнт именно в том, что как бы грубо говоря разница между godon up и rocket science архитектурой она может быть не в архитектуре, а в количестве усилий. Ну да, да. Это правда интересная мысль. То есть как бы если ты основываешь свою работу на опыте большого количества предыдущих поколений подобных продуктов, то ты можешь вложить немного, потому что у тебя немного усилий, потому что у тебя много Он нет имеет в виду, он имеет в виду, что, возможно, как бы, если у тебя есть одинаковый бюджет, то не так важно ты берешь архитектуру из последнего paper или классическую а я как раз хочу как бы обратно попытаться доказать то что если у тебя есть классическая которая показана что работает то тебе достаточно вложить небольшое количество усилий, потому что она известна и уже доказана. Ну да, ты можешь усилие не то что небольшое, ты можешь в том же бюджете усилие перераспределить на просто оптимизировать какие-то другие вещи. Да-да. А если ты делаешь современный rocket science, в котором одна работа и выпущено там два пейпера вместо там двадцати, то ты можешь наткнуться на что-то такое, на что никто ещё не натыкался, и тебе придётся вкладывать ещё кучу усилий для того, чтобы заставить это работать. Мне это напомнило схожую, но другую мысль, что иногда good enough это good enough. То есть, не помню, было в подкасте, не было в подкасте, Почему в свое время был большой хайп вокруг План 9 и почему он не полетел. Потому что Linux Goden Aff идеален? Нет. Но достаточно хорош, чтобы людям не хотелось. Видишь, даже как бы под бенчмарком получается местами ноздря ноздрю. То есть когда мы говорим про QuariExecution Engine, то самая важная для них метрика это ну собственно тип CH всякие померить и вот они получаются местами ноздря ноздрю а там где нас не ноздря ноздрю как правило виновата не архитектура потому что типа в open source data Fusion что-нибудь еще не оптимизировано если просто ну как же на этом потрачено типа ноль усилий Если я правильно понял посыл, то идея такая, что если вы возьмете себе теоретически оптимальную архитектуру, то не факт, что вы ее сможете быстро и дешево реализовать так, чтобы она на практике оказалась оптимальной по сравнению с уже хорошо понятой и разведанной классической архитектурой, где все грабли уже У него не с этой стороны заходит, он скорее наоборот, что типа если вы возьмете просто хорошую классическую архитектуру и вложите достаточное количество серий, вы скорее всего будете достаточно близки к оптимальной архитектуре, в которую вложили сравнимое количество усилий. Тут я еще имею дополнить насчет теоретической оптимальности. Теоретически оптимальная сортировка это пирамидальная, но она не используется примерно нигде, потому что на практике быстрее работает quicksort. Просто железо так устроено. Тут все-таки речь про вещи, которые сравнимы друг с другом на бенчмарках, но ладно. За мем б ясно. Так сортировки тоже сравнимы на бенчмарках. Ну да, это тоже правда. Вот второй доклад про Apache Data Fusion Comet. Что такое от Энди Гроува? Энди Гроув это по-моему я даже уже притаскивал ссылку на его набор статей, которые он как раз писал, когда он писал о Fusion DataFusion и Баллисту. Собственно он основатель data Fusion и, к сожалению, померший Баллисты. Он много где поработал, сейчас он работает в яблочной компании и ускоряет там спарк. Для этого он полный спарк ускорил в Nvidia. И вот тут они спарк ускоряют при помощи data fusion как раз. Что такое ускорение спарка? Вы некоторое время назад выпуск, наверное, нам нужно опять же пару лет назад в рамках этой же секции с докладами с s7u мы разбирали видос про DataBreaks фотом. DataBricks компания которая стоит за в основном стоит за спарком да тут же нужно оговориться я работаю в компании конкуренте поэтому все что я говорю я до я да Но на самом деле мы не будем сильно про этот брейкс говорить и просто хотел упомянуть фотон как пример того, что ускоряет спарк. Мы берем физический план спарка и вместо того чтобы его исполнять в джаве, мы его даем кому-то другому внешнему энджину, который может быть какой-то сильно более быстрый и исполняется на нем. Есть какой-то проект, который использует meta velax и вот ребята из apple open source Comet, который исполняется на DataFusion Что такое исполняться на DataFusion? Шеделером все еще выступает в патче Spark и в общем-то они Fusion просто через GMI вызывают GNI просто в том плане что они не запускают какого-то отдельного распределенного кластера Data Fusion они внутри процессов Spark который запускает Spark отдельные вещи исполняет внутри в Data Fusion Доклад полон технических деталей, которые не готов пересказывать отчасти потому что нужно посмотреть предыдущий доклад, чтобы понять этот. Больше того, если вы в целом не интересуетесь такими вещами как кишки вот этих вот спарков и похожих энджинов и как к ним прикручиваются какие-то другие энджины чтобы сделать их быстрее вам в принципе можно и скипнуть этот доклад Это очень важная работа в рамках Data Fusion и Spark сообществ. Это не что-то такое, что даст вам какую-то концептуально интересную штуку, в отличие от вот. То есть если выбирать какой доклад посмотреть, вам в любом случае стоит посмотреть доклад про deta Fusion, хотя бы даже просто чтобы понять этот доклад. И доклад про deta Fusion или пошла типа пачка Аль сайт вам даст больше кругозора, больше интереса, хотя вам преподнесет. Здесь же в принципе просто такая важная работа которую нужно закатав рукава делать и он там разбирает некоторые кривые кейсы типа с поведением типов с тем что вообще система типов между Data Fusion и Spark не совпадает местами В принципе там такие же грабли налетали ребята, которые ускоряли спарк при помощи velax и про то, как они это тестируют, про то, что значит они там фазят, то что они там генерируют случайные паркеты, случайные запросы, проверяют, что ускорен или не ускорен спарк себя одинаково ведет. Я помню когда-то рассказывал в подкасте про то что я делал спарк коннектор для SAP и я там когда делал пушдаун, тоже таким же приходилось заниматься по тем же абсолютно причинам, потому что как только вы имеете две системы у которых не идеально похожая система типов, не одинаково работает сравнение и все такое, вы налетаете и у вас примерно одни и те же способы, чтобы это починить. Из того что еще в докладе интересно, если вам такие вещи интересны, если вы хотите поконтрибить во что-то на расте что про обработку данных, вот коммент открытый и он прям там в конце доклада приглашает contribitity, что-то типа у них есть отдельный список good firstage issue. Вот, как-то так. Я закончил вопросы. Звучит как менее интересный доклад чем предыдущий. Ну сценарий, конечно, он субъективно менее интересный тебе. Мне он был очень интересен потому что я в таком варился две работы назад. Ну да, широкому слушателю наверное не очень интересно. Известно, что там дальше по программе. Да, дальше твоя карточка про то, как писать игру, которую не продукт. Я имел ввиду в серии LekSights? По-моему, кто-то что-то говорил, но я не помню. Обычно, когда выходят на YouTube, я смотрю, если мне это интересно. Я тебе сообщу. Вроде у них на сайте обычно есть программа. Я хотел поговорить за игростроительство. В прошлом выпуске я что-то там загонял про пиксель-арт и сочетание красного с бирюзовым. Потом запостил видосик в телеграм-канале и запостил пост у себя в блоге про игру, которую я писал.",
    "result": {
      "query": "DataFusion push‑based vs pull‑based execution"
    }
  }
]
[
  {
    "segment_id": "e35323cf-3990-4916-9b67-54139f8df80a",
    "episode_id": "b74fe6c2-9576-4c08-a4ab-4f15370fd33a",
    "episode_number": 307,
    "segment_number": 3,
    "text": "В системах, которые я поддерживаю, это пайплайны, и поэтому там очень часто есть существенная задержка между, собственно, плохим событием и тем, как оно начнет показывать симптомы, просто потому что там требуется некоторое время до того, как проблемный кусок данных продвинется по системе или где-то накопится достаточно backlog или где-то производительность деградирует достаточно, чтобы система начала ломаться. Поэтому искать корреляции еще и со сдвигами во времени довольно сложно. Но вообще подход валидный, он помогает срезать небольшие углы и сузить количество подозреваемых причин, но при этом он не решает проблему полностью, в том смысле, что он не говорит нам однозначно, что вот у нас есть известный баг, и в данном случае вот это именно он выстрелил. А хотелось бы именно так, что у нас есть список известных проблем, и мы такие – оп, мы видели эти метрики. В прошлый раз, когда эта проблема выстрелила, значит, она и сейчас выстрелила. И тут мы как раз подходим к кулсторию, которая, собственно, основана на моем собственном опыте, потому что в какой-то момент я попытался такую систему построить для нас, для нашей команды. И в принципе, когда я начинал этот проект, все выглядело очень здорово, единороги, я этот пейпер еще в глаза не видел, поэтому у меня была куча надежд. И я исходил из того, что данных у меня вагон, потому что системе, которую мы поддерживаем ей, типа там порядка 12 лет, у нас, соответственно, есть 12 лет истории он кол, у нас есть дофига инцидентов, накопленных за это время, казалось бы, все должно сработать. Собственно, какую задачу я поставил перед собой, у нас есть некоторый список известных проблем, которые в принципе меняется довольно медленно. И я хотел написать классификатор, который скажет, что это похоже на одну из известных проблем, либо неизвестно. Вот, таким образом я срезал вот этот угол о бесконечном количестве возможных проблем, потому что я сказал, что у меня есть класс неизвестно и интересные мне проблемы. После чего я взял в руки SQL-клиент и пошел изучать свой датасет. Сначала все выглядело неплохо, потому что у меня было, оказалось, примерно 15 тысяч разных инцидентов, которые были хоть как-то размечены с багами. А немножко контекста. У нас есть конвенция, что каждый инцидент должен быть помечен специальным стандартизированным тегом cause и, грубо говоря, ссылкой на баг в баг-трекере, который соответствует этой причине. Поэтому это очень удобно, мне практически не надо было чистить датасет. И вся обычная нудная работа, которую датасиантистам приходится работать 90% времени, я все это пропустил. Я, соответственно, взял вот эти 15 тысяч инцидентов, подумал, что, наверное, это как-то маловато, но вдруг все-таки прокатится. Из известных багов у меня было 34, и мое ощущение было, что они должны быть на каждом углу, потому что я не знаю, я не помню все эти баги наизусть, но процентов 30 из них я, наверное, мог бы наизусть перечислить, если захотел. Оказалось, что я не прав, оказалось, что из 15 тысяч инцидентов всего 300 были помечены хотя бы одним из этих основных известных багов. Соответственно, мой датасет, точнее, интересная его часть, внезапно схлопнулась, получается, что там, ну, на несколько порядков. Дальше я пошел смотреть дальше, и посмотрел, а, собственно, сколько у меня примеров есть для каждого из этих известных багов, и оказалось, что в самом лучшем популярном случае у меня есть всего 90 примеров одного бага. В среднем это было там между 10 и 30 примерами, и также довольно длинный хвост из одиночных. При этом, если поискать, проанализировать всю историю всех инцидентов и посмотреть на список багов, которые не находятся вот в этом списке обычных подозреваемых, то там оказалось 7 тысяч инцидентов, размеченные какими-то багами, и в каждом случае это был один или два примера для, один или два примера autogena bug. Тоже особенно не пообучаешься. Но я решил, что я уже зашел слишком далеко, чтобы просто так сдаться на основе теоретических плохих ощущений, и все-таки закинул эту систему и поигрался с киперпараметрами, попробовал разные типы обучения, и никакая моя попытка не оказалась существенно лучше случайного угадывания. Есть, конечно, оговорка в том, что я не эксперт машинном обучении, возможно, я сделал миллион глук ошибок, но, по крайней мере, это показывает, что проблема даже не такая простая, даже если у вас есть продукт, казалось бы, долгой историей, потому что 12 лет в IT это много, и не у каждого есть история 12 лет autogena. Но даже этого всего не хватило для того, чтобы сделать хоть какую-нибудь вьюзабельную модель, предсказывающую вот эти самые баги. Собственно, все. На этом моя кулстори и на этом пейпер заканчивается. В конце пейпера есть несколько выводов как раз на будущее, и выводы, в общем-то, такие. В данный момент это ничего не работает, но наука не стоит на месте, и, возможно, умные ученые в какой-то момент такие найдут способы решать проблемы обучения на маленьких датасетах или вообще без них, и, возможно, тогда это все сработает, поэтому пока у вас есть продакшн, пока у вас случаются инциденты, вы, значит, эти данные аккуратненько записывайте, размечайте, чтоб мне пришлось потом все размечать за раз. И, возможно, в будущем когда-нибудь картина станет не мрачной, но пока что она совершенно не впечатляет. Собственно все. Я очень скептически отношусь к этому оптимистичному окончанию. То есть я сейчас читаю книжку House Engineering, это основная тема книжки, с которой я сейчас совершенно согласен, что сложные системы, а у нас в программировании в продакшне всегда сложные системы, нелинейные системы, которые очень тяжело предсказать, чаще всего просто невозможно предсказать, но что самое плохое, они со временем меняются непредсказуемо точно так же. То есть может пройти недели, и у тебя полностью старый датасет перестанет работать на новой системе. То есть те же самые проблемы, которые были тогда, какие-то метрики, приходящих в данных, или те же самые проблемы, происходящие с оборудованием, они могут привести совершенно к непредсказуемым другим проблемам в продакшне. И ты никак с этим не справишься. Я не верю в большие данные в данном случае совсем, а на маленьких я не думаю, что мы когда-нибудь научимся делать работающую систему. Я в целом согласен с тобой. Я думаю, что очень мало вероятно, что мы сможем применить машинное обучение на уровне отдельных продуктов, но в принципе я могу себе представить, что у больших компаний, у которых есть данные о большом количестве инцидентов из разных продуктов, я не знаю, у Google есть собственная база данных, их внутренних инцидентов, я не знаю, всякие сервисы типа PagerDuty наверняка имеют порядочный датасет. Возможно, наше спасение кроется в том, что мы сможем построить модель, которая генерализуется между разными сервисами. И это не то чтобы полностью неправдоподобно, потому что в целом многие проблемы сводятся к довольно простым причинам. Где-то сеть упала, где-то диск летел, где-то перегрузили определенный сервер, и все затормозилось следом. Поэтому в принципе какие-то общие темы есть, и возможно мы в какой-то момент научимся этим пользоваться, однако не похоже, что пока мы знаем как. Напомню, мы решаем проблему, чтобы нас вообще не будили без реального инцидента, или чтобы нас реже будили? Напомню еще раз о формулировке проблемы. Строго говоря, мы не решаем проблему, это классический случай решения в поисках проблемы. У нас есть решение, машинное обучение, давайте попробуем найти проблему, которая может решить в Operations. Одна из таких потенциальных проблем это как раз в том, чтобы реже просыпаться по ложным срабатываниям аллертов, или чтобы нам стало полегче писать аллерты, и не нужно было самим собирать сигналы и анализировать какая метрика подойдет, а какая не подойдет. Но ни в одном из этих случаев не кажется, что мы можем либо построить модель, которая будет существенно лучше того, что люди напишут руками, либо модель, которой люди будут на самом деле доверять. Потому что мы упираемся в классический трейдов между количеством ложно-положительных и ложно-отрицательных срабатываний, и как правило ты можешь оптимизировать только одну из этих двух переменных, или найти какой-то баланс. И получается, что пока все вменяемые балансы они не лучше, чем то, что люди могут сделать вручную. Я ответил на твой вопрос? Да, да, я просто вспоминал последние проблемы, которые я решал, к счастью, не на Production. Рецепт у тебя есть операция в системе, которая бесконечно летает по системе, в какой-то момент фейлится, и спустя какое-то время на нее приходит снаружи ретро, и она снова там какими-то путями ходит, и снова фейлится, это крутие бесконечно, у тебя как бы незакрываемая транзакция. Естественно, на такое мелся аллерт, сделанный руками и так далее, и в общем-то, это не упавшая сеть, не сдохший сервер, а как бы программисты написали фигню. Не потому, что они глупые, а потому, что система реально сложная. И я вот пытаюсь понять, с какой стороны здесь прикладывать Machine Learning, и для меня это звучит как какой-то бред. Да, я согласен, что вот логические баги, скорее всего, мы не сможем отлавливать с помощью машинного обучения, по крайней мере, в базаревом будущем. Я думаю, что частные случаи, что вот такие сложные вещи машинного обучения не поможет решить, это не означает, что оно неприменимо в каких-то более простых случаях, но в простых случаях мне проще написать реальную метрику, что бизнес стал получать меньше бабла, или вот этот сервер не пингуется, а должен пинговаться, и так далее. Да, да, ну собственно об этом и пейпер. Отлично, ну... У меня есть вопрос. Слушай, я знаю, что есть система под названием Boss. Она написана на ГО, и она умеет навизировать метрики по вашим графикам и данным в Graphite, и может управлять уведомления, если что-то не похоже на предыдущие пареные. Ты с ней сталкивалась, не знаю, смотрели ли вы вообще в эту сторону? Какое мнение о ней? Я с ней не сталкивался, к сожалению. Одна из проблем работы в больших корпорациях состоит в том, что у них зачастую все свое. У нас есть похожая система, которая звучит похожа на то, что ты описываешь, которая ищет аномалии в метриках, и она в частности используется для канареечных релизов. К сожалению, проблема не к сожалению, а просто она не использует машинное обучение. Она использует обычные статистические методы поиска аномалий. И она опирается на то, что программист скажет, на какие метрики ей смотреть в первую очередь. Поэтому она может найти аномалии, которые мы не ожидали, в том смысле, что мы не предсказали именно форму аномалий, но где искать, мы должны сказать. И алгоритм там тоже просто статистика. Я вообще думаю, что проблема большинства систем машинного обучения в том, что они работают и действительно облегчают во многих случаях нашу жизнь. Но потом появляется случай, когда она, если она не срабатывает, она резко ухудшает нашу жизнь. И вот там примеры из жизни. Вот в наших айфонах есть Face ID, который в принципе работает, но в какой-то момент она не срабатывает. Оно жутко раздражает. Когда маску носишь? Ну, когда маску носишь, конечно. И получается так, что когда без этой… Кажется, у Светы опять интерпресс, интернет сломался. Но я могу похвастаться, что я один из тех людей, которые скептически относились к идее Face ID, и поэтому iPhone SE это вот мое все. Просто за то, что там Touch ID, и он работает гораздо лучше, чем Face ID. Пока ты не в перчатках. Ну да. Но к счастью, я теперь живу в таком климате, где перчатки особенно не нужны. Моя мама не работает опечаток пальцев. Я постоянно поражаюсь этому фактом каждый раз, когда я приезжаю в гости, пытаюсь ей наскрыть. А у нее насколько старый или новый телефон? Потому что в ранних версиях этой технологии она реально херово работала. А по мере того, как они делали новые террации, она стала работать чуть менее… В общем, она стала чуть менее не работать. Понятно. Ну, у нее 6S. Это одна из ранних терраций. То есть, может она на новости работает. Может, просто твоя мама шпион в отставке, у нее отпечатки такие, чтобы по ней узнать нельзя было? Ну да, у нее проблема, она любит фазиться с землей, и соответственно, у нее трескается кожа микротрещенно. А не реально через два дня отпечаток пальца. А в тот же день она отлично работает. То есть, в этот же день, на следующий день с утра, проходит дня два, и она не работает совсем. Ну да. Ну, именно поэтому во всех таких телефонах есть все еще бэкап с пин-кодом или под-кодом. Ровно по этой самой причине. Да. Согласен. Так, мне кажется, мы уже закопали эту идею о том, что нас может кто-то спасти от онкола. Нет, нас не может никто спасти от онкола. Но что нас может спасти от онкола? На самом деле, я вообще вообще всю эту историю ожидал, что мне сейчас придут и расскажут, как мне, короче, Эмель будет чинить мои штуки за меня, но это, видимо, слишком в будущем. Да. Когда это придет, мы уже будем не нужны, и не за тебя оно просто будет чинить, а ты будешь это... На обучение условия. Я к тому, что есть ситуации, когда, я не знаю, я думал, что в Гугле это не проблема, потому что в Гуглу достаточно все автоматизируют, но есть ситуации, в некоторых компаниях не буду показывать пальцем, где может быть, например, ранбук, который просыпает человек и выполняет. И этот ранбук может быть довольно тяжело автоматизировать, потому что вещи в компании сделаны так, как они мне сделаны, или там еще какие-то исторические причины, не знаю, там, бывает. А вот ситуация с ранбуком, это звучит как что-то, что можно, возможно, сделать по автоматическим режиме, и чтобы оно потом полностью автоматически выполнялось, возможно, не прям буквально, не рассеть ее, но каким-то адаптивным процессом автоматическим, но, видимо, я вообще не в ту сторону думал. Меня так умиляет, что думаешь, что в больших компаниях все не так. Ну, я просто хочу верить, что у вас чуть меньше говно по стенам намазано. Ну ладно. Ты должен сказать, не могу ни опровергнуть, ни подтвердить твою информацию. Да, действительно.",
    "result": {
      "query": "машинное обучение в инцидент-отслеживании проблемы"
    }
  }
]
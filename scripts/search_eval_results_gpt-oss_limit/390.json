[
  {
    "segment_id": "451d9493-f2a8-45c0-911d-708fed5298e7",
    "episode_id": "ce9d706f-9dd8-42b5-97f6-18b1d3070c10",
    "episode_number": 390,
    "segment_number": 11,
    "text": "Понятно. Но есть прям вот point in time recovery, прям вот вообще point in time. Всего кластера, то бишь. Таблицы. Тоже по табличной, вот собственно откуда я взял табличный. Что point in time recovery по табличной. Ну нет, мне хорошо, хорошо, хорошо, но я так же дал. Ну да, не совсем по-настоящему осидно, да. Согласен. Еще из интересного, про геймдей я уже упоминал, что у них есть геймдей и еще у них есть автоматическая штука, которая приходит и в отдельно взятой availability зоне начинает включить питание. Потом, когда она включила обратно, приходят наши старые знакомые, которые проверяют, что ничего ни где не разъехалось. Такая вот интересная штука. Вот про такое я еще тоже нигде не читал. Внимание, вопрос. А если разъехалось? Ну здесь это явно не прописано, но обычно в таких ситуациях, там где разъехалось считается, ну то есть если разъехалось в меньшинстве, то есть обычно же как ворум, если в меньшинстве корма разъехалась, понятно, кто виноват. Если у тебя там отличается бэкап от того, что сейчас на большинстве реплик, бэкап неправильный, если у тебя реплики, там типа одна отличается, там не знаю, две реплики отличаются, а одна, то есть да, наверное, может быть ситуация, когда у тебя бэкап и одна из реплик говорит одно, а две реплики другие говорят другое, я подозреваю, что они в такой ситуации эскалируют оператору. Нет, я имею в виду вот что. Вот ты выключил DC, вот ты включил DC, я правильно понимаю регион, это типа DC? Ну да, да, АЗ, пока это не регион, регион-то другое, у них есть АЗ, есть регионы, у тебя в одном регионе несколько АЗ, АЗ это дата-центр, а регион-то регион. Все, я понял, ну вот и вопрос. И да, я еще хочу прям подчеркнуть, что по умолчанию репликация между АЗ, а не между регионами, есть вариант репликации между регионами, но это прям отдельная подсистема с другими SLA, довольно дорогими, как бы с запросами транзакциями, и ну типа она есть, но это короче мы, она здесь почти не обсуждается в репере. Так вот, вопрос. Когда ты поднял регион и начинаешь проверять его на консистенцию? В этот момент мое приложение уже ходит в то, что раньше было недоступно? Я, если честно, не уверен, что они это делают на живых пользователях. Хорошо это знать. Ну то есть тут так уклончиво говорится, что using realistic simulated traffic, random nodes are powered off, то есть они не везд деца и выключают, они скорее всего делают куда-то шедло копирования чего-то, возможно с попяченными данными, потом это куда накопировали выключают, потом включают и проверяют, что оно не стало более попячено. Слушай, ну это значит, что у них есть стенд, большой стенд. Слушай, ну это не большой стенд, это рандомно где-то вот происходит такое наливание с simulated traffic. Нет, у них большой стенд с реалистичными данными и эмулированным трафиком. Это не статический стенд в одном месте. Мы берем значит наш глобальный кластер, то есть понимаешь, у них же, у них DynamoDB это не так, что вот Саша DynamoDB поставили, там Валерий DynamoDB поставили, Свети DynamoDB поставили, он один большой сервис DynamoDB, который гомогенный и просто это вот Malty Tenant среда. Если ты его, если ты обесточиваешь регион, но при этом делаешь это не на живых пользователях, это называется стенд. Ну просто в моей голове стенд, это когда ты берешь и выделяешь заранее что-то, это здесь динамически происходит, просто как часть работы системы. Мы берем, куда-то что-то насимулировали, налили, выключили, включили, проверили, что ничего не сломалось. То есть это те же самые машины, куда потом могут приехать пользователи грубо говоря. А, кажется у Вани был комментарий. Да, у меня был комментарий. Я хотел сказать, что когда я читал их книжку про то, как они проводят геймдей, у них была попытка сделать все как можно больше на продакшене. Конечно я не могу сделать здесь однозначный вывод, что именно это они проводят на продакшене, потому что всегда у них есть сноска, что то, что не получается делать на продакшене, делайте на копии продакшена. Но я не вижу, почему это не делать на продакшене, если они уверены в своей системе. Ну да, то есть они в любом случае не выключают весь DC. Я там именно что повторюсь, включают random nodes, то есть не весь DC. Ладно, идем дальше. Следующий помет, к которому есть, это про failure detection. Я не помню, приносили ли это подкаст, но вообще есть как бы, когда вы берете протокол, вроде того же RAF, Paxos, а чего-то такого, у вас там какой-то failure detector. Обычно просто hard-биты. И большинство систем, с которыми я вообще на практике видел, там просто hard-бит. Тем не менее, вообще есть и даже в продакшене довольно сложные failure detectors. Есть, по-моему, кажется, в касандре используется FI, failure detector. Он довольно замороченный, там типа, где ноды, ну и реак, тоже помню, так делал, где ноды друг другу, госпит, кто откуда кого видит, с какой вероятностью тот доступен, тот недоступен. Здесь довольно простой подход. Обычно просто hard-биты. Когда hard-бит не проходит, мы не сразу говорим, что ой, давайте перевыборы устроим, потому что если мы возьмем и сразу молча устроим перевыборы, перевыборы займут время, то это нам понизит availability, давайте так не будем. Вот они просто, когда hard-бит не прошел, тот, у кого он не прошел, пытается к кому-то еще достучаться и спросить, а вот тот, с тем все нормально? Если с тем все нормально, то значит, цено что-то не так, и нужно тут, значит, я фанатомлю, values, а не тот другой. Это очень-очень простая техника, особенно на основе всех этих сложных госи протоколов, и утверждается, что для них она, типа, тут нет процента, но работает в огромном числе случаев, то есть она для них решила проблему. Это довольно интересное наблюдение, что вот такой, опять же, довольно бесхитростный подход достаточно хорошо работает. Ты ждешь комментариев, и я поэтому добавлю комментарий. Я часто встречал ситуации, когда для решения какой-то проблемы предлагался подход, который был сложный, интересный к реализации и к попытке попробовать на продакшене, но при этом, при приведении какого-нибудь мозгового штурма приходил в голову еще один способ решения той же проблемы, бесконечно простой по сравнению с предыдущим, и он работал прям, как это сказать, он был намного хуже, намного проще, но работал в подавляющем числе случаев, и использовать, конечно, надо более простое решение. Окей, едем дальше. Дальше они измеряют, что получилось в плане доступности. SLA у них для основной DynamoDB 5 девяток, для глобальных таблиц 4 девятки. Как они его измеряют? Большая часть секции, ничего особо, не знаю, что снокошибательного, тут телеметрия, там телеметрия, у своих приложений, у внутренних прямо расширенная телеметрия, значит, на клиентах простых, где можно телеметрию встать и вставлять, что меня удивило, и прям так в каком-то смысле тоже, идею, которую я больше никогда не видел, опять же, наверное, потому что только Amazon может так сделать, они просто берут и где-то на Amazon, на институт Deployed Canary Applications, и эти Canary Applications входят и стучатся в разные, как бы, как это, они не стучатся в кастомерские базы данных, конечно, но я так понимаю, что они их так распределяют, чтобы, опять же, это в пейпере не написано, это из-за контекста, чтобы покрыть более-менее все availability zones, и они, имея вот по Canary, которые там для каждого availability zone, и которые ходят во все возможные опишки, оценивают общую доступность системы, тоже довольно интересная идея, которая применима только для DBAs, наверное, не только для Амазона, но вот если вы DBAs компания, вы можете так делать, в принципе. А почему это не работает для остальных? Ну в смысле, если ты не DBAs компания, ну как ты в он-премис сделаешь Canary application, в который, куда он вам примет, будет ходить, тебе нужно знать, где у тебя дата-центр. Ну то есть, идея в том, что тебе Canary нужно запустить там же, где у тебя, прям в той же availability zone, где у тебя там узлы твоей базы данных запущены, постучаться туда, ну, кстати, запущено, может быть, не обязательно быть в той же availability zone, но оно должно быть как бы для этой availability zone, плюс ты должен знать количество, ну то есть, чтобы сделать статистическую оценку, тебе нужно знать, где у тебя сколько чего запущено и какой процент всего ты увидел, там, грубо говоря, какие узлы ты, на самом деле, просэмплировал. Так, ну то есть, тебе нужно облако с обоих сторон видеть из стороны application и из стороны, где ты базу данных развернул. Ну, если ты делаешь систему, которая мониторит состояние твоей системы, то, как бы, конечно, она знает все это. Ну да, ну в смысле, что это, понимаешь, интересно, что это can replication, оно запускается так же, как запускаются другие клиенты сервиса, в том числе внешние, просто приложение на институтом или не знаю, может быть, не на институт, на elastic binstalk, где-нибудь еще, ну то есть, где-то просто вот в их облаке деплоится приложение, и оно ходит и как бы тыкает пальцами во все, что можно и проверяет, что вот, точнее, замеряет, где как, и из увиденного сэмпла пытается выстроить общую картину. Ну то есть, я просто такого подхода нигде раньше не видел и я подозреваю, что если вы не DBAAS, вам такое сложно сделать. И даже если вы DBAAS, вам может быть такое не совсем тревожно сделать, в зависимости от того, где вы запускаете. Это вообще сложно сделать, я согласен. Ну то есть, просто как это DBAAS, работающий поверх просто Амазона, наверное, ты можешь предположить, что если ты попросил, ну ты уже лабелитезон, а тебя скорее всего там поставили, но я не знаю, могут ли там всплыть какие-то подводные грабли с тем, что там как-то, не знаю, не совсем там где тебя захотел, тебя зашедулили и там, не знаю, у тебя какой-нибудь, ты думал, что ты в одно место идешь, что ты в другое место пришел, не знаю, может ли такое быть или нет. Не готов утверждать, наверное, должно быть легко решаемо, во всяком случае, в рамках Амазона. Ладно, едем дальше. Как они деплоются? Тут, в принципе, это опять же ничего, все равно уж, снокошибательного, но просто такой полный набор хороших практик. Во-первых, у них тестируются не только грейды, но и даунгрейды. На случай, если, то есть у них заведомо считается, что если мы какой-то софт катим в продакшн, есть хороший шанс, что нам придется его откатывать. И нам очень важно, что когда мы откатываемся, мы откатились в какое-то состояние, которое может продолжать работать, а не какое-то интересное состояние. Поэтому у них есть несколько уровней тестов того, как накатывается и откатывается. Там у них есть просто тест и плюс они потом накатывают какую-то временную систему, которая это все проверяет, и только потом уже накатывают на какой-то меньший объем, когда всем уже все нормально, они раскатывают на весь объем. Во-вторых, любые изменения, которые потенциально могут быть не обратно совместимыми, вначале раскатывается то, что, то есть грубо говоря, если придумали какой-то новый месседж, вначале раскатывается версия системы, которую не удивишь новым форматом сообщения, а потом уже раскатывается система, которая умеет его посылать, а потом уже раскатывается конфиг, что так можно начинать посылать. Из специфичного прямо для них это апдейты того, где есть MultiPaxos. Как мы выше потяку, что я упоминал, что есть ситуации, когда, то есть если у нас просто происходит перевыбор мастера, у нас он может какое-то время, там несколько секунд быть недоступен, потому что у нас там мастеру новому выбранному нужно подождать, пока закончится срок, на который выбрали предыдущего мастера, прежде чем он может начать что-то делать. И это обычно по довольно консервативной оценке делается, чтобы не дай бог ничего не нарушить. Здесь, поскольку мы знаем, что происходит в штатной ситуации, у них мастер вместо того, чтобы инициировать обычную процедуру перевыборов, он покидает свой пост, и новый мастер заходит в управление практически моментально, чтобы не терять в доступности. Это вот из таких интересных решений, которые специфичны для этой системы. Дальше начинается история про каши. Да, есть какие-то комментарии по поводу деплоя. Видимо нет, потому что ничего на самом деле действительно супер интересного не произошло. Дальше про каши и про метаданные. Я уже про это да, как бы вскользь упоминал в прошлых выпуски и в этот раз пару раз на это натыкался. Смысл такой, что когда они только начинали все это системы делать, у них просто каждый роутер запросов брал, высасывал себе, если он занимается роутингом кажем таблице А для юзера Саши, он возьмет и просто высадит все маршруты, которые могут быть, вот кто он обслуживает и просто локально кашировал. Если у нас произошла какая-то радикальная переменная или если у нас роутер новый добавили в строй, что кстати довольно часто бывает нужно делать, довольно штатная ситуация или если роутер там погиб и перезапустили, кашь исчезает и вот в некоторых-то ситуациях у них доходило до того, что нагрузка на тот сервис, который занимается, который является источником правды для этого каша, возрастала до 75%. Это на 75%. Это довольно ненормальная ситуация, вы не хотите в ней находиться. Это как раз у вас система бывает в двух состояниях или все хорошо или все очень плохо, когда все очень плохо, но может, если у вас есть такие вот радикальные перескоки в нагрузке, это может оказаться вторым стабильным состоянием, в котором вы не хотите находиться, но система там продолжает находиться, потому что она, к сожалению, стабильная в плохом смысле. Чтобы больше не попадать в такую ситуацию, они сделали так, что есть теперь отдельное распределенное in-memory-хранилище в кашовом методанно. Локальные каши, как я понимаю, все еще есть, просто каждый раз, когда в него кто-то обращается, даже если это был кашхит, все еще происходит запрос в эту распределенную реплицированную in-memory-базу, ну так скажем, просто на всякий случай, чтобы нагрузка всегда там была постоянная. Соответственно, во-первых, если у нас происходит перезапуск или что-то такое с узлом роутера, или мы добавляем новые, от этого не происходит какой-то резко дикого спайка нагрузки на эту in-memory-базу данных, она у них называется бесхитростная ММДБ. Во-вторых, если, ну и она все еще in-memory, она довольно быстрая, во-вторых, если в ней что-то происходит, опять же, получается, довольно отвязано от других каких-то ситуаций, с других каких-то проблем, обычно не сильно коррелировано, потому что, во-первых, она тоже реплицированная, есть откуда эти данные еще взять, во-вторых, есть все еще локальные каши на узлах. Из интересного, там используется нечто под названием Percol 3, это смесь Patrice 3 и Merkle 3, я кстати не знаю, что такое Patrice 3, нужно будет пойти почитать, но звучит довольно не так, я понимаю, что просто какое-то упорядочное дерево, которое позволяет искать по префиксам. И я подозреваю, что Merkle 3 там используется как раз для инвалидации каша. Источником, правда, все еще служит какая-то таблица внутри DynamoDB, но в нее теперь, как это, из нее теперь, обдейты в нее теперь активно пушатся в этот MemDB, и если в MemDB вдруг почему-то оказались stale данные, то когда оно дойдет до сторож узла, неправильно сработчий запрос, ему скажут, извините, вы куда-то не туда пришли, пожалуйста, обновите ваш каши. Вот, на этом все. Какие-то комментарии на секцию про каши? Нету комментариев на секцию про каши. Еще раз. Я бегло загуглил про Patrice 3, будто бы действительно какое-то префиксное дерево. Окей, большое спасибо. Еще раз такой завершающий, не знаю, summary, как это по-русски, блин, выжимка моих мыслей по этому поводу. Во-первых, интересная статья, если вы занимаетесь чем-то таким, в какой-то облачной компании работаете, даже не обязательно до баз, просто, в принципе, одна из немногих статей, которые рассматривают именно проблемы многотенантного облака, его роста, его эволюции, и в частности, проблема с DataSquare, она реально очень сложная, у Amazon заняла 6 лет, ну, как бы, да, реально сложная. И при этом DataSquare еще в разных вариациях бывает, они в одной конкретной вариации его бороли. Во-вторых, что в 2012 году, когда я был на хайпе, как саша выразился, плохой NoSQL, ну, или такой плохой, который становился хорошим, у Амазона уже была DynamoDB, которая уже была более консистентна, чем большинство NoSQL этого времени. В-третьих, мой личный любимый вывод, что в больших системах и вообще в любых системах, может, скорее всего, стоит приоритизировать однообразность и предсказуемость вместо сурового перфоманса. И здесь эта история подкрепляется больше, чем одним, на самом деле, историей. Вот эта история про кэш — это одна из ситуаций. Вторая из ситуаций, на самом деле, если мы посмотрим, у них очень многие системы, они самостоятельные, распределенные, возможно, распределенные по другому принципу, чем основная система, подсистема, микросервисы. И каждый, как бы, такой избыточный, независимый, отдельно, так сказать, люди плывется, занимается своей задачей, и баз данных перестает быть таким гомогенным монолитом внутри, остановится такой, не знаю, продуктом работы, совместной работы нескольких сервисов. И такие отдельные идеи, которые я не могу под каким-то сонтиком объединить — это лог-реплики, очень изящное решение, на мой взгляд, и кэнри-приложение для того, чтобы оценить доступность вашего сервиса. Тоже, мне кажется, прикольная тема. Вот, я все. Мне, в принципе, понравилось довольно свежий такой, типа, пейпер, который, да, рассматривал вопросы, про которые обычно мало кто говорит. Обычно где-нибудь, может быть, в блогах или подкастах немножко побубнят. В подкастах. Я хочу сказать, Валер, ты большой молодец, что принес нам пейпер и так подробно его пересказал, хоть и выброшенное, но на час. Это серьезная тема. Это не за что. Был рад принести. Надеюсь, я тут, в пресс-шоу, обсуждал, что у меня бывает, вроде целый бэк-лот пейперов, нужно к нему, наверное, по-другому начать относиться. Нужно просто не все подряд, что из заголовок зацепил, начать читать, а просто брать и вот к тому, чему душа лежит, читать, а все столь ну просто выбрасывать. Потому что, вот скажу честно, вот мне уже Джепсон немножко надоел. Ваня, давай ты его будешь читать. Ну давай. Или не знаю, у меня еще был вариант, если нас кто-то слушает из тех, кто не знает, ребята из репанда к нам приходили, не знаю, слушать вас или нет, но если вы готовы прийти и обсудить вот Джепсон, может вы просто прийдете, вы нам про него расскажете, это будет даже интересно, типа Джепсон с пострадавшими. Вот. Как-то так. Я бы с удовольствием по такому поучаствовал, но вот прям просто читать Джепсон от начала до конца мне уже просто тяжело. Я их слишком много за 8 лет прочитал. Не, я считаю не надо себя заставлять читать то, что нравится всех пейперов, то все равно, ну ни при каких условиях не прочитаешь. Так что. Спасибо что принес, на самом деле очень полезно читать пейперы про системы, с которыми ты сам напрямую работаешь, чтобы лучше их понимать и лучше понимать, как их можно создавать. И да, это клево. Вот было бы хорошо, если бы все системы, которые мы используем в продакшене, все они были с какими-то пейперами. И мало того, что оригинальный пейпер, еще пейпер, потому как бы, как изменилось наше видение, что мы поменяли в системе, почему мы это поменяли, это все очень полезно бывает. Да, это был практически уникальный в этом плане пейпер. Обычно, вы узнаете, большинство пейперов в такой средств состоянии системы. В лучшем случае ты по родной системе выпускаешь там 2-3 пейперы в разное время, и есть шанс посмотреть на какое-то развитие системы, но очень редко так, что у тебя прям в одном пейпере эволюция чего-то рассматривается. Это прям на мой память просто уникальный случай. Я залинковал пару выжимок, если вам не хочется читать пейпер, но вам интересно такой, другие обзоры, которые не я делал посмотреть. Я залинковал еще 2 блога. Я считаю, мы очень продуктивно обсудили эту тему. Спасибо большое еще раз о нее. На этом наши темы на сегодня иссякли, и мы переходим к темам и вопросам слушателей. Как обычно, лучшее в начале. И, да, я извиняюсь, мне уже сложно говорить, у меня час ночи. Но я постараюсь. Первую самую нагласованную тему принес Кайрат Сатрапов. И Кайрат интересуется, как мы относимся к практике проведения ретроспектив по итогам спринта. Могут ли ведущие поделиться собственными историями про самое безупречно проведенное ретро? Ну и также про самое унылое. Я могу начать. У меня в целом довольно смешанные чувства. С одной стороны, по субъективному опыту, в 90%, может быть, 70% случаев ретроспективы достаточно... Постоят рады достаточно большого количества времени. Но иногда, иногда очень редко, в ходе их удается узнать что-то полезное, что можно изменить в процессах. Все еще есть смешанные чувства. На этот счет не уверен, что оно стоит стабильного выложения команды разработчиков своего времени на регулярной основе. Но я в этом подкасте далеко не project manager или не скрам-мастер. В общем, никто так не проводит ретроспективы. Поэтому наверняка у них есть какой-то тайный смысл. Ну типа, не знаю, психологически людям важно собираться вместе и поплакаться о том, как тяжелая их жизнь. У меня на это... Извините, что я прямо отбираю слово. У меня на это такой тоже смешанный взгляд. Я не буду делиться прям историями, потому что, ну не знаю, за моей жизнью было столько ретроспектив, что я, наверное, не помню каждую отдельную, они все для меня как-то в какой-то общего поцелелись. Тут, как в любом... Вот Саша обычно любит говорить про инструменты в программировании, что инструмент сам по себе не виноват. Ретроспектива — это инструмент. Но его важно правильно приложить. Чтобы ретроспектива работала, вам нужно две заинтересованных стороны. С одной стороны, как бы команда, над которой производится ретроспектива, она должна быть в этом заинтересована. У них должно быть что-то наболевшее, они должны к ней туда вообще приходить, подготовленными. А не так, что, ну я тут час придумаю, высосываю из пальца, проблемы потому что меня заставили. Я, в частности, обычно вот между ретроспективами, у меня есть черная тетрадка, в которой я записываю вещи для one-one и вещи для ретроспективы. Она черная, там не обязательно плохие вещи, но там могут быть хорошие, но просто в принципе, когда я произвожу какое-то наблюдение, проработал день, у меня там случилась или приятная эмоция, или негативная эмоция, я ее записал потом, если я ее вот рефлексировал. И у меня есть просто прометки, что вот это на one-one принести, а вот это принести на ретроспективу. Во-вторых, те, кто обязуется взять на себя какие-то действия по итогам ретроспективы, это могут быть какие-то другие люди в команде, это могут быть ваш менеджер, это могут быть кто-то, не знаю, выше по званию, вообще там над вашей командой стоящие, они должны, во-первых, фиксировать свои обещания, а во-вторых, нужно посмотреть, как бы выполняются ли они. Если они не выполняются, то, в принципе, весь ритуал действительно абсолютно бессмысленный. Если обещания и действия какие-то выполняются и совершаются, то поздравляю, у вас как бы на самом деле есть прогресс. Даже если вам какой-то момент оказался скучным и потраченным в пустую, глобально вы совершили прогресс. Я могу по-тоже рассказать про свой опыт с ретроспективами. На самом деле, я согласна с Валерой, это инструмент, и не всегда это правильный инструмент. Иногда это хороший инструмент, который работает для вашей команды. Ретроспективы не обязательно проводятся в конце спринта. Ретроспективы проводятся часто, я видела, когда что-то пошло, например, не так в процессе найма. Там ретроспектива, почему что-то сломалось. Я даже видела ретроспективу как часть пасмортома, когда люди собираются и проводят ретро, то есть митинг в формате ретроспективы как пасмортом, что довольно необычно, но очень интересно это видеть. То есть, опять же, это инструмент, и это не только про спринты. Дальше ретроспективы, у меня в целом к ним такое нейтральное отношение. Опять же, это инструмент, и его использовать нужно в тех ситуациях, когда, допустим, как я это делала, как новый менеджер, я прихожу, например, в команду, я вижу, команда как-то работает, и я новый человек в команде, я вижу проблемы, и вариант первый, я начинаю просто брать вместе процессы, и у меня есть шанс, что я сделаю какую-то, ну, поменяю штат, что на самом деле не является проблемой, или я не все хорошо понимаю, почему какая-то ситуация, ну, то есть, почему команда ведет себя таким образом. И для меня этот инструмент очень классно делать, когда я вижу проблемы уже, я могу использовать ретроспективу как способ об этом поговорить со всеми людьми из команды одновременно, и мне скажут, да, мы все видим проблемы, у нас куча митингов. Я такая, круто, замечательно, давайте мы такую штуку поменяем, либо что-то уберем половину митингов. То есть, ретроспектива как инструмент, чтобы изменить что-то в команде, и при этом, чтобы все люди понимали, почему мы что-то меняем. Такой способ всех на одну страницу поставить, get on the same page. Вот, поэтому это раз. Два ретроспектива еще я видела использоваться как такой способ людей вообще узнать друг друга. Например, в компании одной, в которой я работала, в ретроспективе один вопрос был, то есть, например, что пошло круто, что пошло не очень круто, и рандомный вопрос про, не знаю, если бы вы писали автобиографию, как бы вы ее назвали, то есть, или там, не знаю, какая ваша любимая, не знаю, или там, еда, которую вы ненавидели в детстве, сейчас вам нравится. То есть, такие штуки, которые помогают команде лучше узнать друг друга, и оно становится, ну, веселее с другой стороны. Вот, я такие ретроспективы тоже видела. Дальше есть классный инструмент для проведения ретроспектив. Я очень-очень рекомендую Team Retro, очень классный тул, и, наверное, лучший инструмент, которым я пользовалась, потому что вам, вы можете, ну, вы можете, оно похоже на трэла в каком-то смысле. Люди могут свои карточки добавлять, что они понравилось, потом они автоматически группируются, вы можете их перегруппировать, вы голосуете за что вы хотите сделать, из этих голосов вы, они отсортируются сразу же, вы поговорите, вы сделаете там какие-то конкретные, там, эти action items, назначите людей, которые за это отвечают, назначите дату, которая должна быть сделана. Прям такой инструмент всё в одном, это суперудобно использовать. Я очень рекомендую этот инструмент. Вот, и ретроспективы, наверное, последнее, что я могу добавить, это постарайтесь менять формат, потому что я видела, когда ретроспектив остановилась просто рутиной и одинаковый формат, что пошло хорошо, что пошло плохо, каждый спринт каждые две недели, и люди перестают использовать этот инструмент как что-то, что работает. И я видела ретроспективы, которые формат из разряда, то есть мы не пытаемся всё обсудить по максимуму, нет, мы выбираем одну большую тему, и вот мы говорим ему на эту тему, и мы прямо придумываем, как это пофиксить, и договариваемся, что мы прям меняем серьёзно наш процесс. Вот, наверное, я молчу и дам больше слов на Ване. Я на секундочку вклиниваюсь, ты пока говорила, мне напомнилось, напомнило про смену формата в одной компании, это было очень давно, ещё когда люди работали в офисах, а у нас Project Manager, которая также проводила ретроспективы в той компании, на одно из ретро принесла кубики Lego, и мы всей командой из кубиков Lego собирали всякое, а потом это описывали, то есть вот это проект, вот у него так получилось, что у него три колеса, четвёртый мы наделать не успели, поэтому он вот типа заваливается, вот и нам очень важно доделать это колесо, ну какие-то такие аналоги получались, достаточно забавно, мне запомнилось, по крайней мере. Я присоединяюсь ко всему, что сказали до меня, я хотел бы добавить, что здесь в опроте не уточняется, и все в основном рассказывали про этот инструмент, как применение к командной работе, но ведь он возможен для применения к индивидуальной работе, к самому себе, скажем, если вы будете ставить себе какие-то",
    "result": {
      "query": "point in time recovery DynamoDB tables"
    }
  }
]
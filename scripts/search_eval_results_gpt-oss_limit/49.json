[
  {
    "segment_id": "90d113ad-4c04-4bcf-8ad2-955d61028d39",
    "episode_id": "1f325aa8-3fc7-4156-b8b1-84550827c6b4",
    "episode_number": 49,
    "segment_number": 4,
    "text": "Например, нам было неудобно делать недельные спринты, конкретно нам, это значит в нашей команде, с которой я сейчас работаю, потому что недели это долго. То есть, наши внутренние заказчики не могут ждать неделю, когда мы что-то сделаем. Тут возникла другая проблема, что программисты очень не любят, когда его постоянно дергают. То есть, вот он сел, он загрузил себе в мозг нужный ему код, и он начинает его потихоньку или фиксить, или писать и так далее. То есть, дергать программистов это очень-очень плохо. Поэтому программисты вышли и сказали, слушайте, ну мы все понимаем, но так не пойдет. Если вы к нам будете каждый 10 минут бегать и дергать нас, так не нужно делать. Мы вас начнем ненавидеть просто тихо. И поэтому сказали, окей, давайте сделаем по-другому. Давайте если, ну у нас есть список приоритетов, есть специальный человек, Product Owner, который постоянно занимается только этим списком приоритетов, и вообще со всеми внутренними заказчиками общается он. То есть, к нему приходят люди, говорят что как, к нему приходят программисты, которые говорят, слушай, у нас тут Technical Debt накопился, нам тут нужно кое-что перефакторить и так далее. Он собирает все в готовый список приоритетов, а программисты разбирают этот список в соответствии с тем, кому чего нравится. И когда программист задачу взял, его трогать нельзя. То есть, если он за нее сел, пожалуйста, не трогай его. Не вырывай его из контекста. Единственное пожелание, которое возникло у нашего Product Owner, что давайте бить все-таки на не очень большие задачи, где-то там до 3-4 дней. И это довольно сильно нам помогло. Мы меняли процесс довольно много раз. Это, наверное, уже третья его редакция. Потому что один раз было вообще смешно. У нас был нормальный процесс, у нас была Jira, мы смотрим на задачи, ну окей, вроде все понятно. Очень важно, чтобы все знали, кому что делать надо. Для этого лог приоритетов, единственный бэклог, он нужен. Но тут возник казус, потому что Jira так показывает, что задача сделана, она ее вычеркивает. Типа, все, готово. И мы посмотрели на некоторые задачи, о, ну что, все готово, давайте это все заливаем в продакшн и так далее. И тут выяснилось, что Jira показывает, что все готово, но она показывает, что все готово для всех вариантов. Даже что QA еще не видел, но она уже все равно показывает, что задача готова. В результате у нас там пару раз, мы слишком рано отправили, сделали релиз и решили, давайте сделаем более прозрачно, давайте перехачем в арду и сделаем так, чтобы состояния были видны более четко, чтобы было понятно, что нет, вот это еще не релизнули, это еще не протестировали и так далее. И после всех наших правок процесса, с участием всех заинтересованных сторон, то есть это внутренние заказчики, это программисты, и это отчасти менеджмент, да, вот сейчас та версия, которая есть, она удобна. И производительность повысилась, и программистам меньше мозг трогают. В общем, как все довольны, значит все нормально. Какое-то время хватает. Я думаю, что это опять же будет меняться, когда придет больше людей. Сейчас у нас команда не очень большая, где-то человек 10. Как только это изменится, будет больше людей, или будут какие-то другие типы задач, нужно будет опять пересматривать эту штуку. Про короткие спринты хотелось бы добавить, что у нас перешли к недельным после соображений, что когда у тебя спринт 2 недели, бывает так, что, например, клиентская команда решает, что они будут делать эту фичу, но после того, как эту фичу сделает бэкэнд, а бэкэнд ее должен делать в течение спринта, и бывает так, что, например, у бэкэнда возникли какие-то проблемы, и в результате фичу они выкосили на полторы недели, какой получается, типа седьмой день рабочий, и у клиента почти не остается времени. И вот чисто чтобы не было такого, что в течение спринта есть какие-то зависимости, были введены недельные, и такое правило, что никто не делает то, нет такого, что кто-то от кого-то зависит в течение спринта. Да, у нас была тоже похожая штука, поскольку у нас два офиса, один в Киеве, другой в Сан-Франциско, и как только начали увеличивать больше инженеров в офисе в Сан-Франциско, то начались задержки, поскольку разница почти 10 часов, и ты пишешь человеку вопрос, или наоборот, тебе откуда пишут вопрос, а ответ будет на следующий день, и вот тоже была проблема, то есть срочно пришлось менять структуру, чтобы команды меньше зависели друг от друга. Поэтому, кстати, до этого у нас были более чистые фронт-энд и бэкэнд команды, но мы начали их в результате, сейчас движемся все-таки к фулл-стэку, потому что неудобно, если фронт-энд далеко, то пока с ними скоммуницируешься. В такой ситуации, когда у тебя несколько команд, и люди из одной команды есть и в одной стране, и в другой стране, это плохо работает, я по себе знаю, очень неудобно. Даже если у вас примерно совпадают часовые пояса, эта коммуникация берет много сил, энергии, и вообще намного проще подойти к соседней столу, спросить чего-то, нежели по скайпу говорить, спрашивать и договариваться. Я плясаю, даже если одна команда, и она просто распределенная, например, бэкэнд пилит половину людей в Москве, половину в Питере, это уже большая проблема, хотя и временная зона, одна и та же, и так далее. Просто реально удобнее намного подходить и говорить, я очень рад, что у нас в текущей команде нет такой проблемы. Кстати, Стас, а ты в котором из офисов, если не секрет? Не секрет, сейчас я с января в Сан-Франциско. Я там буду через две недели, может, пересечемся. Давай, с удовольствием. Вообще у нас последние шесть лет разработка все время идет с участием команды через, там сколько, 10-11 часов в Штатах. И это реально головная боль. То есть очень большое количество микровещей есть, которые не замечаешь, не думаешь, что они существуют, когда команда все вместе в одном помещении сидит. Но постоянно возникают какие-то дополнительные проблемы, и на самом деле очень тяжело. Знаешь, как мы эту задачу решали? И когда возникает вопрос, когда несколько людей в Минске, несколько людей в Виннисе сидят, я говорю про свой проект, и решили сделать таким образом. У нас спринты были по две недели, и вот в конце спринта мы собираемся все вместе. Сначала минская часть едет в Виннис, потом Виннис едет в Минск. Мы там собираемся на ретро, обсуждаем, делаем техническое планирование, всякие вопросы решаем. И это дало очень хороший результат. Это очень круто. Это стало очень заметно после какого-то второго раза, когда мы собрались и просто стали намного больше общаться. Нет такого, знаешь, ну вот я лучше напишу в Скайп, либо как-нибудь сам решу вопрос, вместо того, чтобы взять и позвонить просто человеку. Просто берешь и звонишь человеку в Скайп, и у тебя как-то снимаются куча этих барьеров, и ты намного эффективнее работаешь. Да, да, у тебя этот человек, это не иконка в Скайпе, и не имя какое-то в e-mail, а это фактически визуальный образ, ты себе точно понимаешь, что это за человек, что у него там стоит, какой характер, как ему надо спросить. То есть это намного проще становится. Я предлагаю Стасу это посоветовать, ну, себя в компании в Граммарле, что просто нужно из Киева летать в Сан-Франциско, Жахара, Звенецфиля. Нам тоже посоветовать, это вообще чудесно. Или, кстати, у вас спринты недельные, значит, раз в неделю в Сан-Франциско и обратно. У вас здесь, конечно, специфика своя, то есть там не налетаешь, а у нас два с половиной часа, и на поезде, и все, ты на месте. То есть у нас это хорошо решается. А вам, я не знаю, наверное, все-таки придется какую-то команду, чтобы она становилась командой, билдить команду, тимминг. Мы уже обсуждали варианты, что надо из двух точек слетаться посередине куда-нибудь. Или в Исландию. В океане где-нибудь. Ну, там вот где-то в районе Исландии, или там, не знаю, что там посередине еще получается. Гринландия, вы можете. Ну, Гринландия все-таки к ним ближе. От нас подойдешь. В океане. Прям посередине. Да, да, да. Ну и Китай, кстати, тоже где-то там. Тоже неплохо, да. Ну, ездить вообще очень важно, даже не с этой точки зрения, а просто иногда возникает очень... Вот странно, когда я работал в киевском офисе в прошлом году, ты все равно начинаешь другой офис как-то странно воспринимать. То есть ты, поскольку, ну, не видишь, постоянно не общаешься, ты думаешь, да чего они там вообще делают? Вот. Да? Обращали внимание. Абсолютно. Вот ты верно сказала, что они там делают, почему так долго. И они думают то же самое про нас. Вот чем они занимаются, почему так долго, что они так долго делают. Такая же простая задача. Почему вы не можете это раньше решить? И это... Такие вещи, это проблема. Огромная проблема. У нас было еще веселее, потому что у нас весь менеджмент в основном сидел здесь, а там сидели программисты. И программисты думают, блин, да что там в жизни менеджеры? Как бы, ну, что они знают о нашей жизни, о нашей доле тяжелой? А менеджеры думают, блин, что там вообще происходит? Ну, что они там вообще работают? Другая проблема, когда у тебя половина команды, то есть в одном оффисе, а половина в другом. И, не знаю, начинаются какие-то обидки друг на друга, что вот там ребята совещались и без меня чего-то решили. Давайте сейчас позвонимся по скайпу, все перерешим с нуля. Вот такого рода вещи. Это очень неприятно. С другой стороны, у меня сейчас была неделя такая, что вся команда уехала в отпуска. Я осталась одна. У нас всего три человека. И в комнате сидит четыре человека. До этого было несколько студентов. Студентов выпустили, они ушли. Один человек ушел работать из дома, двое ушли в отпуск. Я осталась вообще в офисе одна. У меня точно такая же. У меня такие студенты. У меня такая же. Вы что с ними делаете? В их батареях, что ли, притягиваете? Паспорта вернули. У нас есть академия, и они три месяца учились в академии и их выпустили. То есть они научились и теперь, скажем, закончили свое обучение здесь. Ну, типа стажировки, можно так выразиться. У меня была похожая ситуация. Коллеги ушли. Один в отпуск, второй заболел. И я сидел один на проекте. Знаешь, а я сижу одна в этой комнате. И, как ты понимаешь, работать очень тяжело. Но это одна проблема. Вторая проблема, что нужно решать всякие вопросы технические. И хочется с кем-то посоветоваться, хочется кому-то отправить на ревью. И была ситуация, когда я себе ревью назначила. Ну, то есть, ну, как-то привычно пишешь все в ветке, потом нужно ветку мержить. Ну, в мерже ты осанишься, кого ревью, осанишься на себя. Ну, не знаю. Я лично кайфовал. Я весь проект переписал, как надо. Коллеги вернулись, вообще ничего не узнали. Ну, у них и правда ощущение было. На этой неделе как-то... Вот проблема в том, что есть технические вопросы. И куда идти, кому их задавать? Просто ты можешь подойти, в принципе, к любому человеку из другой команды. Но попробуй его сначала введи в курс дела, что ты тут хочешь. И это очень, не знаю, тяжело. Удивительно, но это было тяжело. Следующий теме, может? Давайте. Что еще тяжело? Дайте я немножко доскажу. Ну, то есть, буквально у меня тут пару пунктов еще записанных, важных. По плану оптимального процесса. Ну, то есть, довольно очевидно, что процесс должен быть чем-то обусловленным. То, что его должны делать не наверху, и не где-то там, а его непосредственные участники, чтобы интересы всех были учтены. Но есть еще пара моментов. Один очень важный момент. Процесс очень легко саботировать, за исключением случаев, когда он автоматизирован. То есть, если хочется, чтобы он был... Во-первых, занимал меньше ручного времени, вообще, в overhead. Во-вторых, чтобы он более-менее следовал. Если он будет использоваться, то лучше, конечно, его максимально автоматизировать. Если нельзя, например, коммитить в мастер, то пусть будет hook. Если нужны тесты, то пусть там посчитается coverage кода, и пусть там начнется какой-то крик. То есть, чем больше он автоматизирован, тем он приятнее, и тем больше вероятность, что он будет работать. И еще один момент, что процесс, в общем-то, должен быть поддержан со стороны руководства. А руководство, оно вообще очень важно в плане задавания тона и атмосферы. И оно тоже должно понимать, что это хорошо, что он правильный, что нужно тратить на это время, что, возможно, нужны тренинги какие-то и так далее. Поддержка руководства обычно очень важна. Как-то так. Да, и еще я могу добавить по поводу процессов. Я до вечера разговаривала с человеком из такой компании EEPAM. Наверняка все слышат. И у них есть такая процедура, называется асессмент, когда человек проходит некоторые этапы, ему дают новый тайтл, и, может, какие-то еще плюшки. И, собственно, чтобы пройти этот асессмент, человеку нужно прочитать там просто ту-и-ву-хучу всякой документации, касающейся проектов. Как вот именно по организации, по процессам. И на мой взгляд, довольно странно, что вот эти вопросы будут спрашивать на этом асессменте, например, у девелопера. И мне кажется, что это на самом деле излишне. И когда я это все слышала, мне было странно это слышать. И я вообще не понимаю, зачем вот эти вещи вот так досконально изучать, все вот эти понятия. Может быть, там, специфика дела. Не знаю, для меня это непонятно. Я считаю, что это излишне. Что вы думаете об этом поводу? Ну, я считаю, что если что-то именно непонятно, то здесь, может быть, это действительно какой-то рудимент остался. Потому что тут так заведено, как в анекдоте. А может быть, просто не хватает информации. То есть, если что-то вот именно не так, то лучше всего сразу прийти и начать разбираться, почему все вот именно так. Может быть, это будет как раз повод, что что-то нужно поменять. Может быть, это будет как раз последний голос в большом количестве голосов, которые кричат, давайте уже менять. И наберется достаточно фидбэка. Тут трудно сказать, не зная всего контекста. Ну что, мы тем временем переходим к новой теме? Все так. А, ну перед этим хочу напомнить про спонсора. И вторым спонсором у нас является компания MachineZone. Она известна своей игрой Game 4. Это топ-1 гроссинг в США. Сейчас она активно развивается в России и ждет свою команду разработчиков, пишущих на Erlang и Python. Ключевые слова, по которым вы можете отнайти Erlang, Python, Distributed Applications, REST API, Docker, Linux, Vgrunt, Ansible, Continuous Delivery, Code Review. Если вы готовы к релокации в Ульяновск или Новосибирск, а также к пиатистским командировкам в Silicon Valley, заходите на machinezone.ru или пишите нам на jobs.machinezone.ru Нам, не нам, им. Так, Валера, что ты хотел нам рассказать? Ну да, как возможно некоторые заметили, меня не было в прошлом выпуске. Куда же подевался? Ответ на этот вопрос прост. У нас вначале был корпоратив, потом у меня был самолет в Прагу. Что я забыл в Праге? Там была довольно занятная конференция под названием Корион. Что за конференция такая? Ну, в общем, формально это подразделение более крупной научной конференции European Conference on Object-Oriented Programming Languages. Или как-то так. Короче, Корион, он не проект ориентированный, у него слоган «давайте позволим индустрии и академии поболтать». И, собственно, что в ней такого примечательного просто в конференции? Вот прям в конференции. Я про доклады потом чуть позже поговорю. Во-первых, спикеры. Там некоторые спикеры были, я дальше буду проходиться по темам, там, в общем-то, вплоть до очень известных личностей. Во-вторых, действительно присутствие докладов на одной конференции и в одной аудитории зачастую людей из академии и индустрии. И что самое главное, была такая тема, называлась час-ток, час-тамер-ток. Это когда действует натурально на шахматные часы, у докладчика есть 20 минут его времени, 20 минут времени аудитории. И переключение происходит в любой момент. То есть, когда аудитория хочет развести дискуссию, таймер перешелкивают, и время забирается у аудитории, а не у докладчика. Это, с одной стороны, очень интересно. Конечно, пара докладчиков, у которых получилась тока, им, короче, в итоге ток немножко испортили относительно того, что они готовили. Но, с другой стороны, те, которые получились, получились интересные, и дискуссии все равно в любом случае интересные очень. Ну и, наконец, после первого дня конференции там была пати. Я на ней выловил Криса Майклджона и подопытывался у него про CRDT, всякое такое, точнее, про какие детали имплементации вложенных в CRDT. Такие дела. Ну, если это кому-то интересно, могу пройтись, в общем-то, по докладам, которые там были. Вообще там была запись видео, я так понимаю, доклады будут вообще доступны. Кому-нибудь интересно пройтись по докладам? Конечно, конечно. Хотите бы вкратце сказать самое интересное, что там было? Куда обратить внимание? Слушай, я не могу сказать за все, потому что там было два трека. Я пройдусь по тому, где был я, и там, где я не был, ну, извиняйте, посмотрите на сайт. Может быть, вам будет интересно, когда доклад выложат в видео, я обязательно сообщу дополнительно. Собственно, открывал конференцию к кинотам господина Глайдбрача из Гугла. Доклад назывался Programs wanted dead or alive и затирал он про довольно странную штуку, мол, вот есть мертвые программы, которые написаны на статических типизированных языках, в редакторе скомпилированы и работают, и есть живые программы, которые а-ля Smalltalk Environment или Lisp Environment, которые, короче, можно хачать прямо пока они там летят. И, короче, вообще сплошно репл и, короче, вот, очень они живые. И как бы нам так типа совместить плюсы обоих, и все такое? Ну, короче, довольно мутный доклад, который, ну, как это, он вроде как задает какую-то такую вот тему, с другой стороны, он совершенно ни о чем не был. То есть, ну, ничего конкретного там особо предложено не было. Дальше я пошел на Андрея Бреслова из JetBrains. И он рассказывал про то, как они боролись со всякими сложностями при реализации Kotlin. Мне доклад показался интересным. И я бы его рекомендовал, потому что он рассказывал не столько про язык, сколько про то, как они воевали за то, чтобы его сделать. Ну, там, воевали со сложностями. Дальше я пошел на Рональда Куна из TypeSafe. Доклад назывался Archetyped Between Session Types and Doctor Model. Тут нужно сделать заметку о том, что такое Session Types. Это такая странная абстракция, которая есть в языке под названием Scribble. В общем, идея в том, что у вас описывается не тип чего-то одного, а как бы есть сессия какого-то протокола, и она описывается целиком. Ну, то есть, в типе очередного сообщения есть тип ответа, который на него ожидается. И Рональд Кун немножко показал, как сейчас выглядят Type Attackers, из которых в итоге нафиг выпилили сендер. И поскольку сендера нет, то в сообщении оказался тип того, кому нужно вернуть значение. Поскольку там тип того, кому нужно вернуть значение, то там получается по сути Session Types. Они, конечно, не инфорсятся глобально. Есть такая тема Global Session Types, когда можно заранее писать всю раскладку актеров, которая вообще будет заставить Type Checker проверить, реализует ли наша система актеров протокол. Но там есть свои ограничения. Global Session Types не работают с динамически создаваемыми актерами. Ну, короче, в целом, довольно интересный был доклад. Это был один из частолков. И как раз в какой-то момент Рональд Кун начал просто общаться с аудиторией, в которой сидел Филипп Вадлер. И довольно интересное у них обсуждение получилось. Дальше я пошел на Марка Шапира с докладом Encapsulating Replication, Hyping Currency, and Consistency of CRDT. Меня доклад разочаровал. То есть доклад был офигенный. Но меня он разочаровал, потому что я такой пошел на него и думаю, ага, сейчас мне господин Шапир, это один из авторов статьи про CRDT изначально, расскажет, короче, все, что я не знаю про CRDT. А он про них рассказал все, что я уже и так знаю. Поэтому я разочарован был немного. Поэтому я потом пошел ловить крысы у Миклоджана. Дальше я пошел на био-нотицера из Гугла, который рассказывал про эволюцию V8. Но что-то меня выключало. Я пока был в Праге, я был больны, потому что я как дурак умудрился в плюс 37 на улице заработать насморк и больное горло. Поэтому я был в каком-то таком пролапсе, не особо слушал. Доклад был дико унылый. То есть там вроде рассказывали про какую-то техническую мякотку в какой-то момент. Но к тому времени, когда докладчик добрался до технической мякотки, он успел усыпить аудиторию. Поэтому я его рекомендовать не могу. Но вдруг если вы сможете дожить до технической мякотки или просто проскипать видео, может быть там будет интересно. Дальше я пошел на доклад It Probably Works Тайлера Макмулина. Это сетево небезызвестной CDN Fastly. И это был один из крутейших докладов, потому что Тайлер рассказывал про всякие пробиблистические, ну, вероятностные алгоритмы. Как то HyperLockLock, например, который позволяет, ну, если кто не знает, есть такая задача оценить мощность множества. Ну и проблема в том, что если у вас там очень-очень много данных, например, то чтобы оценить мощность множества, нужно построить множество полностью. Если данных очень много, то возможно оно не влазит в одну машину. Есть такая вероятность, что структура данных называется HyperLockLock. Она при помощи, я не буду описывать в подкасте, она неплохо описана в интернете, можете пойти посмотреть. Но в целом идея такая, что при помощи этой структуры можно получить с какой-то ограниченной ошибкой примерно число элементов в множестве. Что самое главное, его можно распилить по разным машинам и потом сделать юнион. И, в общем-то, это будет не целиком множество гонять между машинами, а опять-таки эту маленькую структуру. Потом он рассказывал про броадкаст, который они используют в FAST для того, чтобы валидировать кэши. Там тоже какой-то такой, по-моему, bmodel broadcast, не помню, кто автор статьи, но тоже идея в том, что простая как тапок штука, которая за какое-то количество шагов с такой-то вероятностью сходится при таком-то уровне потери в сети. Вероятность алгоритма – это сила. И одна из главных идей этого доклада – это не то, что вероятность алгоритма – это «а, хай, вдруг оно, наверное, заработает, и хрен с ним, колхоз-колхоз». Идея в том, что все эти алгоритмы имеют в частности такую штуку, как ограничение ошибки. То есть, задав параметры этого алгоритма, можно понять, с какой вероятностью у нас будет все хорошо и с какой вероятностью будет плохо. Или в случае этого алгоритма с броадкастом, сколько еще раундов броадкаста потребуется, чтобы при еще больших потерях сообщений в сети сойтись. Дальше я пошел на Тони Принтезиса из Твиттера. Это был еще один унылый доклад, потому что я ожидал, что они расскажут, как они жаву у себя насилуют, а они рассказали про то, что у них есть Твиттер GDK, который Fork Open GDK. Ничего суперинтересного из этого я не узнал. Дальше я пошел на небезызвестную Бодил Стокки, которая рассказывала про пост-FRP фронт-энд программинг на поняшах. Ее слайды уже доступны, можете на это сами посмотреть. Я не знаю, как это в двух словах передать. Нас просто знакомили с FRP и тем, что последовало после него, чтобы удобно писать фронт-энд в вебе. В целом довольно интересно. Бодил обычно зажигает, поэтому можно посмотреть. И последний доклад в тот день был закрывающий кенот от автора в Julia. Это тот язык, который про numerical computation. Если вы не интересуетесь numerical computation, вам, скорее всего, этот доклад не интересен. Ребята рассказывали, как они боролись со специфичными проблемами при разработке языка для numerical computation, который называется Julia. Сам по себе язык, наверное, интересный, но конкретно этот доклад, я бы не сказал, что он такой широкой аудитории был бы интересен. Второй день открывал Брэндон Эйк. Это, если кто не знает, человек, который разработал JavaScript. Он рассказывал про JavaScript, что за это время произошло, что изменилось. И что меня очень порадовало, вы, наверное, знаете эту смешную презентацию, которая называется WET. Брэндон Эйк ее показывает на своих докладах. И он, в частности, очень неплохо осветил историю, которая привела к появлению такой создамени, как JavaScript. Самое главное, что для себя вынесли с доклада, они сейчас работают над такой штукой, которая называется WebAssembly. JavaScript уже используется как такой ассемблер для веба. И они сейчас в итоге к тому и ведут, что они просто выкинут весь синтаксис оттуда и будет просто ассемблер. Который можно будет компилировать из JavaScript. И виртуальные машины будут реализовать это в WebAssembly, JavaScript. И все остальное будет просто компилировать в WebAssembly вместо JavaScript. Потом я пошел на Клиффа Клика. Это, если кто не знает, человек, который очень многие годы работал в Oracle, пилил JVM. Доклад назывался Bits of Advice for Virtual Machine Writers. Я почему-то подумал, что это будет интересный доклад. Я был прав. Но есть одно но. Клифф Клик выдавал такое количество информации с такой скоростью и, полагаю, такой уровень знаний в реализации виртуальных машин, что я немножко прифигел. То есть, когда доклад появится на видео, я, наверное, раза три его пересмотрю еще, чтобы до меня дошло хотя бы половина того, о чем он говорил. Потому что до меня дошло, наверное, где-то треть сейчас. Это тот случай, когда человек кидается в вас аббревиатурами, которые специфичны для этой предметной области. Просто потому, что ему некогда вдаваться в детали. Потому что у него и так времени не хватает, доклад большой и вот это все. Но в целом все очень интересно. Дальше я пошел на Тома Сарца, который рассказывал про то, как они кликчек прикладывают к разным местам. В частности, к верификации автомобилей, точнее кода автомобилей. Но вообще в целом доклад был не столько про сам кликчек, не столько про эти подходы. Он очень во многом был про то, как довести вашу идею, которая у вас появилась в академии где-то, как конкретно они проходили путь продуктизации, какие ошибки они делали. Как в итоге заставить вашу прикольную идею продаться какой-то компании. Чтобы ее кто-то использовал и еще бы вам за это деньги отваливал. Казалось бы, при чем тут кликчек? Ну да. Короче, я доклад рекомендую всем очень, потому что интересно. Это довольно непрограммерский доклад, но если вы интересуетесь продуктизацией своих идей, вам это должно быть интересно. Дальше я остался в той же аудитории. Там в это время шел доклад Сумита Гуани про Data Manipulation Using Programming by Example and Natural Languages. Я в это время был в прострации, но я примерно уловил, о чем шла речь. Очень интересная штука. Жалко, что я был в пролапсе в это время, в прострации. Я, наверное, пересмотрю доклад, когда будет видео. Идея в чем? Представьте, что у вас есть спротшит типа экзеля. На самом деле, конкретно это сейчас в виде спротшита. В последних версиях экзеля это есть просто как фича. И еще есть какая-то штука, не помню как называется. Надеюсь, видео выложат. Как отдельная плагинина для PowerShell. Возможно, какого-нибудь SDK появится в скором времени. Представьте, что у вас есть спротшит. И у него есть левая колонка с каким-то данным. Например, адреса в каком-нибудь формате. На правая колонка вы хотите почищенные данные ставить. В левой колонке у вас не идеально регулярный формат. Или где-то скобки не закрыли. Или что-то такое. Это совершенно магическая штука. Имея эти грязные данные слева, вы вписываете несколько примеров чистых данных справа. И дальше оно само. Если оно где-то немножко ошиблось, можно указать, как именно вы хотите в таком случае, чтобы оно работало. И оно дальше снова само. Это реально гребанная магия. Как они это делают? Я так понял, что они каким-то чудом ваши примеры, которые вы даете, превращают в набор правил. Потом по этому набору правил происходит поиск программы, которая удовлетворяет в пространстве возможных программ. Это довольно нетривиально. Пространство возможных программ довольно бесконечно. Тут внезапно вполне себе конечное решение. Мне бы интересно было послушать, как это в глубине работает. Шалко, что я был в прострации. Слушай, они это на Visual Basic писали, что ли? Нет, не знаю, на чем они это писали. Ты просто говоришь про Excel. На PowerShell. Это доступно из PowerShell и Excel. Но написано, скорее всего, подозреваемо на C-Sharp. Или даже на Crystal. Дальше, кстати, был доклад. Я пошел на Дэвида Кристенсена, который рассказывал про то, как писать всякие штуки на Идрисе. Примерно был доклад Бьярда Струс-Труппа про C++. Я на него не пошел, потому что Бьярд странный. И при мне случилась следующая штука. У него спрашивают, вы там в Морганстейн работаете? Ну да. А у вас там еще, кроме C++, Хаскелль используется? А что? Притом строит себя такого глухого старичка. Ну Хаскелль используется. А что? Ну Хаскелль, язык такой. Хаскелль, я не люблю собак. Нет. Да, как-то так он на это реагирует. В общем, я решил, что он очень странный и не пошел на него. По поводу доклада про Идрис. Мне доклад понравился. Чем мне он понравился? Тем, что обычно, когда рассказывают про языки с зависимыми типами, делают одну из двух вещей. Либо рассказывают про то, что такое зависимые типы, не показывая, как на этом писать. Что-то ужасное. Ну окей, я примерно понял, а что дальше делать? Куда прикладывать? Либо делают настолько матановый доклад, который предполагает, что вы уже и так все знаете. Этот доклад – это такая золотая середина, где немножечко, совсем в паре слов, примерно рассказали, что такое зависимые типы, а дальше потом показали, как с этим писать. Вообще отлично. Мне понравилось. Дальше я пошел на очень знаменитого человека Филиппа Вадлера. Если вы интересуетесь, например, Хаскелем, то, например, вы можете про него знать, потому что он автор статити «Theorems for Free». Ну и в общем, довольно известный товарищ в научных кругах. И, кстати говоря, крайне зажигательный и крайне отлично все объясняет. После его доклада такое ощущение, что ты все понял. У тебя нет вопросов не потому, что ничего не понятно, а наоборот, ты все понял. Еще он очень забавный. Я просто рекомендую посмотреть видео ради лолзов. Он, во-первых, на других докладах иногда очень забавно троллил докладчиков, во-вторых, он сам просто очень лолзово докладывался. Рассказывал он про «Quoted domain-specific languages». В чем идея? Идея в том, что если у вас есть что-то такое линкообразное, ну или что-то еще такое. Слушайте, нет, я, короче, просто скажу, что, ребят, смотрите толк. Я не смогу это сформулировать, ничего не рисую на доске. И я просто вам всем скажу, что, в общем, если вы интересуетесь как бы макросами или функциональщиной, или просто хотя бы интересно, как заработают всякие линки и прочие такие магии, которые позволяют вам писать на вашем языке, получать SQL, вы обязательно смотрите толк. И даже если вы этим не интересуетесь, просто чтобы посмотреть на Вадлера и позабавиться, рекомендую. Дальше я пошел на Филиппа Пизло из Apple, который рассказывал про то, как они прикрутили четвертый тайр Jita к JavaScript 2, который основан на LLVM. Я считаю, что этот доклад обязан был быть перед докладом Клиффа Клика, а так понятнее было бы. Потому что как раз Филипп Пизло некоторые аббревиатуры объяснил довольно хорошо, то есть, наверное, нам надо было бы вначале доклад этот Филиппа, потом доклад про V8, потом доклад Клиффа Клика. Если бы они были в таком порядке, это, наверное, можно было бы даже хорошо понять и переварить. А так получилось, что у Филиппа был самый интересный и адекватный доклад. В целом, довольно интересно. Если вы интересуетесь тем, как устроена виртуальная машина или тем, как устроен JIT, то есть, даже если вам неинтересен конкретно JIT про JavaScript, из докладов довольно понятно, как в целом приделать JIT куда-нибудь. Хотя он у них, как они сами признаются, довольно такой влопный, что в общем-то и хорошо, наверное. Дальше я пошел, точнее я остался в той же аудитории, был доклад Феликса Клока про Rust. A type system you didn't know you wanted. У меня есть стойкое ощущение, что доклад предполагался рассказать какие-то интересные перетурбации системы типа RELUST и как к ним она помогает, но в итоге, из-за того, что это был чест-ток и аудитория заняла очень много времени, то так получилось, что сам этот доклад получился где-то над Rust Introduction. До мякотки, я так понимаю, докладчик добраться просто не успел. Дальше я был на докладе Pony, Making it easy to write efficient concurrent data race free programs. Как я для себя это понял? В общем, если бы вдруг АКИ не было, и ребята вместо того, чтобы строить поверх скалы, они бы взялись писать свой собственный дофига эффективный рантайм поверх LVM, и вместе с языком, который похож на Ruby, и при этом бы они еще упоролись по дороге Rust, втащив 5 разных типов поинтеров, то получилось бы Pony. При этом язык совершенно никак не про то, чтобы делать IEO, то есть IEO нужно будет делать так же уродско, как FAKI, со всеми этими футурами. Поэтому мне, честно говоря, поинт языка не очень понятен, кроме того, что единственное сильное место языка это то, что можно мутабельные сообщения передавать между актерами, при этом безопасно, потому что если оно мутабельное, то гарантируется, что его только один актер сейчас имеет и мутирует. Но блин, я не представляю вообще, когда это было бы полезно, настолько городить такие сложности вокруг чисто этой фичи. Отличная антиреклама у тебя получилась. Грубо говоря, если бы я захотел что-то такое, я хочу порт Акина Раст, может быть, но не Pony. А, да, почему язык называется Pony, потому что есть же такая шутка, что хочу того, хочу этого, а Pony не хочешь. И они решили назвать язык Pony, потому что you can have a pony. Но мне кажется, что они такие приносят жертву, просто не скорость работы или что-то еще. Они приносят жертву, очевидно, просто то, что реализовывать и использовать. И закрывал второй день. Эван, я боюсь произнести эту фамилию правильно, но это то же самое, как одна из организаторов, когда его объявляла, она просто сказала, извини, Эван, ты будешь просто Эван. По-моему, это правильно читается Чаплицкий. Ну да, наверное, Чаплицкий, действительно. Из прези. И он рассказывал про то, как, это один из авторов языка Elm, и он рассказывал про то, как, по сути, доклад про маркетинг технологии. Но он конкретно про Elm рассказывал. Доклад очешуительнейший. Он очень забавный, очень доступный и очень правильный. И там в то же время несколько раз появляется Филипп Вадлер в комментариях. Поэтому, когда у вас будет время, я бы рекомендовал просто, если вы хотите посмотреть в конференции один доклад, посмотрите этот. Он вообще не про программирование, вообще не про языки программирования, он про маркетинг, того, как ваши технологии, но он просто классный. Лучший доклад, наверное, с конференции so far. Вот, такие дела. Можно комментарии? Ну давай, давай вопрос сначала. Я, Валер, не один раз за тобой замечал, что ты говоришь такую фразу для меня странную, что какой-то распределенный алгоритм был верифицирован при помощи квикчека. Или ребята чего-то писали для автомобилей и верифицировали это при помощи квикчека. Вот ты не мог бы объяснить, как распределенные алгоритмы верифицируются квикчеком? Я не могу понять, куда его прикладывать. Во-первых, никогда, вообще никогда я не говорю слово верифицировать. Потому что квикчек, это как это... Это best effort, он может доказать, что ты не прав. Он не может доказать, что ты прав. Валер, я вот в этом выпуске поймал тебя на слове, потом переслушай. В каком выпуске? В этом. В 49-м. Когда я говорил слово верифицировать? Когда говорил про автомобили. Ну не важно. Окей, давай, Валер. Не важно. Как-то нужно было предположить, что алгоритм корректный, допустим так. Короче, ну если я так сказал, то это потому что Саша меня покусал. Короче, идея в том, что квикчек, он ни в коем случае, даже если я так сказал, короче, да, меня можно покидать с помидорками, квикчек он ни в коем случае не верифицирует, ничего не доказывает, кроме того, что ты дурак, если он тебе какой-нибудь контрпример нашел. Что ты молодец, он не доказывает. Просто если очень долго его гонять, то можно подумать, что если он, не знаю, за 4 дня не нашел... Да, кстати, Башов и в некоторых случаях гоняют квикчек 4 дня. Просто непрерывно. И, короче, если он за 4 дня, например, не нашел ошибок у вас, то есть хорошая уверенность, он дает более лучшую уверенность, чем какие бы то ни было юнит-тесты. Но, с другой стороны, если, конечно, удастся таки верифицировать нормальными средствами программу, если это возможно в вашем случае, то, конечно, это будет большей степенью уверенности. Меня другой интересует. Как приказывать, да? Есть распределенный алгоритм, да, как его приложить-то? Ну, я могу... Мне кажется, уже пытался это как-то рассказывать, как я это делал, например, я. Общий совет, сходите в репозиторий React KV, посмотрите на тесты. Там файлики обычно начинаются с трех букв EQC. Но предварительно нужно будет хорошенько раскрыть квикчек на примерочках попроще. Потому что у них в React довольно такой же advanced level квикчек. Идея следующая. Есть у нас какая-то система, например... Кстати говоря, вообще очень по-разному можно это делать, потому что, например, если ты перекладываешь его к CRDT, то на самом деле тебе не нужно никакую распределенность верифицировать. У тебя CRDT это просто... Да, это понятно, окей. N стейтов, и ты просто с этими стейтами делаешь операции такие, которые, в частности, предполагают, что, например, два стейта менялись параллельно. Ну, ты их, понятно, можешь делать последовательно менять, но ты в какой-то момент говоришь, ага, вот эти два параллельных стейта, давайте теперь их смержим, посмотрим, что будет. А теперь смержим в другом порядке. Это все понятно. Меня больше интересуют случаи типа рафта какого-нибудь, что-нибудь такого рода. Окей, да. Ну, что это, по сути, может быть? Тут можно, в целом, много фантазировать. Во-первых, можно, что я неоднократно замечал с Забашовцем, опять-таки выделять часть, которая не имеет непосредственно стейта, точнее, наоборот, которая является только стейтом. То есть, грубо говоря, вот внутри твоего актера, который реализует рафт, у него есть какой-то стейт, и есть какие-то функции, которые этот стейт менеджит. Которые, грубо говоря, аппенд в лог. То есть, не команда, которая тебе пришла, а аппенд в лог, а именно как ты уже в лог этот аппендишь. Или, например, штука, которая модифицирует твой view-кластер. И, соответственно, добавить мембра, убрать мембра и так далее. Просто каждую из них можно, например, на вот эту штуку, которая менеджит view, написать какие-то свойства, потому что инварианты там сохранялись. Типа, она никогда не заменяет view целиком, она всегда проходит через joint quorum или что-нибудь такое. И просто этот стейт погонять без запуска актера. Второй момент, как это еще можно прикладывать. Ты таким можешь насимулировать себе... Точнее, как это делал я, например. Я генерировал... Как это? Последовательность. Ну, сейчас, как бы так сказать. У меня, например, была задача, мне писал штука, которая выгребает данные с ряка очень кастомным образом. Что я делал? Я генерировал трассы, даже не трассы, я генерировал ответы реплик заранее, заведомо. То есть, я знал, какой запрос я сделаю. Я генерировал запрос, после этого я знал, какой запрос будет сделан и генерировал ответы от реплик. Включая, например, такие вещи, как молчание реплики. Ну, то есть, реплика ничего не прислала. Извините, это либо обрыв сети, либо реплика сдохла или по дороге, или что-то такое. И включая ответы, типа, извинения, нет данных и все такое. Дальше я запускал реплики с этими трассами. Ну, не с трассами, а с этими заранее заготовленными ответами. И дальше запускал, собственно, клиента. Клиент запускался просто честный. Ну, то есть, как бы, то, что мой код. Дальше клиент ходил и тыкался в эти симулируемые реплики, которые, на самом деле, были не настоящими репликами, которые реально в проекте, а вот именно этими репликами, которые просто читают эту сгенерированную последовательность и знают, на какую часть запроса как отвечать. Ну, то есть, там запрос был длинный, то есть, типа, дай мне рейндж с такого-то по такой-то. И, короче, клиент ходил этот рейндж, пытался получить. А каждая из реплик, она знала, когда ей очередной кусок рейнджа нужно отдать, что ей при этом отдавать. Молчать ей или отдавать что-то, или что-то еще. И при этом на основе тех же данных, что я скормливал репликам, у меня была функция, которая на основе данных, которые есть у которой, типа, на основе того, как поведут себя реплики, строила ожидание того, как должен вести себя мой код. Ну, то есть, что в итоге мой код должен по-хорошему получить от реплик, учитывая их поведение, которое я для них сгенерировал. Собственно, дальше запускался мой код, ходил во все это, тыкался, так и получал какой-то ответ или крэшился. Кстати говоря, он и крэшился, несколько крэшу себе нашел, то есть, совсем дурацкое поведение. И в конце концов он давал какой-то ответ, после чего ответ моего кода сверялся с тем поведением, которое ожидалось от него при таком вот раскладе, какой я генерировал. Этот тест выловил примерно штуки три таких неочевидных ошибки на начальном этапе, а потом я решил в одном месте сделать оптимизацию, и он выловил баг, который там содержал в себе шагов 10, чтобы воспроизвестись. И он вполне реальный был на реальной системе, и мне ушла неделя, чтобы понять, что происходит. Ну, я себя понял. То есть, краткий ответ, что вариант первый, ты говоришь, что у тебя есть стейд акторов и есть функции, которые отображают на приход сообщения этот стейд в какой-то другой стейд, и ты на этом моделируешь. Второй вариант, ты говоришь, что у меня есть примерно такой, скажем, юнит-тест, и, условно говоря, ты генерируешь квик-чеком то, что у тебя дают моки, грубо говоря, и на этом гоняешь. В принципе, я тебя понял. Окей, спасибо. Ну, ты не просто что моки генерируешь, ты поэтому еще генерируешь то, что при этом твой код должен получить в результате. Ну, конечно. То есть, ты фактически в тесте описываешь функциональность основного модуля, потому что ты, зная то, что моки ответят, ты должен сказать, что у тебя ответит основная часть. Ну да, да. Ну просто нам среди в чем, почему такое сложное все еще приемлемо, потому что сам модуль еще сложнее. То есть, грубо говоря, из этих реплик, там процедура, ну, грубо говоря, может быть, на полэкранах где-то, которые генерируют ожидаемый ответ, но она тоже не очень тривиальная, потому что там сама психологика была не очень тривиальная, но хотя бы небольшая. И до этого, не знаю, 5 экранов кода самого моего кода. И понятное дело, что заставить правильно работать штуку в полэкран гораздо проще, чем штуку в 5 экранов. То есть, оно все еще имеет какой-то value за собой, потому что простой последовательный код, который не делает ничего конкарнт, проверяет код, который делает кучу всего конкарнт. Стас, вот раз мы... Подожди, подожди, я добью с этой конференции. Во-первых, Валер, когда видео они обещали? Я посмотрел, там ты говоришь, где есть слайды, я заглянул, я слайдов не нашел. Я знаю, что есть слайды, просто потому что некоторые из докладчиков в своих твиттерах уже постили. Запись точно была, я уверен, что они сделают доклады публичные, я это очень надеюсь, у меня нет оснований полагать, что доклады будут закрытые, что контент будет закрыт. Но они еще не появились, потому что надо понимать, что ЕКУП, он только-только сегодня закончился. А это была формальная часть ЕКУПа. Мне кажется, Крис Майклджан, я не знаю насчет Хизер, но я думаю, что Ян Витик и Крис Майклджан, которые оба организаторы, мне кажется, они еще оба в Праге и продолжают просто на оставшуюся конференцию ходить. Понятно. Ну и в целом спасибо тебе за то, что вычеркнул мои очередные выходные, из моей жизни буду смотреть доклады. Я просто убийца Ваниных выходных. Так, для контекста, Ваня тут шевелит плату, потому что я ему про это рассказал. Ты вообще убиватель выходных. Я последовательно лишаю Ваню жизни. Свет, я тебя перебил, извини. У меня был вопрос к Стасу. Мы затронули тему тестирования, а вот расскажи, как вы тестируете ваши средства работы с NLP? Ну, там NLP штука такая довольно своеобразная. Вообще, когда первый раз услышал, там есть волшебное слово «ресеч», и при слове «ресеч» все сразу начинают, глаза загораются, думают, что вот сидит человек, какие-то опыты ставит у себя один, потом выходит и говорит, что только что изобрел электричество и так далее. В NLP все довольно не так уж прямо весело, поскольку, ну, даже если речь идет о спеллчекере, то ты должен построить какую-то модель, и эта модель будет использоваться для того, чтобы предложить, например, лучшую замену. И чтобы это проверить, там же нет такого совсем бинарного случая. Например, тебе присылают приложение и говорят, что спеллчекер показывает неоптимальную замену. Ты говоришь, ну, я все понимаю, извини, я ничего не могу с этим сделать. Просто потому что я же не могу там ифочку вписать на это слово, правильно? Поэтому там работа происходит так, что есть большое количество корпусов. Например, если мы говорим про спеллчека, то это есть корпуса текстов. И мы эти корпуса запускаем внутрь нашего спеллчекера, он проверяет и смотрит, что вот это слово неправильно, это замена на такие-то, такие-то, такие-то. Вот это слово, например, есть как бы четыре типа ошибок в НОП, если кто не знает. Не четыре типа ошибок, а четыре варианта работы НОП-алгоритма. Есть true positive, это значит, что действительно была ошибка, и мы ее заметили и триггернули. Есть true negative, это значит, что ошибки не было, и мы промолчали. Есть false positive, это значит, что ошибки не было, но мы-таки ее нашли. И есть false negative, это значит, что ошибка была, но мы ее не нашли. И когда хочется потестировать, соответственно, есть какие-то правильно уже размеченные файлы, ты эти файлы скрамливаешь и смотришь, ага, что изменилось у тебя после того, как ты поменял модель, поменял алгоритм, поменял еще что-то. Что стало true positive, что стало true negative и так далее. По этим четырем показателям ты пытаешься посмотреть, ну, что же как бы, в какую сторону изменилось. Это звучит как бы как просто, но на деле это получается так, что у тебя есть, например, 5-6-10 корпусов, ты там долго курил статью, попробовал новый алгоритм, запускаешь свои корпуса и видишь, что, например, 4 корпуса стало лучше, а 3 корпуса стало хуже. И ты смотришь и думаешь, ну и что? То есть, что делать-то дальше? Непонятно. Поэтому тестирование там очень важно, поскольку иначе не проверишь. То есть, нужно взять действительно большой объем данных, его загрузить, посчитать, посмотреть, что получилось в результате. Но тестирование иногда бывает такое палка о семи концах. Что-то стало лучше, что-то стало хуже, ты начинаешь чесать реп и думать, ну, да, что же, где можно посмотреть. Начинаешь смотреть. Единственный способ это начать смотреть, что там, где, когда сработало, пытаться все-таки поменять контекст, поменять коэффициенты какие-то. Хотя это довольно грубо, но тем не менее иногда это нужно делать. Вот примерно так это выглядит в NLP. Окей, спасибо. Что, следующая тема? Сашина. Я на самом деле хочу сначала убить одну тему, которую я думаю не забить ли. Буквально в двух словах, что в России стали продавать Ubuntu-фоны, можно купить, не заморачиваясь на счет. Ну, как раньше было. Нужно на eBay найти какой-нибудь LG Nexus 4, привезти его домой, прошить его Ubuntu. Больше этого не нужно, можно прям заказать готовый. И ссылки будут в шоу-ноте, если это кому-то интересно. А тема, про которую на самом деле говорил Света, заключается в том, что с сайта HighSkillability.com пришла статья о том, что ребята сделали штуку под названием Reborn DB. Что это такое? Вот у ребят есть... Представьте, что у вас есть Redis, да? У него есть мастера и реплики. Вы их объединили, грубо говоря, в репликосеты. Ребята поверх всего этого прикрутили пару утилит, которые делает, во-первых, автофейловер. То есть, у тебя упал какой-нибудь мастер, реплика запромочилась до мастера. Они сделали к этому автоматический решардинг и так далее. Они сделали нормальный распределенный Redis, который похож на Couchbase, например, но у него есть мапы, сеты и так далее. Они отмечают, что это молодой проект, что он довольно непрост в плане использования, потому что нет красивой веб-мордочки. Потому что довольно много надо всего настраивать. Но мне кажется, идея просто отличная. Ты знаешь, я немножко скепсиса добавлю. Redis очень хорош как раз тем, что он в памяти все держит. То есть, он за счет этого очень быстрый. Разработчик Redis из-за скорости не пытался делать его многопоточным. Он работает в один поток, берет все с памяти и бесконечно быстро. Когда у тебя все синкризано на файловую систему, когда только набор гречи хранится в памяти, у тебя это все замедляется и сама идея редисовской скорости пропадает. То есть, да, это получился очередной кивэль. Кстати, есть возможность, там есть модифицированный, там два компонента, Саша немножко не точно сказал. Там есть персистент вариант Redis, и есть модифицированный вариант обычного Redis, который работает с их проксей. Я посыпаю голову пеплом, они сделали свой сторидж, который умеет хранить только горячие данные в памяти, а вообще все на диске, в отличии от Redis. И фишка в том, что оно совместимо по протоколу с Redis. И там главное, что есть обычный Redis. Грубо говоря, ты можешь иметь горячий Redis для обслуживания, и какой-то там, не знаю, для каких-то... Они там предлагали какую-то конфигурацию, короче, когда ты можешь иметь, грубо говоря, и то, и другое в кластере, и это будет малосмысленно. Я вот, честно говоря, не помню, я статью довольно быстро пробежал. В целом, выглядит более адекватно, чем Redis Sentinel, но в любом случае это настолько все молодое, что, ребят, вы на каких-нибудь хотя бы базовых ансамбльтах потестируете, потому что у меня буквально на этой неделе в продакшене была ситуация, когда сервер, зараза, с избыточными линками, таки пережил на... Ну, там, пара серверов таки пережила на сплит. И, как бы, блин, избыточные линки, две сетевые карты в банде. По-хорошему, я не уверен, может быть, конечно, там нафар... напортачили что-то острое, и там были роутеры нередандант, но, мне кажется, они тоже должны были быть редандант. Хорошо, что у нас на том сервере ряк, и ничего, на самом деле, не сплитнуло. Но, короче, вот, это случается, даже если у вас избыточная сеть. Я это своими глазами пронаблюдал впервые. Жесть какая. Ну, то есть, понятно, что оно все очень сырое, возвращаясь к твоему... к твоей предъяве. Но, все равно, я желаю проекту всяческого добра и развития, и мне очень хочется такого же для пасгри. Ну, вот, короче, я тоже присоединяюсь. На самом деле, я говорю, что оно выглядит приятнее, чем сенчанел. Если бы я начинал сейчас какой-то новый проект, я бы, наверное, попробовал, просто предварительно погоняв бы какие-нибудь такие тесты на... А, давайте сейчас сломаем сеть. Вот. А дальше, видимо, я и продолжать должен, да? Угу. Давай, шки. Короче, дело в том, что, ну, все, наверное, знают, но в неоднократном упоминании такой алгоритм называется RUST. Ой, ой, прости, господи. РАФТ. Тебя пропусали. Такой консенсус, который, в общем, типа, мол, понятный, доказуемый, нечепокуляренный. Дело в том, что про RAFT было несколько статей, вообще, в общем-то, были более-менее одного автора, но алгоритм там переживал некоторые мутации за это время. И дело в том, что, сожаленно недавно, вышел у Диего Ангара, вышла его, собственно, его диссертация. И там часть алгоритма, которая ответственна за изменение VIEW, она немножко другая. И, в общем, в ней он буквально недавно нашел баг, где-то дней 12 назад, и сегодня он опубликовал баг вместе с решением. В общем, если у вас используется RAFT, который был реализован на основе пейпера, где используется Join Quorums, вам волноваться не стоит. Волноваться стоит тем, у кого реализация использует, как бы, очень-очень недавнюю, например, версию. И я так понимаю, таких имплементаций сейчас в продакшене нет. Я, конечно, топик читал только утром, когда там была пара комментариев. В принципе, я посмотрел на него сейчас. Если там нет постов от авторов ETCD или консола, я подозреваю, нет, потому что это другое, мне казалось, использовать Join Quorums. Пока ты это думаешь, у меня вопрос. ETCD, мне кажется, может быть забрызган. У меня там линк какой-то, залинкован какой-то ищью ETCD, так что возможно, что ETCD забрызгал. Но мне кажется, что консола забрызгать не должно, потому что, мне кажется, консолу использовали Join Quorum approach. Я хотел спросить, как ты думаешь, сколько наших слушателей имеют разные реализации RAFT в продакшене, но потом ты назвал консолы ETCD, так что, если это к ним применимо? Нет, ну я так понимаю, консолы нет, ETCD возможно. То есть, я не очень понял. Я утром этих постов еще не было, я наутром смотрел. И я бы просто последил за веткой, если не появится что-то из тех имплементаций, которые у вас используются, то вам нужно будет проапдейтиться. Вот. Я кончил. Могу сразу следующую тему свою добить, и я дальше потом пойду отойду, если кто не против. Вперед! Я нет. Вот, короче, тут есть такой проект Mirage, если кто не в курсе, это такой Unikernel для Caml. Что такое Unikernel? Это когда мы умеем гонять наш языковой рантайм без ядра операционной системы, прям просто запускаем Zen-виртуалочку, и в ней прям сразу только наша программа и ничего больше. Ну, собственно, сейчас есть два, вообще глобально есть, мне кажется, три Unikernel. Это для Caml и Mirage, для Erlang и Ling, он же Erlang и Zen. И есть еще, не помню как называется для Haskell, мне кажется, HVM, или как? Нет, HVM для HipHop, Virtual Machine. Просто на HVM, не помню, в общем. Но делает компания GoA, о которой в прошлом выпуске упоминали. Вот у них есть Unikernel для Haskell, но я про него давно ничего не слышал. А Mirage и Ling, они живут и здравствуют. Ну вот, проект Mirage, они запилили довольно интересный проект, называется IRMIN. Это такой подход довольно интересный к тому, как делать распределенный Storage. Идея в чем? У нас есть куча мутабельных блоков, которые объединены в мутабельную, как бы, древовидную структуру. Дальше, подобно Git, у нас есть теги, которые указывают на голову каждого дерева. И, в общем-то, может быть несколько параллельных писателей, у каждого из которых своя голова. Когда хочется их смерчить, примерно как Gitmerge получается. В общем, очень интересный дизайн, если вы интересуетесь дизайном распределенных систем. Или, возможно, это Саша тоже будет интересен, мне кажется, он что-то такое как-то раз предлагал. Хотя, в данном случае, это Eventually Consistent штука. Точнее, она будет Eventually Consistent и Strict Consistent, как развернешь. В общем, рекомендую полистать эту статью, она довольно интересная, в целом, довольно интересная идея. И от какого-нибудь CRDT отличается тем, что есть полная история. То есть, информации для мерджа больше, и поэтому сам по себе мердж может быть проще. И я увидел какую-то из дистрибьютивных сетей обсуждения, где делается предположение, что, возможно, эта штука имеет больше overhead по хранимой истории, зато, возможно, она будет применима более широко, чем CRDT, например. Слушай, а как конфликты решают в таком случае? Ну, в смысле, зависит от твоей структуры данных, очевидно. Ну, как ты в Gitе конфликты решаешь? Не, ну я вручную их решаю, а там это тоже вручную придется делать? Ну, в простейшем случае CRDT прикладываешь туда. В более сложном случае, ну, то есть, это все зависит от твоей семантики. На самом деле, там такой дизайн, что если у тебя... Ты можешь иметь только один поинтер, у тебя будет как бы... Как это... Contention за этот поинтер, но при этом писать в сам Storage ты можешь, параллельно во много потоков, потом просто тебе нужно будет кончик поинтера обновить. Или ты можешь иметь такой поинтер, например, просто для каждого... Для каждого, например, ключа, который тебе интересен, такой поинтер иметь. И вот только для каждого отдельного ключа иметь Contention на этом поинтере. А типа все остальное будет там параллельно писать. То есть, ну, короче, тут есть варианты, и это такой, ну, очень широко применимый дизайн, мне кажется. Понятно. Я окончил. Смотрите, пожалуйста, с доски. Отлично. Тогда я хотел бы рассказать про то, что Amazon анонсировала на этой неделе. Я тебя перебью, мне знаю, что сейчас еще очень интересно обказалось. Мы, короче, темы нашего подкаста вторую неделю подряд, или нет, ну не вторую, а через неделю, то есть, предыдущий выпуск, потому что там было много Хаскера, он не считается, но, короче, последние два выпуска подряд, темы, которые вот здесь провоскакивают у нас в Дельзене, они очень хорошо сочетаются с тем, что у нас в рабочем чате проскакивают. Почти один в один. Ну вот. Итак, Amazon анонсировала на этой неделе два новых продукта, достаточно интересных, может быть, показаться кому-то. Первое – это называется Amazon API Gateway, где вы можете описать с помощью либо юзер-интерфейса в AppUI, либо с помощью CLI каких-то консольных команд, тот REST API, который вы хотите иметь, и привязать к нему каких-то обработчиков. Для тестовых вещей, например, вы можете привязать, что на GET, на такой-то адрес, я возвращаю всегда статическую штуку, например, номер версии или так далее. А в целом они в своих примерах привязывают туда лямбду. То есть, обработчики там написаны на JavaScript. И вы получаете легко конфигурируемую снаружи, но ложащуюся на амазоновские сервисы и хосты, как-то прозрачно, независимо для вас, все обработчики. То есть, вы говорите, что я хочу иметь бесконечно скалируемую, бесконечно растущую, в смысле, с бесконечности возможностями для роста обработчики. И я хочу только описывать, что они будут делать. Но больше ничего не хочу знать. И вы все это пишете там, и дальше Amazon делает все остальное за вас. В принципе, довольно интересная идея, особенно если вы хотите написать какое-то быстренькое REST API и готовы тратить много денег, я уверен, что там будет много денег на то, чтобы большое количество пользователей пользовалось. Ну, такая интересная, интересный конструктор. А вторая тема, которую они анонсировали, это Continuous Delivery на Амазоне. Называется Co-Pipeline. С очень демократическими ценами, то есть, один pipeline стоит 1 доллар в месяц. Но это практически ничего не стоит. И я не знаю, знакомы вы или нет с концепцией GoCD, Continuous Delivery тоже толза такая. Вы там определяете pipeline, в котором есть разные стадии, начиная со сборки проекта, заканчивая всеми возможными стадиями тестирования, каких-то ваших ручных проверок, или попыток залить результаты, артефакты работы pipeline на какие-то внешние серверы. И все это составляет один pipeline. Вы определяете стадии. Если на какой-то стадии сломалось тестирование, или вообще любой процесс, чтобы поломался, pipeline дальше не идет и ждет, когда вы вручную перезапустите, либо следующего коммита. Мы у себя очень глубоко и хорошо используем GoCD с этими pipeline. Я вообще нахожу это очень удобную концепцию. И они теперь запилили примерно то же самое у себя, только как сервис. То есть, они не предоставляют ни исходников, ничего. Все работает на амазоновских серверах, где-то там, что-то там. Я считаю, что если вы уже жестоко завязаны на Amazon, и вам хочется какую-то удобную фичу для быстрого континент-деливерия настроить, это как раз неплохая вещь. Притом, что цены очень хорошие. Как-то так. А если вы не жестко завязаны на Amazon, я советую быстрее отвязаться до конца. Вы, кстати, используете, нет, какой-нибудь континент-деливерий в себе, ребят? У нас в TeamCity есть задача, которая раскладывает. Это считается? Смотря, что она раскладывает и как она раскладывает. То есть, если вы готовы на каждый коммит создавать RPM, которая может разложиться к вам на продакшен и в дальнейшем сделаться активной, то есть, чтобы она сразу на продакшен раскаталась и запустилась, то это да, это считается. Подожди, если сразу на продакшен, это continuous deployment, а не continuous delivery? Нет, deployment, это когда ты сразу запускаешь, а delivery, это когда ты только доставляешь. То есть, ты потом кнопку нажал, она сразу стала активной дополнительно. Мне всегда казалось, что continuous delivery это хуяк-хуяк и в production, а continuous integration и, а, сейчас, есть integration, delivery и deployment. Да, вот они по очереди как раз, ты их правильно назвал, в нужном порядке. Короче, то, что у нас есть, это ты, когда замерзшел в dev, в ветку, у тебя собирается билд, прогоняются тесты с coverage, проверяется, что coverage не упал. Притом, в Team City на реальной базе прогоняются, у нас там у тестов есть флаги, нам мог их прогонять или на реальной базе. Потом из этого собирается depacket, depacket ставится на виртуалку в Амазоне, из нее делается образ, а образ уже раскатывается в автоскейлинг-группу. Ну да, это уже у вас все отлично. Это как бы до dev, а потом, если тебе нужно на stage, ты кнопку нажимаешь, и этот же образ скатится на stage. Ну да, вот у вас delivery полноценный. То есть, до deployment, это когда вы кнопку не должны нажимать, когда она уже сама будет раскатываться на staging. Вы не готовы так переключаться, да? Ну в смысле, она по мерзши раскатывается просто на dev. На dev, а я имею в виду на production. Ну нет, мы так не готовы совсем. Совсем. И не будете. Что, мы наркоманы, что ли? Ну просто есть люди, утверждающие, что continuous deployment – это настоящее благо. Очень рад за них. А у вас, Свет? У нас используется много внутренних инструментов, и вся инфраструктура довольно сильно на них завязана, и много печальных вещей. Мы очень хотим перейти на Go, вот которую ты упоминал. И это звучит очень здорово, и в принципе много ребят исследовали именно вот эту тему, и в принципе она нам довольно хорошо подходит. Но из-за трудностей внутренних нам не разрешают переходить на что-то другое. Вот, так по сути у нас есть проект, который собирается в Maven, либо SBT. Дальше артефакты выпадают в Nexus. После этого TeamCity берет эти артефакты нужные, она создает… TeamCity создает некоторый пакет, который заточен под наш специфичный тул для диплойментов и для релизов. Дальше ты открываешь UI, в котором есть твой проект, и некоторые окружения там. И ты говоришь, что вот пожалуйста, задеплойте именно такое окружение. Ты нажимаешь явно кнопочку, что вот давай деплой. И в принципе, с одной стороны это нравится менеджменту, потому что можно посмотреть историю всех деплойв, и явно видно какой пакет был задеплойен, что там было. Но есть много нюансов в связи с тем, как менять, например, настройки. Вот у тебя есть файли конфигов, например, и нужно поменять, например, углы к базам данных. Тут у нас будет для одного энвариомента база данных, тут для второго энвариомента, для продакшна своё. И чтобы вот это менять, это не такая простая задача, что в текущей инфраструктуре приходится использовать старые тулы. И это, скажем, мне не нравится. Мне хочется автоматизировать, и в принципе мы добились того, что нам наконец-то дали какой-то API, чтобы можно было автоматически дёргать эти кнопочки деплоймента. Грубо говоря, я хочу такую штуку, что я делаю commit, либо мы мержим с мастером какую-то ветку, и после этого автоматически у нас прогоняются тесты. У нас там готовится эта джарка, готовится нужный пакет, и оно автоматически раскатывается, например, на тестовое окружение, на стейджинг, ещё какой-нибудь стейджинг, например, при продакшн. А вот на продакшн, окей, давайте нажимать на ту же кнопку, когда мы готовы, мы всё знаем, что, как. Но этого мне сильно не хватает. Я надеюсь, что в каком-то будущем мы к этому придём. Понятно. А у вас, Таз, как? Когда произошёл commit, запустились тесты, всё собралось, мы не выкладываем на прод, мы выкладываем на тестовые сервера. А тестовые сервера — это то, чем у нас пользуется команда тестеров. Но тут есть такой момент в том, что у них кроме... Ну, у нас в коде, понятно, есть юнит-тесты, у них есть свои тесты, они более высокоуровневые, и эти тесты постоянно эти сервера так или иначе дёргают. То есть, когда что-то коммитнулось, протестировалось, окей, всё нормально, оно заливается туда, и там начинают работать немножко другие тесты. Но прямо в продакшн пока как-то вот нет, не готовы. У нас практикуется, бывает, такая вещь, как стейджинг-энвайрмент, то есть мы направляем сколько-то процентов трафика на какую-то новую версию, чтобы посмотреть, как там вообще она себя чувствует, что там происходит. Мы также её мониторим, собираем метрики, смотрим, что меняется, и потом, например, её открываем уже для всех. Но вот чтобы вот так вот прямо раз и в продакшн — не, не делаем. Понятно. Ну что, Свет? Ну, я могу рассказать про своё дело. Я думаю, это довольно короткое получится. Давай. Я набрела довольно интересный подход, как хайлить людей. И, собственно, тут в блоге Medium кого-то описано, как его пытались захайлить через GitHub. Ему прислали интересную задачку, и что, собственно, это задачка? Это просто некоторый блок букв, и дальше говорят, что вот, пожалуйста, вам этот блок, и расшифруйте, и вам, если понравится, давайте пообщаемся. Вот, и человеку стало интересно. Он прикинул что-то за блок текста, он понял, что это B64, расшифровал, и там получилось следующий блок букв и текста в виде такой бутылки. И кроме этого были некоторые подсказки, три подсказки, что нужно делать с этой бутылкой, чтобы получить из него какую-то нужную информацию. Там была функция для дешифрации на Python, на JavaScript и на Scala. Он это все применил, расшифровал послание. То есть получилось так, что в одной бутылке было и то, и то, и то. И в итоге человек почитал, посмотрел, довольно интересно. Я говорю, что это очень классный способ, если бы вот так HR поступали и прислали такие задачки, мне кажется, это было бы здорово. В принципе, это не напряжно, это просто, это не требует больших усилий, но, скажем, как идея, мне понравилось. А что вы скажете, ребята, по этому поводу? Они там чувака нашли по GitHub, по проектам, которые у него на GitHub. То есть если меня так HR будут искать, то меня будут хайрить на должности, на должности Perl 6, например. Что-то не готов пойти, что ли, работать туда? Ну конечно, Perl 6. Но Perl 6 устарел, я только на Perl 8 забыл, что ли. Отлично же, я забыл, забыл. В целом мне походу понравился, и мы на работе обсуждали, как можно его еще больше улучшить. Но я рассказывать ничего не буду, а то вы тоже применять начнете. Забирайте всех орландгистов. Да, да, да. Мне очень понравилось. А кому они нужны? Мне очень понравился подход, потому что наблюдая, что происходит конкретно здесь, где я сейчас нахожусь, кадровый голод тут совершенно невыразимый, и люди пытаются, ну вот как только не пытаются, хоть как-то выделиться, чтобы обратили внимание. То есть пытаются там что-то кофе напоить, пытаются там какие-то специальные письма писать, особо завлекательные. Это очень хороший подход, мне кажется. Бывает, что, ну как бы известный такой хинт, что когда людям нужны фронтендеры, они начинают в консоль из своего приложения, в консоль какие-то рекламные сообщения выкладывать. Разработчик открывает и видит, что его прямо в консоль уже начинают хайрить. Но эта идея, конечно, поинтереснее. Я тоже думаю, что надо будет очень серьезно подумать, как можно что-то именно выделиться, потому что все говорят почти одно и то же. Если это не какой-то суперизвестный бренд, то довольно непросто найти людей. Извини, я перебил. У меня самое веселое было собеседование, когда я через одного знакомого пришел на это собеседование. То есть он там работал в этой компании, говорит, ну приходи там пособеседуем. Это еще в студенческие годы было. И я такой прихожу, а он на выходе меня встречает со своими коллегами, они идут с работы. Говорит, о, слушай, мы тут идем пить текилу, давай с нами пособеседуем. Это было самое веселое собеседование, которое у меня было. Так, я думаю, можно перейти к темам наших слушателей. Никто не против? Давай. Она мне грозится очень долго, как всегда. Я могу покончить. Может, забить эфир чем-нибудь. Первый вопрос, который поддержало максимальное количество человек, это предложение позвать в выпуск практикующих лисперов и делать целый подкаст, посвященный этому. Вот, все мне загрузилось. Почему нас вообще постоянно просят кого-нибудь позвать? У нас есть, кому надо, пусть сам приходят. У нас прямо на сайте написано, как. Кто из нас сейчас будет бегать искать лисперов? Скажи честно, я не знаю ни одного. Лисперов я вам обеспечу, если нужно. Давай, обеспечь. Хорошо. Неприятно, почему вы против так клую жюристов. Я бы за то, что позвать Никиту Прокопова, он бы нам рассказал чего-нибудь. Так уже звали. Еще раз позовем. Надо бы традицию возрождать. Помните, как в каждом выпуске было? А, было, да. С мистер лиспер веселей. Скобок больше, в два раза быстрее. Мистер лиспер. Так, хорошо, следующий вопрос. Про Kotlin. Почему Kotlin? Следующий язык программирования. К моему сожалению, я не читала эту статью. Кто-нибудь читал? Мне уже неинтересно читать статьи про идеальные языки и вот прочие перфекционисты. Намного интереснее делать системы, которые круто работают. Саш, ты же у нас специалист по Kotlin. Давай прокомментируй. Я не вижу хорошей инфраструктуры рядом с Kotlin. То есть у меня были такие мысли, что да, надо бы на Kotlin выписать такой неплохой язык, вроде потом ты думаешь. А вот мне бы актеров в Kotlin. Наверное, надо взять Аку. Но Ака, она же там как-то уже на скале написана. И как-то странно уже тащить как-то runtime Kotlin и runtime Scala в свой проект. И то же самое применимо каким-нибудь веб-сервисам, серверам типа Finagle и так далее. Ну то есть, я знаю, Android разработчикам Kotlin очень нравится, потому что им реально больше не надо. Наверное, UI программистам, ну, под десктоп и так далее, тоже на Kotlin прям в самый раз. Но на backend на Kotlin я с трудом представляю, как писать. А какие основные трудности? Ну, я только что писал. Ты берешь все, что угодно, а у него ничего нет. Ты берешь, тебе нужно на Kotlin писать... Ну, кроме конкретика. Ну, кроме конкретика. Тебе либо брать Spring, тогда непонятно, чем он лучше Java, или тебе брать, не знаю, Ака, Play и так далее, тогда непонятно, почему не взять Scala. Понимаешь? Ну, то есть ты представляешь, ты будешь все котлиновские типы конвертить в скальные и обратно. Зачем? У него нету веб-фреймворков, у него нету ничего для бекенда. Ну, так допустим, писать на Kotlin, но использовать либо Java. То есть такая идея, чтобы писать в той же... Ну, как обычно ты привык писать, но с использованием языка Kotlin. Там же все те же библиотеки будут работать. Ну, удачи. Я что, я против. Понимаешь, это... Ну, у тебя есть опыт с Java, и ты привыкла там на гуавовских футурах, или еще как-то. Я так не умею и боюсь. И вообще считаю это уродством после for-comprehension. Так что нет, в принципе, если всю жизнь писал на Java и хочется такое же, только с автоматическим выводом типов, то пожалуйста. Окей. Переходим к вопросу про GCF Go 1.5. Говорят, его там прям совсем разогнали. Он там прям суперреактивный. Вот все, что было до этого, это вообще не считается. Ну, мы когда в прошлый раз обсуждали планы по развитию GCF Go, мы как раз и говорили, что в 1.5 они хотят сделать, чтобы не было больше Stop the World. И как-то его делают правильно и конкурентно, как concurrent GC. Я посмотрел графики, и судя по графикам, ну, стало, конечно, намного лучше, но все равно можно получить парочку миллисекунд на GC в 400-500 мегабайт памяти. Если было использовано HIP size 400-500, даже на 300, судя по всему, можно получить 2 миллисекунды задержек. Ну, не знаю. Наверное, стало намного лучше. Надо попробовать, посмотреть. Кто может в комментариях отметиться, кто сильно использует и понимает, насколько все стало приятнее. Ну, вот я смотрю на эти графики, которые приводят то, что при размере HIP в 20 гигабайт у тебя сильно меньше 1 секунды времени уходит на GC, а на более крупном масштабе тут 500 мегабайт HIP за чуть больше 1 миллисекунды собирается. Ну, понятно, что любые бейчмарки, они такие синтетические, ничего не значат, но, надо сказать, это выглядит очень интересно по сравнению с тем, что было раньше. Ну, это да. Мне интересно, планы, что они дальше планируют. Там очень коротко написали, что они хотят, куда хотят развиваться. Но вот в целом, каких пределов они хотят достичь и к чему прийти в конце концов. Ну, ладно, давайте дальше. И следующий вопрос. Следующий. Да. Что почитать по тайм-серии с практическим клоном? Вы вроде упоминали в каком-то из предыдущих выпусков. Я помню, к нам гость заходил и советовал какую-то книжку. У нас Валера большой специалист по тайм-серии. Валера, что почитать? Что? Нет. Я тайм-серии никогда не обрабатывал. Не надо говоря, я не настолько умный, чтобы обрабатывать тайм-серии. Я их только кушал очень активно своим кодом, но совсем ни разу. И агрегаты считал? Ну, агрегаты, ну, считали, знаешь, извини, почитать по тайм-серии по окону максимум, минимум цену открытия и цену закрытия, это большого ума не надо. Там гораздо больше ума было проживать поток данных. То есть, серьезно, какой-то более-менее вменяемый анализ тайм-серии, который обычно подразумевают, когда говорят тайм-серии, блин, ну, это совершенно, ну, это довольно отдельная, сложная область, и нужно идти к специалистам, которые в этом специалисты.",
    "result": {
      "error": "API request failed: Error code: 400 - {'error': 'Trying to keep the first 20025 tokens when context the overflows. However, the model is loaded with context length of only 12276 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 193, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': 'Trying to keep the first 20025 tokens when context the overflows. However, the model is loaded with context length of only 12276 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}\n"
    }
  }
]
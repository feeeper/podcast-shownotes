[
  {
    "segment_id": "f6ef2c86-78d5-41c7-b2d1-645ffa0d64c2",
    "episode_id": "eb8bc1ab-a149-4d85-b45b-54ae7fc5dd8d",
    "episode_number": 92,
    "segment_number": 3,
    "text": "Это и очереди, это и блобы, и table storage плотно используется. Мы также используем... у нас есть различные вещи, связанные с операционными вещами. То есть у нас есть Kibana, у нас есть различные backstage и прочие прелести, необходимые для мониторинга студийной системы. Что еще есть такого? У нас есть сейчас Erlings появился, у нас есть технология микросервисов. Мы используем Cloud-сервисы в Azure. Мы используем как deployment tool, мы используем Octopus Deploy, стандартно для Дотнет-проектов, наверное. Ну что еще? Ну, там, development, понятно, там, TeamCity и прочее. Это как у всех. Ну ты назвал много всего интересного. Давай начнем тогда с вашей микросервисной архитектуры. Ты упомянул такую замечательную вещь как Erlings. Расскажи подробнее, как давно вы с ней живете и насколько вам нравится этот framework. Расскажу. На самом деле, давно живу с ним только я. Я с ним живу еще с момента его первого появления в open-source. Помню, даже выпуск был у вас про Erlings, какой-то очень древний, 26-й, по-моему. Вот тогда, наверное, я начал заниматься. Мне было просто интересно. Я являюсь энтузиастом в стиле студентки в кафе. Извините. Пожалуйста. Пожалуйста, не забывай ставить мьют. Окей. Извините. Срочно. Да, так вот. Я с ним жил достаточно долго. На самом деле, в компании притащил его по необходимости. У нас был вставлен выбор, на чем реализовывать один из микросервисов. В этом микросервисе были проблемы многопоточности, были проблемы. То есть необходимо было сделать некий stateful service, который держит некоторые состояния в памяти, состояние обновляемое, чтобы он был надежный, собственно говоря, горизонтально масштабируемый и так далее. И Erlings подвернулся очень вовремя. И мои знания, и мой опыт использования Erlings в том числе. Сейчас мы написали на нем всего один сервис. Он уже работает у нас в проде. Кашу не просит. Один раз он у нас упал. Точнее, не он упал, а упала соответствующая нода. И мы дали уже выкокер Erlings. Успешно переподнял умерших актеров на новой ноде. То есть в принципе сервис там с наглушавой работает, но просто медленнее. Так что мы уже вовочь наблюдали все прелести использования Erlings как технологии в страте. Алло. Ну, по поводу Erlings понятно. То есть в цепи технологии рабочей. А вот ты упомянул, что были проблемы с многопоточностью. А что конкретно? Что конкретно? Ну, конкретно у нас есть, как я уже говорил, мы мониторим большое количество разнообразных тем. Каждая такая тема представляется в единице многопоточности. Ну, конкуренция, скажем так, unit of concurrency, unit of distribution. Ну, если вы представите, что такое обработка stateful stream processing, то у вас есть какой-то входящий поток данных. И из этого потока данных можно надергать сообщения, эти сообщения могут попадать в разные темы. Соответственно, мы не можем каждый раз переподнимать для каждой темы все ее настройки, весь ее стейт, все ее каунтеры и прочее для каждого упоминания. Нужно этот стейт хранить в памяти, чтобы это было быстро и эффективно. Вот, собственно говоря, такой простой кейс у нас был одним из первых. Стоит вы честно мерджите или вы просто забиваете, когда актер переезжает? Ещё раз. Если актеру нужно переехать, вы стоит честно мерджите или забиваете? Если актеру нужно переехать? Ну да, у Марлинса, насколько я помню, он не даёт гарантии на то, что у тебя актер строго один. В какой-то момент, если актер переезжает не потому, что машина упала, а потому что сеть провалась, актера может быть на самом деле краткое время два. Да, есть такой момент. При сплитбрейне действительно рейтинги сходятся подобным образом. Мы на самом деле рессолвуем проблемы такого рода через сторидж. В сторидже, безусловно, используются оптимистические конкуренции. В случае, если два актера живут и пытаются записать этот стейт, то мы, собственно говоря, это рессолвуем через underlying storage. Нет, подожди, а какой-нибудь может результат через underlying storage, если у тебя есть две копии актера, одна живёт-живёт-живёт, что-то делает, накопила какой-то стейт, ещё не успела сохранить, и то же самое происходило со второй, она тоже накопила какой-то стейт, который не совместим с первой, и успела сохранить. А потом первая захотела тоже сохранить. Ну прекрасно, и она получит проблему, что тег не совпадает. Мы сохраняем данный поток, который на самом деле точно так же имеет собственную версию, тег не совпадения простой версии, мы получаем этот secret currency conflict, то есть обычный rss. И что вы с ним делаете? Мы просто деактивируем одного актера, и всё. То есть один актер деактивируется, а один остается. То есть все данные, которые он увидел, которые не успел записать, они просто выбрасываются? Нет, неправда, они не выбрасываются. Дело в том, что данные на актера попадают... Ну, тот, кто кушает данные на актера. Вы знаете, Orleans — это же RPC-система, асинхронная в принципе. То есть мы всегда получаем аннольджмент от актера, записал ли он данные, обработал ли он их успешно или нет. Соответственно, если он сказал, что их не обработал, не успел их записать, то месседж, скорее всего, просто обернется в очередь. У нас еще есть система очередей, о которой я не говорил. А если вы на каждую обработку сообщения пишите в Storage, то зачем тогда Orleans? Не на каждую обработку сообщения. Во-первых, у нас есть батчинг, достаточно оптимально написанный. Во-вторых, orleans нужен, я же уже сказал, даже если мы будем каждый раз каждый месседж писать в State, нам все равно необходимы некоторые данные для обработки этого упоминания. Мы не можем за этими данными постоянно лазить куда-то и где-то их искать, не даже находиться в памяти. Этот State, который необходим для обработки этого упоминания, собственно говоря, стоит самой темы, но он может достаточно быть обширным. Это может быть какой-то набор словарей, это могут быть любые другие настройки, это могут быть кантеры по теме и прочее. Это может прилично занимать количество памяти, поэтому на одной машине реально такое поместится. Собственно, orleans нам дает простой способ распределения этого State между машинами в таком надежном отказов слышимом виде. То есть я понимаю, у вас получается один актор, он затвечает за какое-то одно упоминание, правильно я понимаю? Нет, не за упоминание. Актор отвечает за topic, за целую тему. А хорошо, что у вас такое тема? Надо было бы начинать. Окей, GSCAN занимается мониторингом социальных сетей. Что это значит? Это означает, что наши клиенты создают, например, представьте себе, вы какой-то бренд, допустим Nestlé, у вас есть там куча каких-то продуктов, киткат и прочее. Вам интересно, что люди говорят о данном продукте в интернете. Ну, для каких-то своих целей. Собственно говоря, каждая тема представляет из себя, каждый topic представляет из себя вот такой выделенный запрос по GSCAN, под который мы подбираем данные. То есть у нас есть свое решение, мы данными буквами его запустили, это наш разработка карикатуры мы сделали, которая сделана на базе эластика. Он умеет подбирать, собственно говоря, упоминания под поисковые запросы. Такие поисковые запросы достаточно сложные, это не какой-то интересный физического разбора, который необходимо быстро проверить на входящем тексте. И вот это все занимает очень большое количество времени, собственно, и ЦПУ времени, и прочего. Хорошо, то есть я понимаю, у вас получается один актор на один topic, а почему какую-то социальную сеть, скажем? Просто на один topic. То есть получается один актор отвечает за несколько социальных сетей, правильно? Ну, у нас в 14-м деле не так выглядит, но может быть, у нас очень серьезные подробности, я не знаю, насколько я могу об этом говорить, но примерно выглядит это так. Представьте себе, у вас есть весь интернет, вся эта свалка, называемая интернетом, Facebook, Twitter и прочее. Вот они все наваливают сообщения на одним большим потоком. Представьте себе, да, приблизительно, вот этот стрим входящих в поминание. Теперь нам нужно с этого стрима вытащить все знания, которые подходят под наши поисковые запросы. Каждый поисковый запрос — это тема. Тем у нас тысячи. Я понимаю, то есть у вас получается, вы все-все-все, грубо говоря, весь интернет сваливаете в один большой стрим, а потом уже по этому стриму вы с помощью запросов его разбиваете на маленькие потоки, и за каждый поток отвечает конкретный актор, правильно? Вот, похоже. Некоторые приложения очень похожи, да. То есть, грубо говоря, у нас есть каждый актер, это маленький поток, который отвечает только за свою тему, за свой набор, за свой поисковый запрос. А вот расскажи, ты упомянул Orlinx, а есть еще проект Orlinka, это одно и то же? Типа, с чем они отличаются? Ну, расскажу. Значит, проект Orlinka, он называется Орлянка, ну ладно, пускай будет Орлянка, Орлинка. Значит, это проект, который я делаю с Анаисом Сунцоном Молдаваном, с которым я и говорил в начале выпуска. Проект этот стартанул в свое время как такой, ну скажем, мы были очень недовольны тем, как Орлинкс, мы были довольны тем, как Орлинкс концептуально, что он с этой историей, ну и как он сделан изначально. То есть, у него было очень много подводных камней, грабель, он был очень неудобный, и как только появился лотансорс, он был очень такой сложный в использовании и понимании, и он совершенно не работал в офшарпе. Так как мы были фанатами офшарпа, то решили все-таки сделать что-нибудь, запилить. Я думаю, сейчас Антон скорее всего это расскажет. Антон, ты хочешь мне рассказать больше про Орлянк и про офшарп? Да, да, да, конечно. Боже, сука, что происходит. Пожалуйста, мьет гости, которые не говорят, не забывайте. Окей, да, вопрос про Орлянку был. В общем, я написал блог-пост про Орлянку, introduction to Орлянка, и там я описал главные причины, по которым мы захотели сделать что-то похожее. Нам очень нравился, скажем так, нам нравился API Аки, то, как накидывается, как он работает, нам нравился API Аки, то, как нативно вам представляется актер, как abstraction над стейтом, и API. И нам хотелось добавить, основная штука была, нам хотелось добавить поддержку офшарпа. На данный момент времени офшарп довольно показывает хороший профит, популярность, в дутнет комьюнити сейчас многие начали о нем говорить, это что-то, может, подобие скалы наджавеями, но не такая популярность еще, конечно, как в скале. Мы знаем, почему скалы, такая популярность. Но в офшарп она тоже начинает набирать обороты, и в принципе Орлянку основной из идей было добавить поддержку офшарпа в нее, но чтобы это выглядело синтаксически похоже с АКА. То есть в офшарпе, как в языке, вы можете добавлять свои операторы, вы можете строить неплохой DSL, местами мне он больше нравится, чем в АКИ. И, собственно, с этого мы и начали. Мы начали прототипировать API, так, чтобы нам было это удобно использовать, чтобы он был readable, читать было понятно. И старались какими-то, не знаю, не вбиваться, не вдаваться сильно в пьюрити подхода. Например, тут же есть АКА.NET, порт АКИ, но на дотнете. И у них офшарп API есть, биндинги, да, АКИ. И они там используют, например, они актер представляют как рекурсивная функция, что является вроде бы прикольно. И правильно, но выглядит, скажем, читать не так это удобно. И даже для, ну, просто вот, ты просто define актер, убираешь с него просто state, убираешь какую-то логику. У тебя просто есть актер, приходит, у тебя есть mailbox, ты с него получаешь message. И вот эта вся штука, она создает noise, хотя актер, по сути, ничего вообще не делает. И уже noise есть. Вот, нам это очень не нравилось, с рекурсивными функциями, все такое, работать, ну, не всегда удобно. Вот, мы смотрели на это прагматично, чтобы это было в шарп, но это был обычный класс, в нем был какой-то state. И у нас, в принципе, есть эта функция receive, которая в АКИ есть. Но этот receive у нас, он purity, он не purity, sorry, он fpash сделан, то есть у вас есть input и у вас есть output всегда. У вас нет какой-то, ну, фракции, то есть у вас есть input и у вас есть output всегда. У вас нет как в АКИ, просто any и unit возвращается, ничего. То есть у нас возвращается реально result всегда. И вы можете на этом строить ваш pipeline, data processing, что угодно. В принципе, про орлянку, не знаю, она еще много фишек. Могу еще рассказать интересное кое-что. Начинай с простого. Сейчас уже больше стали развивать проект в сторону добавления каких-то фишек, которых нам, казалось, не хватает в орлянце. Последнее, что я добавил, это была поддержка подписок на стримы. В орлянце есть, в принципе, абстракция стримов. Опять же, удобство использования самой абстракции такое себе, и для меня было интересно попробовать сделать. .. Знаете, кто вообще знаком с CQRS, с таким же как и Unsourcing и CQRS? Ну, я думаю, у нас все знают про это. Супер, супер, прекрасно. Вот я как раз и начал развивать орлянку именно больше в сторону абстракции CQRS и Unsourcing. Туда добавили подписки, интересно было сделать что-то вроде декларативных проекций, то есть возможности подписываться на потоки декларативным образом. Добавили различные абстракции, вроде подписки по RegEx и прочих шалостей. В последнее время проект сейчас... Что самое интересное с орлянкой произошло, это то, что нас заметил Microsoft. Мы достаточно плотно общались с ребятами из Microsoft. Многие фичи, которые есть сейчас в орлянке, они в том или ином виде уже портируются обратно в Orleans. То есть у нас там, грубо говоря, воруют все, что понравилось, что я считаю хорошо. Вот. Про орлянку, собственно, все. Считайте, что орлянка это некий такой гибрид между Orleans-ом и ACA-й. Изначально, когда я делал орлянку, само слово орлянка, если вы знаете, такая русская игра была, по сути, это Орел и решка, когда подбрасываете монетку. Игра слов заключалась в том, что всем нравится Orleans, но в ACA лучше API. Так вот, чтобы не приходилось выбирать, мы сделали орлянку, нечто среднее между Orleans-ом и ACA. Ну, по сути, все. Я еще хотел добавить... Уважаемый ProGhost, ставь милки, я тебя очень прошу, сколько можно? Я не могу камп включить, секунду, он у меня заблокировался. У тебя что, Windows? Нет, у меня... да, Windows. Окей. Секунду. Ага. Окей, я продолжу. В общем... Ты это, мышку трогай периодически, чтобы такого больше не было, пожалуйста. Поглаживай ее. Ну и да, я просто хотел бы попросить второго гостя, там говорят, ты чат не читаешь, вот, почитай. По той же причине у меня был заблокирован компьютер. С другой стороны, мне звонила жена, встретила у нас тут проблемы на работе, так что мне извините. Секунду. С другой стороны, он предоставляет вам, он делает такую, как бы, RPC модель, что ли, то есть он вас врапит, делает вам API определенный, то есть если это на C-Sharp вы девелопируете, да, то есть вы просто делаете интерфейс с определенными методами, функциями, и для вашего клиента, там, кто разрабатывает, для него это просто общение с классом. То есть он не понимает реально, ну, что происходит under the hood, да, что там посылается message, там, сериализируется и все такое. То есть, да, он использует, он видит это на pipe level, он видит, что это future, он понимает, что это что-то асинхронное, но вот как это происходит, этого не явно. В F-Sharp, с другой стороны, очень хороший, ну, стандартная фича для фпшных языков, pattern match, но там очень выразительно они смотрятся, они так, как в Scala, ну, и плюшка, что у вас by default, всегда компайлер заставляет handle case, в Scala вам, если я не ошибаюсь, приходится метить ваш модификатор, добавлять какой-то sealed или какой-то, чтобы ваш pattern matching был более умный и он уже понимал, что вот эти кейсы входят в этот тип, а эти, ну, их нужно по-любому handle. В F-Sharp та же самая штука, но она by default включена, ее нельзя отключить, и она очень природно выглядит, то есть мы просто конвертнули, то, что в Orleans есть, мы сделали так, что мы просто явно человек создает message, он явно отсылает, это очень отличает Орлянку от Orleans. В Orleans вы работаете просто как с обычным классом, его создали, объект на нем методы вызыватель, то есть вот эта фишка, она нам очень не нравилась, не нравится в Orleans сейчас. У нас также, кроме F-Sharp, такая же очень похожая C-Sharp версия, она была даже первой, и там нет pattern matching, как бы в C-Sharp пока его нет, его вроде бы обещали в 7 C-Sharp добавить, но я не знаю, добавят или нет. Но там у нас просто есть хендлеры отдельные, мы там просто используем convention over configuration, вы просто define ваши хендлеры и типа message, и диспатч у вас происходит за кулисами. А расскажи, вот эти актеры, они у вас типизированы, либо как в ACK, просто N не передается? Нет, у нас они могут быть, смотрите, фишка F-Sharp, F-Sharp использует Hindley-Miller type inference, как в Haskell, если не ошибаюсь, в Caml, в CML, ML подобное, ML family. И много вещей, это очень реально, ты кайфуешь, когда пишешь на F-Sharp, что ты не define типы, настолько классно, когда ты пишешь API, мы не пишем реально тип message, какой мы принимаем, он все понимает, ты начинаешь match, он понимает, какой тип message ты начинаешь match. С return type, когда ты return, у нас реально возвращается объект, но на клиенте, когда у тебя есть F-Sharp клиент, и он этот актер послал message, и теперь он делает await на него и приводит к типу, так вот это приведение делается типизировано, хотя в рентайме может произойти ошибка, но в F-Sharp, когда ты пишешь тип, он уже понимает, что ты работаешь с string или ты работаешь с integer, это как некий side effect, он тебе чуть помогает, ты реально понимаешь, тебе не приходит object, хотя бы что-то он помогает, но с посылкой message, когда ты реально посылаешь message, у нас есть эта фишка, у нас есть фишка type от актеров, мы можем метить наши актеры определенным интерфейсом, и после этого вы не можете этот message, грубо говоря, когда вы делаете ask или send, ваш актер ref, он ожидает только этот тип message, а никакой другой, по практике мы его не использовали, это фича есть, но я не видел какого-то распространенного, даже вот Женя не использует орлянку в проде, на продакшене они, если я не ошибаюсь, не используют эту фичу.",
    "result": {
      "query": "Orleans / ..?"
    }
  }
]
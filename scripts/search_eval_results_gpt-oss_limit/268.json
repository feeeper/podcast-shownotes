[
  {
    "segment_id": "b87151c9-5e68-4dd8-93e4-2d1a963b1e6f",
    "episode_id": "82f616fe-bf9f-4b8f-b7f3-1e42e249fae5",
    "episode_number": 268,
    "segment_number": 5,
    "text": "Это правило, то есть всё, что заболевает, всё то и забирается. То есть её зачастую так многие используют для того, чтобы данные из одного места переложить в другое. И даже некоторые проекты её используют буквально, как лог транзакции для себя. Средственно, вокруг Kafka есть... У компании Confluent, которая её разрабатывает, есть экосистема, в частности, фреймворк Kafka Streams для поточной обработки на основе Kafka. И поверх Kafka Streams у них был SQL-интерфейс к нему, назывался ksql. Но он был не очень популярен, потому что, ну, как-то... Не знаю, наверное, потому что он не так много вещей позволял делать, а им хотелось большего. И вот они взяли и на этой неделе анонсировали, по-моему, на этой неделе, может быть, ну, была раньше, я просто пропустил, но мне кажется, на этой. Они анонсировали, что они делают ksqlDB. По большому счёту произошла следующая штука. Они помимо того, чтобы SQL-поверх стрима делать, они добавили возможность что-то из стрима материализовывать в какие-то вьюхи, в RoxDB или в памяти, и потом к этим вьюхам тоже ходить через тот же самый SQL, через REST-интерфейс. Вот, это, на самом деле, очень офигенно мощная абстракция, потому что, ну, теперь можно довольно нетривиальный стрим-процессинг делать на... Ну, как бы при помощи довольно простых SQL-выражений, которые просто будут жить в этом, как бы, ksql-е. И почему это важно? Потому что я человек, проработавший, там, не знаю, года три с флинком, например. Ну и, в принципе, на самом деле, Spark в этом плане не то чтобы кардинально лучше, хотя Spark поудобнее, на самом деле. Обычно, когда у вас есть, скажем, поток данных, там, ну, вы откуда-то данные забираете, ну, если вы от тех, например, у вас есть клики рекламные, вы их кладёте в кавку, ну, там, не только клики, но и всякие разные события. Внутри этой кавки, там, что-то происходит. Вы, например, там, хотите делать, построить разные срезы, там, не знаю, вы хотите, например, срез по каким-то, там, не знаю, который будет делать вам метрики в плане того, что, не знаю, с каких-то источников трафика приходят, скажем, пользователи, которые в среднем столько-то живут, столько-то платят. А можете, например, делать какой-то другой срез. Я не буду вдаваться сильно в детали, но я думаю, идея примерно понятна. Или я слишком мутно говорю? Всё нормально, продолжай. Вот. И вот вы, чтобы это делать, чтобы этот срез строить, вы обычно ставите какой-то, там, не знаю, офигительный процессинг-энжен, типа того же Spark, типа Flink'а, садитесь на этот поток, начинаете строить эти агрегационные окна, потом вам это нужно куда-то обратно записать. Скорее всего, вы берёте там какую-то ещё базу, в неё пишете, вот, построены агрегаты, и потом вы пишете какой-то веб-интерфейс, который, или, там, не знаю, какой-то рест-интерфейс, который выходит в эту же материализованную базу, из неё выгребает и отдаёт в сокет. И это просто, типа, простейший вариант. В реальности там обычно гораздо больше всего наверчено. Ещё какой-нибудь, не знаю, Airflow стоит, управляет теми джобами, которые в разные места перекладывают. Ещё какой-нибудь, не знаю, Hadoop стоит с каким-то Data Lake'ом, тут всё. Это на самом деле абсолютная бакханалия, с которой тяжело и сложно жить. Кроме самых сложных или требующих какого-то безумного перформанса кейсов, на самом деле можно гораздо меньшими силами обходиться. И вот CSQLDB, похоже, стремятся решить, вот, пойти именно в эту сторону, потому что, не знаю, какой-нибудь Flink, если смотреть на их маркетинговый материал последних лет, они пытаются, типа, утащить всё внутрь Flink'а, то есть, типа, у вас есть какой-то поток, вы на него садите прекрасный Flink, и дальше у вас там происходит обработка близко к данным, и у вас, значит, всё состояние внутри Flink'а, Flink его клёво менеджит, снапшотит и так далее. Прекрасно на словах, быстро работает. Одна проблема — этот стейт внутри Flink'а, он... это просто чёрный ящик, к которому хрен подберёшься. А здесь же они идут от, ну, ребят из Confluent, они идут от экспириенса, который... ну, как-то, да, девелоперского опыта, который люди имеют с SQL базами, и очень многие Data Engineers, они, ну, норм все чувствуются с SQL'ем. И что прекрасно в SQL базах, ну, и на самом деле даже в обычных NoSQL базах, вы всегда можете хоть как-то получить значение по ключу, то есть, если у вас какой-то внутренний стоит Flink'а или Spark'а, просто к этому внутреннему стейту, к нему фиг подберёшься. То есть, если у вас какая-то проблема на продакшене, нужно там чуть-чуть вот в одном месте подкрутить, это нужно специальный кистыль завозить для этого обычно. В случае SQL баз или даже в случае NoSQL баз вы просто можете сходить в нужный ключ там и что-то поправить, ну, как мы привыкли в обычных приложениях делать. В случае SQL база ещё можно довольно легко получить ответ на какой-то нетривиальный вопрос, который, ну, не запрограммирован в основное приложение, но поскольку у нас довольно гибкий язык запросов, мы можем вот этот запрос как бы одноразово сделать, а потом уже как-нибудь его встроить. Собственно, да, здесь пошли по похожему пути, то есть идея в том, что у нас есть какая-то система, которая сама умеет данные выгребать, сама умеет по ним вьюхи строить, и даже может, как бы, типа, динамически их перестраивать и так далее. И потом она же может содержимое этих вьюх отдавать каким-то внешним приложениям, и это позволяет большинству вот этих вот кейсов по всасыванию массивного потока данных и построению каких-то срезов, которые потом дальше используются там сервисами в вашей инфраструктуре, она позволяет всё это держать в одной системе. И я считаю, это очень круто, и эта система, она ещё, кроме прочего, скорее всего, будет достаточно хорошо оперироваться, потому что она исходит от гибкого языка запросов, а не из того, что напишите вот здесь кастомного кода, кастомному размахрованию их состояния, а мы вам сделаем быстро. Да, всё ещё для каких-то прям очень высокотрафиковых нагрузок вам, скорее всего, придётся затепловать Cluster Spark или Flink или ещё чего-то, но мне кажется, что большинство кейсов это покроет, и я очень рад, что технология вот... что ребята из Confluent пошли в эту сторону. Я прям не могу достаточно выразить, насколько я этому рад. Никто больше не рад? Один я рад. Если вкратце, в чём была... Ну, то есть я уверен, что в чём-то была, я просто с этим не работал, поэтому расскажи, пожалуйста, в чём была проблема это выгребать каким-то приложением и складывать в Postgres? В чём проблема? В том, что приложение нужно написать. А потом это приложение будет в внутреннем state, ну там, скажем, эти окна, которые там 20 минут агрегационные, и... типа, как бы туда вообще никак не слазить, ты никаких-то механизмов не построил. А здесь у тебя готовый программный продукт, где ты пишешь одно SQL-выражение, ну или там два SQL-выражения, которые делают тебе нужный... строят тебе нужный срез данных, и всё, ты в дамках. А есть ли этому решению 10 лет? Пока нет, к сожалению, но я очень рад, что хоть кто-то туда пошёл.",
    "result": {
      "query": "ksqlDB потоковая SQL агрегация"
    }
  }
]
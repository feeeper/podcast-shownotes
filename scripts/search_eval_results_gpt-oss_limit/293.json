[
  {
    "segment_id": "d158f87f-2fff-42c5-83a8-dd3e3e3e103e",
    "episode_id": "f42a7787-9b35-4bba-8d35-e1da1dfa8636",
    "episode_number": 293,
    "segment_number": 5,
    "text": "Да, все верно. Окей, спасибо за объяснение. Ну, по поводу Моноге, я в этом уже решении не участвовал. Но первая мысль, что, как я уже сказал, почему-то была выбрана система, когда все запись и чтение идет через мастер-ноду, хотя поднимаются их несколько. И так как в будущем предполагается, что система будет управлять непосредственно всей фабрикой, она, конечно, не очень большая, порядка 100 руб. рук, наверное, из десяток этих логистических модов, известно, где-то еще порядка, ну, также сотни камер, что это все будет одна единая система. И информацию, которую, условно, выплюнул камера на одном конце фабрики, она должна быть доступна на другом конце фабрики относительно максимально быстро. И насколько я помню, тогда из разговоров говорилось, что с Монгой будут проблемы при вот таком горизонтальном масштабировании, что мы упремся в пропускную способность мастер-серверов, в то время как Кассандра нужна больше нагрузкой, докидывай в нее ноды, и будет тебе счастье. Но, опять же, насколько так оно будет, не могу сказать, так как Кассандру в продакшене никогда не использовал. Слушай, а еще вопрос. Ты сказал про требования довольно жесткие к latency, 20 мс. Это круто. А скажи, откуда они пришли? И если такое latency, насколько со скала это все работает? Потому что зачастую, когда идут такие жесткие требования к latency, используются другие инструменты, и там часто идут на языки, где нет garbage-коллектора. Особенно если учитывая, что 20 мс. это же на всю систему. Это жестко. В RTV real-time bitting там 100 мс. и уже это чувствуется как довольно жесткое ограничение. 20 мс. это еще жестче. Расскажи, пожалуйста, про это. Это требование от компьютерного зрения исходит. Там какая концепция? Стоят несколько камер, они обрабатывают каждый кадр, получают с него какую-то информацию. Нашли деталь, не нашли деталь, какие-то опорные точки на сцене, которые они смотрят. И вот с этой информацией они уплевывают в нашу систему. На другой конце нашей системы стоит сервис-агрегатор. Он собирает эти данные с камер и выплевывает уже обработанные. То есть где конкретно находятся детали по уточненным координатам трех камер в относительных мировых координат нашей системы. И, собственно, это требование порядка 27 мс. исходит именно из частоты работы камер. По самом деле камеры работают с более высокой частотой. Сейчас они меньше выдают. В будущем есть в планах порядка 60 fps, но такое мы уже не потянем, но особой необходимости в этом нет. А вот порядка 20 мс. камеры работают, порядка 30 fps они точно пишут. Скажу, что мне сам нравится. А что ты думаешь по поводу использования скалы как языка и платформы для такого требования? Мне кажется, что GVM вполне подходит, если высокочастотную торговлю на ней пишут, то почему нет? Когда у нас все было на concurrent flashmaps, у нас такая задержка составляла порядка 10 мс. Иногда были короткие пики в районе 50 мс. Подожди, стой. 20 мс. это на всю систему целиком. То есть когда у вас кавка передает сообщение, эти 20 мс. учитываются в этой кавке, поэтому кавка не подошла. Да, да. То есть одна система принимает запрос, формирует в касанду какой-то запрос, потом другая система из этой касандры вытаскивает это, что-то обрабатывает, потом отправляет по обратному маршруту, и все это вмещается в 20 мс.? Нет, с касандры не взлетело. А с кем взлетело? Я просто пропустил, извини, пожалуйста. Да, я же говорю, что у нас получилось, у нас есть когда-то требование, порядка 20 мс., ну, потолок 30 мс., но все равно достаточно жесткий потолок. Да, это жесткий потолок. И понадобилась персистентность, поэтому параллельно как бы шла монга, параллельно были попытки затащить с целой с касандрой. Монгу затащили, она на текущий момент нам обеспечила требуемую персистентность и близкие к целевому лэттенсе. На нее получился лэттенсе, по-моему, порядка 40 мс. Погоди секунду, это больше, чем 30? Больше. Поэтому это и не целевая, поэтому, кстати, в том числе, да, наверное, поэтому еще не целевая текстура. Далее еще вопрос. Как вы в данном случае используете монгу? То есть я пока не очень понимаю, что вот эти 30 мс. разрешают. То есть вам кто-то делает кадр, посылает вам через что? То есть делает запрос или у вас сама система делает этот снимок, и уже внутри системы есть начало, или как это происходит? Я пытаюсь понять, как вы считаете 30 мс. То есть в РТБ там, понятно, там приходит запрос в систему, и СИСервис должен отдать там за 100 мс. какие-то данные. В данном случае у вас сервис, кавка, плюс еще раз сервис, или сервис-кавка, сервис-кавка-сервис, или как происходит обработка? Кавки нет. Я кавку утверду, в данном случае, любая система, которая сохраняет данные, передает данные, редис, что угодно. У нашего сервиса есть АПИ. Оно, кстати, в неданном моменте РСТП. У него есть такой замечательный метод. Он утепляется, говорит, я жду условно 30 секунд, пока не прилетит данные, нужные мне под запрос. И соответственно есть также постметод, который эти данные отправляет. И считается задержка, когда мы данные повесили консюмера с этим методом, с ожиданием 30 секунд, пока он какие-то данные не получит от нас, и отправляется сообщение в нашу систему также через РСТП. И смотрится, заслуг она долетела до консюмера. Давай повторю, чтобы точно понять. У вас есть РСТП, которые кто-то делает ползапрос к вам, и ждет в течение 30 секунд, вы должны быстро отдавать туда сообщение. Это ГЭТ, получается. ГЭТ запросом вытаскивает с вас данные и ждет, пока у вас нет данных. В этот момент кто-то постом вам шлет сообщение, данные с этой картинкой, и вы должны их обработать и на тот предыдущий на ГЭТ отправить ответ. Я правильно сказал? Да. Понял. И вот это все должно выполнится за 20 секунд, но я так понимаю, что вам поставили какой-то лимит в 30, вы пытаетесь оптимизировать до 20, чтобы у вас оставался какой-то запас в прочности. То есть вы ставите себе 20 мс, и 20 мс включено, у вас есть какое-то брокер сообщение, вы через этот брокер сообщение кому-то присылаете, получаете ответ, и отдаете обратно все это в 20 мс? Да. Окей. Так как первоначальная архитектура, по ее итогам, пока это все было на конкретных хэшмоб, пока это все прекрасно работало, но в реальном мире, когда это нужно еще сохранять, перестает работать. Я вот, знаете, пока упор не понимаю, окей, у вас есть две задачи – передать и сохранить, и вы такое ощущение, что их решаете как будто бы одновременно, то есть что вам мешает построить какую-то систему передач данных, вообще типа реал тайм, обход всей скальной истории, там типа максимально о готовых технологиях, и потом просто на нее же присесть к каким-то отдельной штуке, которая будет просто вычитывать и сохранять, и типа вообще не писать никакого кода для этого, потому что ну типа есть какие-то брокеры с низкой задержкой, и есть типа готовое решение для Persistence, который там, не знаю, хоть на файловую систему кладите, и как бы не очень понимаю, зачем вообще-то как бы типа пытаться как вокруг какой-то скалы писать какой-то код, который будет сохранен в какую-то монгу или к Сциллу еще или еще куда-то, или пытаться найти реал таймер. Может в них транзакционность требуется? Нет, нет, нет, транзакционность не требуется, просто была идея сделать некоторые апи, в котором можно уже пользоваться, который будет удобен для команд, который будет позволять чуть больше, чем просто отправить сообщение и получить его на другом конце, то есть он там может делать некоторые преобразования. Это, кстати, не секция сообщений, в частности, для тех, у которых установлен лимит в 20 мс, там их никак предобрабатывать не надо, они просто что на входе получили, то на выходе отдали. Вот, и так как в текущей истории стиктура не взлетела, сейчас решение переписывается, то есть пока апи остается тот же самый, но предполагается, что будет использоваться как раз вот RabbitMQ данные, в общем, я так понимаю, что RabbitMQ с персистентностью, что он не потеряет данные. По крайней мере, если мы в него отправили, то он их уже не потеряет, что если мы вдруг упадем, переподнимемся, данные останутся.",
    "result": {
      "query": "Mongo master node latency 20 ms"
    }
  }
]
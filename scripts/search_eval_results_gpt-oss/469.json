[
  {
    "segment_id": "2410e6d0-9a9f-49cb-8f07-992a1a91b3f5",
    "episode_id": "a9f0c2ca-8b90-4ee0-a232-c581ad983e79",
    "episode_number": 469,
    "segment_number": 13,
    "text": "Если подумать, то если у тебя есть массив byte, то byte всего 256 штук. И зная, что ты сортируешь массив byte, ты вместо наивного алгоритма, там, типа, там, quicksort, да, вызвать, ты можешь применить алгоритм подсчетом. То есть просто завозишь 256 счетчиков, считаешь, каких bytes сколько у тебя в массиве, и потом генерируешь или заполняешь in place исходный массив. И получаешь алгоритм со сложностью o, a, t. Как бы классно-классно. Что еще? Из неочевидного у тебя там в какой-то момент докладчик задает вопрос. Вот я предлагаю всем, над ним подумать. У тебя имеется некий объект, некая сущность в двух экземплярах. И известно, что их внутреннее представление, то есть они с точностью до бита идентичны. Как бы первый объект и второй объект. Верно ли утверждение, что во всех случаях эти эти сущности, эти объекты будут считаться равными? Кто как считает? Ну, мне кажется, если я сортировал. Не разобрал. Можно вопрос еще раз? Я спрашивал в контексте сортировок. Ну, неважно. У тебя есть объект a, объект b. Ты знаешь, что внутри они с точностью до бита эквивалентны. Спрашивается, верно ли, что мы такие объекты, такие сущности всегда считаем равными? Они по одному адресу лежат? Да неважно. В смысле, неважно? Я утверждаю, что для решения задачи эта информация не требуется. Они могут лежать по одному адресу, они могут лежать по разным адресам. Это неважно. Ну, то есть, если это два разных объекта, это уже совершенно точно не... Если это не одно и то же место в памяти, это совершенно точно уже не... Я понял. Их физически... Я могу тебе сказать, что их адрес в памяти не учитывается. Наверное, у тебя есть сортировки, тебе меньше либо равно, а есть сортировки, тебе строго меньше. И у тебя операция равности может... Подожди. В вопросе сортировка вообще не фигурировала. А, сортировка, окей, да. Просто всегда можем считать их равными. Равность — это настолько размытое понятие, что я вот начинаю думать, и я понимаю, что я не понимаю вопроса. То есть, вообще ты всегда хочешь дать человеку, оператор, ну как, не знаю, опять же, ты всегда хочешь человеку определить оператор равенства. То есть, это равенство с точки зрения языка программирования, как ты пишешь семантику программы. Так скажем так, я знаю... Мы тут все писали на языке программирования, где если объекты равны до байта, они будут считаться равными. Да. Так я не услышал ответ. Я хочу услышать... Мир, он черно-белый, есть только единички и нольки. Я хочу... Всегда ли... Наверное, не всегда, но есть языки, где всегда. Я хочу услышать, да или нет. Ваня, равны? Могу на двух языках написать программу, где они будут не равны. Это ответ, да или нет? Ну, я так его интерпретирую, что ты считаешь, что нет, не всегда. Получается, что не всегда. Хорошо, а Макс? Ну, они опять же... Может, не могу. Никаких it depends. Я хочу услышать, да или нет. Я, кстати, титку собираю. Ну, а эти дан... Эти экземпляры класса идентичные. Ну, то есть у них есть какие-то свойства, которые могут мутировать их же самих? Ну, то есть я к тому, что они могут быть одинаковые. Еще можно это смотреть. В какой момент мы сравниваем, да? Ну, я могу тебе сказать, что ты можешь считать, что у тебя на одном процессоре работает в один thread программа, она берет локи перед тем, как сравнить, то есть как бы без подвоха. Не упарываем, то есть вот такого нет. Ну, окей, давайте я, чтобы была другая позиция, скажу, что всегда одинаково, хотя я подозреваю, что, может быть, подвох в вопросе. Но давайте скажу, что всегда одинаково. Хорошо, окей. Валера? Я не принимаю твоего отсутствия it depends, потому что, как минимум, человек джавист. В java equals можно переопределять, поэтому больше, что у тебя сортировки полагаются на equals, но у тебя еще есть оператор равно, который, если не ошибаюсь, equals не учитывает. Вроде учитывает, но я давно не писал на java. Ну, у java нормальная семантика в этом отношении, и это все, что я помню. Да, возможно, я дурачок. Может быть, ты еще плюс-плюс путаешь, но там нет equals. Да, там есть перегрузка оператора. Короче, неважно, есть языки с перегрузкой операторов, где, можно написать любое, пошел в жопу. Вот, но даже если бы мы... Короче, я просто не хочу затягивать выпуск. Даже если бы не было перегрузки операторов, у тебя для флоутов и дабл есть такое занимательное значение, как not a number. Not a number не равен любому другому числу, включая самого себя. Поэтому, если у тебя даже есть объект, и в нем есть поле дабл, то если ты присвоишь ему not a number, этот объект, и ты его сравниваешь с каким-то вменяемым оператором сравнения, все равно у тебя not a number не равен любому другому даблу или флоуту. Вот. Плюс к этому, ну, вообще-то мы тут все бэкэнзеры, и у нас есть базы данных, а в базах данных есть такое замечательное значение null. Null equals null. Это значение равно чему? Null. Правильно. Я боялся, ты скажешь false. Вот. Да, поэтому это было просто такое занимательное упражнение для самоконтроля, которое, если ты автор алгоритма сортировки или вообще каких-то библиотечных функций, ты должен об этом помнить. А еще в этом же контексте ты должен помнить, что бывает ноль и минус ноль. И это разные значения. Вот. В целом я рекомендую этот доклад посмотреть. Он прикольный, он идет 40 минут, его можно смотреть на скорости полтора, при том, что там часть доклада занимает ответы на вопросы. Вот. И если вы работаете над чем-то не вполне тривиальным, то есть, ну, типа вот у вас есть проекты, которые используют готовые сортировки, а есть какой-нибудь странный позграс, который использует свои реализации сортировок и контейнеров. Вот. Или, может быть, какие-то компиляторы. Да, в принципе, любой проект на носи. То, посмотрев этот доклад, вы сразу получаете идею для 10-20 патчей в этот ваш проект, потому что ну, казалось бы, такие базовые идеи, что там есть сортировка по счетам, которая работает за линейное время, но если ты вот слишком давно во всем этом варишься и не вечерами не почитываешь, не полистываешь книжки по алгоритмам, об этом очень легко забыть. Вот. А это такая... Это база. Саша, врешь ты все. Равно-равно в Java это не equals. М-м-м. Как интересно. То есть... Ты со скалой путаешь. Очень может быть. И тогда как это работает? То есть есть equals, а есть равно-равно, и равно-равно это по-моему этого сравнения. Это не совсем по-моему... Как бы оно... И equals может быть в некоторых ситуациях одинаково определено, но они не всегда одинаково определены. Ну что ж. Я очень много лет не трогал Java. И не то чтобы сильно этим расстроен. А чем я еще совершенно не расстроен, это следующая наша тема, а именно тем, что фреймворк Laptop 16 уже завезли на склад, и его можно прямо заказать. Напомню, что это как бы открытый, как бы модульный ноутбук, на котором будет офигенно работать Linux, и когда в нем что-то сломается, вы не будете нести весь ноутбук на помойку, а замените его на сломанный модуль. А также вы можете к нему выбрать... Ну то есть у тебя есть вот базовая модель 16 дюймов, а дальше ты думаешь, хочешь ты глянцевый экран или матовый экран. Вот мне нравится матовая, но я сижу на толпанном Mac'е, который из-за меня решил, что все экраны должны быть глянцевыми. А здесь я могу, как нормальный человек, выбрать себе матовый экран, потому что это единственный правильный способ делать экраны. И можно выбрать себе... Типа у тебя есть два варианта колонок, одни из них, у них звук погромче, но АЧХ не очень ровный, а у других АЧХ ровный, но звучат они потише. И ты можешь из тех модулей, которые тебе нравятся, собрать то, что тебе нравится, а не то, что за тебя решил вендор. Я считаю это прекрасно. Что еще прекрасно, это следующая наша тема, а именно инициатива по запихиванию пайтест в Postgres. С этим пропозлом в рассылку на бро... Этот пропозл сделал Джейкоб Чемпион, мой бывший коллега, который к сожалению попал под лей-оффы, и теперь он работает в Enterprise DB и задается мне, что у него там все отлично. И вот он предлагает в Postgres добавить... То есть, напомню, в Postgres в качестве тестов и в качестве скрептового языка для этих тестов используется Perl. Скрептного языка. Скрептного языка для тестов. Скрептного языка для... А, я понял, да. Скрептный язык для тестов. Perl и Framework TestMore, но по неизвестным причинам как бы общим знаменателем для программистов в индустрии как будто бы является Python и многих людей, которые могли бы хотеть прийти в проект. Напомню, в любом проекте есть куча активности помимо написания мозгодробящего кода. Можно писать тесты, можно писать документацию, можно ревьюировать чужой код. Можно организовывать юзер-группы локальные и так далее и тому подобное. Так вот, многие люди, которые могли бы прийти в проект и, например, писать тесты для Postgres, их отталкивает то, что это приходится делать на Perl. И рабочая версия, что поддержка Python и PyTest, это было бы правильным шагом для проекта в долгосрочной перспективе. В целом, в сообществе как будто бы мало людей, которые прям жестко отторгают эту идею. То есть там есть, по-моему, один был такой человек, но большинство людей, они скорее так больше интересуются, типа ну а почему PyTest? Может, есть там фреймворки получше? Давайте обсудим плюсы и минусы существующих фреймворков для Python. В таком ключе. В целом, мне кажется, эта идея, она полетит. Что характерно, убежден, что лет пять назад она бы нифига не полетела. Ну, потому что там еще были вопросики уровня, что вот у нас там есть Python 2 и Python 3, такая странная ситуация, ничего не понятно. Сейчас уже такого вопроса нет. Еще был вопрос, что а вот Postgres надо собирать на кучу разных платформ, и везде есть Perl, а Python как будто бы есть не совсем везде. Ну, или он есть, но неправильная версия. Вот. Сейчас этот вопрос вроде как тоже уже не поднимается, видимо, потерял актуальность. Вот. Поэтому, мне кажется, что это полетит. Другой вопрос, как быстро, то есть это, возможно, работает не на год и не на два, но дело хорошее. Это была тема одной строкой. У меня все. Вопросы, возражения, комментарии. Я надеюсь, это потолкнется, потому что писать тесты на PyTest для даже, возможно, сложных систем в других языках, это гораздо более приятное занятие, чем писать их на смеси Perl и SQL. И, как бы, у меня даже претензии не столько к Perl, но, в данной ситуации, сколько тому, сколько там колец годовых наросло, чего я опасаюсь, что у нас появится еще одно годовое кольцо в виде PyTest, а старые не уедут. Вот было бы здорово, если бы пришел какой-то клевый, не знаю, спонсор, забросал бы этот проект деньгами, и тесты были бы портированы с старого фреймворка на новый фреймворк. Вот это было бы потрясающе. А какие годовые кольца ты имеешь в виду? Ну, то есть, насколько я осведомлен, то, что касается тестов на Perl, там все совершенно, блин, просто язык не всем нравится. Вот эта история с разными шедулерами, расписаниями для гоняния тестов и вот эти регрессионные тесты, это же не Perl, это какая-то еще отдельная херня. Я понял, о чем ты, окей, окей, принимай. Вот, то есть, видишь, уже две херни. Это возвращаясь к прошлому или позапрошлому выпуску про сложность, которая нарастает. И которые люди внутри не замечают, потому что думают, что... Фрактально катятся. В задницу. Ой, там просто вот то, что Валер описывает, это в PostgreSQL не считается сложностью. Там сложность в других местах, и там ебнешься вообще, вот. А это то, что Валер назвал, это ерунда. Хорошо. Знаете, с чего мы еще не ебнемся? С того, какой чудесный клауд раскатил Apple. В общем, тут прошла WDLODC. Мы их обычно редко обсуждаем, но я иногда выхватываю какие-то темки, которые меня зацепили. В данном случае тема одной строкой, потому что я достаточно разбираюсь в вопросе. То есть я прочитал новость, но я не разбираюсь в предметной области достаточно хорошо, чтобы это как-то интересно и детально рассказать. Было бы прикольно, если кто-то, кто в этом разбирается, пришел и помог нам про это поговорить. Там, кроме прочего, анонсировали, Apple много говорил про всякие фишечки для Vision Pro, для того, как они разрешат вам иконки перетаскивать на iOS, а потом они такие, что они могут заработать на Apple Intelligence. Но вот Apple Intelligence, это, конечно, здорово, и Apple старались весь свой былой Intelligence гонять у вас локально на устройстве. Что, ну, Siri, в принципе, ходила в интернет, но кроме отдельных моментов Siri, оно по максимуму исполнялось у вас на устройстве, и они явно в это начали упираться. И в качестве решения они сделали облако, которое работает примерно на том же самом железе, что телефоны и планшеты только мощнее. И интересно здесь то, что оно настолько обмазано всякими проверками, рандомизацией, подписями, криптографией, не знаю, кросс-чеками, какими-то сторонними аудитами и так далее, что они во всяком случае пытаются создать впечатление и возможно, действительно, внутри оно так работает, что вот ваш телефон, ему нужно сделать какую-то задачу, которая не влазит в его вычислительные мощности, но доступен интернет, он ее может зафлодить куда-то в это специальное AI-облако, он там посчитает, с вами вернется результат. Никто никогда, кроме как, вот, не знаю, может быть, если человек имеет прям прямой доступ к машине, вот непонятные статьи из маркетинговой Apple-блога, насколько это хорошо защищено от того, что, не знаю, сотрудник, James, подойдет и нажмет все кнопки локально, не знаю, флешку ставит, я надеюсь, он тоже как-то защищается, но во всяком случае, даже если кто-то вломится в этот дата-центр, он не сможет создать закладку, потому что все постоянно там, типа, кругом Secure Boot, кругом подписи всего софта, который гоняется, и эти подписи сверяются постоянно там, и они на устройство прилетают вещи, которые подписаны. Я, конечно, не разбираюсь, недостаточно глубоко разбирался во всех этих схематозах, и мне сложно прокрутить себя в голове, как каждая из этих вещей, которые в посте отписаны, от каких векторов атак она защищает, но мне это зацепило мой взгляд именно то, что такое количество усилий прилагается к тому, чтобы защитить этот кусочек вычислений, которые вы отправили в интернет, потому что в 99% случаев как бы, не знаю, если мы посмотрим тот же Google или Microsoft, ну, типа, ответно здорово, а там Adobe просто, все ваши данные теперь по EULA наши, иди в жопу. Вот. А здесь такое количество усилий, чтобы ну, как бы, Apple много где в других местах в жопу посылает, но вот здесь в жопу не посылают. Мне это нравится, и просто даже инженерно выглядит как-то в отрыве от того, что это там продукт компании Apple, это выглядит как какая-то безумно крутая задача, вот из той же серии, что мы обсуждали детерминированный гипервизор несколько выпусков подряд, вот мне это кажется из той же серии безумно крутой проект, безумно сложный, не знаю, насколько это реально работает, но звучит впечатляюще. Вот, ссылки все прилагаются и на оригинальный пост, и на трансфер с разбором. Другая вещь, которая зацепила мое внимание на этой неделе, о чем у нас там по времени, черт возьми, ладно, я думаю, я успею быстренько это рассказать. Я раньше очень любил рассказывать про всякие консенсусы, паксы, вот это все. В 2020 году в 2020 году вышла такая такой алгоритм консенсуса Delos, точнее статья. Delos это даже не алгоритм, Delos это система в Фейсбуке, и у них есть статья про то, как они там делали консенсус. Я ее примерно в 2020-2021 году прочитал, и как-то даже не стал в подкаст, по-моему, приносить, я во всяком случае не нашел по сайт упоминаний. Почему так? Потому что я посмотрел на это, ну, глазами пробежался, и оно для меня показалось, не знаю, Фейсбук решает проблемы, а больших компаний применительно алгоритм консенсуса, и, типа, почему нам нужно про это говорить в подкасте, не очень понятно. Мне не очень было понятно, в чем крутость тех идей, которые они там предлагают, про которые, собственно, сами идеи я сейчас до них зайду. А тут я был на метапе, и это всплыло, это всплыло в таком контексте, что у меня как бы щелкнуло все в голове. Я такой, блин, нифига себе, нужно было больше этому внимания уделить, потом, оказывается, я тоже еще вернулся к этой статье, оказалось, что она выиграла вообще лучший best paper, короче, того года на той конференции, где она выходила. Эта статья, в смысле. Вот. Что такого интересного они там делают? Они там не изобретают нового протокола консенсуса. Они вводят такое понятие, как виртуальный консенсус. Когда у нас вся наша, не знаю, вся наша вот система разделяется на несколько более простых компонентов, и, в принципе, у нас есть все, что нужно. У нас есть какой-то метаслой, метастор, который гоняет консенсус. Самый классический, это может быть какой-то максимально тупой алгоритм, включая там даже просто самый обычный Paxos, не MultiPaxos, а прям просто самый банальный Paxos. Там буквально, там нужно, чтобы в этом метасторе нужно хранить минимальное количество информации, и туда с ним редко происходят какие-то сложные операции. Можно взять что-то готовое с полки, можно написать какой-то свой простой консенсус, неважно. Важно то, что это место почти не нужно скейлить, это место хранит мало информации, но, по сути, хранит информацию о том, из чего у нас сейчас состоит виртуальный лог. Виртуальный лог собирается из таких вот штук, которые называются логлиты. Логлит это... Ну, то есть, наверное, с другой стороны зайдем. Большинство современных, прям современных-современных протоколов консенсуса, они пришли к тому, что их сразу начали описывать не в терминах операции над какими-то регистрами, а сразу, ну, типа мы лог собираем. То есть, если посмотреть описание крафта, там натурально про лог идет речь. И обычно нам, когда мы строим базу данных, нужен лог репликации. Мы договариваемся о последовательности каких-то действий. Вот. Ну и делался это тоже распределенная база данных, как я понимаю, из контекста. Им нужен был вот, собственно, лог, в котором операция из базы данных. И, соответственно, они вводят такую штуку, как логлет. Логлет — это под какой-то интервал записи в логе. И общий виртуальный лог собирается из множества логлетов. Логлеты, они бывают как это, опечатанные, sealed. И они бывают, вот один логлет сейчас может быть активен. Чем это интересно? Тем, что вот протокол самого логлета может быть довольно простым. Ему, логлету, оказывается, не нужен настоящий большой сложный логлитм консенсуса. Ему достаточно иметь надежный надежную операцию к воровной записи. Ему нужна к воровной операция «дай последнее» и чтение того, что мы уже знаем, что записано, можно вообще делать типа с одной машины. И еще один очень важный примитив — это отказоустойчивая операция опечатывания. Но если у нас для пэнда нужен кворум, для чектейл, ну типа «дай последнее» нужен кворум, то очевидно, что мы можем при помощи кворумного пэнда на самом деле даже нет, мы можем сделать это. Сейчас. Короче, я уже забыл, как они определяют вот full-tolerance сил. По-моему, достаточно просто хотя бы в одно место записать, что «ой, что-то не шмогли», и тут же оно все сразу печатается. И как только кто-то один заметил, что оно должно быть опечатано, оно продолжает просто писать информацию о том, что оно должно быть опечатано. И соответственно, после того, как логлит опечатывается, вводится в строй новый. Не очень понятно, что значит «опечатывается». Ну, туда больше нельзя писать. Угу, окей. Вот. Ну то есть, короче, как только что-то произошло, как только кто-то заметил какую-то неполадку, логлит сразу опечатывается, и туда больше никто не может писать, и мы, типа, переконфигурируем систему. Вот. Собственно, тут входит в игру Metastore. Это, в общем-то, единственная операция, которая требуется от Metastore, это когда логлит опечатали, типа, на виртуальном логе отметить новую точку, куда встроится новый логлит, ну и, соответственно, инициализировать его. Ну, да. Да. И, соответственно, он будет опечатывать новый логлит. Новый, там, сервер, вот и все. И, там, типа, сохранить, грубо говоря, какой-то endpoint, сохранить, куда дальше ходить. Дальше из этой конструкции можно собирать интересное. Можно, например, сделать такой, типа, striping loglite. Это такой, как бы, еще один слой виртуальных логлитов, который будет между двумя, тремя или четырьмя нормальными логлитами просто по round-robin гонять ячейки. Там нужно быть аккуратным с тем, что, типа, он не может начинать отдавать на чтение ячейку до того, как предыдущая ячейка заполнилась полностью durable на запись. Но в целом оно позволяет скейлить запись в некоторых ситуациях. Но самое интересное во всей этой конструкции, ну, то есть вся конструкция была изначально построена для того, чтобы смочь быстро и надежно в рамках большой компании, большой команды итерироваться вот над этим примитивом виртуального лога, потому что, по сути, вам нужно один раз написать и отладить эту логовицу, один раз написать и отладить эту метастору. А дальше вы можете довольно много себе позволить, потому что вы даже можете за счет того, что у вас есть метастора, вы даже можете атероактивно поменять кусок виртуального лого. Если у вас там произошел какой-то упс, вы, на самом деле, можете заменить часть истории, за счет того, что вы там метастор напишите вот по такой-то кусок истории читаем velond embassy côngана blitz 버кая. облачных системах, это позволяет вам брать просто старые куски лога, не совсем выбрасывать, а, например, переносить их на какой-нибудь более дешевый сторож. Еще это вам позволяет, в принципе, вообще весь консенсус организовать поверх чего-то типа S3. Потому что в S3 вы как раз можете реализовать эту full-tolerant seal и кворумные записи, кворумные чтения. А вот прям консенсусы классического пакса вы на S3 написать не можете. Но если у вас есть какой-то сервер, который вам обеспечивает ваш метастор, то вы можете устроить себе делас, прям просто делас подобный в этот виртуальный консенсус поверх сервера с метастором и S3. И вот это уже прям очень интересный примитив в облаке. Поэтому, в общем, нужно будет мне внимательно перечислять, как они этот full-tolerant seal точно делают, но в целом прям неожиданно интересная система, которую я изначально по глупости своей отмел. Как-то так. То есть отличие от остальных в том, что они ввели концепцию не лого, как делают обычно для того, чтобы делать консенсус, а они ввели концепцию абстрактную, которая позволила им делать консенсус на разных вещах. На самом деле, знаешь, что меня это очень сильно напомнило? Я приносил в 16-м году такой пейпер Корфу, где тоже из очень примитивных, и там, по-моему, были SSD-шки или просто диски с прикрученным к ним FPGA-шкой. Эта FPGA умела посетить очень примитивные вещи, типа Append, тоже, силы, еще что-то еще, и они из этого тоже собирали очень быстрый виртуальный лог. Вот здесь оно по духу очень похоже. Есть какие-то ограниченное количество по-настоящему умных компонентов в системе, которые не обязаны сильно скейлиться. Есть компонент, который, собственно, обеспечивает пропускную способность, и он гораздо более тупой. Ну, то есть, их идея в том, что они разделили реплицированный лог на отдельно сложный кусок с консенсусом и кусок, который легко скейлить и легко улучшать throughput, который делили. Я примерно понял, но хочется почитать. Это относится только к их базе данных Dallas? Или это как-то...",
    "result": {
      "error": "API request failed: Error code: 400 - {'error': 'Trying to keep the first 6591 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': 'Trying to keep the first 6591 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}\n"
    }
  }
]
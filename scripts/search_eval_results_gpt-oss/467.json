[
  {
    "segment_id": "f6d9d2a8-437e-45fb-8d18-031d090c9977",
    "episode_id": "15f7933a-ac2f-4b39-af5f-8e5dc39ac1a8",
    "episode_number": 467,
    "segment_number": 6,
    "text": "И там было написано, что раздел на Curly в скобочках Demos. И я офигел от того, что в 2024 году все еще существует, этот каталог, хотя он переименовался, я так понимаю, он уже за какие-то донаты живет, судя по шапке сайта, но тем не менее. Там есть мой блог. Ничего себе. Там есть мой блог в этом каталоге. Не знаю, кто пользуется каталогами сайтов, но такой занимательный факт. Слушай, учитывая, в какой одище скатились поисковики в последнее время, возможно, это неплохо, нужно попробовать. Попробуй. Тут, кстати, недавно коллега жаловался, он пользуется DuckDuckGo и говорит, что я зашел, и он лежит. Но я тогда открыл Bing, как второй а он тоже лежит. А знаешь, почему? А знаешь, почему хочется, когда откроем? Его версия была, что у них один бэкэнд. Но, может быть, они просто в одном дата-центре. Не-не-не. DuckDuckGo известно, что они используют в качестве базового поисковика Bing. Это нескрываемый факт. Они не анонимизируют твои запросы, но ниже лежачий поисковик Bing. Ну что ж. Ну, все новое хорошо забытое старое. Каталоги сайтов и вперед. Вот. А еще там в статье про Perl были примеры того, как там в две строчки пишется простой веб-сайт на веб-фреймворке Majalicious. Был такой веб-фреймворк, я на нем писал. Прям прот. Он действительно клевый. Вот. Я решил проверить, а как он там, он живой? Не живой. У него есть сайт, у него есть гитхаб. На гитхабе там есть коммиты. То есть как бы технология, видимо, довольно нишевая, но тем не менее она существует, она все еще развивается. И, кстати, вот я вижу эту аватарку Себастина Рейдела. Это создатель изначально Catalyst. Это более старый веб-фреймворк для Perl. А теперь и Majalicious. Он все еще поддерживает. То есть я последний раз трогал эту технологию году в 2012-2013. Даже, нет, Majalicious я трогал в 2011. Я вот прям бложик открыл проверить. В 2011 году я писал под Majalicious. Тогда это была прям, ну, модная новая технология. Она только-только появилась. Такая хипстерная. Вот. Она все еще существует. И тот же человек, который ее создал, он все еще ее мейнтейнит. Что меня удивляет. Это все к чему? Во-первых, если мне, например, в голову придет идея переписать свой бложик, ну, потому что он сейчас на старой версии WordPress, то мне ничто не мешает сделать это на Perl и на Majalicious, потому что какая разница? Я один буду это поддерживать. А второй момент, что сдается мне, что у Erlang у него как бы... Это менее нишевая технология, чем Perl, по моим представлениям. Хотя вопрос дискуссионный. Вот. Поэтому, сдается мне, лет через 13-15 все у него будет нормально. Perl. Perl. Ну, я честно не понимаю, чем людям нравится так этот Python. Ну, вот у меня как человек, который большую часть времени пишет на C, мне более понятна концепция скобочек фигурных, там, точек с запятой. Ну, то есть, мне приятнее на этом писать, а Python, Ruby, ну, как бы я могу на них писать, но мне все-таки кажется чуждой эта концепция. Знаешь, я хочу сделать поиск по регулярному выражению, мне нужно написать там import re. re.majl. re.majl. чего-то там от чего-то строки. Зачем мне что-то импортировать? Зачем мне вызывать метод на каком-то объекте? Я просто хочу регулярку применить. У меня в Perl это один оператор. Ну, как бы это проще, лаконичнее. Ну, как бы это и писать проще, и читать проще. Ну, и опять же, мне вот фигурные скобочки больше нравятся. Но людям почему-то не зашло. Я не вправе осуждать. Но мне для моего личного проекта, почему бы не взять Perl? А потом придешь к нам и расскажешь, скажешь свои ощущения. Будет очень интересно. Ну, ничем не хуже Python, я тебе точно скажу. Давай-давай-давай, попиши. Мне интересно будет через год. То есть, как бы вот прошел год, и вот в этот момент мы с тобой пообщаемся. Пообщаемся про Perl или про Perl? Про Perl. Так, Саша, что много лет писал на Perl? Ну, да, что именно тебя интересует? Ты писал, когда последний раз в Production Radio систему или хотя бы бложик? Ну, вот я несколько минут раньше говорил, что я написал небольшой скрипт для своей задачи. Но в нем 57 строк. Я на Python постоянно пишу скрипт. Но писать систему в Production на Python я сейчас не буду ни в коем случае. Это совершенно разные вещи. Я к тому, что ты с тех пор, как ты писал последний раз на Perl, ты уже много что пописал на других языках, на других платформах, на других системах. И твои воспоминания, они уже не актуальны. Твои воспоминания, это были воспоминания из твоего предыдущего тебя. И мне было бы интересно услышать... Слушай, но, с другой стороны, если около Production система называет свой бложик, то, знаешь, у меня есть такое вот мнение, это не мое мнение, но я его услышал и очень сильно разделяю. Нужно брать то, на что ты можешь быстро что-то захерачить. Что я подозреваю, сегодняшний период, на самом деле, нужно брать что-то GPT. А Perl — это лучшая технология, чтобы быстро что-то нахерачить. То есть человечество буквально не запрело, ничего лучше, чтобы быстро что-то нахерачить. Подожди, ну только бэш, бэш, на бэше. Чат GPT? Ну или так, да. Ну что-то мы отверклись. А что у нас там? Напиши, все равно напиши, а потом приходи через годик. А дальше прям что мы хотим больше, Pre-Commit Fest Party или Fastbook Club? Давай быстро Fastbook Club, а то я забуду уже потом, что я хотел рассказать. В общем, мне досталась тут книжка совершенно случайно, я же пользуюсь Honeycomb, honeycomb.io, вот, и они раздавали книжку за своим авторством для того, чтобы описать лучше, что же они делают и почему они это делают, и я ее тут полистал, почитал. Не скажу, что я прям сильно впечатлился, но несколько вещей меня прям как-то захотелось рассказать в подкасте. И я внезапно понял, я поймал себя на мысли, что у меня уже прям какая-то профдеформация их продуктом. Они, они, внутри себя сравнивают, как же, как же, подождите, сейчас, как они тут сформулировали, мониторинг против observability, это как перевести обзор возможностей, обзору... Observability, мне кажется, лучше не стоит пытаться переводить, потому что, вот, мне кажется, мы привыкли говорить observability, давайте не будем этого переводить, потому что под этим, вот это такой термин, под которым понимаются определенные вещи, и вот, собственно, здесь они даже поставят в противовес мониторингу, и я, когда начинаю вот это читать, я понимаю, что я их, как бы, я с ними согласен, но одновременно я понимаю, что я уже перестал понимать, что значит слово мониторинг. Что такое мониторинг для тех людей, которые еще не пересели, вот, на observability? Мне всегда казалось, что мониторинг это, знаешь, такой, типа, это часть observability процессов, вот, типа, ты обмазался какими-то метриками, ты на них смотришь, ты какие-то на них аллеры поставил, здорово, например, у тебя нет возможности ни в какой-то, не знаю, даун произвести, у тебя не обязательно есть возможность какую-то там переагрегацию метрик сделать, ну, отхок. Опять же, под observability подразумевается не только метрики, но там, типа, логи, трассировочные ивенты, всякая распределенная трассировка, то есть, ну, типа, опять же, мониторинг предполагает, знаешь, как такая, типа, вот стоит какая-то штука, и она тебя просто мониторит, это такой как-то статический сетап observability, это как девоп в свое время, это такое упражнение, такая практика, про которую нужно спрессать всей командой, а не только кому-то одному. Да, и ты прям вот, как будто бы часть книжку читал, часть фраз оттуда повторяешь. Я просто понимаю, что я работал над, я книжку не читал, я просто работал же, когда я работал в Timescale, один из проектов, над которыми я работал, был как раз про observability. Ага, понятно. Вот. В книге делается сравнение с помощью того, что observability это... Нет, мониторинг, сначала мониторинг. Мониторинг это статическая вещь. То есть, как бы, вот ты хочешь мониторить состояние, я не знаю, сколько CPU ты используешь на машине, и вот ты говоришь, я добавляю себе мониторинг уровня CPU, использование CPU, там, раз в секунду, грубо говоря. Ну, я утрирую сейчас. Или какое-то количество реквестов, приходящее в сервис. И это вещь, которую очень тяжело потом использовать по-другому. То есть, как бы, вот у тебя есть число запросов, и ты никак по-другому это использовать не сможешь. В отличие от этого, observability это когда ты фактически можешь любую часть системы, ну, то есть, как бы, ты кладешь в систему, внешнего контроля, внешнего контроля твоей системы, вот, как Honeycomb, которая делает. Ты кладешь туда все. Ты кладешь туда логи, ты кладешь туда трейсы, ты кладешь сюда любые ивенты, а потом говоришь в какой-то момент, о, кстати, а что-то вот мне в этой точке там подозрение какое-то есть. Давай-ка я начну копать. И начинаешь копать то, что ты никогда до этого не копал. И вот возможность копать то, что ты специально не пытался до этого подумать о том, чтобы добавить эту возможность. Вот. Это как раз они отличают observability от мониторинга. То есть, мониторинг, ты заранее подумал, добавил метрику и потом за ней смотришь. Обзервабилити ты добавил туда все, что можешь добавлять, а потом смотришь то, что ты хочешь смотреть, а не то, что ты как бы вот изначально планировал. Вот. И я понимаю, да, наверное, это реально смена парадигмы. То есть, я всегда воспринимал это, у меня в голове перемещение с одного на другое произошло очень плавно. Я не заметил, как я поменял свою... свою точку зрения. И это прям прикольно понаблюдать. А знаешь, просто опять же, будучи человеком, который стартовал, ну не то, что прям стартовал карьеру, но в начале карьеры рано подоконался с такой вещью, как Erlang, где можно обмазать довольно произвольными observability практиками, было практически любую систему без того, чтобы заранее с этим что-то делать. После этого сложно было даже местами без таких инструментов. Сейчас с этим стало сильно лучше, потому что все-таки eBPF вначале появился, а сейчас уже поверх eBPF понавертели инструменты, которые могут в любой скомпилированный код понасувать пробов. Или если вы еще сами пробов понаставили, вообще будет шикарно. Вот. И они это все могут как-то в себя вобрать и потом еще как-то красиво проагрегировать или позволить вам запрашивать это произвольно. Был момент, когда нужно было писать на других платформах, а там этих фичей не было. И общесистемных тоже, ну они уже, eBPF уже был, но пользоваться им было не так просто. Да. И, значит, единственное, что я хочу здесь добавить, на что они прям сквозь всю книжку обращают внимание, я хочу это описать, это они очень сильно подчеркивают на роль кардинальности, размерности метрики. То есть как бы вот вы кладете какую-то строчку, посылаете метрику, там тип запрос, который вам пришел, или метод, там, get post и так далее. Соответственно, если у вас есть метод, у вас там этих, не знаю, 10-15. Вот. А некоторые метрики, некоторые типы запросов, там, или некоторый API, который у вас есть, он может быть, кардинальность у него может быть намного выше, если у вас огромное количество типов запросов. Вот. И, соответственно, если ваша система мониторинга, в кавычках, это как бы вот старая система, она позволит вам какие-то счетчики, кладываете все, она не позволит вам сказать, а вот, кстати, давай-ка найдем те проблемы, когда у нас вот в этом месте была такая строчка, и с чем у нас происходит корреляция в нашей системе, там, с ростом CPU, памяти или еще чего-нибудь. То есть, как бы, когда у вас, ваша система заранее, вы знаете, что у вас кардинальность очень высокая, кардинальность, опять забыл, как ты это красиво перевел. Размерность. Размерность, точно. Вот. Когда вы знаете заранее, что ваша система позволяет работать с метриками, высокой размерности, вы совершенно по-другому себя ведете. Вы, как бы, ваш шаблон работы с этой системой меняется. Вот. Это прямо прикольно понаблюдать за собой. Вот. А вторая, это роль, у них тут все размерности, кардиналити и дименшаналити. То есть, вот, как бы, дименшаналити, точно, размерность, Валера. Вот. Кардиналити, это количество разных метрик внутри, разных, значений внутри одной метрики, дименшаналити, количество разных метрик, которые вы посылаете. То есть, прямо сейчас я понимаю, что мне вот в этой точке хочется послать, ну, например, я печатаю, вот я обработал запрос, и ответ пользователю окей или ошибка. И, соответственно, я не знаю, latency такая-то. Вот, фактически, у меня там три метрики. Первая, это строчка, которая напечатается. Вторая, ошибка или не ошибка. Третья, это, latency. Вот. Но одновременно в этой точке я могу послать ведь еще и кучу всего. А какой у нас, я не знаю, тип пользователя, если у меня несколько типов пользователя, а какой у него ID пользователя, а какой у меня в этот момент использовалось, сильно использовалось CPU, мгновенное значение использования CPU. И, как бы, когда я начинаю вот так вот делать, добавлять возможные метрики, которые меня, возможно, в дальнейшем заинтересуют, а вообще это становится частью библиотеки, просто логирование. Оказывается, что ты совершенно имеешь дикую кучу возможностей для расследования проблемы постктом. То есть, у тебя система просто послала кучу всего, и вот это вот dimensionality, то есть, вы послали огромное количество раз метрик. А потом, после проблемы, ты можешь вернуться назад, посмотреть, так, а вот здесь вот у меня было то, а вот здесь у меня было это. О, кстати, а давай посмотрим вот эту корреляцию, сравним это с этим. И бах, что-то всплывает. То есть, как бы, если вы делаете, если вы делали мониторинг системы в их терминах, то есть, как бы, вы заранее продумали, я хочу вот в этой точке этот счетчик, а вот в той точке количество вот таких ошибок такого типа, вы никогда это не сможете сделать. А если у вас есть система, которая позволяет вот это вот строить observability, то вы сможете восстанавливать очень большое количество информации из той информации, которую вы обычно слете и никогда не используете. Я надеюсь, я понятно объясняюсь. Валер, ладно, ты с этим возился, Саша, я понятно объясняюсь? Ну, в общих чертах. Вот. Короче, книжка, я не скажу, что она прям супер-супер, я имею в виду, что лично мне, после того, как я пользуюсь этой системой или подобными системами, как правильно сказал Валера, мы до этого работали с Erlang, она мало что мне новую информацию дала.",
    "result": {
      "error": "API request failed: Error code: 400 - {'error': 'Trying to keep the first 4161 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': 'Trying to keep the first 4161 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}\n"
    }
  }
]
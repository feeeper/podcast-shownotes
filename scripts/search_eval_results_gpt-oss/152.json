[
  {
    "segment_id": "8fdc3258-c042-4f4e-b422-5cca91858b45",
    "episode_id": "415bd6fd-e4ab-4ae2-809f-a8e93fed86d7",
    "episode_number": 152,
    "segment_number": 5,
    "text": "Саш, ты безопасник или где? Я читаю новость, вижу там Браткома и ни в коем случае не сомневаюсь, что это ненадёжно. Но новость хороша, на самом деле такая хардкорная, тут такие большие фешные листинги, и по-моему я видел куски прямо байт-кода, да, вот они. Так что, ну и с обсуждением на Hacker News, где он новость набрал от 367 очков, вот. Но вы поймите меня правильно, мы просто не можем прям все-все-все темы готовить, вы могли заметить, что их и так было немало. Вот, но я кажется осуждаю, осуждаю, нет, я кажется одобряю эту новость, она интересная, её прям можно распечатать и почитать за кофе. Там дальше пошли противоречивые темы, я думаю мы последний раз смотрим. В частности, слушатель Содин говорит, что Рест устарел и... Простите, Рест устарел и... да, я не мог это произнести спокойно. И Граф Киэль всех заборол, вот. Новость набрала 5 голосов и 2 дизлайка, поэтому она опустилась ниже остальных. Что-то там... Граф Киэль звучит знакомо, это про что? Это фейсбучный... короче, вот смотри, что люди только не делают, чтобы не использовать СКиэль, вот начнём так. То есть ребята из фейсбука поняли, что через Рест тащить сложные вложенные коллекции тяжело, потому что сейчас на Парест нужно будет делать слишком много вызовов, хотя по смыслу мы хотим набор связанных данных одной пачкой. Ну и нужно как-то это описать. В итоге они навертели костылей. Секундочку, я просто хотел бы уточнить. Речь идёт про случаи, когда ты хочешь создать N сущностей, которые с друг другом связаны. Скорее выгрести, ну и создать тоже. Пользователи, вот друзьяшки и так далее. Там не знаю, посты их, комментарии, которые там популярны, например. То есть посты и топ-комментарий к ним. И мы говорим про создание сущностей или их селект с джойном? Ну там в первую очередь селект, я думаю, потому что представь себе фейсбук, которому нужно это в первую очередь показывать. Но на самом деле, что люди только не делают, чтобы не использовать SQL любой другой язык запросов. Они делают какие-то ещё языки запросов. То есть я вообще, чем дольше живу, тем не понимаю, зачем мы вообще... Короче, да, я уже говорил, я не очень люблю SQL, за то, что он не очень позволяет рулить, что происходит внутри базы. Но он хорош тем, что язык запросов универсальный. И вот это просто... У меня в голове не укладывается, просто каждый раз мы, значит, чтобы вытащить что-то из базы, мы пишем целую большую приложуху, которая по большому счёту берёт параметры из HTTP-шного запроса, переписывает их в SQL при помощи кучи кода. И потом это SQL засовывает в базу, база что-то делает, и потом это всё обратно перелетает в сокет. Да, там бывает бизнес-логика иногда, иногда бывает очень нетривиальное, которое в базу не засунешь. Но чаще всего там всё очень тривиально, и на самом деле было бы достаточно просто создавать вьюхи под нужды. И просто потом эти вьюхи, чтобы отвязаться от конкретной схемы, типа для каждого отдельного клиента делаем вьюху, которую он просто queried. И вот мне кажется, что это было бы настолько, блин, проще, если бы все просто использовали один язык запросов, вместо того, чтобы гордиться каким-то REST, GraphQL, потом ещё, потом ещё, потом ещё что-то. И всё это положить на большой жарный сервер с двумя терабайтами памяти, с которого мы начинали выпуск. Ага. И обмазаться всевозможными пермишенами, возможно даже raw level. И в этот момент мы начинаем понимать чуваков, которые топят за «давайте засунем всю бизнес-логику в базу данных». Ну с поправкой на то, что там нет GTA, но вообще идея неплохая. Смотри, на самом деле я не фанат засунуть всю бизнес-логику в базу данных, потому что… Мы только что, извини, что я тебя прервал, мы только что выяснили, что не нужно писать приложение. Подожди, дай я закончу мысль. Потому что её засунутую в базу данных тяжело эволюционировать. Извини, а на основании чего ты пришёл к такому выводу? Ну вот текущий инструментарий так устроен. Ну а подробности ты не мог бы пример привести? Ну как, ты диплоил хранинки когда-нибудь на 10 серверов одновременно? Ну вполне, в Mail это всё только так работает. Ну да, ну короче там questionableные вещи некоторые. То есть у нас, да, мы тоже диплоим хранинки, у нас для этого есть Ruby Open Source. Но я просто поясню, наверное, для слушателей, которым интересно, как это, по крайней мере, у нас работало. Диплоилась новая версия хранинки, но там, я не знаю, наверное, ограничение MySQL, там нельзя было одно имя переиспользовать, поэтому была хранимка v1, хранимка v2 и так далее, которые диплоились новые, когда тебе нужно, потом приложение переезжало на неё, потом старые можно грохнуть. Вот, версионировать можно не обязательно прям последовательно, можно как-то, ну либо 2017.01, либо AB, если вам имена жалко по какой-то причине. Ну то есть в принципе, я просто честно пытаюсь понять проблему, о которой ты говоришь, но насколько я знаю, это вполне решаемо. Это ничем не отличается от двух версий IP, и тебе нужно мигрировать с одной на другую. Ну просто ты можешь делать при каждом диплое, вот в чём дело. При каждом изменении IP или добавлении IP. Ну а чем GraphQL в этом плане лучше? Нет, я про другое. Я про то, что на самом деле было бы клёво, если бы у нас можно было диплоить какую-то отдельную сущность, которая является таким SQL-приложением, грубо говоря, которая принимает запрос на каком-то условном таком SQL-пользовательском, делает с ним всё, что нужно, и передаёт там другой правильный SQL-базы, то есть там может резолвить permission, что-то ещё делать, потом в базу даёт такой более расширенный SQL, и база его исполняет, возвращает результат, и стремится обратно. То есть это возможно сделать, скорее всего, при помощи какого-то более-менее генерик фреймворка, который принимает запросы с одной стороны и просто их расширяет. Я писал подобную штуку. Нужно было выгребать некие данные по произвольному условию, при том условии его прям конечный пользователь в приложении ввозит прям руками. Ну, там для удобства есть кнопочки, но в общем случае он может ввести руками. И я решил это так, что приложение было на Haskell, Валера знает, про какое приложение речь, и там прямо на Ataparsec был написан небольшой парсер куска SQL, который прямо в Airosлове, там этот парсер, он там типа 10 строк занимает. И вот прям произвольный запрос со всеми скобочками, end, if, это я нагнал, end or not, он прям передавался по HTTP, валидировался, чтобы там нету всякой фигни, там BobbyDropTable и так далее, а потом уже подставлялся в полноценный запрос, и это скормливалось базе. Звучит как что-то, что ты хочешь. Или нет? Ну, похоже, близко-близко к тому. То есть мне хочется, чтобы еще, знаешь, какой-нибудь, не обязательно SQL, но стандартный язык на обеих сторонах. На самом деле, если ты из тех харкорных дебей, которые топят за вся логика в базе данных, ты вполне можешь настроить перемешанный так, что у приложения есть только нужные права, только к нужным таблицам, только на селект и так далее. Ну, то есть ты никакой фигни не надворишь. Понимаешь, в чем еще дело? Вот так деплоть в такую отдельную единицу, оно еще удобно тем, что эта отдельная единица может падать, перезапускаться и так далее, отдельно от базы данных. То есть ведь по сути у меня нет... Я не совсем понял. Я просто не понял, что ты имеешь в виду под отдельной единицей. Смотри, у тебя, то есть идея чего-то вроде хранимки в базе, это в том, чтобы... Ну, то есть такой главный плюс, потому что у тебя логика, она рядом с данными, она рядом с данными отрабатывает и возвращает только необходимые минимумы обратно. То есть ничего никуда не ездит, ни того, что не должно ездить. А с точки зрения операционной тебе гораздо проще оперировать. Если у тебя часто изменяющаяся часть, ее лучше отодрать от той части, которая меняется, не знаю, раз в год, когда баженый релиз выходит. Ну, просто тебе это гораздо проще оперировать. Особенность это, скорее всего, большинство оперируют разные команды, поэтому удобнее вот этот вот application logic держать как какой-то отдельный модуль, который там, да, если даже у него есть какая-то ошибка, если он падает, его нужно перезапускать, скорее всего, с ним это случаться будет чаще, чем с самой базой, и ему будет труднее ту же самую базу свалить или там как-то ее намертво повесить, потому что ты прибил этого несчастного, который что-то плохое делает, и запустил заново, вместо того, чтобы перезапускать всю базу и кэши переперегревать. Соответственно, вот этот кусочек хотелось бы иметь независимый, но при этом достаточно универсальный, чтобы он, да, SQL транслировал SQL. Вот что-то такое, не знаю, это довольно странная, возможно, идея. Мне про падение напомнило, что программирование на каком-нибудь PLPG SQL на самом деле похоже на программирование на Python, в том смысле, что, ну, во-первых, ты можешь просто писать хранение на Python, по крайней мере, в подгрузе, а во-вторых, тем, что если у тебя что-то тормозит, вот эти 10%, которые тормозят, тебе ничто не мешает переписать на C. Поэтому, может быть, необходимость в GT для идеи давайте всю бизнес-логику сложим в базу, она переоценена. Я вообще не понял твою мысль. Можно писать хранимки на C, будет быстро, но падать, но быстро. Нарасте. Очень быстро падать, кстати. Ну, у нас как бы, я, то есть, у нас есть C-шное расширение, это не хранимки, но есть C-шное расширение. Это не так больно, как кажется, но это, да, уходит больше времени. И все-таки, смотри, огромный плюс чего-то вроде SQL, в том, что его надо мало писать. То есть, ты можешь написать мало кода, а он сделает много вещей. Это прям даже иногда больно физически смотреть, как люди берут, используют какой-нибудь, не знаю, ActiveRecord, который ходит, просто вгребает по кусочке строчки в ваш руби, потом в руби делают цикл на цикле, на цикле, на цикле, и все это как-то фигачит на стороне приложения, а потом выплевывают маленький результат. При том, что можно было написать гораздо более маленький и компактный SQL expression, который еще будет быстро работать, и сделать больше, и кода нужно будет писать меньше, и тестировать нужно будет меньше. Вот я как-то вот к этому. На самом деле писать хранимки на C действительно совсем не больно. Во-первых, там есть интерфейс SPI, на котором ты вот просто SQL скармливаешь и получаешь в виде C-шных структур данные. Ну, то есть он выглядит прям просто и понятно. А если случай с агрегатами, который Валера приводил, я думаю, ну то есть это точно можно, прямо сходить в heap, прямо пройтись по нему в цикле и все сагрегировать. Я, правда, такого никогда не писал, я думаю, там есть подводные грабли. Но, кстати, это интересная тема для моего персонального исследования. Вы, Валер, таким не развлекались? Из экстеншена сходить прямо в heap и там в транзакции пройтись? Я не очень понимаю, о чем ты сейчас. То есть есть вопросы, подробнее расскажите. Можно, ну вот ты пишешь хранимку, чтобы она работала быстро, пишешь ее на C. Ты можешь через SPI, например, написать select и так далее, и потом обработать результат. Но это плохо работает для случая, который ты приводил, когда тебе нужно посчитать там разные агрегаты по трем столбцам. Всего причин, которые ты сам же озвучивал. Но это C-шное расширение. Тебе ничто не мешает из него ходить в базу не через интерфейс, который с select и так далее, а прямо в heap напрямую, там, где у тебя туплики, xmin, xmax и так далее. Понятно ли так и пытались ли вы так делать? Я понял, о чем ты. Те решения, которые я помню, C-шные, они типы данных, и, соответственно, они работают, в первую очередь, с типами данных. Плюс есть, я сейчас боюсь соврать, там были какие-то решения, которые были связаны с тем, как что-то query. А, нет, для типов данных были кастомные агрегаты, но, опять-таки, кастомные агрегаты для типов данных, они совсем в heap не ходят. Поэтому, мне кажется, мы так не пробовали. По-моему, у нас нет кода, который пытается такое делать. Но я не абсолютно в этом уверен. Но согласен с тем, что должно неплохо работать? Да, должно довольно клёво работать, только за тем исключением, что тебе, опять же, придётся вместо SQL-запроса хардкодить C. И ты, ну, тебе нужно будет переписывать подрис. В pipod переписывать не хочется. Ну, только в 10% кода, который тормозит. По-моему, это не так плохо. Ну, вот видишь, в чём дело? Вот, как бы так объяснить, то, что я упоминал, это практически 100% использования базы, ну, ладно, 99% использования базы, это вот там запрос определённого вида. И он постепенно эволюционирует. То есть у нас появляются новые столбцы, добавляются данные. Мы как-то немножко меняем логику агрегации. То есть это такая постоянно живущая штука. А тебе представь, что там написано на C. Ну, тебе нужны нормальные профессиональные C-шники. Я не вижу проблем, их много. Понимаешь, это даже просто сейчас деплой, опять-таки мы деплоим версию приложения, опа, всё новенькое работает. При том, база не имеет риска свалиться, и вот это всё. То есть, круто говоря, ты будешь время итерации менять на скорость работы самого приложения. И когда у тебя приложение в стадии, у нас клиенты начали этим пользоваться, давайте мы сейчас подпилим под нужды клиентов, оно у тебя будет бесконечно воевать с перформансом. И, да, согласен, технически то, что ты говоришь, это будет сделать можно, мы даже об этом думали, но вот именно потому, что это будет слишком замедлять разработку. А куда вы так спешите? Ну, это новый продукт. Можешь погуглить, adjust audience builder. Так и не надо оптимизировать то, что ещё не тормозит.",
    "result": {
      "query": "GraphQL vs REST nested collections performance"
    }
  }
]
[
  {
    "segment_id": "3cf8ad39-e413-4afd-bc85-41924e3beaa1",
    "episode_id": "9201f683-5681-4fe1-b2e0-2c3e645a235a",
    "episode_number": 73,
    "segment_number": 3,
    "text": "Вот, а про пейперы может вас заинтересовать, вот придите к шоу Ноте и посмотрите, может себе найдёте лёгкое частиво на новогодние праздники. Насколько я понял, пейпер 2015 года именно, то есть свежачок-свежачок. Я так понял имеются в виду пейперы, которые вы прочитали в 2015 году, интересно. А, вот так вот. Я подумал, что это 2015, всё, давай дальше. Следующая маленькая темка. Selectel ищет себе гоферов на проект Vscale. Vscale, это которые как DigitalOcean, только в Питере, из-за рубли. Ага, и у них закончились эти программисты на Haskell, и все три штуки, которые были в Питере, понимали, в чём разница между Монадой и Канадой. А это чё? Ну Selectel же вроде на Haskell всё своё писал. Не, я понял, а Info-то откуда? Они ушли? Из новости, что они теперь гоферов ищут. Ну, понимаешь, да? Подожди, подожди, не путай тёплые с мягким. Там на Haskell был совсем другой проект, который про управление датап-центром. Вот я тоже говорю, всё это какое-то несёшь. Я новости не читал, но... Ага, что случилось, я свидетель. Так, это Vscale, совсем другой проект, если что. Ну, так что же они, если Haskell так летит, что же они его везде-то не двигают? Так, следующая пройдёт конференция C++ Russia в Питере. Это будет уже в следующем году. Мне нравится, когда подходит Новый год, можно про всё говорить, что оно будет в следующем году. Когда катим Fitch.ua в следующем году. Ну вот, 26 и 27 февраля. C++ Russia. Большая конференция. Не пропустите. Дальше предстоит... Пройдёт скоро Positive Hack Days. Это будет 17-18 мая. А ты можешь оказать, что это такое? Это ещё одна хакерная конференция. Я не знаю, насколько она считается true или нетrue, но тем не менее, вот она есть. Я так понял, что название как-то связано с названием компании Positive Technologies, из которой к нам гость приходил. Всё понятно. Так, и... А, да-да-да. Анонсирован курс по Postgres на хабре компании Postgres Professional, который мы уже упоминали. Короче, в офисе компании планируется в феврале проводить по одному семинару раз в неделю. И там расскажут про кишки Postgres, про архитектуру, про то, как вонзиться в эту архитектуру. Мало того, что попилить можно будет Postgres на этих семинарах, можно будет ещё раскурить, как работает MVCC, как пишется ВАУ, как работают индексы и так далее. Запись уже открыта. И проводить этот курс... Это бесплатно? Я так понял, это бесплатно. А ты там расскажешь страшную тайну, когда в курсе появится параллельный запрос? Слышишь? Это уже появились, если что. То есть я могу написать селектор параллель, и они прям будут параллельны у меня? Ну да. Окей, это в какой версии? В 9.6, по-моему, или уже в 9.5. Ну 9... Прости, но сейчас 9.4 продакшн. Прощаю. То есть у нас 9.5 ещё не вышло, и как жить непонятно. В общем, всё сложно, жизнь боль. Но мы все надеемся, что они же патч приняли, а там, которые разруливают всё это, и очень надеемся, что если кто-то из пользователей нас слушает, что они усилят в этом направлении какой-то движух, потому что очень хочется уже использовать несколько ядер для выполнения операции выборки и операции, может быть, даже апдейта. Это было бы безумно круто, честно. Что ещё безумно круто, курс этот будет читать Анастасия Любенникова. Вот. И, ну не знаю, я лично считаю, что это будет очень круто. Очень круто, что это бесплатно, если честно, я не ожидал. Я боюсь, как бы они не ограничили вход, потому что желающих может быть много. А напомните продолжительность? Тут, по-моему, 16. Раз в неделю и сколько раз? 16? Да, 16 лекций. А там в комментариях обсуждается возможность трансляции. Ну, в смысле прямой трансляции. А записи-то будет? Будет по-любому, эфир, я так понял, может быть, будет. Ну, короче, по-моему, это вот время укорочить по хардкору. Я не знаю, кто ещё такие курсы пробует. Да, это клево. На самом деле я хотел бы ещё такой же курс по ядру Линукса и по ядру FreeBSD. И, наверное, по CPython. И, пожалуйста, ещё таблеток от жадности мне побольше. По CPython лучше про Tadapipy, там хотя бы джип есть. Всё-таки в Just In Time компиляция гораздо интереснее, поскольку там... Тогда уж по Piston. Вместо Piston можно взять игрожу Нютку и угорать по полной. Вот, прям огонь-огонь. Прислушайтесь к проекту и пишите там. Прям настоящий транслятор и, соответственно, все оптимизации, которые вам возможны на этапе компиляции. Прекрасно. А можно ссылку на Нютку? Окей, сейчас будет. Мне показалось, у кого-то был вопрос, но кого-то перебили. А вопрос был, в честь чего такой аттракцион индивидуальной щедрости? Ну, я так понял, компания пиарится. Смотрите, мы специалисты по постгресу. Отлично. Хочу больше пиара разных компаний подобного образа. Ну так, возвращаясь назад к нашим интересным темам. Свет, Валер, кто хочет нам рассказать? На самом деле Света, потому что я как бы... Я прочитал это, но я поскольку совсем этим... То есть я не настоящий сварщик, я Spark настройки нашел. И я издалека это всё смотрю, и у меня этого нет в продакшене. А у Света это есть в продакшене. Поэтому пусть она... А мы попробуем как-то, не знаю, поджечь. Помогать мне. Подговорить. Статья от инженеров из Yahoo про то, как сравнивать движки для потоковой обработки данных. Прям тема очень близкая, мне стало очень интересно почитать. Хотя я немножко другого ожидала. Существует множество движков, и инженеры решили сравнить только три из них. Это Spark Streaming, это Storm и недавно появившийся Flink. Всё остальное, там например вроде Samse, вроде Google Dataflow и всего добра. Это можно добавить самостоятельно, есть репозитории для этих бенчмарков на GitHub. Так что всё расширяемо, пожалуйста, приходите. То есть идея какая? У нас есть какие-то данные, которые приходят в кавку какими-то продюсерами. Данные по аналитике в сфере рекламы. И после этого мы из кавки вычитываем данные, что-то с ними делаем, процессим их, фильтруем, как-то трансформируем и отправляем в Redis. После этого мы считаем некоторую характеристику, которая показывает, какая задержка при обработке была потока данных. И в итоге получились довольно интересные цифры. Самым лучшим движком, по мнению этого бенчмарка... Ой-ой-ой, что случилось? У меня что-то было со связи, пардон. По поводу самым лучшим движком оказался Flink, как ни странно. Подожди, я бы так не заявлял. Самым лучшим без тюнинга. Предусловия такие, что мы берем все проекты, все продукты, то есть Spark, Streaming, Flink и Storm, но не тюнем их никак. То есть вот стандартные настройки, которые есть, и просто прогнали на них бенчмарки. И по итогу Flink оказался лучше всех. Но лучше всех, конечно, относительно. Задача была такая, чтобы в пределах одной секунды... Извините, еще перебью, там очень непонятно. То есть понятно, что у Spark по умолчанию включен Asking, и они типа, что если его выключать, он обгоняет Flink. А у Flink вообще непонятно, что у него за гарантии процессинга. Они снапшоттинг выключили, а что у него там кроме снапшоттинга есть, непонятно, они этого не описали. Да, но скажем, по итогу задача была такая. Мы должны обработать данные за одну секунду. И за одну секунду они смотрели, как это у нас происходит. На графике получилось так, что Flink может обрабатывать 170 тысяч ивентов в секунду, а у Storm в лучшем случае получалось 150. И то при выключенном Asking сообщении. Вот такая история. Подожди, подожди, 150... Слушай, по-моему у них там была строчка, что когда мы у Storm выключили Asking, получилось больше 150, то по-моему без Asking. Нет, нет. С вопросом включенным Asking. Нет, у них получилось 135 с Asking, без Asking получилось лучше, потому что тем меньше сообщение перегоняется, 150. Но там они при этом писали, что Storm 2.11, теперь как он там... Да, на текущий момент... Он даже обгоняет Flink, если что-то там выключить. На текущий момент версия Storm актуальная, это 0.10, но есть Snapshot 0.11, и вот в Snapshot 11 появилось много оптимизации, и на графиках это сильно заметно, что в 11 версии прям намного лучше перформанс. Но она пока что Snapshot, так что в продакшен ее рановато тянуть. Что касается Storm, то у него природа совершенно другая, если предыдущие два работают подобным образом, то есть не получают подобного... Подожди, нет, нет, не гони. Как раз Flink больше похож на Storm, вот у Spark другая... Я сказала... Скала Storm. Ой, это, пардон, оговорка. То есть что касается Storm и Flink, они очень похожи между собой, у них действительно потоковая обработка идет, тебе на вход получается кортеж данных, и кортеж ты уже будешь обрабатывать, применяя к нему какие-то операции. Что касается Spark, то Spark изначально был заточен под работу с RDD, RDD такой большой, скажем, объем данных, большой объем данных, и с этой RDD вы можете делать какие-то операции. А потом уже появился Spark Streaming, и Spark Streaming по сути своей работает на микробатчинге. Вы задаете окно, в течение которого эти микробатчи будут производиться, и в зависимости от этого окна у вас по сути интервала времени, когда будет этой RDD производиться, у вас будут сильно меняться характеристики, которые вы получаете на выходе от такого решения. И в итоге это тоже заметно на графиках, потому что если брать Storm или Flink, у них графики такие плавно идут, а в Spark прям заметны вот эти скачки, когда какой-то батч обрабатывается, он примерно равномерно обрабатывается, но постоянно будут такие степы вверх. Поэтому из-за того, что природа Spark немножко другая, он и работает иначе. Но что касается количества операций в секунду, то есть пропускной способности, он, конечно же, значительно обгоняет как Storm, так и Flink. Вот, наверное, все. Мне кажется, такой маленький вывод, если у вас есть стриминг, если у вас стриминг – это ваша основная задача, то не надо брать Spark. Либо брать, но если вы понимаете, с какой целью вы хотите достичь. То есть если у тебя, например, цель – это пропускная способность высокая, то в принципе микробатчи – это вполне хорошее решение. Ну нет, блин, там же именно фишка в том, что пока ты не делаешь микробатч каким-то вообще огромным, у тебя он просто не справляется даже с тем throughput, который вполне себе с минимальной летансии пролетает через Storm или Flink. Я же и говорю, что это зависит сильно от твоей задачи. Нет, ну короче, в каких случаях он будет... То есть я не могу себе представить случая, когда Spark для стриминга реально лучше, чем Storm или Flink. То есть из того, что я сейчас услышал, увидел, читал раньше, если у вас уже есть Spark и вам не нужно немножечко стрим, и вам пофиг на то, что там может быть задержка в минуту или две, то типа можно так вот костыль поставить. Но в целом, если вам нужен стриминг, а стриминг нужен в смысле минимальной летансии, то есть меньше, чем секунда, или около секунды, то он просто не будет настолько же производителем никогда. Слушайте, ребят, да кому нужны эти облака? К черту, теряете данные. Подожди, а при чем здесь облака? Это может на своем кластере зависеть. С вашими метнами обратите, вот эти Big Data и прочие, это все цифровой мусор. Вон даже чувак там пишет что-то на эту тему. Я вообще не понимаю этого вопроса. Давай-ка... Это просто переход. Он очень набросанный, потому что Big Data в кластерах бывает. Да, да, да, посчитаем какие-нибудь данные. Ну, бросьте вы. На самом деле, все то, что вы считаете Big Data, оно все равно крутится на каких-то кластерах, и автор относит часть этого к облакам. Здесь Паша прав. То есть облака это все то, с чем вы работаете, но над чем вы не имеете полный контроль, судя по манифесту вот этого, как его зовут, Джейсон Скотт. Давайте я озвучу, в чем основная идея. Джейсон Скотт 6 лет назад, в 2009 году написал манифест «Far The Cloud», в котором он описывает, что он совершенно не доверяет облакам. Он говорит, он приводит определение облаков в целом и говорит вообще, что облака, концепция появилась очень давно, в 1980-х годах, когда он только вошел в отрасль, уже об облаках говорили как о нечто состоявшемся. И он в целом говорит, что нельзя им доверять все эти данные, которые там крутятся, вы их не контролируете, соответственно, они могут легко пропасть. И отсюда делает несколько выводов, что доверять облакам можно только то, что у вас есть локально, ни в коем случае нельзя доверять поставщикам, которые только в облаках крутятся, типа Фейсбука, которые вы не можете ни дамп какой-то сделать, ни контролировать, ничего, и если они внезапно уничтожатся, то пропадет все то, что вы имеете там. Ну и так далее. В целом, мне понятна, близка его идея, мне кажется, что он написал этот манифест, когда у него в очередной раз кто-то что-то удалил из облака, а у него что-то не было, наверное. Знаешь, я читал тоже эту пост, и я тебе могу сказать так, он как все американцы, поэтому демократически очень рад за это право, или как всем, скажем так, наглоговорящим интернет или цивилизованством, не знаю, как правильно сказать, он очень переживает именно за правовую сторону, он говорит, вы разместите в облаках, и вот оно вам уже не принадлежит, вот когда я плачу бабло, я кастер, а так я не пойми кто усылал по хвосту все мои документы, и вот этим может распоряжаться кто угодно, и он такой переживает, что, по-моему, это больше, вот стандарт, ничего, о том, что я вот тут положил, а оно окажется непоймичим, и я здесь просто разместил объяву, ну короче, какая-то такая... У него первый вывод, то есть у него есть ряд выводов, в которых он говорит, пожалуйста, если вы используете облака, то, и дальше там 4 или 5 пунктов, и первый пункт, не выбрасывайте у облака то, чего у вас нет копии, локально, то есть это вообще не про право, не про владение, то есть да, он там коснулся этого, но это не основной пойм здесь. Слушай, ну окей, купи за 5 долларов себе этот Backblaze там, или что-то. Ну это как раз и будет облако, а он говорит, не доверяй ему. Так оно же Backup, кстати, я его тестил, как мне чуть-чуть пришлось, и оно работает прям вот ок. Но это я сейчас не в флайне рекламы, а просто делюсь опытом. Так вот, ну, окей. Почему нет, то хорошо. Нет, а в чем отличие между тем, что ты купил или не купил? Ну то есть как бы облако может пропасть, вот их, ну я не знаю, давай, кого ты покупал в последний момент? Вот Digital Ocean ты купил, да? И вот сейчас внезапно они там развалились, да? И у тебя все пропало, как бы. Ну купил ты, не купил, разницы большой не будет у тебя от этого. То есть ты потеряешь свои данные, и то есть у него идея в том числе, что ты вкладываешь в это довольно много усилий, и большинство людей очень вкладывают много усилий в том, чтобы не знаю, фоточки выкладывать куда-то там, не сохраняя их себе. И ты можешь потерять очень многое. То есть издевательство ложе, точно так же тебя все потеряет, если у тебя внезапно. Давайте разделим, отделим муход котлет. У меня есть вот три типа вещей, которые живут на моем компьютере. Это какие-то документы, которые относятся к работе или просто являются частью моей жизни, которые, ну у меня есть там по части локальные копии в клауде лежит, есть сходные коды, которые в GIT, ну GIT тяжело потерять, да, оно лежит где-то в каких-то репозиториях, и локальные копии тоже существуют, потому что я с ними работаю. И третий набор данных, это, ну скажем честно, цифровой мусор. Это всякие вот эти фоточки, там что-то еще. Ничего себе фоточки цифрового мусора. Я из-за этих цифровых мусоров только и делаю, что покупаю хранилище в интернете, чтобы, не дай бог, локально не сломалось. Гугл сказал, вот, Гугл фото, бесплатно там клади и живи, и радуйся. Я думаю, у них фактор репликации там двоечка-то точно есть, так что одну сдохнет, хард новую поставит. Ну, то есть, я не называю это цифровым мусором, я вот к чему. Ну, то есть, жизнь ради фотографий? Ну, я увлекаюсь фотографией, да, для меня это ценный ресурс. Окей, ну, Гугл вот дает возможность хранить, пожалуйста, бесплатно. Бесплатно не дает? Нет, там есть у них дополненные разрешения, ты можешь... Да, конечно, мне это не устраивает совершенно, это разрешение. А, вот, вот, вот с этого надо начать, да, это все-таки, уже мы говорим о цифровых материалах, да, но для большинства пользователей, которые существуют сейчас, это, во-первых, решение более чем приемлемое, ну, так, если по-честному, и, ну, почему нет? Ну, вот, положил ты в облако... Так, так, так. Ты будешь утверждать, что у Гугла фактор репликации единичка, что они на одном харддер все хранят, каждую копию их данных? Да нет, ну, разориться они, обанкротиться они, Гугл когда-нибудь, я не знаю, и что у тебя с твоими фоточками будет? Окей, вопрос понять. Но я думаю, что раньше мы там составимся, чем Гугл. Нет, ну, это вопрос вероятности, а здесь у тебя, если у тебя есть локальная копия, то ты вообще ничего не боишься. А зачем тогда туда выкладывать, в принципе, в эти ваши интернеты что-то постить? Ну, то есть, выкладывать, в принципе, в какие-то облака. Ну, пошел я там, да, на Фейсбучек запостил, а так у меня, может, здесь стоит микросервер. Как раз к этому он и призывает, что да, так и надо делать. Окей, а вопрос ограниченности места, там, еще чего-то. Плюс, опять же, нужно сервер обслуживать, поддерживать. Конечно, конечно. Это же накладные расходы. Обязательно. Вот, это все плюс. Опять же, у нас атаки могут быть разные, там, но вот это все. Нет, это все очевидно, это все понятно. То есть, как бы, у него манифест в том, что не стоит переоценивать облака, и нужно их постоянно критически воспринимать. Вот у него только в этом. Слушай, ну, это, как и многое, воспоминание и предание старина глубокое. Какой там год, 2009? Ты знаешь, довольно актуально чуть-чуть. Да мы, честно говоря, довольно недавно обсуждали такую интересную проблему, как вот есть у тебя аккаунт на Амазоне, и там все твои сервисы. У тебя в Амазоне и система, и ее бэкапы. Кто-то получает доступ к твоему Амазон аккаунту. You screwed. Да. Окей, но опять же... А что ты там охренеешь-то? Не шарьте пароли. Да нет, нет, не охренейте в одной корзине. Да, да. Ну то есть бэкапы на S3 это здорово, но неплохо еще за твой S3 бэкапы иногда сливать на какой-нибудь локальный хард просто у себя в компании. Или на альтернативного клаудпроводника. Да. Ну, в любом случае, по аналогии, это все-таки какая-то старая семь темы, и сейчас мы уже...",
    "result": {
      "error": "API request failed: Error code: 400 - {'error': 'Trying to keep the first 5415 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': 'Trying to keep the first 5415 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}\n"
    }
  }
]
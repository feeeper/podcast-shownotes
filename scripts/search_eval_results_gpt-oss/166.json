[
  {
    "segment_id": "37d903d4-859d-47d9-90cf-609a1a218633",
    "episode_id": "98d61f68-62cf-43b4-b3a2-8096e5a8982b",
    "episode_number": 166,
    "segment_number": 2,
    "text": "как минимум с этой библиотекой, но на этой конференции он докладывал про apartment model, в частности, он рассказывал про девайс, собственно, карточка, я так понимаю, там 4 порта по 10 гигабит, и они делают deep packet inspection, то есть определенным образом фильтруют пакеты, смотрят там заголовки и так далее, разные протоколы, могут там полосы регулировать, блокировать и так далее, фильтровать, то есть такое интеллектуальное устройство, возникает вопрос, а как такой объем трафика обрабатывать, то есть это серьезная такая нагрузка на ядра и прочее, вот он рассказывал про apartment model, что они делают, вообще apartment model, надо понимать, это акторная модель, вот в таком чистом виде, единственное, что это специализированная акторная модель, то есть у нас, например, есть там 32 ядра или 16 ядер на процессоре, мы на все эти ядра запускаем по одному треду и эти треды прям пинем к этим ядрам, ну понятно, для максимализации производительности, далее на этих ядрах мы создаем акторы, так называемые, то есть объекты, которые принимают и отдают сообщения, и эти акторы тоже прибиваем к этим потокам, вот, соответственно, shared state нет, все происходит через асинхронные сообщения и, собственно, lock-free очереди для этих сообщений, причем lock-free очередь, насколько я понял, это есть очередь в Юково, bounded очередь, можно сказать, самая быстрая очередь, мультипродюсер, мультиконсумер, и, собственно, там используется эта очередь, так как для акторной модели нужен мультипродюсер-сингл-консумер, то можно ее немного подкорректировать, еще чуть-чуть убыстрить и получится как раз такая очередь. И вот, что самое мне больше всего понравилось, такая неожиданная фишечка, которая прям... короче, мне очень понравилась интересная идея, хотя она лежит на поверхности, следующее, там используется кастомный аллокатор, то есть аллоцируется память специальным аллокатором, и эти аллокаторы привязаны к потокам, понятно, для максимальной производительности, в принципе, тут пока никаких отличий от, например, TC-malloc нет, но дальше идет некоторая интересная особенность, потому что во всех аллокаторах, что в GM-alloc, что в TC-malloc есть общий какой-то шареный объем структуры, которая хранит блоки, которые могут аллоцировать все трэды, вот там аллокатор написан так, что такой структуры нет. Но возникает вопрос, вот если мы память из одного потока передаем в другой, то есть мы память не копируем, а мы прям берем указатель, передаем для максимальной производительности, возникает вопрос, а как память потом обратно отдавать? Ну как обратно отдавать? Просто надо сделать функцию, которая отдает память асинхронной, да, то есть мы асинхронно передаем обратно кусок зааллоцированной памяти так, чтобы он вернулся в то место, откуда он был зааллоцирован, то есть в тот поток, откуда он был взят. Собственно все, и проблема решена, таким образом. Звучит как при аллокаторе в Орланге, честно говоря. Ну я честно говоря не знаю, как в Орланге устроен аллокатор, но в принципе для акторной модели это такой подход достаточно прямолинейный, как мне показалось. Ну да, я сейчас на секунду прерву, привет, Света. Привет всем. Да, привет. Вот, собственно, доклад мне очень понравился, ну собственно на самом сайте, я думаю ссылки мы, будут даны ниже или выше, то есть можно будет посмотреть этот доклад, то есть была онлайн-трансляция на YouTube и там уже можно смотреть. Вот, также был еще доклад про акторную модель, вот, человек, который разрабатывает S-Objectizer. Евгений Охотников. Вот, Евгений Охотников. Мы в этом подкасте наизусть это имя знаем. Да, да, да. Вот, в принципе, как бы ничего нового там я не узнал, но единственное, что ну как бы просто все еще более уложил, зачем нужна акторная модель, когда ее стоит использовать, не стоит, то есть в принципе такой, как сказать, первичный шаг для того, чтобы понять, стоит вообще идти в этом направлении или не стоит, вот, в принципе, такая полезная, полезный был доклад. Вот, вот, собственно, что я хотел рассказать про эту конференцию. Вот, ну, возвращаясь к теме моего доклада, ну, о нем я все-таки более подробно попозже расскажу, вот, но что я хотел отметить, ну, вопросы мне задавали, но возникло такое ощущение, что мало кто понял, о чем это вообще было и там, в принципе, получилось так, что это было продолжение моего первого доклада, который я делал весной на этой же конференции, возможно, что просто не все вспомнили этот контекст, но я постарался сделать какое-то введение, но возможно, что там слишком много было такой специфики и проблематики, поэтому возможно, что не все поняли или мало кто понял, скажем так. Ну, не только лишь все, но мало кто. Все, да, не только лишь все, да, верно. Окей, на самом деле, я не знаю, почему эта тема так высоко, ну ладно, раз она здесь, то почему бы и нет. Я хотел упомянуть, что, в общем, в Elixir официально, ну то есть это уже какое-то время ходило так, типа, просто, ну, было репозиторий, в принципе, было видно, что это происходит, но сейчас они анонсировали по постам. Извини, пожалуйста, я просто, я, может, что-то не понял, мне казалось, что Гридем хотел, собственно, объяснить, к чему была тема его доклада. А, просто, подожди, тема доклада там дальше же по списку, нет? Да, попозже, чуть-чуть. А, всё, я понял, прошу прощения. Там просто, я удивился, что оно разделено темой про то, что я сейчас говорил, но раз уж разделено, ну ладно, что бы с ним. Так вот, к чему это я? К тому, что в Elixir теперь официально, как часть языка, будет строена библиотека для property-based тестов. Так, и вот, потрясающие пироги. Она, конечно, не такая полнофечовая явно в текущий момент, как это самые, ну, не столько клёво, как самые клёвые собаководы умеют готовить, то есть, например, я там пока не заметил, может, конечно, плохо искал, stateful тестов, но уже хотя бы то, что есть, уже здорово. Почему они решили не притащить что-нибудь готовое? Основная причина, как я понял, это лицензия. И вторая причина, это интеграция с языком, поскольку Elixir он весь такой с макросами и прочими свистелками-перделками, то им хотелось так, чтобы оно лучше интегрировалось в их тесты, лучше интегрировалось в их макросы и прочую фигню. Опять же, у Elixir синтекс из леотипов немножко другой, поэтому все эти вещи, там, не знаю, собирать proper из мира Erlang, который умеет при помощи parse transform вытаскивать всякую информацию. Кстати, он, по идее, должен быть вытаскивать из Elixir, потому что я вот не уверен, на куморническом брате Elixir работает. Ну ладно, неважно. В общем, суть в том, что библиотека делается нативно для Elixir, поэтому её будет проще использовать в Elixir. В принципе, с точки зрения Erlang ничего интересного не произошло, в Erlang все эти инструменты давно есть. Но это здорово, что это будет не просто какая-то сторонняя библиотека, про которую знают полторы коллеги, это будет официальный и официально рекомендуемый способ писать тесты в языке. И вот я тут недавно... Собственно, вообще, почему я это притащил, казалось бы, в каком-то непонятном Elixir'е что-то произошло, потому что я тут выпуск или два выпуска назад разразился с тирадой на тему того, что нужно поднимать культуру написания тестов и кода, но вот, собственно, вот оно и есть. Как бы стараниями, казалось бы, хипстерского Elixir'а, а вот так оба и... Пропертивные тесты в стандарте языка. Ну не в стандарте языка, а в стандартной библиотеке. Очень круто. Единственное, что непонятно, насколько это будет быстро работать. Меня сейчас в Elixir'е очень сильно не устраивает. Мне очень хочется в Elixir'е ввести новый стандарт — это скорость компиляции кода. То есть я немножечко потрогал Go, и после Go Elixir ну просто очень-очень тепло и медленно. Ну, понимаешь, как бы всё-таки Elixir'а, во-первых, он умеет... Как это, Go он целиком, если перекомпилирует Elixir'а, так, понятно, всё нормально с инкрементальной перекомпиляцией. Во-вторых, это же Mirror Lang'а, ты можешь вообще запустить виртуальную машину и просто динамические модули перегружать. Ха-ха-ха-ха-ха. Если тебе хочется интерактивно разрабатывать, это может быть не лучшая идея в продакшене, но для интерактивной разработки, мне кажется, норма. Всё так, но когда ты начинаешь переходить на мир как это рядом ли инфраструктуры, когда ты работаешь в докере... Вот не надо мне про это, прекрасно, это в докере работать, ты подмонтируешь вольюм с своими... Я про это работать в продакшене. А, подожди, это как компиляция... Я делаю commit, и мне в Continuous Integration должно всё перекомпилировать в нуля фактически. Ну, как минимум можно Dependent, наверное, где-нибудь оставить. Да-да-да-да-да. И плюс, когда ты изменяешь хоть одну строчку в конфиге, он же не знает, что там происходит, и начинает всё пересобирать полностью. У меня недавно была проблема, я делал для своего приложения такой контейнер для тестового сведения, и в принципе я после нескольких обсиданий сделал так, чтобы он пересобирался чуть-чуть сильнее, чем по любому чиху полностью всё. Там главное разделение Dependent от всего остального, ну, то есть там просто кусок образа с Dependent не меняли, зачем тут слой образа пересобирать. И там ещё какой-то кусок был, я не помню, что там ещё сделал, чтобы он там, если конфиги, по-моему, не менял, чтобы он тоже что-то не трогал. Вот такого рода вещи сделал, и оно вроде теперь более меня адекватно пересобирает, то есть там сам проектик у меня не то чтобы супербольшой, и он перекомпендируется быстро. Но это мало имеет отношения к теме, а тема мне очень нравится. Мне нравится, когда в стандартную библиотеку засовывают подобное нововведение. Ну да, то есть просто мне показалось занятно, что вот я там буквально день назад об этом жаловался, неделю назад об этом жаловался, хоба так, подарочек на Новый Год. А теперь, собственно, самое время поговорить о том, что такое субъекторная модель и чем она отличается от вакторной модели и объектов и прочего такого остального. Правда? Да, давайте поговорим. Пришло время про субъекторную модель. Собственно, статья есть на Хабре, каждый желающий может её прочитать, она достаточно подробно описывает подход, который я использовал. Собственно, в чём идея, в чём проблематика. Когда пишешь асинхронный код, то понятно, что асинхронность, она привносит такой серьёзный недетерминизм и хочется с возникающей сложностью как-то работать. Поэтому возникает вопрос, ну что при этом использовать, какие модели и прочее. То есть в условиях, когда есть какие-то, не знаю, широческое состояние, или надо использовать состояние общее или не надо, что с этим делать, как синхронизовать доступ к объектам, как вообще взаимодействовать с сетью и так далее. Я начал с того, что задался вопросом, а вообще что такое ООП, как его вводили и прочее. На самом деле, если подумать и посмотреть, как вводилось понятие ООП, то окажется, что ООП вводилось, ну впервые прям оформилось понятие в смолтолке. До этого объекты появились в символах. В смолтолке в чем-то идея была, что у нас есть вот эти объекты и они обмениваются сообщениями. При этом в ООП понимание большинства, собственно, было, мне кажется, в основном на сами объекты, а не то, как они будут взаимодействовать друг с другом. А Алан Кей, который вводил это понятие, он говорил, что ООП, как бы это вообще не про Си-плюс-плюс. Это про именно, самое главное это сообщение, то есть то, как будут взаимодействовать объекты. Но я ухватился за вот это сообщение, за понятие, что вот у нас объекты обмениваются общениями и стал раскрывать. Например, мы вызываем какой-то метод возникает вопрос, а что значит, что мы вызываем? В принципе, это можно представить так, что мы по самом деле посылаем объекту какое-то сообщение, но делаем это синхронно. То есть при этом различные методы, это есть различные типы сообщений. А параметры методов, это есть, собственно, данные, которые мы в сообщение запихиваем. Единственное отличие, например, от акторной модели в том, что в акторной модели типа forget semantics, то есть запустил и забыл. А в обычном программировании у нас мы взовем метод какой-то и дожидаемся, пока придет ответ. То есть у нас именно принципиальный момент, что это синхронный вызов. А дальше я что сделал? Взял... Для асинхронного кода очень эффективно использовать СА-программы. В каком смысле эффективно? Код получается более простой, простой семантик. То есть получается такой обычный код, люди привыкли вообще к синхронному коду и привыкли думать действиями, ну как бы последовательно, что делается сначала это, потом это. То есть когда у нас код превращается в асинхронный, то есть мы что-то параллельное действие распределили, а потом ждем результаты. При этом что-то может завершиться ошибкой, что-то не завершится, приходится перепосылать. То есть логика сильно усложняется. Поэтому имеет смысл подключить к этому СА-программу для того, чтобы сделать более линейным, более простым и соответственно синхронным. А дальше я смотрю, ну как объекты могут взаимодействовать, как вообще синхронизировать взаимодействие, синхронизировать данные и прочее. И я выделил тут 5 возможных вообще вариантов для общения объектов между собой. Первый вариант это спинлок. При этом спинлок не обычный, а асинхронный. То есть асинхронный СА-программу. Как устроен вообще спинлок? Если это марная переменная, ну флажок. Когда мы его берем, когда он фоллс, мы переводим в состояние true, спинлок взял и проблем нет. Потом обратно его возвращаем в фоллс. Но когда у нас спинлок не взят, теперь надо нам что-то сделать. То есть придумать какую-то стратегию back-off. Стандартная стратегия либо подождать, погреть процессор, либо передать управление операционной системой, чтобы шедулер переключил на какой-то другой поток это ядро и стал что-то делать. Ядро процессора я имею в виду. А когда у нас есть СА-программа, появляется другая возможность. Мы можем взять, заморозить текущее состояние нашей СА-программы и перешедулить ее на следующее выполнение. То есть когда какие-то другие действия выполняются. То есть мы замораживаем и потом планировщик, выполняет какие-то действия, которые у него накопились. Он может опять снова вернуться к этому и еще раз попробовать взять этот спинлок. Таким образом появляется такой спинлок в наших программах, который более эффективен. Почему он более эффективен? Потому что вместо того, чтобы греть процессор, то есть ничего не делать для этого потока, или передавать управление операционной системой, то есть переключать ядра, переключать стэки и так далее. То есть делать какие-то... Просто переключение из ядра пользователя, из пространства пользователя в ядерное пространство, это все-таки достаточно дорогостоящая операция. Несмотря на то, что есть специальные инструкции, которые это все ускоряют. Гораздо дешевле, если мы возьмем просто СА-программу, заморозим, переключим стэк на другой, то есть перекинем несколько указателей и продолжим выполнение какой-то другой полезной задачи. А потом вернемся и еще раз попробуем. Таким образом можно использовать вот такой примитив синхронизации, для того, чтобы войти в объект и что-то с ним поделать. Дальше что можно использовать? Тот же прием можно использовать с Mutex. То есть когда Mutex занят, мы просто кладем СА-программу в очередь, и она там засыпает. Потом, когда кто-то разблокирует этот Mutex, он смотрит в эту очередь и стартует очередную СА-программу. Собственно, то, что делает ядро операционной системы, когда мы используем обычный Mutex, например, только мы делаем это сами в юзерспейсе, при этом ядро не участвует, ядро операционной системы. Мы полностью остаемся в пространстве пользователя, и это нам позволяет сделать именно нашу СА-программу. Далее есть интересные способы синхронизации через планировщики. Например, я могу создать отдельный поток, в котором делать буду какие-то критичные ко времени выполнения действия. И, собственно, я могу эти действия, то есть брать мою текущую СА-программу и перепланировать, то есть запускать продолжение моей СА-программы в этом потоке. То есть я замораживаю в текущем и планирую возобновление ее в этом потоке. А потом, когда действие завершилось, оно возвращается обратно в мой текущий контекст. Также что я могу делать? Я могу сделать планировщик, который обеспечит мне отсутствие параллельного исполнения в этом планировщике. То есть только одно действие в один и тот же момент времени может быть исполнено. Этот планировщик может работать на любом поле потоков. Например, я создаю там 10 потоков, у меня 10 ядер, создаю 10 потоков, и на этих 10 потоках я создаю этот планировщик, который мне гарантирует сериализованное выполнение. Собственно, я переключаюсь в этот планировщик и выполняю эти действия. И последний способ синхронизации – это использовать канал именно в ГОШном понимании. То есть у меня есть канал, мультипродюсер, мультиконсюмер. На самом деле, в данном случае мне нужен только сингл-консюмер. Собственно, мы сильно приближаемся к модели акторов, но есть интересные отличия. Что я делаю? То есть когда мне нужно позвать какой-то метод, я создаю фонт, внутри которого будет этот вызов. То есть я кепчу входные параметры, запоминаю указатель на функцию и так далее. Запихиваю это в фонтар, даю в этот канал. Из канала я зачитываю и применяю этот фонтар к моему объекту, для которого я хочу делать синхронизацию. И в бесконечном цикле, собственно, я эти операции делаю. Когда я заканчиваю эту операцию, я говорю с программы, что она может получать результат, она разблокируется, получает результат в своем контексте и продолжает свое исполнение. То есть вызов получается синхронный, как будто я зову обычную функцию. Ну и, собственно, я использую подход универсального адаптера, тоже можно посчитать на Хаббле статью. Там используется шаблонно-макросная магия. Заключается в следующем, что я беру класс и причисляю методы, которые я хочу перехватывать. Например, у класса есть какие-то методы HandleEvent, не знаю, все что угодно. Вот я говорю, что этот метод я хочу перехватывать. Что значит я перехватываю? Когда я зову этот метод с какими-то параметрами, вместо того, чтобы непосредственно вызвать метод у объекта, я его заворачиваю в какую-то обертку и зову, например, следующим образом. Я беру SpinLock, потом зову этот метод, а потом отпускаю SpinLock. И так я могу сделать и с Mutex, и с планировщиком. То есть я беру вот этот вызов, например, я хочу сделать синхронизацию через изолированный поток. Я беру, сначала переключаюсь на этот поток, а потом зову этот метод. Это мне позволяет сделать именно шаблонная магия с перехватыванием вот этих методов, которые я указал. И получается так, что у меня интерфейс не меняется, а при этом возникает дополнительная синхронизация, которую я могу управлять. При этом каждый тип синхронизации обладает своими уникальными характеристиками. Например, если я использую Mutex, то у меня, понятно, что могут быть дедлоки, но, тем не менее, поток исполнения не разрывается. То есть если я взял Mutex, то при доступе к другим объектам этот объект будет недоступен для использования из других объектов. То есть неразрывность потока исполнения, более подробно, опять же, в статье можно про это почитать. Но при этом возникают дедлоки. Если я использую планировщики, то при этом у меня дедлоков не бывает никогда. Потому что каждый раз, когда я перепланирую исполнение на другой планировщик, то есть сопрограмма может работать только в одном планировщике. Поэтому, если я переключаюсь с одного планировщика на другой, то, соответственно, этот планировщик отпускается, и на этом планировщике могут исполняться какие-то другие сопрограммы, которые могут иметь доступ к этому объекту. Таким образом, разрывается атомальное исполнение под объектом, но зато у меня нет дедлоков. Вот. Такие есть особенности. Я не совсем понял, не мог бы ты еще раз пояснить. То есть, если ты локи все отпускаешь при переключении контекста, то это, наверное, не очень хорошо, потому что у тебя состояние будет разъезжаться. Если ты их не отпускаешь, то, возможно, дедлок. Я не совсем понял, как у тебя использование скедулеров позволяет избежать дедлоков. Смотри, здесь имеется в виду следующее. Что я использую для синхронизации, вот у меня, например, два объекта, я могу для их синхронизации использовать либо скедулеры для обоих двух, либо спинлоки. Если я использую спинлоки для оба объекта, соответственно, у меня будет дедлок. Может быть, в смысле. Он может не быть, а может быть. Но он, тем не менее, возможен. Если же я использую планировщики, которые гарантируют отсутствие параллельного исполнения, то при этом дедлоков не будет. Просто не будет. Но при этом атомарность будет разрываться, и это, в принципе, может быть критично для тех или иных сценариев. Например, где может это потребоваться? Нет, подожди. Ты не мог бы на конкретном примере. Вот у меня есть два... Я себя слышу. Ты не мог бы сделать наушники чуть-чуть потеше? Вот у меня есть две крутины, которые хотят два лока, которые реализованы как спинлок или неважно как. Но они их захватывают в разном порядке. Первый берет AB, второй BA. И я все еще не понимаю, как ты научился разруливать дедлок в такой ситуации. Смотри, наверное, тут стоит следующее от меня сказать. Что вот это вот спинлоки и прочее, они навешиваются не на коротину, а на объекты, с которыми происходит синхронизация. То есть у меня есть объект, не знаю, пользователь, да? И я хочу с этим объектом использовать, ну, из каких-то других объектов, поделать какую-то информацию. Там, изменить, например, имя пользователя, изменить имейл, фотографию, не знаю, все что угодно. Соответственно, к этому объекту я привязываю определенный тип синхронизации. То есть дальше я могу сказать, для этого объекта я использую тип синхронизации ко-спинлок. То есть коротинный спинлок, который будет, соответственно, брать вот этот асинхронный спинлок и отпускать. Если же я скажу, что для этого объекта использовать синхронизацию на основе планировщика, у него будет такая синхронизация. И возможно, что при доступе к этому объекту, если внутри этого планировщика я делаю еще какие-то доступы к другим объектам, и я могу заснуть. Давай рассмотрим конкретно. Например, вот этот юзер, я, например, изменяю имя. Если я просто изменяю имя, и я оказался внутри пользователя, все операции мои были синхронны, то в данном случае не произойдет разрыв автоматности, потому что нет разрыва. Разрыв возникает тогда, когда будет какое-то синхронное действие. То есть я буду ожидать какого-то действия для продолжения своей работы. Если я просто заменяю поле одно на другое, здесь никакого разрыва не будет. Если же я в этот момент буду обращаться еще по сети, в базе данных, например, обновлять в базе данных, то когда я переключусь к объекту типа базы данных, то моя сопрограмма текущая засеспендится и проснется над объектом, который будет работать с базой данных. И соответственно другая сопрограмма может войти в объект этого же пользователя и начать делать какие-то другие действия. И работать с переменными, которые там потрогала первая сопрограмма. То есть в этом смысле произойдет разрыв отоварного исполнения. Я понимаю все, что ты говоришь, но ты отвечаешь не на тот вопрос. Поэтому давай я немножко другой пример приведу, вполне конкретный. Есть два пользователя, у них есть состояние счета. У первого мани и у второго мани. Есть две нитки, которые хотят перевести деньги. Там от одного пользователя к другому. Первая нитка берет в порядке АВ, вторая в АВ. И меня очень сильно смутило утверждение, что автоматически разрешаются дедлоги. И мне хотелось бы понять, что в этом конкретном случае произойдет. Все, отличный вопрос. То есть теперь я понял. Ну давай конкретно о этом разберем. Значит у нас есть счет. Счет у одного пользователя, счет у другого пользователя. Счет это объект, на котором мы будем навешивать синхронизацию. Если мы навешиваем синхронизацию а-ля спинлог, то тут понятно может быть дедлог. Теперь мы на этот объект навешиваем синхронизацию на основе планировщика. Что будет происходить? Мы позовем функцию, которая будет трансфер, которая будет из одного аккаунта переводить, из одного счета переводить в другой. Значит она первое что сделает, например уменьшит баланс у первого пользователя. Значит она пойдет в объект, в счет первого пользователя. Для этого со программы переключится на планировщик вот этого счета. И сделает свою работу. То есть что она сделает? Ну собственно уменьшит баланс и переключится, и потом передаст управление вот этой функции трансфер. И в этом смысле происходит потеря атомарности, которую ты упоминаешь. То есть у меня обмен деньгами становится не атомарным. Именно так, да. То есть ты можешь увидеть промежуточное состояние, то есть неконсистентное, когда операция посередине еще, то есть не доделывается. То есть суммарный баланс будет меньше или больше, чем ты ожидаешь. Мне кажется это тогда не очень полезно. Если я могу увидеть систему в неконсистентном состоянии, зачем я тогда синхронизирую? Смотри, у тебя в любом случае, точнее не так, не в любом случае. Например, если ты будешь использовать акторную модель, вот как я когда смотрел курс на Курсере, и там рекламировалась акторная модель, и там говорилось, вот смотрите, если мы возьмем лютексы, то будет дедлок. Поэтому если мы будем обмениваться сообщениями, то у нас дедлока не будет. Да, дедлока не будет, но будет та проблема, о которой ты сказал. Будет прорежуточное неконсистентное состояние. Чтобы это разрешить, чтобы у тебя не было и дедлока, и было консистентное состояние, я как раз тебе описываю, что нужно использовать вообще другие модели, нужно использовать какие-то транзакционные вещи. И это уже совершенно другой способ синхронизации, и вообще другой способ построения программы, скажем так. Это гораздо более дорогой способ взаимодействия между объектами. Тем не менее, это тоже возможно сделать, но проблема с транзакционным исполнением в том, что при транзакционном исполнении тебе надо делать ретре, потому что у тебя транзакция может в момент комита заабортиться. То есть ты что-то начинаешь делать, делать, делать, а потом раз, и у тебя сказало нет, не могу. В таких синхронизациях, о которых я говорил, субъекторной модели, такое не может получиться. То есть если мы взяли блокировку, то мы ее взяли, и мы можем делать все, что угодно с этим объектом, и по окончанию работы эти все изменения будут видны. В этом смысле не будет никакой изоляции, не будет транзакционности. Но, как бы, да, если ты посмотришь на какие-нибудь, не знаю, любые способы такие относительно примитивной синхронизации, нигде этого нет. То есть это есть только в какой-нибудь там к софтвере, транзакционном мемори, там и прочее, где слово транзакцион присутствует, да, или транзакции. Вот, поэтому тут моя модель, конечно, не дотягивая до этого уровня, она и для этого не предназначалась. Она предназначалась для такого более-менее низкого уровня взаимодействия между объектами и синхронизации, более легкодействия. Вот не знаю, насколько понятно объяснил. Ну, все понятно, да, ты на мои вопросы ответил, спасибо. Хорошо. Мне кажется, мы чем-то таким универе занимались. Ну, в качестве курсовой. Вот прям очень сильно напоминает, но у нас были немножко другие абстракции. Я сейчас тебя слушал словами, и, честно говоря, некоторые вещи от меня ускользали, но вот по, так скажем, питчу крайне похоже. Забавно. Забавно. Почему это полезное знание? Потому что, я так понимаю, ты какую-то библиотеку релизнул, или нет еще? Еще раз. Я правильно понимаю, что ты уже реторелизнул какую-то библиотеку? Да, это есть на GitHub, то есть каждый может посмотреть, что-нибудь там поделать, pull request, пожалуйста, к лицу, лице Азиапатч. Где-то это применяется? Если это где-нибудь там выйти, этот код есть, или это просто твои домашние эксперименты? Смотри, это мои домашние эксперименты, то есть это не продакшн, надо понимать, это действительно мой такой, можно сказать, pet project, который нигде не используется. Но я использовал в каком-то смысле идеи, которые вот в частности в ИТ, там не только в ИТ используются. То есть, в принципе, не сказать, что я что-то такое серьезное новое сделал, но я, скажем так, что я сделал, я просто взял под одним интерфейсом, объединил несколько разных способов синхронизации, в том числе, например, через каналы. Собственно, что я хотел отметить… А, подожди, так нет, я думал, ты это неправильно понял, потому что у тебя разные способы синхронизации под одной крышей живут, я немножко не так начали понял. Окей, тогда это не то, чем вы занимались, мы только один способ синхронизации смотрели, получается, тогда. Собственно, фишка в том, на что я обращаю внимание, заостряю внимание в этой статье, фишка в следующем, что у нас есть какой-то объект, у него есть какой-то интерфейс. Дальше я хочу сделать так, чтобы этот интерфейс можно было использовать из разных потоков. В общем, при параллельном использовании у нас возникает конкуренция из разных потоков. Ну, короче, понятная проблема многоточности и параллельного исполнения. Возникает вопрос, как получить доступ к этому объекту, при этом особо не париться о том, какие методы должны быть, с помощью чего синхронизированы. Потому что обычно, ну, какая вот типичная проблема такого сложного нетривиального кода, при этом еще асинхронного, что вот у тебя есть какой-то класс, у него есть какие-то методы переменные, разные переменные защищены разными примитивными синхронизациями. Что-то там с пенлокам, что-то от метикса, что-то там через планировщик, то есть надо через этот планировщик зайти, что-то там поделать. Почему вот через этот планировщик? Потому что этот планировщик, например, вообще синхронизует распределенные кайки. Поэтому надо мутировать состояния, изменить состояния через определенный планировщик, чтобы это было тем образом сделано. И ты смотришь по полям через этот планировщик, через пенлок, и ты так смотришь и думаешь, «Блин, а как вообще мне можно из этого места позвать вот этот метод, вот эту функцию?» Или мне нужно что-нибудь там взорваться, перепланировать себя, то есть позвать планировщик, сказать, что сделать какое-то продолжение, то есть позвать вот этот коллбек в этом планировщике и так далее. А потом, когда он завершится, мне продолжить, пожалуйста, вот здесь, в другом уже планировщике и под пенлоком уже изменить состояние. Оказывается, что в большом сложном проекте такие вещи встречаются рядом, и это не что-то такое уникальное, это просто обыденность, скажем так. И реально посадить какую-то багу здесь, это просто как бы берешь в пешкод, и у тебя куча багов сразу возникает. Поэтому мне захотелось это сделать так, написать что-то такое, чтобы это было сделать невозможно. В каком смысле? То есть вот этот объект, который я называю субъектором, в этот объект я не могу зайти, не взяв нужную блокировку, причем блокировку ту, которую я писал здесь. И я могу потом ее поменять, я помню, что, например, это не подходит, а вот это подходит. Я могу ее поменять, при этом интерфейс не изменится, вообще ничего не изменится, просто поменяется способ блокировки. Например, Mutex заменил на Spinlock и сделал его более эффективным, потому что Spinlock все-таки более легковесный, чем Mutex. И все остальное продолжит компилироваться, исполняться, то есть мне надо будет что-то переписывать. То есть идея была такая, не переписывая код, а сделать так, чтобы пональше думать о том, как и в каком контексте этот объект нужно использовать, чтобы это все происходило автоматически. Собственно, решая такое, можно сказать, краткое, некраткое введение в эту модель, значит, что я еще сделал, я сделал следующее. В принципе, вызов функции C++ во многих языках синхронный, поэтому, конечно, когда я перехватываю методы и зову методы в нужном контексте, я это делаю синхронным образом, то есть по умолчанию принят синхронный способ вызова. Но также в библиотеке есть возможность сделать любой вызов асинхронным. То есть я вместо того, чтобы вызовы непосредственно методов, я использую метод .handleEvent. Я что делаю? Я говорю, объект.async, в скобке точка, этот метод. И этот метод зовется асинхронным. И вот если я так сделаю и буду звать все время асинхронный вызов, все время буду использовать асинхронный вызов в своем коде, использовать буду каналы для передачи и для синхронизации моих объектов, то это будет очень похоже на то, что делается в актерной модели. Потому что в актерной модели у нас есть mailbox, который принимает входящие сообщения, потом есть актер, который из этой очереди зачитывает эти сообщения и определенным образом диспатчеризует. В C++ это сделана диспатчеризация через применение лямбды, через применение функтора, в который я зову на самом объекте. Самой диспатчеризации нет, я использую преимущество самого языка для этого. И получается у меня действительно актерная модель, когда у меня изолированная сопрограмма в бесконечном цикле, у меня зачитывает эти сообщения, применяет их к моему объекту и также может любые сообщения отсылать другим актерам и другим объектам. Я вот чуть-чуть хотел спросить, нас время подобными вещами сподвигло заниматься, мы хотели движки писать, мы затачивали попытки писать игровые движки, у нас не такой спектр был, у нас все было проще, но тем не менее. Я почему вообще про это вспомнил, потому что вот что сподвигло тебя это писать? Меня сподвигло писать, вообще когда я экспериментировал с репликацией, ну по-моему в первом выпуске, когда вы меня позвали, первый для меня выпуск, когда я рассказывал, что я сделал, значит там я ввел так называемую концепцию реплицируемого объекта и там мы говорили про алгоритм концепции и прочее. То есть для того, чтобы сделать эту концепцию и для того, чтобы реализовать те идеи, которые у меня были, оказывается, что было бы неплохо сделать нечто такое, что бы позволило в разных потоках, в разных планировщиках выполнять какие-то действия, потому что это очень важно, переключиться на правильный поток. И когда я думал в этом направлении, понял, что в принципе эта вещь для человека хорошо обобщается и в принципе для распределенных систем, где важно, что и когда у тебя запускается, вот эта штука хорошо ложится. То есть когда у меня есть какой-то сетевой взаимодействие нетривиальное, когда у меня есть всякие планировщики для тяжелых задач, для легких задач, какие-то дисковые подсистемы, где мне надо просто синхронные действия делать и, соответственно, выкидывать их из общего пола потоков, чтобы они не мешали и не тормозили. Все вот это потребовало... Ну, если это все реализовать ручками, это все большинство реализовывает ручками, то это становится очень много кода геморройного, который тяжело поддерживать, потому что часто бывают ошибки. Но при этом хотелось именно синхронный код писать, потому что синхронный код тяжело, с моей точки зрения, тяжело поддерживать. То есть либо ты там колбасишь какие-то машины, стрип-машины. Стрип-машины, в принципе, позволяют как-то контролировать сложность, тем не менее тоже тяжелы для дебагинга и тяжелы для написания. То есть надо очень четко представлять эти стрип-машины, представлять, как состояние переключается с одного на другое. Все-таки большинство людей привыкло, ну и я в том числе, писать синхронный код, как будто он однопоточный, и вот делает сначала это действует, потом это, потом это. И возникла, то есть в рамках именно задач по распределенным системам, возникла такая штука. Не знаю, стало ли более понятно, зачем я это сделал? Да, в принципе, да. Ты просто очень много говорил про то, какое оно классное, я хотел, чтобы ты поговорил о том, зачем это кому-то нужно. Да, я думаю, что можно ехать дальше, если ни у кого больше нет вопросов. Видимо, ни у кого нет вопросов. Ну ладно, раз мы заговорили про распределенные системы, распределенные системы обычно работают не где-нибудь, а в кластерах. Кластеры бывают большие, тогда они начинают себя как-то вести иногда не очень хорошо. И вот вторая тема нашего гостя — это, собственно, попытка это смоделировать. Мы в какой-то момент назад обсуждали статью, наверное, уже полгода назад, нет, меньше. Наверное, летом мы обсуждали статью от Мартина Клепмана, про то, как он писал, что в больших кластерах вероятность отказа имеет... В общем, что там надежность всего кластера и вероятность боевого компонента, что они начинают себя не совсем интуитивно вести в больших кластерах. А тут Гриш написал follow-up, но его, мне кажется, вы не обсуждали. Ну давайте обсудим. На мой взгляд, достаточно интересная была проблема поднята Мартином Клепманом.",
    "result": {
      "error": "API request failed: Error code: 400 - {'error': 'Trying to keep the first 9686 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': 'Trying to keep the first 9686 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}\n"
    }
  }
]
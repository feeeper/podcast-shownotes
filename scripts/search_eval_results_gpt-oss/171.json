[
  {
    "segment_id": "cec5b95f-b78a-4694-ab88-039be382a801",
    "episode_id": "d4ab0d0a-e490-4a43-a0c3-e770fbce9329",
    "episode_number": 171,
    "segment_number": 6,
    "text": "Идея в чем? Брендан работает в Netflix, и в Netflix очень сильно используется AWS. Я не знал, что он работает в Netflix, я это из статьи увидел, что он говорит, мы в Netflix, мы тут в Netflix и так далее. AWS, наверное, на Netflix молится, потому что Netflix – это один из самых мощнейших его клиентов, у них очень большая нагрузка на сеть, очень большое количество инстанцев. И Netflix – это показательный такой пользователь, на него все смотрят, равняются, и его репозитория на GitHub звездочками очень сильно помечена. И рассказ начинается с того, что в целом Брендан объясняет, что существует несколько стадий виртуализации, и самая простейшая – это виртуализация в программном обеспечении, то есть это фактически самое простое, что вы можете сделать, написать ПО и запускать в этом ПО что-то другое. Вот это самое медленное, и замедление операций от 2 до 10 раз. Второе – это пара виртуализация, когда у вас на операционной системе запускается гипервизор, и этот гипервизор выполняет все системные вызовы гостевых операционных систем. Для этого гостевые операционные системы должны запускаться не в чистом виде, а с некоторыми хаками, для того, чтобы они не сами запускали все привилегированные какие-то вызовы, а делали обращение к гипервизору. Поэтому вам необходима хакнутая, немножко измененная гостевая система. И происходит улучшение производительности по сравнению с написанной в чистом ПО, ну в смысле чисто на программном языке. И падение производительности от 10 до 50%. И самая лучшая стадия – это когда у вас есть аппаратная поддержка виртуализации, в этом случае происходит очень маленькое падение производительности, 0,1-0,5% по его оценке. И обеспечивается это тем, что в железе есть какая-то поддержка этого гипервизора, и вы фактически можете даже не замечать, что вы работаете с виртуализацией, а вы можете думать, что вы работаете напрямую с железной машиной. И вот эти краткие объяснения, они немножечко поясняют, что это за график, этот рисунок, который я нарисовал. Но далее идет более полное объяснение, и вот это, я считаю, одна из самых интересных вещей. Я довольно много задавался вопросов по поводу виртуализации в AWS, как и многие, наверное, кто работает с AWS. Задавали себе вопрос, чем отличаются C11, C20, C30, C45, задавали вопрос, есть разные виды АМИшек, там, с PV, с VHM, вот. И вот это все фактически в этой статье объяснено. Я сейчас немножечко пробегусь, потому что времени у нас осталось не так много, но чтобы заинтересовать вас, и чтобы вы сами полезли и посмотрели. Все начинается с полностью программной эмуляции. Это некий аналог в мваре 1998 года. Очень большое падение производительности для высоко нагруженных задач. Он, правда, не поясняет, были ли в реальности запущенные AWS подобные инстанции. Возможно, были в стародавние времена, когда еще не вышел на рынок с этой услугой. Следующая стадия – это развитие до ксен паравиртуализации 3.0. Это самое начало паравиртуализации. То есть, Amazon модифицирует гостевую ось, для того чтобы она как раз все системные вызовы, все это делала через гипервизор. И, соответственно, ядро использует аналогично паравиртуальный нетворк и сторидж драйвера. Это улучшает производительность по сравнению с полностимулируемым аналогом, но все еще большие просадки. На подобной технологии работал M1 Small и все, я так понимаю, M1 и C1 инстанции. Его он использует в качестве примера. Следующая версия – это когда начинается использовать хардварную виртуализацию ксен HWM 3.0. Соответственно, какое-то начало хардварной виртуализации. И, к сожалению, все еще прерыва и нейтайны работают полностью по старой схеме, на виртуализации с помощью программного обеспечения. Но работают они достаточно быстро, потому что есть какие-то, видимо, хаки, которыми AWS используется. Поэтому на картинке для таймеров и прерываний, хотя используется старая схема, они все покрашены в зеленый. На следующей стадии начинается самая запутанная часть, которая чаще всего в Stack Overflow обсуждается и которую чаще всего все задают. Это ксен HWM 4.0.1. В этом случае используется тоже HWM, это Hardware Virtual Machine. Но здесь получается очень много путаницы. Во-первых, есть два типа АМИ. iron 1 ОЙ первое это пара Virtualization PVD, во-вторых, это HWM. Но на самом деле там вариантов гораздо больше. То есть, на самом деле, вы можете использовать либо PVD, либо вы можете использовать хардварную Virtualization с драйверами minimumwall либо вы можете использовать Hardware Virtualization с драйверами minionswarmhic, которые используют функциональность хардварной virtualization, так называемая PVHWM. То есть, вариантов очень много, и чаще всего, когда говорят HWM на этом этапе, говорят про HWM как раз с драйверами PV, с функциональностью HWM. При этом возникает еще больше путанец из-за производительности. Самая первая версия, которая как раз на Амазоне появилась, не использовали пары виртуальных драйверов, и поэтому они были гораздо медленнее, чем PV. Из-за этого в Stack Overflow закрепилось, и во всех советах, везде на форумах, советуют не использовать HWM, хотя это более правильная прогрессивная технология, а используйте PV. И хотя AWS довольно быстро все починили, переключили все на использование более правильных, более быстрых драйверов, эта схема закрепилась, и до сих пор эта байка ходит среди программистов. В 2014 году Netflix после своих внутренних тестов полностью перевела все инстансы с пары виртуальных на аппаратную виртуализацию, как раз на схему PV-HWM. После этого где-то в 2013 году некоторые инстансы начинают поддерживать аппаратную виртуализацию для сетевых интерфейсов. Первым таким инстансом был C3, и AWS в своих маркетинговых статьях назвала это Enhanced Networking. То есть они добавили туда драйверов для работы с 10-гигабитной сеткой, потом для 25-гигабитной сетки. При тестах в Netflix, это протестировали, добились 2 миллиона пакетов в секунду на C3-инстанцах. Это небывалая производительность, и все там плясали и искакали от счастья. В 2015 году AWS запустила C4-инстанцы, которые использовали аппаратную виртуализацию уже для EBS, то есть для сториджа. Вообще, если посмотреть на график и посмотреть на стадии развития виртуальных машин, получается, что AWS намеренно сперва пыталась ускорить именно CPU и память, потому что это наиболее часто используемые ресурсы, фактически, наиболее нужные вещи. И поэтому они добились высокой производительности с CPU и память именно в самых первых версиях виртуализации. Все остальные – это сеть, работа со сториджем, таймеры и так далее – они уже по остаточному принципу, и, соответственно, на графике видно эту лесенку. То есть сперва они добились высокой производительности CPU, потом Network, потом Local Storage и так далее. И как раз в 2015 году они оптимизировали EBS и смогли добиться на тестах 3 миллиона сторидж IOPS. Это тоже очень большая производительность, это тоже как раз с помощью хардварной аппаратной виртуализации. Ну и, как Брэндо написал, сразу после этого он решил написать большую статью про все это, и пока он писал, он не успел дописать, как вышла reInvent, и на нем объявили о выходе AWS Nitro в 2017 году. Это новый гипервизор, под которым работает уже C5, следующая, последняя на данный момент поколение инстанциев в AWS.",
    "result": {
      "query": "AWS virtualization stages explained"
    }
  }
]
[
  {
    "segment_id": "620b4974-08d7-4391-9b80-14e905fcde9d",
    "episode_id": "0214f32a-9564-4319-b06c-6bf411b9d100",
    "episode_number": 440,
    "segment_number": 2,
    "text": "Он потом его в свое время записывал. У него там были веселые выпуски, когда он с каким-то микрофоном или с каким-то диктофоном приходит в парк, садится на скамейку и записывает и комментирует, что вот сейчас машина проехала, слышно, не слышно. Звучит музыка, поют, слышно, не слышно. Вот я в свое время из этого подкаста очень много узнал про реверберацию и компрессию и про всякие такие штуки. Если вам интересно, я просто рекомендую. Там не очень много выпусков. Порядка 10-20, я точно не помню. Если только новые не были залиты. Вот, теперь точно все. Алекс, ты чему-нибудь за неделю научился? Я за неделю... Не то чтобы научился, я в очередной раз... Убедился, что делать короткие презентации гораздо сложнее, чем длинные. И чтобы сделать презентацию на 15 минут, я готовился полтора дня на прошлой неделе, мучительно отсекая каждое лишнее слово и каждый лишний абзац. Но в итоге получилось норм. И это прекрасно. Что еще, оказывается, получилось норм, это доклад про foreign data wrappers, который я Саше не очень рекомендовал, а Саше он в итоге понравился. Саше в итоге стало скучно, и вот прямо перед выпуском он его посмотрел. Речь идет про доклад, который читает Кристоф Петтус на Pigeocom 2023. Доклад про то, как писать foreign data wrappers. FDW это штука Postgres, которая позволяет из Postgres входить в другие штуки. То есть из Postgres можно сходить в речи, в интерфейс, в интерфейс. То есть, если ты не понимаешь, что это значит, то это не значит, что ты не понимаешь. Ты можешь сходить в речи, в интерфейс, в другой Postgres, в файлик, в паркет файл, во что угодно. В небо в Аллаха. Во что? Это была шутка про даже небо, даже Аллаха. Так вот. И в докладе рассказывается, как этим пользоваться. Первые 10 минут действительно не очень хороши. Вот примерно как Валер описывал, что рассказывается про исключения в Postgres, про то, что такое датум, про то, как происходит управление памятью. Если вы писали о расширении для Postgres, то вы все уже знаете. А после 10 минут начинается уже более интересно, конкретно про FDW. Приводится картинка, что вот у нас есть Postgres, а вот у нас есть расширение, которое реализует FDW. И Postgres входит в расширение два раза. Первый раз Postgres приходит и говорит, вот мой запрос. Верни мне на этот запрос все возможные Path. Path — это способ исполнения запроса. То есть у тебя расширение может сказать, я на этот запрос могу сделать, например, SIGSCAN. Или я могу сделать INDEX SCAN. Или что-нибудь еще. На практике, согласно этому докладчику, обычно FDW реализует SIGSCAN. Но это необязательно. Так вот, из всех возможных путей исполнения запроса Postgres... Точнее, то, что было выше сказано, это в расширение приходит планировщик. Потом планировщик выбирает план исполнения запроса, передает его в Executor. И уже Executor второй раз приходит в расширение и говорит, у меня тут план исполнения запроса. Верни мне на этот план исполнения запросов, я так понимаю, кусок плана, конкретные картежи. И расширение уже возвращает исполнителю картежи. Дальше приводится список callback. Вообще FDW — это интерфейс, устроенный так, что ты просто регистрируешь кучу callback. А уже FDW — это интерфейс, устроен так, что ты просто регистрируешь кучу callback. Потому что сtım Sandy эти callbacks будет вызывать. А прото многие из них опциональные? Многие из них, к счастью, опциональные, можно их не заполнять, и система как-нибудь сама разберётся. Но некоторые из них опциональными не являются. Вот тот callback, который возвращает P Еще там есть callback, который оценивает размер отношений. Например, если сегодня мы не ввести налоговую нажимания, отношения, в смысле таблицы. Есть хеллбеки начать скан, интерьироваться по скану, закончить скан, начать скан заново. Если скан начнется заново, то кортежи не обязательно возвращать те же кортежи в том же порядке, просто нужно сбросить свой стейк и начать заново. А глупый вопрос. Зачем ручка для начать заново, если можно закончить и начать? Зачем она отдельная? Видимо, предполагается, что ты можешь реализовать более выгодным способом, чем если закончить и начать заново. Например, у тебя в закончить может... Самый простой пример. У тебя в начать может быть открыть соединение, а в закончить может быть закрыть соединение. А в ResCAN ты можешь не закрывать и не открывать сетевое соединение. Логично? Понял, спасибо. Ну вот. Дальше докладчик подробно идет по всем хеллбекам, разбирает, что в них приходит. Постоянно утешает аудиторию, что если вы носить пишки и не беспокоиться, это на самом деле все очень просто. Говорит, где посмотреть более сложные примеры, потому что в этом докладе, например, рассматриваются штуки, в PostgreSQL поддерживаются штуки. Называются pushdown join, pushdown group by, pushdown order by и, возможно, какие-то еще. Идея в том, что ты в своем расширении можешь сказать, что вот здесь в запросе join я знаю, как сделать join на стороне вот той системы, которой я являюсь FDW. Например, если у тебя FDW в MassQL, ты можешь сказать, что вот тут join его MassQL сделай. Но если ты не умеешь в pushdown join, тогда это будет выглядеть так, что если у тебя есть две таблицы, например, Postgres считает кортежи из первой таблицы, потом он считает кортежи из второй таблицы, потом на своей стороне подjoинят, а лишнее выбросит. Но, понятно, это не очень эффективно, как минимум, лишние данные туда-сюда гоняются, потому что у тебя собственно выполняется join, а потом часть данных выбрасывает. Если можно реализовать это на стороне той-другой системы, это обычно выгоднее, но это также сложнее в реализации. Про сложность реализации. Pushdown joinов сложен, но вот, например, одна из вещей, которую на уровне путей можно делать, если я правильно помню, я не знаю, есть ли это в докладе, ты можешь, например, сообщать порядок туплов в твоем sequential scan. То есть даже если ты join перекладываешь на Postgres, ты можешь Postgresу сказать, что ты, конечно, подjoин не за меня, но вообще, если что, у меня тут таблица отсортирована по такому ключу. Это отличается от pushdown order by? Это какой-то флажочек? Смотри, pushdown order by — это когда ты говоришь Postgresу, если мне отдашь order by, я смогу это исполнить. А если... Еще можешь сказать просто, что, типа, ну, чувак, типа, ты как pushdown не pushdown order by, а у меня тут... Я, кстати, не помню. Может, ты pushdown order by? Просто помню, что довольно давно в одном из... Я сам платформу не разрабатывал, Ильдара бы разрабатывал, можешь помнить Ильдара. Да, ты точно работал. А я просто как-то... Я был... Системой... Я отвечал за систему, которая его употребляла. Там была эта фишка с тем, что в path добавлялась информация о том, как именно отсортированы данные на диске. Ну, в противофайле, в том случае. Полезно знать. Спасибо. Ну, пускай вопрос... Path в данном случае это что? Это на файловой системе или что? Нет, это path, это в смысле способ выполнения. То есть, типа, вариант плана, так, наверное. Или даже вариант подплана. А, понял. Окей, спасибо. Я сам не очень хорошо разбираюсь в частях Pathgress, которые касаются планирования и оптимизации запросов. Вот, мое дилетантское понимание, что path... То есть, path — это название объекта, тип объекта, и в нем сказано, что этот путь исполнения запроса, например, сделает секс-кан таблицы. Или он сделает... Как пример, индекс-скан этой самой таблицы. И у тебя у path есть стоимость, и планировщик, глядя на различные пути исполнения запросов, и зная в каком контексте разный path, как они друг с другом взаимодействуют, потому что там слева, например, FDV, справа у тебя таблица Pathgress, потом они в несколько уровней как-то джоунятся, потом с каким-нибудь другим FDV идет под запрос, да, и тебе нужно выбрать из всего множества возможных планов наименее дорогой. Понимаешь, да, суть проблемы? Ага. Вот. Про сложность. Автор много говорит, что обязательно все это нужно основательно тестировать, потому что, на секундочку, вы, знаете, вы можете сделать расширение, которое крутится в ядре Pathgress. Если что-то сломается или пойдет не так, это очень плохо для SubD. Поэтому нужно очень серьезно все это тестировать. Как именно, в докладе, к сожалению, не уточняется. Валер, ты случайно не знаешь, как тестировалось вот это FDV, которое вы использовали? Делать много разных запросов, особенно те, которые предполагается гонять. Ну, не знаю, вот тот конкретный FDV, с ним все было проще, потому что вариантов запроса, которые к нему можно сделать, было не очень много. То есть он был в проприетарной системе, он, наверное, уже не торчал, к нему ходила одна-другая система, и ну, типа, можно было просто проб-тестом нагенерировать широкий класс запросов, которые, скорее всего, будут сделаны, и проверять, что во всех случаях на них ничего не падает. В общем случае, это сложно, потому что, ну, вам нужно, типа, делать какой-то файзер по SQL. В принципе, это рабочий подход, на самом деле, но это очень трудно, как это... Ты такой на CI не погоняешь, потому что, ну, на каждый коммит, во всяком случае, потому что это очень долго. Реалистично брать какие-то запросы, которые частые, типичные, проверять. Опять же, типа, тебе не нужно парсить SQL, тебе нужно просто убедиться, что фигню, которую ты делаешь, что она работает примерно, а не работает. Это не ожидаемо, то есть, как в большинстве случаев, достаточно протестировать. Типа, если ты реализуешь какой-то pushdown, что pushdown pushdownится. Если ты реализуешь, там, не знаю, да, когда он pushdownится, ничего нигде не ломается. Если ты реализуешь скан, что он, вне зависимости от того, какое количество строк ты взялся сканировать, что он просканирует, ну, столько, сколько запрошено, а не добавит лишнего, не уберет, ничего не потеряет по дороге.",
    "result": {
      "query": "Postgres FDW presentation summary"
    }
  }
]
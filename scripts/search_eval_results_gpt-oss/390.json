[
  {
    "segment_id": "9f1afb7d-9e09-4a84-9ba7-4f7ae044ce5f",
    "episode_id": "ce9d706f-9dd8-42b5-97f6-18b1d3070c10",
    "episode_number": 390,
    "segment_number": 8,
    "text": "партий, в каждой партийце сдается 10-я часть. Там есть некоторые исключения типа того, что не стараясь балансировать, там есть два вида балансировки по занимаемому месту и по throughput, и там в некоторых случаях типа они могли немножко там хитрее его разделить, но в любом случае оно статически назначалось, что вот в этой партиции столько-то попугаев можно в секунду. И конечно же они налетели на то, что скажем, вы на таблицу запровижили тысячу попугаев. Допустим, ну простой случай, у нас есть две партиции, у каждой оказалось по 500 попугаев. Но так получилось, что первой партийцей нужно обслужить на самом деле 900 попугаев, а второй партийцей 100 попугаев. И это неприятная ситуация. И это тем не приятнее, что мы в этой ситуации можем оказываться по-разному. Во-первых, потому что мы там по месту разделились, когда нагрузка была на самом деле по-другому распределена, или мы пытались разделиться по нагрузке, у нас там нагрузка, вот тут я сейчас не помню уже случай, в общем да, больше одному способа оказаться в этой ситуации. И Amazon, ребята из Amazon, которые работали на DynamoDB, они терирулись много лет этим. То есть система была выкачана в первый раз в 2013 году, я чуть упомянул, я не помню, когда появился bursting, но вторая техника, про которую буду говорить, появилась году в 2016, а последняя техника чуть ли не в 2018 или типа того. То есть чтобы сделать правильно, у них ушло порядка, сколько получается, 6 лет, чтобы сделать так, чтобы наконец работало нормально. Вот такие вот они, они чисто боролись с DataSquare при разделении квоты на запросы. И ситуация сложается тем, что они же как бы Amazon, они не могут, если они просто overprovision от тебя, то они деньги теряют, или они нечаянно создают назолевого соседа кому-то еще. Все эти ситуации, они все сложные, их всех хочется избегать. Собственно, первый механизм, который они придумали, это просто давать, если вот какая-то партиция сейчас кратковременно испытывает страдания. Но вот сейчас на узле у нас есть немножко свободных ресурсов, мы разрешаем этой партиции на короткое время отражать чужие ресурсы, грубо говоря, если они там никому не нужны больше. Это работает коротко время, там они придумали систему токенов, я не буду в них вдаваться, если интересно, в пейпер посмотрите. Но смысл такой, что вот краткосрочные такие вот всплески, они довольно легко победили. Однако, это никак не помогает тем, что если у вас перманентный прям для это скив. Они это пытались бороть очень хитрым механизмом, когда они вместо того, чтобы выделить попугаев поровну, пытались их там переразделить, там вот тут значит набросить попугаев, вот тут-либо меньше попугаев, а если там набросили попугаев, оно стало, не знаю, в другом месте где-то, оно типа все еще не починилось, там еще какое-то действие выполнено. Опять же, не хочу вдаваться в подробности схемы, потому что я не помню почитать и пейпер, но смысл такой, что получилось довольно замороченная схема перераспределения попугаев. И что еще хуже, она включалась уже после того, как юзер пострадал, ну то есть кастомер пострадал. То есть вот у нас как бы случается дейт эскью, у нас какой-то партизу начинает жестоко тротлить, запросы отваливаются, после этого, может быть, вначале не отваливается, потому что происходит бёрст, потом бёрст заканчивается, запросы отваливаются, через какое-то время адептиф capacity начинает часа трепу перераспределять попугаев, и там типа несколько минут, возможно, выстрадали. Sorry, плохо быть вами. Вот. И да, стало понятно, что несмотря на то, что вот эта попытка сделать такое локальное принятие решений о квотах, оно, конечно, вроде было хорошим и выглядело элегантно, но на практике нифига не работает. Поэтому они запустили вот отдельный сервис, который занимается чисто подсчетом попугаев, и он очень похож на только робот бёрст. То есть они там не совсем по-настоящему, они не досконально считают попугаев. Я так понимаю, что там такой временный стейт, если я правильно понял, из фейпера, который нигде специально не хранится, он просто, поскольку попугаи возобновляются, ну, если у нас там тысяча запросов в секунду, например, нам нужно просто каждую секунду учесть, что у этого, по этому адресу можно снова выделить тысячу запросов. Поэтому если там какая-то реплика этого сервиса отваливается, то ничего страшного, просто переподнять, а на следующую секунду стейт правильно получит. И когда роутер запросов хочет зараутить запрос, он вначале идёт в сервис admission control, как бы забирает в себе некоторое количество попугаев, дальше этих попугаев распределяет между теми запросами, которые к нему пролетают, а дальше снова идёт за попугаями. И таким образом у нас попугаи распределяются действительно на таблицу, а не на партицию. Плюс механизм бёрдста они оставили, механизм этого адаптивного capacity, когда они там перераспределяли попугаев между партийцами, они им полстую выбросили. Здорово, попугаи перераспределяются честно, но им пришлось накрутить систему, которая потом упаковывает узлы, чтобы не создавать шумных соседей, они, к сожалению, не вдаются в подробности, как именно они это делают, просто что им пришлось решать эту проблему. Что им нужно как бы получается так распределить реплики, что у них одновременно никто, никому не шумный сосед, хватает capacity всем, нету двух реплик одного и того же партиции в одном месте, ещё это всё разбросать по нескольким availability зонам, довольно сложная задача. К сожалению, вообще, ну то есть она только просто напоминает, что такая задача встала и они её как-то решили. Вопросы, комментарии? Жаль, что некоторые детали опускаются. Да, как и во всех таких пейперах, к сожалению. И в заключение, Amazon, конечно же, Amazon, они решили, что ставить квот это сложно, поэтому они добавили возможность просто сказать, авто скейль меня, вот я короче, вот сделай мне таблицу и пусть она получит столько попугаев, сколько ей потребуется, но с другой стороны, если ей сейчас не требуют попугаев вообще,",
    "result": {
      "query": "Amazon DynamoDB capacity balancing"
    }
  }
]
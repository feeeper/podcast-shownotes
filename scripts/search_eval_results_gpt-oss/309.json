[
  {
    "segment_id": "6fcd68db-def7-4cb5-894f-d50f49772ef9",
    "episode_id": "32d39d5e-7f15-4c5b-a75b-fb1d01c31a34",
    "episode_number": 309,
    "segment_number": 2,
    "text": "Вот, и всегда это несколько болезненно, и хочется, если это небольшая вещь, то, как правило, то моя команда просто берет и делает. Но, опять же, с помощью соседней команды это все договаривается. Вот, расскажи, как это реализовано в Microsoft? Ну, на самом деле, мне кажется, как и везде. У нас есть процедуры и процессы по планированию. Естественно, все для чего нужно серьезное большое изменение. То есть, например, если мы хотим добавить какую-то фичу в DNS в Windows, или если мы хотим добавить какую-то фичу в CLR или в DUTNET, то мы действительно идем в планирование. Собственно, для этого, ровно для этой штуки, у нас есть PM. То есть, мы работаем с PM организацией, они работают, соответственно, с PM организацией того Division, от которых нам чего-то надо, те дают нам истимейты, и мы объясняем, почему нам это очень надо прямо вот завтра, и они пододвигают свои истимейты. На самом деле, в этом плане Microsoft, скажем, 5-6 лет назад, пока у нас еще был Steve Ballmer, было заметно-заметно хуже. Сейчас, за последние 5 лет, именно этот аспект улучшился просто на 3 порядка. То есть, сейчас действительно получить какую-то фичу от Windows или от DUTNET, или от Azure можно, и достаточно быстро, и это реалистично. Есть еще Out of Band изменения, которые, например, связаны с какими-то проблемами Security, или с какими-то серьезными багами, или с чем-то еще. На них Turnaround вообще очень короткий. То есть, можно получить действительно правильно сделанные изменения в течение нескольких дней, и оно будет нормально протестировано, и вот это вот все. На самом деле, там где-то даже вот цикнишки, которые Иван упомянул, у нас там есть даже небольшой кусочек про то, как мы занимались Mildown-успектором, и вот, собственно, это один из прекрасных примеров, как можно очень быстро получить, как мы смогли очень быстро получить толковые изменения, быстро запихнуть его в продакшен, и оно прямо все заработало из коробки, и все было замечательно. Можешь сказать, потому что не все прочитали эту книжку? Ну, наверное, все слышали про Mildown-успектор, да, то есть, это была серьезная уязвимость, связанная с тем, как работает BIOS, и с тем, как он хендлес в разных операционных системах, и у нас, как у всех в индустрии, была проблема с тем, чтобы пропатчить эту уязвимость до того, как она стала публичной, и нас, собственно, хакнули. Я как раз в то время владел инфраструктурой патчинга операционных для ажуром, и у нас, собственно, была проблема с тем, что, во-первых, не существует патча, во-вторых, нам нужен механизм доставки, который очень быстрый, в-третьих, доставка сама по себе, она на самом, ну, это очень низкоуровненый драйвер, нельзя поменять его на горячую, да, то есть, надо обязательно выключать машину, включать ее обратно, перезагружаться, и вот это все. Вот, это было очень нетривиально, в контексте того, о чем мы разговариваем, получить, собственно, патч от ребят из Windows было очень прекрасным experience, да, это было быстро, это было действительно неплохо сделано, и оно реально работало, и они работали с нами практически round the clock для того, чтобы понять, как оно работает в продакшене, есть ли какие-то проблемы, performance degradation, вот это все, и было каких-то пары минорных проблем, которые они пофиксили по дороге, ну, в общем, как-то так. То есть, на самом деле, вот конкретно эта проблема, да, если слышишь то, что говорит Света, и такое, конечно же, тоже бывает, да, что люди просто отказываются делать фичу, которая вам нужна, потому что у них нет на это времени, другой backlog, другие приоритеты, но в действительности оно не так часто происходит, как мы об этом думаем. Ну, со security, security багами обычно действительно приоритетизируются, и они фиксятся очень быстро, потому что там большие, большие риски, а вот, что касается таких, ну, рядовых более вещей. Ты сказал, что они делаются довольно быстро, особенно когда ушел Стив Балмер, расскажи, что такое быстро. Это хороший вопрос, да, на самом деле зависит от приоритета, скажем по контрасту, да, в 2012 году я нашел баг в стеке DNS в Windows, пофиксить его заняло три года, вот, в том, чтобы сейчас, когда мы файлим баг, и мы хотим получить на него фикс, это занимает примерно месяц, если мы не приоритизируем и не давим на то, чтобы починить его значительно быстрее. Месяц, причем, связан с тем, что мы стараемся ратировать операционку раз в месяц, да, не чаще. Мы могли бы делать это и чаще, но мы считаем, что месяц это такое, достаточно полковный интервал, порядок причем. Окей, спасибо, и, то есть, получается, соседние команды, в принципе, могут через месяц делать какую-то задачу? Да, если она достаточно высокого риоритизирована, да, то есть, скажем, у нас есть разные итерации планирования, да, у нас есть то, что мы называем long-range планированием, это долгосрочным планированием, это горизонт порядка 3-5 лет, когда мы в принципе решаем в рамках компании, какие продукты должны развиваться и все остальное. Хороший пример, если вы видели, недавно Xbox выпустил то, что они называют X-Cloud, это вот для Android, теперь у вас есть Xbox в Cloud, ваш Android может быть экраном для этого Xbox, и вы можете играть на любые игры от Xbox, не покупая себе сам девайс. Совершенно, мне кажется, потрясающий проект, мне очень нравится, мы им долго занимались со стороны Cloud, это реально работает, да, вот это проект, который был, скажем, запланирован там на трехлетнем горизонте, потом был с дизайном hardware, был с дизайном software, все это было тихонечко заделиврено, да, и вот это все. В рамках трехлетних итераций мы делаем полугодовые итерации, да, полугодовые итерации помогают нам... Подожди, притормози, вот ты сейчас говоришь hardware, plug-horizont-planning, мне 3 года, hardware, для этого Xcloud, я помню, когда Dropbox рассказывали, как они переходили на железные сервера для своей системы Magic Pocket, что у них были, например, даже банальные проблемы, ну, по числительной мощности физически доставить до центра, потому что там, типа, потерялись машины с серверами, всякое такое, я подозреваю, что Xcloud, если я правильно помню, он все еще в бете, я не знаю, сколько у вас там моих мощностей, но вот вообще это, в принципе, интересный момент, как бы, и, возможно, ты имеешь какую-то по этому поводу, можешь тут чуть больше сказать, как бы, вот, наверное, это не совсем по теме хаос инжиниринга, но это интересный момент, как вот, вот, вот такие-таки такое облако для, с не самыми стандартами, я подозреваю, требованиями, потому что там, ну, под игры нужно GPU хороший, который должен виртуализироваться, и были ли какие-то интересные кулстори про то, как это затапилось, и можно ли это чем-то поделиться? Хороший вопрос, я, на самом деле, не очень знаю, чем я могу поделиться, я могу просто сказать про то, что я точно знаю, может быть, публично, да, кулстори, на самом деле, мы смогли сделать это очень быстро, потому что мы переиспользовали кучу того, что уже было доступно, да, начинают железо, которое уже было, да, самое сложное, что было, что нужно было сделать, нужно было разрешить хастомерский доступ к железу, которое стоит в дата центре, да, ну и второе, соответственно, да, вот то, что ты говоришь про логистику, доставки железа и подключение его он-сайт, да, это, на самом деле, очень-очень болезненный процесс, который мы все пытаемся автоматизировать как-то лучше, ну, потому что, да, потому что мы купаем железу каких-то сортпати большими блоками, потом оно доставляется в дата центре, в дата центре его надо физически подключить в сеть, в выхлаждение, в питание, все вот это вот, а если вы когда-нибудь видели, ну, наверняка видели настоящую рабочую стойку, да, то количество проводов, который из нее торчит, это что-то умного не постижимое, и включить все провода в правильные разъемы, и вот это все, да, достаточно тривиальная работа, но ее просто очень много, да, это, кстати, тоже отличный топик для хаос инжиниринга, да, что делать, когда у вас саппорт он-сайт влекает провода не в те разъемы, и как симулировать такую ситуацию, насколько часто она случается, надо ли с ней как-то бороться, и вот это вот все, ну, как сказать, банальное решение использовать разные разъемы, да, это правда, но, например, разъемы для сети все одинаковые, да, то есть для Ethernet разъема, да, или оптические разъемы, они все в общем-то выглядят абсолютно одинаково, но и не должны быть одинаковые, да, потому что у вас, скажем, в одной из стойки там есть несколько десятков машин, в которых втыкается одна и та же сетевая карта, да, то есть, ну, одного и того же производителя одной и той же серии, вот это вот все, да, расскажу вам. Я им сказал, что они могут быть физически одинаковыми, но если ты можешь в железе, ну, как бы в фирмваре зажить, что воркнул не тот порт не туда и у тебя загорелся красный светодиод, типа оператор ошибся, перетыкай, не тот код пришел. Наверное, а как потом это менять? То есть, например, если мы так сделаем, то если нам нужно поменять, например, одну из машин в этой стойке, да, нам надо будет сначала делать firmware patch на эту машину, и эта машина нельзя будет переставить ни в какое другое место, только подключив ее только к этому же нет другому девайсу, это как-то не очень скалируемо получается, видишь. Да, она становится, у тебя установятся машины довольно уникальными, и это удорожает косты, потому что тебе нужно, ну, то есть, раньше ты можешь эти машины как угодно переставлять, а потом становится уже это невозможно, ну, то есть, так не делают.",
    "result": {
      "query": "Microsoft feature release process"
    }
  }
]
[
  {
    "segment_id": "e686c38e-c095-4361-a02c-95ee39c1de26",
    "episode_id": "50b6dbc7-25e3-446d-81ca-b9679d22ff93",
    "episode_number": 437,
    "segment_number": 6,
    "text": "Почему это вообще интересный paper? Потому что это очень уникальный подход к тому, как это сделать. На фоне всего, что мы до сих пор обсуждали в подкасте, обычно накручивают MVCC, обычно накручивают как это, какую-нибудь координацию транзакций, или, как это сделано в FoundationDB и похожих системах, когда у нас есть глобальная упорядочивающая штука транзакции, либо как это сделано в Cockroach и Spanner, когда у вас есть какой-то протокол, который, по сути, делает двухфазные блокировки или двухфазный commit. И все это, в любом случае, обычно наверх, наверх, мультиволюционность. У DynamoDB одна из таких основополагающих принципов это предсказуемость. Они ни в коем случае не хотели жертвовать, во-первых, предсказуемостью в принципе, и поэтому они отказались от MVCC, потому что MVCC создает на их масштабах, создает непредсказуемость по стороджу, по времени того, сколько у вас lockup ключа будет происходить. В общем, очень не хотели они MVCC сделать. Во-вторых, они ни в коем случае вообще не хотели, то есть, если вы этим не пользуетесь, у вас вообще не должно быть никакого влияния на вашу систему. Вот. Тот подход, который они пошли, он интересен. У них все еще есть двухфазный, по сути, двухфазный коммит, но у них нету многоверсионности. И транзакции у них есть всего двух видов. У них есть или транзакция читающая, и она будет только чтение делать, или транзакция, которая содержит операции записи и операции проверки ключа. Ну, то есть, по сути, вы делаете вначале читающую транзакцию, а потом при записи, если у вас есть что-то, что, ну, в общем, чтобы не нарушилась консистенция, вы можете проверить свои предыдущие чтения. Никаких других видов транзакций у них нету. У них транзакции не интерактивные. Вот. И еще интересный момент. Ну, нет MVCC, но какой-то Concurrency Control уже должен быть. У них Concurrency Control на основе таймстемпов. Почему это OK? Потому что безопасность, ну, есть гарантия того, что все будет записано, как бы, консистентно, и, типа, записи не разъедутся, она обеспечивается все еще фазным коммитом. То есть нет такого, что у вас где-то система будет смотреть на таймстемпы, чтобы, как это... Нет такого, что у вас какая-то отдельная взятная нода будет принимать какие-то решения на основе таймстемпов. Нет. Если какая-то транзакция коммитится, она коммитится целиком вся на всех машинах. И нигде не коммитится. Это решается двухфазным коммитом. Таймстемпы используются исключительно для того, что если у вас двухфазный коммит, и во время двухфазного коммита вы обнаружите, что у вас есть конкурирующая транзакция с таймстемпом, который больше вашей, то вы идете на фиг. И потом, как бы, неважно, откуда этот таймстемп взялся, это все, как бы, такие просто, ну, не очень важные детали. Это просто с точки зрения Concurrency Control, вы можете вообще хоть монетку подбрасывать на самом деле. Чем, собственно, блокчейн-системы и занимаются, если так подумать. Вот здесь выбрано, вместо монетки выбраны таймстемпы, потому что Concurrency Control на основе таймстемпов, кроме того, что он обеспечивает, собственно, Concurrency Control, то есть, что у вас только какая-то одна транзакция из двух одновременных, или там, N одновременных будет успешной, он еще обеспечивает то, что транзакции более-менее как-то разумно упорядоченные с точки зрения пользователя получаются. Ну, то есть... Плюс можно синхронизировать часы, у них тоже есть атомные часы, но это, опять же, это никак не влияет на корректность, это влияет просто на то, как часто транзакции будут оборваться. Вот. Двухфазный коммит у них сделан так, что у них есть... Да. Прежде чем мы поговорим про двухфазный коммит, в принципе, DynamoDB без всяких даже транзакций у них... Он так устроен, что каждый каждый каждый шарт это Paxos группа и, собственно, поэтому у них всегда DoubleCast на отдельные ключи. В случае с транзакционным... Да, и у них всегда, я так понимаю, просто есть Request Router, который занимается в частности, аутентификацией и всяким таким. Так вот, если я правильно понимаю, о чем речь, то когда Request Router видит у вас запрос транзакции, он его отправляет не напрямую в шарт, а отправляет его транзакционному координатору, одного из многих, так понимаю, их может быть много. Даже я немножко вру. Их не то, что может быть много, их совершенно точно много, притом они не как-то специально назначаются, они просто как бы транзакционные координаторы, они... Сам по себе он... Он ни к чему не привязан. Ну, то есть, поскольку у вас двухфазный коммит, вам не нужно типа, например, через один и тот же транзакционный координатор все транзакции, которые касаются определенных шартов, прогонять. Вам не важно. Если у вас есть конфликтующая транзакция, вы это на первом шаге двухфазного коммита узнаете. Поэтому транзакционные координаторы, они не какие-то специальные, они просто, ну, типа, вот вам сколько их нужно, столько вы их запускаете. И они свое состояние сохраняют. Да, поскольку коммит двухфазный, как вы можете знать из литературы, двухфазный коммит имеет, если его просто наивно делать, он имеет такую проблему, что если у вас... хоть что-то, хоть где-то сломалось, вы рискуете не восстановиться. Ну, или, в смысле, вам нужно ручное восстановление. В случае с шардами у нас понятно, у нас, кстати, группа, поэтому там, ну, сбои, как это... Если он происходит, то у вас весь шард лежит. Обычно до этого не доходит дело, потому что у вас много реплик. Транзакционный координатор свое состояние хранит в специальном, ну, они это называют ledger, но по большому счету, это... Есть специальный шард, где трансакционные координаторы хранят свои состояния. Если транзакционный координатор упал, то у них есть специальный процесс, который периодически смотрит состояния, которые почему-то не обновились и назначает транзакционных координаторов, которые бы, ну, доведут этот транзакцию до конца. Вот. Ну и, собственно, трансакционный координатор пополняет, по сути, двухфазный коммит. Там есть некоторые детали в paper, в которые нет смысла большого пересказывать в подкасте про, собственно, их concurrent control я уже поговорил. Ну и как бы главный такой, наверное, интересный момент, что, да, действительно у них получилась очень предсказуемая система. Они, к сожалению, не публикуют точные данные по задержкам, но у них есть просто такие, типа, столбики, в котором... Ну да, у них, к сожалению, даже шкала не нарисована на этих столбиках, поэтому у нас вообще непонятно, что они показывают. Просто видно, что с транзакциями, что без транзакций, разница очень маленькая. Хотя бы написано логарифмическая шкала или нет? Нет, ничего не написано. Типа, власти скрывают. Как я люблю такие paper. Ну, увы. Спасибо, что хоть такое paper написали, потому что я вот до этого не знал, как у них транзакции сделаны. Теперь мы знаем. Вот. Очень интересно, очень необычно. В принципе, если в этим интересуетесь, рекомендую почитать. Хотя бы, если уж не paper, то статьи, которые я заранковал. Почему я вообще взялся это читать? Я, наверное, все-таки немножко спойлерну, чтобы у меня была мотивация, может, как-нибудь дочитать. Я взялся разбираться в том, как в Cassandra сделаны транзакции. Я не помню, было ли это в выпусках или нет. Уже некоторое время как устаканился как там у Cassandra, он называется CEP, у Кавки есть, ну, в общем, Cassandra Enhancement Proposal про транзакции, да, про транзакции в в Cassandra. Это было CEP-15. И как результат этой работы, кроме того, что в Cassandra появился protection code, есть протокол Accord, который строится на много чем, что мы в подкасте уже обсуждали. Я вот, мне стало интересно вот посмотреть на то, как транзакции устроены в DynamoDB и как они, как вот Accord устроен, ну, как бы я начал это раскручивать. Я не знаю, хватит ли мне, наконец, сил, не знаю, сделать прям полную подводку, но я хочу хотя бы Accord разобрать. Про DynamoDB мы сегодня поговорили. Прежде чем мы перейдем к Accord, я бы, наверное, хотел еще пару других пейперов, которые привели к этому рассказать, но посмотрим, насколько мне хватит силушек. Вот. Вопросы? Предложения? У меня есть новичковый вопрос. Ты сказал, что когда клиент хочет создать транзакцию, ему назначается случайный координатор транзакций. А как потом раутер запоминает, куда все последующие запросы в рамках этой транзакции отправлять там же координатор? Я не думаю, что он прям настолько случайный. В смысле, я думаю, что там есть какой-то stateful routing, конечно. Я имею в виду, что я под случайным, я имею в виду, что у тебя есть система типа FoundationDB, где у тебя конкретный координатор транзакций, у тебя не может никуда больше ничего пойти, никакой трафик, потому что у тебя все транзакции должны пойти через этот вот координатор. И он все их упорядочивает. Или есть другие протоколы, типа, не знаю, какого-нибудь Келвина, или там, уже не забыл, как Тилиус, или как-то есть недавняя работа, тоже от создателя Келвина. Или Дейделус, не помню. В общем, там больше, чем один транзакционный координатор, но там все равно есть какой-то протокол, как они между собой обменяются информацией. Не суть важна, смысл в том, что есть системы, где транзакционные координаторы, они какие-то специальные. Здесь они не специальные в том смысле, что любая конкретная сессия на протяжении всей сессии может общаться с любым конкретным транзакционным координатором. Ну да, ты верно заметил, что если вот прям каждый раз вообще все совсем рандомно посылать... А, сейчас, даже нет. Я сейчас понял, а вот копир التي отвечаю, потому что у них же транзакции, они отомарные транзакции — это один запрос, ты даже может буквально рандомно граутить. Перед каждой транзакцией всегда один запрос. Тебе не может быть больше, чем один запрос. А, т.е. транзакция не в том смысле, что ты прочитал, записал, а в том смысле, что ты записываешь несколько ключей, либо записываешь во все ключи, либо ни в один ключ. Да, да. Плюс ты можешь на записи, иметь проверки. И чтение. сразу много ключей того и кстати чтение интересно сделаны я хотел произвести рассказе забыл если для записи в них делается более-менее классический двухфазный комит но просто случае если вы с как это какой-то чек то вам нужно запись реальная будет просто таймстем запишется который возле конкурс контрол использовался значение не будет изменено просто он был проверено что правильная ну и собственно запись запись там будет вдвоение значения обновления таймстемпа для конкуренции control для чтений они не хотели создавать некую дополнительную нагрузку на на запись поэтому у них довольно хитрая схема которая по сути тоже реализует двухфазный комит но без комитов у них просто двухфазное чтение на первой фазе вычитываются все все что нужно вместе ставим стемпами на второй фазе делается снова то же самое и потом просто сверяются таймстемпа если как бы значение не изменились и таймстемпа не изменились значит мы прочитали консистентное состояние почему это работает потому как бы даже так от какой аномалии это защищает вас почему нужно два раза прочитать представьте что что у вас есть две транзакции 1 начале другой на здесьuck есть контент две т以及 printing-net Repair&Draw но movement speak 하고 обе транзакции и трогают ключей обе ключи а иб на разных шардах вас значит происходит предысторGood laugh происходит типа чтения ключа а после этого приходит транзакция которая за ус niqiz special оба ключа айбэ после этого 4 ключ б если вы вас как бы одна фаза на чтение но вы прочитаете какое-то состояние и она как будто бы даже нормально прочиталось и вроде дождь Meltoin говорю думали вы будем двигаться к чему-то нам окружает голова чтобы fist ничему не противоречат. Но на самом-то деле вы прочитали, у вас получился skewed rate. Потому что вы прочитали один ключ до транзакции на записи, а другой ключ после. Хотя на самом деле там была запись согласованная и оба ключа обновлялись. А если вы делаете второй проход, вы заметите, что ага, у меня первый ключ поменялся. И значит у вас получился неконсистентный snapshot, транзакцию на чтение нужно переоткатать. Это понятно? То есть у них получается транзакционные чтения в два раза дороже обычного? Да. Вот. Еще вопросы? Это вроде все понятно. Ну то есть, понятно, что они сделали всю ту боль, которую Сашу когда-то настолько травмировало, что он теперь только Postgres трогает. Да ничего они не сделали. То есть вот эта вот штука про ты можешь прочитать все ключи одним разом. Да, полезно. Но не решает. Ну скажем так, решает очень небольшой процент задач. Ну я скорее согласен, чем нет, потому что да, хочется уже нормальных SQL систем. И больше того даже говорю. Мне кажется, что у Amazon уже у него есть какие-то SQL базы, которые тоже предлагают. Ну Aurora, например, да. Только она очень дорогая. Но она есть. Но на она есть. Но с DynamoDB тоже нельзя слезть вроде. Это... В этом и заключается секрет успешности Amazon как облачного провайдера. Справедливо. Ну с DynamoDB наверное легко слезть в том плане, что проще слезть в том плане, что у него очень бедный API. Если вы найдете систему с похожими какими-то гарантиями, ну то есть, например, не знаю, какой-нибудь NUKASANDRA, о которой, надеюсь, мы в какой-нибудь поговорим, то может быть вы даже и слезете. Там еще вопрос. Вопрос в том, как много у тебя данных, потому что читать из DynamoDB стоит денег. Ну в смысле, буквально берут за деньги, там чуть ли не за запрос. Если ты туда записал много, мигрировать дорого. Ну это ж сколько надо записать, чтобы сделать одно прочтение запретительно дорогим. Ну если у тебя, туда пишется time серии, и ты очень редко возвращаешься. Ну то есть ты туда писал, писал, писал, а запросов на чтение у тебя в принципе в системе мало. На самом деле у них же есть всякие еще выгрузки из этих Dynamo и так далее. То есть ты понимаешь, что типичная ситуация, когда ты, не знаю, из DynamoDB выгружаешь потом через какой-нибудь Kinesis в Redshift или еще что-то такое, чтобы как-то удобнее работать с... аналитику поэтому гонять, чтобы не пытаться на джойне, а Dynamo делать.",
    "result": {
      "query": "DynamoDB transaction design unique approach"
    }
  }
]
[
  {
    "segment_id": "780d543a-d087-40f3-948a-5d3e29e49684",
    "episode_id": "2e90c7f3-6aa5-4e91-b9ec-09d2a09eb5d0",
    "episode_number": 337,
    "segment_number": 9,
    "text": "как-то ее там повертеть, потом выключить обратно в текстуру, при этом имея в виду цвет. Но в целом, как бы, такая модель, она достаточно сильно ограничила то, что в целом можно было делать, во всяком случае с разумной производительностью, то есть на самом деле на GPU раньше трассировали лучи, просто это было для оффлайн-рендеров, тот же самый в блендере Cycles, он работает с счет того, что он, типа, на куде считал что-то. Собственно, как мы типично просчитывали свет? Мы берем, и самое простое, что вы можете сделать, там не знаю, скорее всего, если в универе у вас был курс компьютерной графики, и вы шли дальше к какой-то так называемому тенвейерам, чтобы там, если у вас есть железо с поддержкой шейдеров, вы просто, как бы, на каждый треугольник, каждую вершину треугольника вначале исполняете такую небольшую программку, вершины шейдер, потом на каждый пиксель или фрагмент, если у вас OpenGL, исполняете программку, которая, ну, типа, фрагментный шейдер. Плюс сейчас в современном графическом пайплане, там еще есть всякие другие шейдеры, есть как минимум геометрические, есть, по-моему, текстурные, есть сейчас месшейдеры, короче, их много разных, но смыслов всегда один и тот же. Вы берете какой-то, примитив какой-то грануалярности с его параметрами входными, производите какое-то вычисление и отдаете дальше по пайплане измененный набор параметров. Сам простое, что вы можете сделать, взять, короче, вершинку, ее нормаль, и там посчитать в ней свет и использовать просто какой-нибудь такой может использовать какой-нибудь простой вещь, типа там, диффузную сочетание часто считается, типа, как вектор скалярного произведения, помноженный на какой-нибудь коэффициентик. Вот, можно использовать какую-то сложную модель света, там сейчас популярно используют такие BSDF функции, которые описывают, насколько материал отражающий, в зависимости там от кучи специальных параметров, он очень реалистично выглядит, но это все еще будет только свет в одной точке, которая учитывает только то есть, вам чтобы произвести это вычисление, что простейшее скалярное произведение, посчитать, что BSDF посчитать, вам в любом случае нужны вектора на камеру, и его легко как раз получить, и вектор на источник света. И как бы, если у вас много источника света, вы обычно их для каждого должны это вычисление произвести, а потом с весами просуммировать. И если у нас какой-то простой рендер, но у нас источники света просто в сцене описаны, и мы просто как бы до них знаем как бы вектор, и можем произвести это вычисление. Проблема в том, что мы при этом считаем только одно направление света только от источника, и мы даже таким образом, в простейшем случае, мы даже не будем учитывать его размер, хотя это вообще говоря влияет на ток выглитобекта. Но в реальном мире источником света является каждая другая точка, каждая точка в пространстве тоже является источником света, потому что свет не может просто переотражаться. И до трассировки лучей мы как-то на самом деле умели показывать этот вот остальной свет в сцене, который не является другими, ну типа заранее заготовленными, расставленными источниками света. Есть куча техник, и всякие карты освещения, заранее пропеченные, там не знаю, расставленные так называемые light probes, когда мы берем короче кеометрию, которую мы сейчас рендерим, сэмплируем наш источник света, и еще ближайшие к нам light probes, такие специальные точки, как бы в пространстве повешенные, в которых заранее при спорке уровня собирается информация о свете окружающих объектов и о свете. И мы как бы используем эти probes как источник света. Тоже. Ну не совсем так, но я упрощаю. Или там мы как-то, если мы не имеем системы light probes в движке, мы можем ходить там прям руками короче специальные источники света проставлять, чтобы они нам делали вид, как будто у нас есть какой-то какой-то отскок света, например. К чему я все? Все такие вот ухищрения, они с одной стороны очень трудозатратные, потому что или вы вообще руками расставляете специальные источники света, что у вас картинка хорошо выглядела, или вы вынуждены каждый раз при любом изменении, которое вы сделали с уровнем, вынуждены, короче, нажимать кнопочку запечь, запечь, запечь, чтобы ваш уровень там изменился как-то, чтобы вы могли там в игре посмотреть на свои изменения. Я помню какой-то, в принципе, может, я не помню конкретного толку с GDC, но, наверное, в каждом N-ном толке на GDC кто-нибудь упоминает на этой конференции про разработку игр, кто-нибудь упоминает, как у них собираются уровни и нередкостью слышит, что у них там есть какой-нибудь C.I., который пересобирает игру, типа за, ну, типа ему требуется вся ночь, чтобы пересобрать игру в актуальное состояние. То есть, понятно, что вы как-то локально конкретно свой кусочек можете переделывать, не меняя все глобально, но там типа пересобрать условно 3.5 игру может занять ночь на кластере. Это долго, дорого и больно. И это все еще выглядит фальшиво. В принципе, есть в последние годы интересные техники, типа того, что применяется в игре Control. Всякие техники в духе Contracing, Voxel, что-то там Global Illumination, я уже не помню, что VXGI назывался, Invidivskaya тоже похожа на Contracing технология, когда мы не заранее что-то запекаем, а вот эту вот как бы, не знаю, трехмерную сертификацию информации как-то при помощи трассировки обновляем на живую. Но это пока не очень много где применяется, потому что это довольно вычислительно затратно и тоже имеет свои проблемы. Это все, вся эта болтовня была, чтобы подготовить к мысли о том, что вот тут одна из первых больших игр, которая использует трассировку лучей вот прям по полной. У нас до этого был Minecraft RTX, который был полностью Path Traced Renderer. Да, когда говорю Path Traced, еще один, наверное, такой в виду термин. Обычно, ну, то есть можно услышать два термина, Ray Tracing и Path Tracing. Обычно под Ray Tracing понимают в целом вообще любой подход, когда мы куда-то трассируем луч по сцене. То есть классический Ray Tracer, если там не знаю, в универе его писать, вы берете, просто исками пуляете один луч и просто его переотражение или до первого источника света или до другого-другого объекта, чтобы его отражение показать. И там не важно, насколько это по-настоящему физически корректно все ведет. Path Tracing — это прям конкретный способ решить уровнение рендеринга момента Монта-Карла. Ну, то есть это сейчас злообно звучит, но смысл в том, что мы можем использовать трассировку лучей и задать себе некоторые правила, чтобы найти такой, типа сходящийся к правильному ответу решение того, как должна выглядеть картинка в таком-то, в какой-то сцене. И в действительности там типа Path Tracer, частно написанный, он сойдется к физически корректному ответу. Ну, опять же, если настройки сцены не противоречат законам физики. И, собственно, у нас есть Quake 3 RTX, sorry, Quake 1 RTX, это одна из первых технодемок общеполонной с использованием трассировки лучей, и она вот полностью Path Traced, но это переделка старой игры. У нас есть Minecraft, Minecraft RTX, который тоже полностью Path Traced, это современная, ну, не то что прям tripple-ая игра, но игра, у которой бесконечный бюджет. Она не совсем попадает в, не знаю, ощущения, которые... поток игр, которые обычно называют словами tripple-a, но технически эта игра, за которой надобно стоит Microsoft, там бесконечное количество денег. Но эта игра тоже со специфичным арт-стилем. Там это выглядело круто, но, опять же, у нас не было примеров, что вот прям вот игра, классический tripple-a, Path Tracing. И вот теперь есть. И, насколько я понимаю, я прилинкую статью с очень подробнейшим описанием того, как они все это делают. И с тем, какой у них раньше был рендер, и с тем, какой у них сейчас рендер. Плюс я забыл ссылку добавить сейчас в карточку, но я докину. У Digital Foundry моих любимых тоже выходил такой обзор. Тоже, в общем-то, по следам этой статьи, даже с какими-то кадрами от разработчиков, где они как раз вот объясняют всю эту историю с расстановкой света вручную. Собственно, у них, насколько я понимаю, непосредственно луч от камеры до объекта, он все еще, ну, можно сказать, растеризация происходит, но весь остальной свет, весь не прямой свет. И отражения считаются как раз таки при помощи Path Tracing. То есть, раньше в их обычном метро, как это получается, Exodus, без какого-то суффикса дальнейшего, у них, по их статье, использовался для диффузного света, то есть, ну, типа свет, который у нас в том месте, где не блик, не прямого. У них использовался на основе нидиевского фреймворка для RTGI, такая трассировка с одного от сколько. Что они делали? Мы берем, когда визуализируем пиксель, какой это не пиксель, но да, пиксель, считаем, мы уже, например, познаем его положение в пространстве, все такое. Мы строили все наши стейты для работы с DXR API для трассировки лучей. Ну, если что, трассировка лучей сейчас на уровне железа, и в API, и в Vulkan, и DXR, проброшены на уровне того, что вы ставите специальную структуру акселерации, которая, ну, она вам на самом деле наружно торчит, но это в том или ином виде так называемый BVH, то есть, это какая-то такая иерархия ограничивающих объемов в геометрии. Это почти любая трассировка всегда ну, типа, имеет какую-то структуру, которая помогает быстрее найти, об какой объект луч прилетит, без того, чтобы перебирать их все. Вот, собственно, это прямо на уровне API вынесенные, где-то видеокарты или драйвер умеют как-то эту структуру потом оптимально отдать железу. И у вас, по сути, в шейдерах есть во-первых, воспроявляются специальные шейдеры, типа, шейдер генерирующий луч, шейдер, который исполняется при хите луча, шейдер, который исполняется при миссии луча, типа, луч никуда не пролетел в описанной структуре. И там еще, короче, несколько специальных шейдеров. Вот, и как бы, они вот все это настраивают, и по сути, у них какая логика. Берем, когда мы из, как бы, основного, основного паса стерилизующего генерируемых, как бы, по несколько лучей. Нет, даже, потому что по одному лучу из пикселя, который куда-то полетит, и когда он летит, он уже работает не с геометрией настоящей, он работает с упрощенной геометрией, упрощенным светом, упрощенными текстурами, и он типа, до первого столкновения с чем-то в уровне. И, как бы, они, если я правильно помню, накапливают информацию между кадрами, и в итоге у них получается достаточно такая шумная картинка, но, в принципе, показывающая более-менее состояние такого света, как он будет, типа, какими бы он был, непрямой свет, который отскакивает от предметов, но только, типа, не больше одного отсока. Не знаю, понятно я, объясняю или нет. После этого у них довольно интересный подход был к динозингу. Они восстанавливают в сферической гармонике, и я специально в твиттере спросил, они восстанавливают по сферической гармонике на каждый пиксель. Сферическая гармоника — это такой градиент, натянутый на сферу, короче. Так можно себе представить. Это довольно популярная в графике история, потому что она позволяет довольно компактно записать какой-то переход цвета, возможно, даже нелинейный на сфере. То есть, в зависимости от того, какого порядка гармоника, это, может быть, такие, типа, такие завитушки, короче, на сфере. Или там, низкий порядок гармоники выглядит просто как градиенты линейные на сфере. Вот. Они, в общем, восстанавливают на основе информации шумной многих кадров. В каждом пикселе восстанавливают сферическую гармонику, и это уже им позволяет как-то восстановить это непрямое освещение в, типа, для одного кадра, для одного откока. И, в принципе, как бы это, они просто дальше блендали со своим... Ну, не то что блендили, использовали для расчета вместе со своим остальным расчетом освета. И, как бы, так и жили. Это была не самая дешевая фигня, но подключав к этой другие эффекты, которые она автоматически делает у старевшим, вы можете помнить, что я в какой-то момент, например, очень любил жаловаться, что в играх очень... В некоторых играх очень плохой скринспейс эмбириенто клужин. Вот, собственно, скринспейс эмбириенто клужин такая штука, которая, в принципе, просто по своей природе не может делать хорошую картинку, потому что она оперирует с заведованием правильными данными. И вот это одна из тех вещей, которая, к счастью, наконец будет выброшена нахер, потому что она теперь больше никому не нужна. Это очень дорогой эффект, потому что ему нужно очень много данных. И, то есть, он не столько вычислительно дорогой, сколько он очень дорогой, потому что он очень много лазит по разным текстурам. То есть, лазание в текстуру на гбью — это примерно такая же история, как, ну, типа, не обязательно мисс кэша, но вообще-то может приводить к таким же историям, как миссы кэшей на CPU. Это может быть очень дорого. То есть, как бы, Memory Bandwidth на CPU ограничен. И вот, наконец, как бы, во всяком случае, этот дурацкий эффект будет заменен другим дорогим эффектом, но хотя бы производящим более нормальную картинку. В общем, их Path Tracing реализация, в общем, они взяли просто и выбросили вообще нахер все, что было. То есть, их прошлая реализация была такой пробной камень, который, не знаю, дали сами себе попробовать технологию. Тут они, ну, я не знаю, как это, наверное, совсем за деталями вас отправлю в статью, но смысл в том, что они в какой-то, не очень понятно, по статье, она не очень подробная, в какой-то такой пространственной структуре, похоже, тоже, видимо, на какую-то такую сетку, накапливают информацию обо всех отскоках света в течение многих кадров. И потом используют, как бы, трассируют, я так понимаю, до ближайшей геометрии, до ближайших узлов сетки. И таким образом получают, как бы, собственно, актуальную информацию о свете. И я так понимаю, только, я так понимаю, даже первый луч, в смысле, у них, как бы, есть, насколько я понимаю, проход рестеризации, но там, типа, только что-то очень ограниченно считается, но почти весь свет, почти весь, как бы, как раз получается из этой вот структуры и трассировки лучей. Плюс они используют его для отражений и для всего остального. И это, как бы, мало того, что это выглядит лучше, чем старый навор к столе, это еще и гораздо удобнее с этим работать самим разработчиком. Потому что теперь, наконец, вы банально в редакторе видите прям то же самое, что у вас будет в игре. Больше того, на достаточно временном железе даже нормально перформит. То есть даже на, типа, RTX 2060 довольно старом, это в принципе с какими-то нормальными настройками, ну, не самыми топовыми, но нормальными можно запустить. Это будет нормально работать. И я, например, я не очень большой фанат серии Metro в основном, потому что мне кажется, как бы, весь сетинг кажется немножко крижовым. Но я буквально вот вчера на распродаже в Epic Games Store купил копию, немножко погонял ее. Она на моем компьютере, ну, то есть у меня топовая видеокарта, но не самый топовый процессор.",
    "result": {
      "error": "API request failed: Error code: 400 - {'error': 'Trying to keep the first 4256 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': 'Trying to keep the first 4256 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}\n"
    }
  }
]
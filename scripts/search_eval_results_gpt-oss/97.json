[
  {
    "segment_id": "acb34c64-3eb6-4ccd-bf31-d34d12b076a8",
    "episode_id": "e91c8ffd-6f00-4e69-a1c0-554c0fa4f458",
    "episode_number": 97,
    "segment_number": 3,
    "text": "Книжка действительно прекрасная, я добавлю в шоу ноты ссылку, там, несмотря на, например, на Java, то есть пусть они вас не пугают, в остальном книжка клевая. Вот, кстати, я не знаю, там, есть ли, были ли примеры на Java, может, мы о разных книжках говорим, я потом тоже поделюсь ссылкой. Были, были, но там это не очень важно, ну, то есть, там просто какой-то язык можно использовать любой. Да, но там как бы формализм использовался такой, там псевдоязык, и использовался модель, очень похожая на модель актеров, то есть есть сервисы, которые принимают сообщения определенного рода, если пришло такое сообщение, меняем состояние и так далее. Вот, и что мне понравилось, что там именно с нуля начали, то есть какие бывает, вот что может случиться с сервисом, что может случиться с нодой, какие там, фейл-стоп, например, режим, да, фейл-омиссион и так далее, то есть как нода может вести себя неправильно, не так, как ожидалось. Вот, и там были приведены еще интересные византийские алгоритмы, что в общем-то, я считаю, большой плюс этой книги, несмотря на то, что византийские используются, я не знаю, практически нигде, по-моему, не используются, но... Ну смотри, на самом деле, как бы они часто, они не то чтобы прям используются, они как такая подпорка, и, например, ну типичная ситуация, это детектор, что у тебя, ну то есть у тебя паксос с паксосом, но... Ребят, подождите, можно я вас прерву? Вы когда начинаете обсуждать вот такие темы, вы очень глубоко погружаетесь, вы не могли бы вкратце рассказывать слушателю, что только византийский? Я переслушал и понял, что тяжело бывает иногда врубиться сразу в то, что вы говорите. Ну в общем, бывает обычный сбой, типа нода отвалилась, или нода недоступна, или большая лайтенсия. Бывают такие ситуации, которые называются византийский сбой, это кривой перевод на русский, на самом деле, лучше нету. На самом деле, бизантий, то бишь, ну по-английски запутанный. Когда нода вроде отвечает, что-то осмысленное, но какую-то херню несет. Типичный пример из реального мира, который может встретиться просто в любой системе. Вот есть у нас паксос, прекрасный консенсус, все хорошо, работает. И у нас есть в этом паксе какой-то старый элемент лога, о котором вроде все договорились и забыли. И вдруг у нас с одной из нод что-то было, наш паксос прекрасно это пережил. А когда ноду восстанавливали, админ поднял диск не из того бекапа. И после этого у нас консенсус может быть в таком интересном состоянии, когда вроде бы все договорились об этом в прошлом. Но содержимое диска у одной из нод немного поменялось. И вот тут у нас начинаются интересные состояния. И есть, я не видел, чтобы это решали на практике, но я видел, что это детектируют на практике. Т.е. берут старый добрый меркл-трик, который есть практически в любой Eventual Reconsistency системе, и периодически чекают диск. Что действительно содержимое одинаковое. Если я... ну вот у меня кластер, все работает. Я в сеточку занес разбери-пай, который нарочно фигню несет. Это считается такая вот атака византийским случаем или нет? В принципе может быть, зависит от того, что он несет. Это есть классика. Т.е. византийский случай это в классике, потому что кто-то у тебя специально пытается разрушить твою систему. Не обязательно специально, это может быть ошибка админа, например. Я имею в виду оригинальное значение византийской системы, это именно когда у тебя кто-то нарочно пытается. .. Нет, не обязательно византийская система, это когда у тебя есть какой-то актор, который живой, отвечает, отвечает херню. Почему он отвечает, неважно. Намеренно или ошибка. Ну собственно мой вопрос был в том, считается ли намеренно частным случаем. Ну видимо считается, окей. А давайте вернем слово гостю. Да, сори. Ну давайте я дополню немножко. С моей точки зрения византийский это любое нарушение протокола. И наибольший интерес представляет в этом смысле именно преднамеренное, словом намеренное нарушение этого протокола. Потому что это наиболее тяжелый случай с точки зрения алгоритмов. Поэтому именно их рассматривать в первую очередь. А так в принципе любое. Биты покарабкались на диске, в сети, в памяти, где угодно. Процессор сбойнул и прочее. То есть хэш суммы по-разному посчитались. Логика разъехалась. Одна надо так работать, другая... В принципе с точки зрения византийской постановки задачи, неважно откуда пришел источник проблемы. То есть это может быть хакер ноду в одном дата центре хакнул. Получил доступ и начинает от имени этой ноды слать специальные сообщения так, чтобы система пошла в разнос. Это византийский случай как раз. И византийские алгоритмы предотвращают такого рода поведение. Собственно мы затронули византийскую тему. Эта тема на самом деле очень обширная. Хочу сказать, что в этой книге она как раз освещена. Причем там есть первая редакция, в которой про византийский алгоритм вообще ничего не сказано. А вторая редакция именно посвящена, расширена именно с учетом всяких византийских алгоритмов. В принципе считаю это большой плюс этой книги. Там вот некоторые коллеги пытались начать читать эту книгу. Она в начале очень занудная. Но самое мягкое в конце. Но чтобы понять в конце, надо понять все предыдущее. И она еще толстая. Она еще толстая, да. И она в таком академическом стиле, поэтому надо набраться терпения. У меня почему-то терпения было. В принципе ее можно читать как первый раз прочитать. Не обязательно все понять. А потом со второго раза уже будет гораздо лучше. И она зайдет гораздо быстрее, бодрее. После того, как прочитал книгу, вообще меня интересовал вопрос. Почему же, есть как бы алгоритмы известные. Почему люди так много времени тратят на то, чтобы поддержать работоспособность распределенной системы. Казалось бы, бери там стандартный алгоритм, и прочее. Оказалось, что там слишком много нюансов. И это накладывается на то, что общий уровень на самом деле ниже, чем реально необходим для создания таких систем. Потому что чем больше я погружаюсь во всякую литературу, тем больше узнаю всякого нового. То есть, это тема такая. Можно копать, копать и копать. Особенно какие существуют модели консистентности. Там можно... То есть, я вроде прочитал, но уже что-то забылось. И опять надо восстанавливать. То есть, когда этим не пользуешься, все забывается. Все забывается, потому что это очень большой объем информации, который необходимо знать. То есть, в принципе, тема такая сложная. И с учетом того, что там асинхронность изначально присутствует, плюс еще в любой момент у тебя может запэлиться. И ты еще не знаешь, что происходит. Например, какая-то нода в начале выполнения какой-то сложной операции. Она должна понять, что при этом другая нода делает. Они как-то должны синхронизоваться. Но при этом в любой момент может произойти разрыв связи, тайм-аут и прочее. Плюс еще, если мы добавим тогда изантийские проблемы, то станет вообще очень весело. И возникает вопрос, а что же делать в таких системах? И ответ на самом деле достаточно простой. Надо использовать алгоритм консенсуса, который как раз позволяет решать самосогласованную задачу. Когда у нас есть несколько нод и одновременно принимать решение. Ну, как одновременно? Тут одновременно надо взять в кавычках. То есть, она позволяет нодам в группе договориться о каком-то комплектном значении. Собственно, это и решает алгоритм консенсуса. И тогда я еще общался с моим коллегой. И он говорит, смотри, на Java есть решение, которое позволяет объекты памяти, которые находятся, их реплицировать без проблем прозрачно для пользователей. Эта штука называется Sterakota. Типа, было бы неплохо сделать на плюсах такую же штуку. Но я поймал тогда сложность такой задачи. Потому что в чем сложность? То есть надо помимо того, чтобы реплицировать объекты, надо еще поддерживать консистентность. И консистентность хочется поддерживать на высоком уровне. Но мне показалась эта задача интересной. То есть, это в принципе не связано вообще с моей основной деятельностью. Мне просто just for fun, как говорится, было заниматься. Потому что я первую статью написал про асинхронность, тоже было интересно. И начал распределенность заниматься просто потому, что было интересно. И вот эта задача мне показалась достаточно тривиальной. Я сначала начал, к тому моменту у меня уже инструментарий для асинхронности, для сериализации уже был подготовлен. В принципе надо было решить только вот эту задачу с согласованностью. Я сначала хотел использовать Raft для этого. В Raft там много всяких моментов, которые стоило бы улучшить. Я начал с того, что хотел сделать более детерминированным алгоритм выбора лидера. Потому что можно легко показать, что даже если ноды не падают и сообщение отправляют нормально. То есть никаких проблем у нас в сети с нодами нет. Алгоритм выбора лидера детерминированный, он может не сходиться и не сходиться достаточно долго. Только за счет того, что у нас в Raft, например, тайм-ауты разнесены по времени. Например от 100 миллисекунд до 200 миллисекунд. И там случайно выбирается. Только за счет этого удается как-то более-менее свести задачу. Ну то есть сделать его более сходящим. Можно легко показать. Чем больше нод, тем сложнее ему сходиться и выбирать лидера. У меня была некая задумка, как это можно сделать более детерминированным. То есть когда нода, которая начинает становиться лидером. Если понимать, что есть нода, которая более приоритетная. Она просто отзывает свой голос. И тогда сходимость сильно улучшается. Потом я стал думать и вспомнил книжку про introduction. И там большинство алгоритмов, которые связаны с регистром. Когда мы говорим про shared memory. То есть память, которая распределена между нодами. Там большинство алгоритмов используют броадкаст. И вот я за эту тему ухватился и понял, что на этом можно построить алгоритм консенсуса. Начал в голове крутить возможные варианты. И на мой взгляд придумал некий алгоритм, который позволяет эту проблему решить. Потом посмотрел вообще, а как народ что делает. Есть вот E-Pack создан. Я так понимаю, говорили о нем в каком-то из выпусков. Больше года назад, на самом деле, говорили о нем. Да. И за E-Pack создан последовал еще алгоритм Alwin. О нем, по-моему, вы не говорили. Я даже о нем первый раз слышу. Да, плюс один. Еще, кстати, есть вещи, о которых мы не говорили, но про которые я знаю. Называется Humming Consensus. Есть по шоу один из немногих крутейших людей, который встал в по шоу. Скотт Ричи, кажется. Он сейчас работает над имплементацией чего-то похожего на Chain Replication, но с Blackjack и шлюхами. И у Chain Replication есть такая особенность, что ему нужен какой-то Oracle. Который не Chain Replication. И поскольку городить какую-то еще стороннюю систему для координации другой системы ему не очень хотелось. Он хотел сделать что-то такое, чтобы пир-то-пир и порядок консенсус. И чтобы достаточно простой был, проще, чем всякие паксосы. Потому что нужно только довольно небольшой стейк менеджить. И он придумал этот Humming Consensus. Я, честно говоря, уже не расскажу эти алгоритмы из памяти. И, к сожалению, нет какой-то пейпера, в котором он в двух словах. Есть какой-то summary. Но если погуглить, или может быть я даже ссылку на видео в шоу-ноту прицеплю. Есть видео с реклоном, последнего который был. Там, где он про него рассказывает про этот свой Humming Consensus. Да, интересно, потому что я о нем ничего не слышал. Я бы тоже с удовольствием посмотрел, что там было сделано. Наверное, стоит кратко обсудить, что я знаю на сегодняшний день. Понятно, что самый главный алгоритм, самый такой старый, это паксос. Который был изобретен Лэмпортом. У паксоса существует огромное количество различных вариантов. И в принципе, крафт, можно сказать, это определенный вариант паксоса. Но сделанный так, чтобы... Он позиционируется как более простое понимание. Извини, что перебиваю, но паксос, на мой взгляд, больше похож на ViewStamped Replication. Это, кстати, еще один такой консенсус, очень известный, ViewStamped Replication. На самом деле, рафт похож на паксос в чем-то. На самом деле, рафт, с моей точки зрения, это фактически тот же самый мультипаксос. Только там прибиты гвоздями определенные недомовки, которых в паксосе просто нет. Но которые очень важны для практической реализации алгоритмов. Потому что в паксосе, когда читаешь, а где там фейловер? То есть там с фейловерами как-то это все не очень хорошо описано, не очень подробно. А вот в рафте там вот прям разобрано по полочкам, там еще хорошо сделано. Потому что очень важный момент, как мы переходим от одного шага до другого. И как мы параллельно эти шаги можем выстраивать. Вот в рафте это можно параллельно коммитить разные сообщения. И плюс рафта как раз в том, что он эти самые сложные штуки, он это хорошо объясняет. И в этом алгоритме различные фейловеры-сценарии достаточно подробно объяснены и рассмотрены. Также плюс рафта в том, что он изначально содержит в себе алгоритм, который изменяет группу. То есть когда у нас в группе три ноды и мы хотим ее расширить, то рафт, вот в оригинальном пейпере, он содержит то, что нужно. Собственно алгоритм как-то делается. Ну это как раз называется joint consensus, извини, что снова перебиваю. Кажется называется joint consensus, но на самом деле они теперь в поле новой версии. То есть не в оригинальном пейпере, а дальше уже в диссертации Диего. Они пошли дальше, поскольку joint consensus, он как бы рабочий. И в некоторых ситуациях достаточно простой, но конкретно для рафта это не самое простое и доступное решение, которое может быть. Учитывая, что рафт сам по себе это протокол для репликации лога, а не отдельного значения. То они сделали так, что они ввели такие правила, что смена членства в кластере, это просто еще одни специальные операции в логе, которые ничем не отличаются от других операций в логе, не требуют никакого специального режима. В отличие от joint consensus. И просто у них есть правило, что нельзя коммитить больше одного изменения в такой лог. Ну и они доказывают, что это все хорошо и безопасно. На самом деле рафт, его последняя редакция, он еще и хорош тем, что разные части алгоритма взаимоопираются на хорошее свойство друг друга. Да, в принципе я согласен с тем, что лучше как раз изменять группу, именно коммитить сообщение, которое изменяет группу. И прикол еще с этим joint consensus в том, что в первой статье про рафт, там была ошибка в алгоритме и в Extended Version, то есть есть обычная, есть Extended Version, там это поправлено. Это говорит о сложности и интриганности таких сценариев. Собственно есть вот группа Paxos, Raft и Zap, это то, что используется в Zookeeper. Я их условно называю алгоритмами, которые имеют мастера со всеми вытекающими. А вытекающие последствия следующие, что если у нас лидер падает по тем или иным причинам, то необходимо иметь какую-то логику по восстановлению состояния и восстановлению консистенции, переизбрании лидера и так далее. То есть все такие алгоритмы имеют Failover Logic. Вторая группа алгоритмов это как раз E-Paxos и Alvin, это более современные алгоритмы. Там уже нет такого стабильного лидера и там используется интересная модель, что каждая нода может послать сообщение и она становится лидером конкретно для этого сообщения. И она коммитит это сообщение. Получается, что если несколько у меня нод, они все параллельно свои сообщения посылают и получается у нас в один и тот же момент может быть несколько лидеров, но для конкретного сообщения всегда один лидер. Это имеет большие плюсы, когда мы рассматриваем геораспределенную систему, когда у нас дата центры в разных локациях находятся, потому что там не надо достучаться, передавать лидеру сообщение, чтобы закоммитить его. Можно в ближайшем ноде передать и все будет хорошо. Но там опять же есть та же самая проблема, что если нода стала лидером сообщения, послала его, а потом умерла, то необходимо, чтобы кто-то другой взял лидерство над этим сообщением, чтобы его докоммитить. Получается, что логик у нас никуда не девается, но алгоритмы, как я уже повторяюсь, являются более эффективными и более интересными, но и более сложными. Гораздо более сложными, я бы сказал. И есть третья группа, которую я ввел. Так называемый алгоритм консенсуса без мастера. Принцип там очень простой. Извини, хочу заметить, что классический PAX, как это называется, single... Классик. В общем, PAX про одно единственное значение, без смены с чего бы то ни было, он на самом деле тоже, ему не важно, кто там лидер. Есть, конечно, пропозор, но он может смениться, пропозор отвалился, пришел другой пропозор. В любом случае, к самому классическому PAX, ему лидер не нужен, просто кто-то первый начинает бродкаст. Там действительно, этот момент мне указали в комментариях, и я этот момент подробно раскрыл. В классическом PAX действительно нет лидера, но эффективно там лидер есть. Может быть несколько пропозоров, но выиграет только один. В этом смысле, что пропозоры, они друг другу мешают, и прогресс в принципе, если у нас больше двух пропозоров, то у нас вообще в системе может не быть никакого прогресса. И если какой-то пропозор выиграл, то есть акцепторы выбрали именно этого пропозора, то если он умер, то необходимо вот это сообщение взять и дальше уже другому пропозору закоммитить. То есть фактически, несмотря на то, что изначально у нас лидера нет, но он появляется, так сказать, неявно, и со всеми вытекающими, что если лидер уходит, то надо доделать его работу кому-то другому. И это на самом деле принципиальное отличие от того, что я предлагаю. У меня изначально нет лидера, и главное, нет ролей, нет выделенных ролей фолловера, лидера и прочего. Акцепторы, как мы в PAX, например. То есть все ноды независимы друг от друга и действуют параллельно и независимо. У них есть только внутреннее состояние, и они это состояние пытаются констатным образом изменять. Алгоритм основывается на простой идее, что если мы броудкастим значения на все остальные ноды, и потом нам приходит ответ, мы хотим сделать так, чтобы наш ответ, точнее наш запрос и наш ответ был одним и тем же. Если мы получаем одно и то же значение на запрос и на ответ, значит можно это значение коммитить. Если же мы получаем разные значения, например, у нас две ноды захотят закоммитить эти разные значения, соответственно тогда нода получает другой ответ. Она мерджит то, что у нее есть в состоянии, и с тем, что ей приходит от других нод. Это алгоритм мерджинга, он детерминистичный и на всех нодах должен быть одинаковым, чтобы алгоритм сошелся. После этого мерджинга все ноды делают то же самое. И получается так, что следующий броудкаст уже на этом же этапе, все приходят к одному и тому же значению, и тогда уже это значение можно коммитить. Вот это вкратце я описал. Слушай, мне это конкретно напоминает хамминг-консенсус. Вот, надо познакомиться мне, потому что возможно, что мы до одной и той же идеи разными способами дошли. Вот. И в статье я разбираю различные варианты, там я достаточно подробно описываю алгоритм. Также я привожу C++ код, на котором я разбираю, как он работает с комментариями. Привожу различные диаграммы, что у нас происходит, когда у нас одна нода, две, три и так далее. Что происходит, когда у нас одновременно сообщения приходят. Что происходит, когда какая-то нода уходит из строя и так далее. Конечно, это все было бы замечательно, но по-хорошему, все алгоритмы консенсуса требуют какой-то верификации. И для этого я сделал специальную программу, которая просто проверяет все асинхронные варианты. То есть в любой момент у меня любая нода может отказать. Сообщение может сначала прийти до первого, может до второго, может в обратном порядке и так далее. То есть просто brute force перебираю все варианты, смотрю в остатке, что у меня приходит к одному и тому же значению на всех нодах или нет. Если приходит, значит все нормально, если нет, значит есть проблемы. Вот. И таким образом я верифицирую свой алгоритм. И, по крайней мере, моя программа выдает, что да, этот алгоритм позволяет решить проблему консенсуса. Ну вот как в качестве фидбэка можно дать, да? Да. Я не так много читал описаний алгоритмов консенсуса. Но те, которые читал, и в частности Raft, меня очень радовали тем, что они вводили какое-то формальное описание без больших кусков кода. Я понимаю, что иногда код читать проще, чем описание формальное. Но, скажем, в Raft-овском описании его было понимать намного проще, чем куски C++-ного кода. За что я отдельно люблю папер по Raft-у, там есть такая врезка, называется RPC. И там вот просто каждое сообщение, что она делает и как она меняет стейт. И все это на одной страничке. Все это на одной страничке, и вот этой штуке, на самом деле, достаточно, чтобы реализовать протокол. Ну, конечно, потому что нужно будет еще его отладить, но это реально гениально, что они сделали весь протокол. Ну нет, чтобы понять, нужно прочитать папер все-таки, но чтобы быстренько себя напомнить, и просто как гейдлайн по реализации, это идеально. Я бы советовал тоже иметь какое-то описание, все, чтобы... Либо на одной страничке, во-первых, а лучше и так, и так. А во-вторых, формальное описание, какие, типа, бывают сообщения, вот как бывает в этом. Есть же специальные аннотации для описания синтаксиса. Еще по поводу верификации. Ну, я понимаю, что TLA+, это такая вещь, которой нужно заниматься и тратить на это время, но есть такая штука, которой нужно немножко меньше заниматься, это JEPSON. Но вместе с Moses. Там клоушна надо знать. Ну, как бы надо, но это точно меньшее вложение, чем TLA, и это совершенно точно. То есть у тебя есть твоя собственная тулза для верификации, я верю в то, что ты мог сделать это хорошо, но точно так же я верю в то, что там может быть какой-то недосмотр или даже баг, и всегда лучше... У меня не тулза, я делаю просто, там поднимаешь лексиконтейнер и ходишь. Я про автора говорю. Да, это все... Не-не, я имел в виду, что, сорян, свои тулзы пишутся очень просто, то есть поднимаем LXE или Docker или что там нравится, и каким-нибудь питоном вы прямо в них заходите и IP Filters, рубите сеть, эмулируемые сплиты. Это, возможно, проще, чем изучать клоушу и потом их запортить. Просто мой пойнт был немножко в другом. Я как раз говорю, что, допустим, у тебя есть такая тула, либо как у автора доморощенная, либо как у тебя доморощенная, я сам такие доморощенные делал, всегда неплохо взять какую-то еще чужую тулу и отравить на свое добро. Потому что своя тула это хорошо, но свою тулу писал ты сам и как бы... Мог заметить какой-то момент. Да, да, да, то есть лучше больше глаз, скажем так. Вы все правильно говорите, я согласен. Во-первых, мне показалось, когда я писал статью, я отвечаю по поводу того, что в рафте есть страничка, а у меня такой странички нет. Что я могу в оправдание сказать? Что мой блог посвящен, в принципе, C++. То есть я, в принципе, не ожидал, что я туда напишу, говорит, концессуса. Но так получилось, что я туда записал, и поэтому мне показалось логичным привести код на C++. Я почитал, что лучше привести код, который реально работает, который можно запустить, чем псевдокод, который может содержать ошибки. Потому что в C++ компилятор точно проверит, что там никаких косяков нет. Но я согласен, что для того, что... Потому что некоторые люди не знают, например, C++ или не очень хорошо знают, что для более массовости было бы неплохо иметь на таком псевдокод, иметь такую страничку, на котором весь алгоритм, от корочки до корки написан. И, наверное, пожалуй, что-нибудь я такое сделаю. Что касается по поводу верификации, ну, как бы да, это туза для бедных. Мне просто она уже была, я когда-то ее писал для тестирования всяких алгоритмов. И я просто ей воспользовался. А по-хорошему надо, конечно, и Джепсон запустить, и ТЛА+, и прочее. Но, как говорится, было бы время, я бы все это сделал, но пока вот так вот. Я, как бы, с одной стороны, не претендую на что-то такое серьезное, но с другой стороны, вроде как... Слушай, такие красивые картинки, такие классные объяснения, а ты будешь не претендуеть. У тебя она уже сама по себе претендует. Ну, хорошо, тогда буду повышать уровень, так сказать, чтобы претендовало что-то большее. Слушай, только такой вопрос. Ты прям меня запутал, когда я, ну в смысле, я имею в виду, как читатель блога, открываю там часть 1, часть 2 и часть 7. Это ты специально так сделал или ты удалил ненужные вещи? Не, это будут третья, четвертая и так далее части. Просто, ну, значит, вообще я начинал писать про replicated object. То есть объект, это концепция такая, когда у меня есть объект в памяти, причем можно его сделать персистентным, чтобы копия на диске, и потом при рестарте она поднималась. Но сейчас, то есть, есть объект, объект может быть достаточно сложный, но главное, что у него все методы, они выполняют, как по-русски сказать, детерминированные операции. Вот. И прикол в том, что я хочу иметь такой любой объект. Если я сделаю это хэш-мап, у меня получится kvly-storage, и мы мыли сразу, да? Добавлю свойство персистентности, получится хэш-таблица, ну, kvly-storage просто уже распределенный, причем консистентный, да? Если я там возьму какой-нибудь экзекьютор и сделаю там запускалку, то, в принципе, можно сделать распределенный экзекьютор. Используя эту технику, можно сделать очень мощную вещь. И я что-то просто делал, делал, делал, и потом понял, что надо писать статьи, ставить точку, и стал писать статьи. Написал первую статью, она была введения. Вторая уже некая фишка конкретно для C++, идиома C++, можно так сказать, которая позволяет сильно упрощать взаимодействие с объектами, синхронизацию их, сериализацию и прочее. И потом у меня была пауза, связанная с определенными личными соответствиями, я понял, что если я еще так буду тупить, то я никогда не напишу. И взял просто самый жирный кусок, самый, на мой взгляд, важный из этого реплоба, да, или какие-то тетрадок, облежек, вот, и написал. И он просто у меня был сильно позже по плану, поэтому получилась вот так вот, часть седьмая, а остальные будут позже. И дальше идет чистейший в эдик троллинг. Но мы опустим эти детали из нашей статьи, потому что они тривиальны, все могут это задуматься сами, ну вы же понимаете, да. В общем, настолько троллинг, и точно так же у тебя получается, знаешь, такой троллинг, часть один, два, семь. Думайте сами. Ну, да. Очевидные вещи пропустим. Там в седьмой части тоже есть небольшой троллинг, потому что когда я начинаю писать алгоритм, потом оказывается, что это ошибочный алгоритм. Ты знаешь, как некоторые препода по математике, но я не считаю их преподавателями, это могут быть отличные ученые, но я не считаю их хорошими преподавателями, они очень любят говорить такую фразу, легко видеть. Окей. Очевидно, что. Они говорят, очевидно, что всегда. Обычно читаешь доказательства, какая-то теорема, и там написано, очевидно, что. А за этим очевидно, что скрывается чья-то диссертация. Вот, короче, у меня был интересный случай, не у меня, а вот просто история, которую мне рассказал мой одногруппник. Значит, это был экзамен, и там у нас были ландавшицы, и у нас была книга по теоретической физике, и мы изучали статистическую физику, и там была формула, интеграл, и там было написано, беря легко интеграл, получаем ответ.",
    "result": {
      "error": "API request failed: Error code: 400 - {'error': 'Trying to keep the first 7410 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': 'Trying to keep the first 7410 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}\n"
    }
  }
]
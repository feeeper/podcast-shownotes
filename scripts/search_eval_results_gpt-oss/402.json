[
  {
    "segment_id": "9928a6b5-a543-4460-ba04-55c75d72f19a",
    "episode_id": "12745074-5b6b-484d-8695-cb47876790ad",
    "episode_number": 402,
    "segment_number": 7,
    "text": "Это, во-первых, возможность декларировать таблицы, которые вот всасывают данные из какого-то внешнего источника, и у них там штуки три или четыре разных источника есть. А во-вторых, это как раз возможность Materialized View перестраивать инкрементально по мере обновления исходных данных. И мне было интересно, а есть ли решение для пасгресса, который умеет это делать? У Timescale же вроде что-то похожее было, да? Ну смотри, во-первых, ты всегда это можешь, если брать ванильный пасгресс, то это можно сделать на хранимых процедурах и триггерах. Я это успешно делал, это не очень сложно. Оно будет прям весь View пересчитывать или как-то может по умолку? Нет, то есть преимущество этого решения в его гибкости. Ты можешь сказать, что у меня есть таблица, а вот триггер на вставку или обновление строк в этой таблице, и когда я что-то вставляю, обновляю, удаляю, нужно произвести какие-то действия. И на этой логике ты можешь реализовать какие угодно инкрементальные View. А, ну то есть с точки зрения схемы баз данных, это будет не Create View, а ты создаёшь таблицу и просто в неё что-то там по триггерам добавляешь, удаляешь, так? Да, да. Это может быть не так удобно, как коробочное решение, но зато оно очень гибкое. И я такое для прода делал, оно действительно хорошо работает. В Timescale это есть, это называется Continuous Aggregate. Нужно внимательно читать документацию, то есть это не такая магия, что там как бы жух, и у тебя автоматически обновляемые View. То есть предполагается, что вот у тебя идёт поток Time Series, и ты говоришь, что потенциально у тебя на твои Time Series могут приходить обновления в общем случае. И если в твоей системе возможны обновления в Time Series, то тебе нужно правильно настроить Continuous Aggregate, чтобы они обновлялись. Короче, при селекции ты всегда получишь правильный View, потому что к материализованным данным будут подмержены последние вставленные данные. Но чтобы… как бы это объяснить, чтобы это не звучало слишком запутанно? Непрерывный агрегат поделён на две части. Первая часть — это твои материализованные данные, которые просто хранятся в таблице. Но в процессе ты дозаписываешь Time Series. Это твои горячие данные, они в материализованных данных ещё не были учтены. И когда ты делаешь селект из непрерывного агрегата, он берёт материализованные данные из таблицы и подмешивает к ним горячие данные, которые ещё не были материализованы. И чтобы это работало эффективно, ты должен настроить непрерывные агрегаты так, чтобы материализация происходила в правильный момент. То есть, когда ты… если представить себе такое временное окно, например, у тебя окно один день, и представлять себе поток данных. Пишется, пишется, пишется. Вот ты должен обновить свой непрерывный агрегат в то время, когда ты знаешь, что за это окно данные больше не будут обновляться. Тогда это будет работать хорошо и эффективно. Иначе оно всё равно будет работать просто менее эффективно. Звучит, наверное, очень запутанно, когда это говоришь голосом в подкасте, но если открыть документацию, оно достаточно понятно и разумно. Мне кажется, я примерно понял, о чём ты. Мне интересно, говорил ли докладчик о том, как они делают это инкрементальное обновление. Потому что из того, что ты объясняешь, я начинаю понимать, что в общем случае, если ты представишь себе, что у тебя Create View, обычный ванильный базоданный Create View с опросом, очень непросто для произвольного такого View придумать алгоритм, как его обновлять инкрементально и эффективно. То есть Timescale решает эту проблему тем, что он, во-первых, накладывает ряд ограничений на то, что может быть источником для Continuous Aggregate. Кажется, когда-то я наступал на гроблю, что Continuous Aggregate не может иметь join, например. Да, это до сих пор ограничение. Ну, точнее, внутри, в определении твоего Continuous Aggregate не может быть join. Сам ты можешь его, конечно, join. Да-да-да. И мне было интересно, собственно, как докладчик в своей Rising Wave базе данных решает вот эту проблему. Потому что я так понимаю, что они-то как раз View определяют просто вот как Create View. И там делают какую-то добрую магию. И, кстати, они join и умеют, судя по их документации. Это действительно интересно, как они это реализуют. Это действительно непростая проблема. Возвращаясь к Postgres, есть ещё одно одновременно и расширение и патч для ядра. Потому что это разрабатывают одни и те же исследователи из Японии, насколько я припоминаю. То есть они сначала предложили патч для ядра, пытались его оттолкать, поняли, что это долго и сложно. И нужно постоянно ребетить, потому что ядро изменяется, а твой патч должен применяться. Поэтому в какой-то момент они сделали расширение. Расширение называется PGIVM. Я его даже скину в чатик. И оно на самом деле было у нас в шоу-ноутах, сколько-то выпусков назад. А в какой момент я замьютился? Я случайно кнопочку нажал? Когда ты ссылочку отправил в чатик. Хорошо. Да, простите, я в мьют говорил. Я говорил о том, что PGIVM, если посмотреть его документацию, то становится понятно, что это всё ещё сложная проблема. В IVM всё ещё находят баги. И даже без них имеются просто фундаментальные ограничения на то, какие агрегаты ты можешь использовать. То есть ты, например, не можешь… ну, в подгрессе у тебя пользователь может объявлять свои функции и писать их либо на SQL, либо на PLPG SQL, либо на C. И ты не можешь сказать, что у меня есть произвольная функция, я её использую в определении своего агрегата, а потом начну его инкрементально обновлять. Так не работает. То есть у тебя есть заранее объявленный перечень функций, которые поддерживаются, встроенных функций, ну там типа min, max, средняя и так далее. И при этом я очень бегло читал о том, как устроен API в IVM, они говорят, что вот у нас есть данные, а мы к данным цепляем некую метку, когда они в последний раз обновлялись, и когда мы их снова обновляем… а, или они используют… вот я уже забыл. Или у них есть какие-то указатели, что от чего зависит. Смысл в том, что когда ты строишь агрегат, и у тебя в агрегате есть строчка, они трекают, из каких данных эта строчка была посчитана, то есть какие исходные данные внесли свой вклад в эту конкретную строчку. И когда ты те строчки обновляешь, IVM понимает, что ага, мне вот эту строчку в моем агрегате надо полностью пересчитать, и поскольку ты знаешь, из чего она считалась, то ты можешь… ты знаешь, где найти все данные, по которым ты вот одну строчку можешь пересчитать.",
    "result": {
      "query": "Postgres incremental materialized views"
    }
  }
]
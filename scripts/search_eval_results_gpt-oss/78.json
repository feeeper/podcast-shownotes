[
  {
    "segment_id": "e2e4238b-d85b-4a30-b682-fd3dd6204357",
    "episode_id": "b2b29131-bec9-4209-ba74-3b776e8cd208",
    "episode_number": 78,
    "segment_number": 3,
    "text": "На самом деле я делаю, ну, очень мало. Я работаю на дни в день, там, ну, полчаса, час. Не больше. У меня просто есть правила, я стараюсь каждый день писать код. Даже когда у меня нет работы, связанной с кодингом, я пишу какую-нибудь документацию, сижу, я все равно прихожу домой, что-нибудь делаю. Ну, и так, в свое время я решал задачки для Project Tailor, и все в таком духе. Потом я решил, почему бы мне не приложить усилия к чему-нибудь побольше. Потому что все равно я трачу свое время, лучше бы что-то из этого хорошее вышло. Вот так появился этот проект, потому что у меня есть некоторый опыт использования TSDB. То есть предпредыдущая работа, которая именно в энергетике, там есть большой продукт, это SCADA-система. И главный компонент любой SCADA-системы — это своя TSDB, с которой ничего работать не будет. Расскажи для тех, кто темный, как три подвала, что такое SCADA. SCADA — это система сбора и обработки данных со всяких датчиков. То есть там, по сути, есть TSDB, которая хранит данные в виде временных рядов. Но помимо этого, там есть еще сложная модель объекта-мониторинга. В нашем случае это был GRID, то есть электрическая сеть. И там, естественно, мониторятся всякие датчики, которые измеряют частоту, всякие перетоки, генерации и прочую фигню. Это все собирается вместе в одном дата-центре и в итоге все записывается в TSDB. Но чтобы эти данные потом как-то понять, используется уже вот эта сложная модель. Что-то вроде графа, в котором есть все эти объекты инфраструктуры, всякие электростанции, линии передач, трансформаторы и прочая фигня. По сути, такая система мониторинга на стероидах. Там есть всякие расчетные модели, которые позволяют вот эти все данные из одной модели и из TSDB вместе свести и посчитать что-нибудь. Например, мы хотим узнать, что будет, если у нас вот эта электростанция будет выключена из сети на какое-то время из-за ремонта или из-за аварии. Как будут меняться перетоки в сети, мы можем запустить расчетную модель, она нам скажет. Мы можем даже что-то сделать с этими данными потом. Ну, как-то так. Как-то так. Алло, меня слышите? Да-да-да, возвращаясь к... как это правильно произносится? Акумули. Акумули. Какие... вот я темный, как Валера выразился, как три подвала. Какие есть аналоги и в чем неоспоримое преимущество Акумули перед ними? Ну, пока нет никаких неоспоримых преимуществ, в принципе, потому что проект не production-ready. Ну, аналоги из open-source есть... ну, самое первое, open-source TSDB, это RRD Tool. Ну, наверное, все знают, что это такое. Потом, по-моему, в 2009 или что-то в этом... примерно в это время появился Graphite. Ну, Graphite, он, кстати, написан на бетоне. Существует до сих пор, это в принципе довольно... Извини, пожалуйста, Жень, у тебя вот какие-то странные звуки, как будто кто-то пишет карандашом, рвет бумажки. Если это ты их издаешь, мы все это слышим, не надо, пожалуйста. Окей. Ну, у меня здесь еще кресло соломенное, это, наверное, вы тоже слышите. Ну, с другой стороны, в другом месте у меня холодильник. Я не вижу выхода из... Как ты работаешь в такой обстановке? На самом деле это все очень тихие звуки, я не знаю, почему вы их слышите. Ну, в общем, я продолжу. Потом появилась OpenTSDB, такая штука, написанная на Java, которая кладет данные, ну, хранит данные в EdgeBase. Там используется довольно оригинальная схема хранения данных, то есть там много колонок. Каждая колонка это плюс сколько-то секунд относительно начального интервала времени, поэтому там у них ограничена точность меток времени. То есть ты не можешь хранить метки времени с миллисекундной точностью или с микросекундной точностью. Они все округляются до одной секунды, по-моему. Сейчас у них, кажется, что-то изменилось, и можно более точно данные хранить, тем не менее, эта проблема у них есть. Просто не так остро. Ну, плюс, самая главная проблема это EdgeBase, а EdgeBase это сложно. В плане эксплуатации не все конторы... Сори, что перебиваю, была же вроде пара форков, которые, по сути, OpenTSDB, но там, например, на Cassandra. Да, есть KairosDB, которая хранит в Cassandra. Еще что-то, я уже не помню. Еще InfluxDB. Да, InfluxDB. InfluxDB, он вообще какой-то странный. Он очень странный. Я за ним слежу, в принципе, с самого начала. Но я могу, в принципе, про него довольно много рассказать. А вот давай, потому что у нас какой-то момент, мы с Сашей работали в одном месте, и вот конкретно тот проект, на котором был я, мы в какой-то момент чуть-таки... А вот есть же Influx, давайте посмотрим на него, и что-то мы посмотрели-посмотрели, и ну его нафиг. Да, они странные. У них сначала очень часто меняли... Ну, у них сейчас меняются движки, у них поменялось несколько движков для хранения данных. Они изначально использовали LevelDB, они хранили очень неэффективно данные. То есть, по-моему, ключ буквально каждому датапоинту притягивался... Ключ на датапоинт? Ну, то есть, мы, конечно, тоже LevelDB использовали, но мы не использовали ключи на датапоинт, мы использовали ключи на фрейм. Фрейм мог иметь кучу датапоинтов. Ну, я смотрел реализацию, по-моему, там именно так было сделано. Ну, я смотрел давно. Может быть, я смотрел... Вот именно эта реализация была очень ранней. Может быть, я что-то напутал. Ну, не буду утверждать, но, по крайней мере, там очень плохо было с местом, ну, с сжатием. С сжатием. Там данные занимали сильно больше, чем... Ну, вот просто если ты возьмешь 64 бита подметку времени, столько же подзначения... Ну да, тогда, значит, видимо, так и хранили. Потом они использовали несколько форков LevelDB, RoxDB, там... А, нет, они еще использовали LMDB, который вообще не похож ни разу на LevelDB. Который вообще не похож на то, чтобы надо было... на то, чтобы можно было данные быстро писать. Да, ну, как бы он, по-моему, рассчитан в основном на то, чтобы их быстро читать. Вот. В принципе, LevelDB тоже довольно сомнительный выбор, потому что, по-моему, оригинальный LevelDB, он имеет неприятную особенность. Там есть Compactions, то есть база, когда она большая, она может замирать на какое-то время и плохо себя вести. То есть там будут паузы, на протяжении которых LevelDB просто переупаковывает свои файлы в левое положение. На самом деле в Rox это получше сделали. То есть они, видимо, не просто так на Rox прыгнули, потому что с LevelDB с ним куча проблем, в том числе то, что ты сказал. Поэтому почти все, кто использует Level в продакшене, то есть там BASHO, с React, HyperDeX, еще пара компаний. То есть почти все, кто имеет продакшен в левлдб в продакшене, у них всех форки. То есть то, что я назвал плюс Rox, это как бы они почти все, при том каждый по-своему, починили примерно одни и те же проблемы. Ну да. Потом они, по-моему, перепрыгнули на BoltDB. BoltDB это клон LMDB, написанный на Go. Там тоже были какие-то проблемы. Я, честно говоря, в тот момент не очень активно читал их список-рассылки, поэтому не помню, в чем там проблемы. И наконец, где-то в октябре, по-моему, прошлого года, они запилили свой собственный движок, который они назвали TSM. Times Structured Merge Tree, что-то в этом духе. Ну, по сути, это тот же LSM3, только специализированный под временные ряды. По сути, там просто есть сжатие специализированное, ну и все. Сжатие, у них статейка недавно вышла о том, что у них 2,2 байта на каждый датапоинт. Ну и все такое прочее. И он 70 раз быстрее работает, чем раньше. Ну, естественно, если раньше у них работало не очень, возможно, сейчас лучше. Сжатие, я, в принципе... Вот этот новый движок, он построен, в принципе, на основе информации, которая была... По-моему, Facebook опубликовал недавно пейпер про свою систему, которая называется Gorilla. Это система мониторинга, которая хранит данные временных рядов, но она их хранит в оперативной памяти. И эта штука использует сжатие, и они там используют точно такой же алгоритм сжатия для флоатов. Он там описан. Ну, в принципе, я смотрел. Ну, опять же, не последний релиз, но когда это все только писалось, я периодически поглядывал. Ну, в принципе, там примерно то же самое. Ну, там нифига нет 2,2 байта на датапоинт. Там такое может быть, если писать очень-очень... данные очень низкой точности. То есть, если мы взяли инт, привели его к флоату, флоат 64 и записали... Причем этот инт у нас не очень сильно менялся в процессе. Ну, то есть, мы записали 100 точек, они там имеют низкую точность, плюс они... Ну, просто колебания, то есть, они какой-то одной и той же величины, много одинаковых значений подряд и все такое прочее. Ну, тогда может быть и меньше даже. Но если туда писать реальные данные, какие-то достаточно высокой точности, например, сгенерировать Random Walk... И использовать случайные 64-битные числа, и тогда там просто будет больше 8 байт на флоат. Вот это не очень клево. Ну, в принципе, это нормально. Ни один алгоритм сжатия не дает такого сжатия для флоатов. Такого никогда не было. Если взять, например, тот же GZIP, там будет тоже что-то около 8 байт на каждый флоат. Поэтому у них очень много усилий в области маркетинга и раскрутки, они очень активны в социальных сетях, на Hacker News. Ну, пожалуй, все, что про них можно сказать. Ну, знаешь, если ты заходишь на сайт, у них тут прям... А, это InfluxData, а не InfluxDb сейчас. Да, теперь InfluxData, и у них появились какие-то новые инструменты. Капаситор, ну, у них целый стек инструментов, которые... Они, по-моему, назвали его Tick. Да, Tick. И он умеет альертинг, он умеет рисовать всякие графички. Но, насколько я помню, там многие из этих инструментов с закрытым исходным кодом. Ну, может быть, я ошибаюсь. Я за вот этими остальными проектами как-то особо не слежу. Я так понимаю, судя по ним, они все-таки таргетятся на мониторинг систем. То есть, для мониторинга, наверное, нормальная база. Мне просто на них кажется нормально, если у тебя тайм-серия, это основной продакшен. Ну, в принципе, да. Ну, для мониторинга, конечно, все что угодно подойдет. Но, мне кажется, для их нагрузок подойдет и графит. Ну, то, что держится на FlexDB, вполне может держать и графит, если его поставить на толстую машину какую-нибудь. Мне кажется, что совсем что-то сейчас оказалось, что совсем вышесказанное, мне кажется, оно уже эффективнее графита. Я как-то видел статью, по-моему, кто-то из Яндекса публиковал, она была на Хабре. Там у них какие-то фантастические цифры про графит были, что-то чуть ли не полмиллиона. Датапоинтов в секунду, что-то такое. Я, честно говоря, сначала не поверил, но подумал, что почему бы и нет на какой-нибудь толстой машине с большим количеством памяти. Очень даже может быть. Я не мастер готовить графайт, поэтому я не буду спорить с этим. Но, в общем, если кто-то знает, что имеет сравнение последних версий Influx с графитом, приходите, расскажите. Ну, на самом деле, когда идёт речь о тесте с ДБ, там могут фигурировать довольно большие цифры в плане 100 тысяч инсортов в секунду. Да, на самом деле оно всё в батчах. Да, на самом деле оно всё в батчах, и оно всё сжимается до такой степени, что на диск идёт 200 килобайт в секунду. Что-то в этом духе. Так что не стоит этого пугаться. В Акумуле я тоже реализовал сжатие, причём раньше, чем Influx DB, где-то на год. Но у меня оно по-другому работает. И я могу записывать больше миллиона значений в секунду на своей рабочей машине без особых проблем. На диск идёт, на самом деле, там тоже не очень много, и упирается всё в процессор, потому что сжатие ресурсоёмка достаточно. Всё это очень хорошо сжмётся, потому что обычно серия, представляете, что там есть у каждого значение метка времени, какое-то значение, идентификатор или имя серии. То есть мы сжимаем много значений одной серии, естественно, у них один и тот же идентификатор. А метки времени там обычно просто монотонно увеличиваются на одну секунду или на 10 секунд, всё зависит от того, как у вас там всё работает. Но обычно это монотонные серии, и это всё сжмётся элементарно. Там Delta RLE и всё это сжимается до нескольких байт. Буквально все метки времени. Этот процесс происходит просто практически мгновенно. Очень быстро. Самая большая проблема — это сжать флоаты. Для сжатия флоатов я использовал очень хитрый алгоритм. Есть paper, я, наверное, скину ссылку на него. По сути, он работает так. Мы берём первый дабл и пытаемся предсказать, каким будет следующий. Потом мы эти два дабла ссорим, и вот эту разницу мы пишем в выходной поток. И обычно там в начале, где мантиса и всё остальное у дабла хранится, там бывает нулит, потому что преддиктор довольно хорошо предсказывает эти начальные биты. Даже если просто брать в качестве прогноза предыдущее значение, то есть считать, что следующее будет таким же, и ксорить между собой соседние даблы, то получится довольно хорошо. Можно немножко это улучшить, если использовать FCM предикторы или DFCM предикторы, что-нибудь в этом духе. Но это всё довольно просто и довольно быстро работает. Такие дела. У меня сейчас такой вопрос возник. Как тебе вообще про это почитать? Я просто немножечко тайм-серии в свою жизнь уворочил, но конкретно про то, что ты сейчас сказал, про такие всякие хитрости с сожетиями я даже не слышал. Ну, почитай Gorilla Paper. Набери прямо в гугле Gorilla Paper. Ну да, я на него уже смотрел. Горилла Paper, я знаю, что он есть, он лежит в закладках. Там довольно неплохо описан этот алгоритм, только они используют его очень простой вариант. Они просто два соседних значения друг с другом ксорят. И потом они считают, сколько нулевых бит в начале и сколько нулевых бит в конце. То есть если в начале нулевых бит больше, они хранят оставшийся. Если в конце нулевых бит больше, они хранят начало. Вот это 8-байтовое слово. Ну и там в начале кодируется, что это. Нулик, значит, предыдущее значение такое же, как текущее. Ну и дальше переменная количества бит используется для того, чтобы закодировать, сколько конкретно бит мы сохранили. И нулевые биты в конце или в начале. Как-то так. Вот это все довольно медленно работает, потому что нужно работать с битсетами, манипулировать битами. У меня немножко другой алгоритм, в принципе, он похож. Я использую предиктор, поэтому немножко лучше сжатие. И плюс я работаю на уровне байтов. То есть блок 4 бита кодирует, сколько конкретно байт хранится. Точнее даже 3 бита. Значение от 0 до 7. И плюс еще один бит используется для того, чтобы указать в начале нулевые биты или в конце. Ну и даблы, они объединяются по 2. И вот эти 4 битные контрольные блоки, они тоже объединяются. Получается один контрольный байт, который управляет двумя следующими байтами. Их декодированием, точнее. И это все довольно быстро работает. Я измерял примерно 30-40% выигрыш в сравнении с таким кодированием, когда все это на уровне бит отдельных. Выигрыш по перформансу или выигрыш по сжатию? Выигрыш по перформансу, по сжатию там примерно одно и то же. Хотя казалось бы, должно быть хуже. Должно быть хуже у кого? У тебя или у них? Да, должно быть хуже у меня, потому что я храню отдельные байты, то есть я могу сохранить 3 байта. Вот это 8-байтовое слово или например 1 байт. Они могут сохранить какое-то конкретное количество бит. То есть они могут сильнее сжать, чисто теоретически. Но видимо из-за того, что они просто ксорят соседнее, у них получается хуже. Вот такие дела. Есть еще другие, есть на самом деле много всяких алгоритмов сжатия. Можно просто сжать кзипом, кзип жмет намного лучше, чем вот эта вся фигня. Но он жмет в десятки раз медленнее. Ну, кстати говоря, мы как раз кзипом и жали. У нас так было, что основная нагрузка была построить агрегаты, данных чисто физически. Их там еще так, что там не чистая тайм-серия, там тайм-серия, грубо говоря, стаканы. Пряжевые, тайм-серии внутри тайм-серии. И мы не стали совсем уж заморачиваться. И на самом деле мы просто строили в первую очередь агрегаты, а в вторую очередь мы просто паченьки складывали. Потом звали кзип один раз в минуту на эту пачку. И один раз в минуту писали в сторидж. Вполне себе отлично работало для нас. Ну, я не сомневаюсь, что хорошо работают. Это должно хорошо работать, если у вас довольно большие патчи. Ну, по минуте. Ну, смотря сколько данных вы туда кладете. Хотя, на самом деле, если у вас мало данных приходит, и вам нужно будет мало жать, и кзип будет тоже быстро работать. А вот ты говоришь, что кзип медленный, он насколько медленнее? Ну, в моих тестах он медленнее где-то в 30-40 раз в среднем. Грубо говоря, на каждый дейтапоинт ты его точно не хочешь. Это раз. Во-вторых, если дейтапоинт у тебя это число, то ты тоже не хочешь кзип. Не понял последнюю мысль еще раз. Ну, просто у нас дейтапоинт это не одно число. У нас дейтапоинт это было... Я уже там сейчас не работаю, но судя по тому, что дейтапоинт, он был сильно сложнее, чем просто число. Ну, я согласен. В этом случае проще сделать так, как вы сделали. И не возниться. Потому что чем больше у вас типов данных в серии, тем сложнее. Потому что для каждого типа данных нужен какой-то свой алгоритм сжатия. Для меток времени там какой-то свой, для флота свой и так далее. Ну, если серия такая очень гетерогенная, там много разных данных, то конечно. А, кстати, еще вот такой вопрос. У тебя все-таки флот или у тебя можно хранить там fixed point integer? Ну, можно хранить fixed point integer. Флот позволяет хранить целые числа до 52 бит. Ну, просто смотри, знаешь же, такая тема, что в финансах на самом деле нельзя флота использовать. Я знаю. Ну, то есть насколько твоя база данных, как она есть сейчас, подходит для того, чтобы хранить integer точку? Ну, это можно реализовать. Но на самом деле я не стал этого делать. У меня изначально было два типа данных. Флоты и блобы бинарные. Потом я от этого отказался, чтобы просто все упростить и сделать проект более таким сфокусированным. Плюс это очень сильно упрощает язык запросов и все остальное. Тебе не нужно описывать в запросе, что ты выбираешь. То есть у тебя есть какая-то серия, а там несколько полей. Тебе нужно в запросе оперировать этими полями и что-то может быть не выводить в итоге в output и по-разному их обрабатывать. Я не знаю. Но это все довольно сложно. А если сделать это все для простых числовых временных рядов, все сильно упрощается. Я в основном один это все пишу, поэтому мне естественно понравился второй вариант. А какие запросы у тебя есть? Я все-таки перебью немножко. Это все еще получается численный временный ряд, если хранить отдельный int на основное значение, отдельный int на значение после точки или как-то хитро хранить точку. В принципе, можно фиксированные длины int можно хранить без floating point? Можно, конечно. Ты на Lua программировал когда-нибудь? На Lua давно было дело. Там нет int, там есть только double. Ну вот это же плохо, потому что в итоге... Нет, ты можешь хранить 50 бита в каждом double без проблем. Ну, при этом с ними арифметика же довольно интересная. Ну да, это все по-моему элементарно обходится, это не проблема. Ну, можно сделать, если что. Ну, это проще, чем кажется, на мой взгляд. Просто не хотелось бы этим заниматься, честно говоря. Просто как бы баз данных в целом довольно вкусно для финансовой области, но мне кажется, что в финансовой области класть данные в double это нехорошая идея. Ну, пока им не делать... То есть, наверное, можно положить данные в double, но его не надо при этом использовать как double. То есть, наверное, не стоит все-таки точку использовать как точку, наверное, дело в этом все-таки. Ну да, как-то так. Так расскажи, какой у тебя интерфейс? У меня язык запросов на основе JSON, ну, примерно как в Мунге или в Elasticsearch. Я, честно говоря, даже не помню все запросы, которые там есть. Ну, запросы элементарные, которые позволяют выбрать данные за определенный интервал времени, указать начало-конец запроса, ну и в любую сторону прочитать. То есть, можно из будущего в прошлое двигаться, можно двигаться в обратном направлении, можно по всякому фильтровать, то есть, выбирать определенные серии. У серии есть метрика и комбинация тегов. Ну и можно указать, что какой-то тег должен быть равен тому-то или... Какой-то тег должен присутствовать обязательно, ну и так далее. Естественно, можно выбирать по метрике, можно группировать. То есть, если есть несколько серий, у них один тег отличается, можно их все слить в одну серию. Ну и всякие запросы, которые обрабатывают данные. Есть даже детектор аномалий. Ух ты, стой, место поподробнее. Да, я там скидывал ссылку на пейпер, который описывает это все. Ну, есть довольно простой детектор аномалий, который предиктивный, который просто использует какой-нибудь алгоритм для того, чтобы предсказать следующее значение. Потом, когда следующее значение появляется, он на него смотрит и вычисляет разницу. И если она там превышает какой-то threshold, он говорит, что это аномалия и что-нибудь воспрощает. Вот, этот детектор есть... Ну, там есть несколько алгоритмов для смузинга. Есть простой... Простой moving average, есть hold winters. Есть обычный, есть seasonal. У меня нет метода для расчета всех этих коэффициентов, которые требует hold winters. То есть предполагается, что пользователь сначала данные за какой-то период времени прочитает, рассчитает эти коэффициенты себе и дальше будет гонять. То есть эти коэффициенты, которые требуются, там три параметра, их нужно в запросе указывать. Возможно, в будущем не нужно будет, но пока так. И вот у него всего есть вариант этого запроса, который работает приблизительно. То есть он не требует памяти много, но он может давать ложные позитивные срабатывания. Он, в принципе, довольно интересный, но его довольно сложно объяснить. То есть он анализирует, если есть у нас какое-то количество временных рядов, допустим, миллион, и мы хотим считать hold winters на этих временных рядах, нам не нужно смотреть на каждый временной ряд. Мы считаем скетч на каждый период и потом на основе этих скетчей считаем hold winters. Или благодаря речи, или что угодно. Можешь, пожалуйста, на hold winters скинул ссылку или какая-то другая? Я скидывал ссылку. Окей, спасибо. Ну и в итоге получается довольно неплохой прирост производительности. То есть нужно в реал тайме считать этим методом аномалии, когда пишется огромное количество данных в базу, то есть при том, как они записывают, сразу выдавать аномалии или нет. Ну и так далее. Ну вот этот метод, который приблизительно работает, он выдает кандидата на аномалии, кандидатов в аномалии, и потом нужно точным запросом уже посчитать, действительно ли это аномалия или нет. То есть нам уже нужно меньше данных смотреть. Ну поэтому это все довольно быстро работает. Что еще про это нужно рассказать? Это очень... я забыл сказать, что база данных написана на C++. И вот это все, этот метод, он очень классно оптимизируется компилятором, он викторизуется практически полностью, и там SSE инструкции, и streaming extensions, и все это просто нереально быстро гоняется. К сравнению с... у меня раньше была более простая реализация, непростая, сложная, компилятор не мог ее оптимизировать нормально. Потом я немножко упростил код, и все буквально в десятки раз быстрее на бенчмарках стало работать. Я посмотрел в Dizasm, ну там реально все завикторизовалось, все очень классно. Такие дела. То есть ты как бы даже не думал, что у тебя такой внезапный буст случится просто... Ты прям понимаешь, что ты алгоритм сменил, или ты просто тот же самый алгоритм написал проще? Нет, там просто... ну по сути, простые рифмические операции над массивом. То есть там каждый элемент массива, двух массивов между собой там либо складывается, либо участвуется, либо делится и так далее. Да, я понимаю, но просто вопрос был немножко не в том, извини. Ты сменил алгоритм, я немножко не до конца понял, или сменил имплементацию алгоритма?",
    "result": {
      "error": "API request failed: Error code: 400 - {'error': 'Trying to keep the first 6665 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': 'Trying to keep the first 6665 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}\n"
    }
  }
]
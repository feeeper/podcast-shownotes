[
  {
    "segment_id": "878a7eed-eb84-4cca-8a64-5bb9c8e28d66",
    "episode_id": "7f8b0a4e-15c8-48e4-9822-16cb37dc2b53",
    "episode_number": 4,
    "segment_number": 6,
    "text": "Может сложиться ситуация, что ты приходишь домой, а тебе звонят, что у нас там полчаса назад все адово тормозило, а теперь оно перестало тормозить. Вот разберись, почему оно полчаса назад тормозило. И репл тебе… Не репл, ремшел имелся в виду. Он тебе при этом никак не поможет, потому что проблема уже исчезла. И вот тут-то тебе нужны логи, тебе нужны метрики и, не знаю, какие-то отладочные концы, мониторинг. То есть, отладка – это такая большая проблема. Очень сложная тема, да. То есть, у тебя должны быть обязательно отладочные ручки, которые позволяют… Если у тебя есть какой-то стейт в памяти, кэшик какой-то, мэп, ключи начиня, у тебя должна быть отладочная ручка, которая позволяет этот стейт как-то там по ХТТП, по определенным правам доступа, например, только из внутренней сети, считать этот стейт. У тебя должны быть логи, что, когда, зачем происходило. У тебя должны быть метрики, а вот тут у нас время выполнения запроса в 10 раз скачало. Ну вот это хорошо, если у тебя есть доступ к продакшену, а что если его нет, и тебе даже логи под вопросом, чтобы выслали? Ну, это очень просто делается. У нас очень много, помимо логов, у нас очень много рисуется графиков. Для того, чтобы смотреть графики, тебе нет необходимости лазить на продакшен, то есть, ты идешь на специальный сервис, у нас там графит висит, и смотришь все графики всех ключевых каких-то процессов происходящих. То есть, количество запросов, я не знаю, средняя, лейтенанс, максимальный размер какого-то буфера и так далее, все, что угодно. У нас этих графиков, ну, я не знаю, сколько. Вот реально, там десятки, сотни тысяч, я без понятия, я сейчас даже боюсь посчитать. А во что пишете? Ты имеешь в виду бэкенту графит какой? Ну, вы пишете в графит, да? Да, мы много в графит пишем. А смотрите прямо на его дашбордах, да? На самом деле, по поводу дашборда графит – это больной вопрос. То есть, напрямую на дашборде ты лезешь только тогда, когда у тебя на каких-то дашбордах уже собраны специально для каких-то целей, если там не хватает какого-то графика. А чаще всего мы используем графити, и на графите там вот есть, например, текущие ошибки, у тебя там сотня графиков, какие, возможно, ошибки в системе наиболее часто проявляющиеся, как они скачут за последний день. Я не знаю, какие-то подсистемы, для каждой подсистемы отдельные графики. Ты все эти графики можешь видеть сразу собранные в одной куче. Если тебе чего-то не хватает, лезешь уже в сам графит, и там по дереву смотришь, какие графики тебе нужны. И вот эти графики очень сильно помогают вообще искать проблему. Мы в свое время даже прикручивали туда некий анализатор, поиск совпадающих паттернов в графиках для того, чтобы в какой-то момент у нас случилась проблема, и он тебе выводит, у тебя есть 20 графиков, которые в этот момент примерно точно так же вскакнули, кто-то вверх, кто-то вниз. И это сильно позволяет понять, какие связанные системы задействованы, почему оно перестало работать и так далее. А вот скажи, у графита по дефолту, если ты его никак особо специально не настраивал, у него исторические данные, например, недельной давности, они, я не знаю, как это правильно называется, но они сжимаются. Например, ты писал какую-то метрику, максимальное время выполнения запроса за минуту. Ты ее агрегировал, агрегировал, сагрегировал этот максимум, записал его в графит. А когда ты хочешь посмотреть исторические данные, недельной давности, он по дефолту, сволочь такая, берет и усредняет по соседним точкам. И у тебя средний от максимумов, это вообще непонятная фигня, она тебе ни о чем не говорит абсолютно. Вот вы его как-то перенастраивали, выделили место много на диске. Как вы это решили? Нет, у нас за последнюю неделю хранится самая четкая градация, какая возможно. И нам этой недели в принципе хватает для того, чтобы подобные анализировать вещи. А пики, да, пики он не покажет тебе в дальнейшем, но мы не пытались как-то обойти эту проблему. Ага, ну тоже нормально. Еще я встречал, ну это немного костыльно, но ты в принципе можешь писать все нужное тебе время в логе, то есть там название метрики и там время, например, или количество, смотря что за метрика. И потом по логам строить графики с произвольной нужной тебе точностью. То есть это на первый взгляд немного костыльно, но зато это такой железобетонный способ безо всяких там вот таких подводных кораблей, что оно у тебя исторические данные усреднит или еще что-то. Ну да, то есть получается, что вот эта отладка на продакшене, она как бы происходит, это поиск ошибки в данном случае, не отладка. Поиск ошибки происходит вообще не на продакшене, а на каких-то третисторонних сервисах, типа анализатор логов или графики, отображение графиков. Отладку на продакшене я бы тоже не рекомендовал, как и Саша, потому что, ну да, у тебя есть... Должно быть отложено до продакшена. Да, конечно. Хотя бывает иногда, что в продакшене что-то приходит, какой-то юзкейс, который там только там, и для того, чтобы максимально быстро починить, понятное дело, что легче всего там посмотреть время, Саша, что у тебя не тот пришло, почему у тебя какое-то нестандартное данное, грубо говоря, там понять, что происходит и потом запилить какой-то фикс. Тут еще нужно отметить момент, что, ну если ты не полный дурак, то ты должен планировать, что ты будешь делать в случае ошибок. То есть, ну например, у тебя, ну, вот горизонтальное масштабирование, да, все думают, что это вот там для того, чтобы там, только для того, чтобы... Масштабируемость обеспечить. Чтобы масштабироваться, на самом деле нет. Вот, допустим, у тебя работает твое приложение на двух машинках, держит нагрузку, все хорошо, потом раз, и все стало тормозить. Вот ты вместо того, чтобы там долго, мучительно, там полдня разбираться, почему она тормозит, и пользователи в это время страдают, ты просто поднимаешь там еще две машинки, поднимаешь копии сервиса, и вот так вот быстро, ну, эффективно решаешь проблемы с тормозами. А потом уже разбираешься, а что там за тормозила. Вот и есть масштабирование. Да, но я имею в виду, что горизонтальное масштабирование, оно еще полезно в контексте решения вот таких проблем на продакшене быстро. А не только в том, что там вот мы видим, там плавно нагрузочка растет, давайте там через неделю машину закажем. Ну, я надеюсь, я понятно. Да-да-да. Выложил свою мысль. Из той же серии, что ты будешь делать, если тебе нужно выкатить фикс, да? То есть, например, у тебя там только один экземпляр приложения крутится, и ты нашел даже причину ошибки, но ты не можешь ее зафиксить, потому что ты сейчас установил приложение, и пользователи будут страдать, и ничего не доступно. А у тебя приложение там полчаса прогревается после старта. То есть, ты это тоже должен предусмотреть, то, что можно один инстанс запустить, обновить, потом второй инстанс запустить, обновить, а балансировщик в это время все правильно забалансирует. То есть, все это надо заранее предусматривать, и это позволяет нормально фиксить баги на продакшене. Ну, вот что касается для мира Java, я бы посоветовала такие штуки, как Zabbix и Nagios. Очень хорошо отображают все метрики и рисуют графики. За любой промежуток времени можно посмотреть, сравнить что-то и делать какие-то выводы. Но это не только для Java, это везде. Ну, в принципе, для любого. С Nagios, ну и все большие системы должны рассчитывать на какие-то аналоги подобные. Роман спрашивает нас про Nix OS, просит что-то рассказать. Ну, я не знаю, я так краем глазика посмотрел, это вроде Linux с пакетным, как он правильно называется, package-менеджером Nix. И этот package-менеджер обладает определенными свойствами из серии. Ты можешь накатить апдейтов на сервер, а потом, если что-то пошло не так, то атомарно откатись, как было. Такого рода. Ну, что я могу о нем думать? Да, прикольно. Я, правда, с такой проблемой не сталкивался особо. Мне кажется, что все подобные штуки, они малоприменимы. Я имею в виду следующее, что пока вы работаете, зарабатывая какие-то деньги, вы не будете приходить к каким-то непонятным, пока еще не production-ready системам. Только тогда, когда полмира скажет, что да, Nix это классная штука, давайте ее использовать, только тогда мы, например, будем туда переходить, потому что сложно переходить на какую-то раннюю бету или даже раннюю готовую систему. Тут еще такой момент, что у тебя, если ты живешь в облаках, и у тебя там ты можешь сделать машину с Ubuntu всем понятной и широко используемой, или с CentOS всем понятным, но не можешь с NixOS, то ты на него особо даже смотреть не будешь. Ну, и, соответственно, когда ты работаешь на локальной своей машине, зачем тебе использовать NixOS, если у тебя в production его нет? То есть, получается такой замкнутый круг, из которого очень сложно выбраться, на самом деле. Есть такое замечательное объяснение, почему никому не нужен план 9. Вы знаете, да, от Google такая? Да, слышал о ней. Почему? Ну вот, очень простое объяснение, то что там всякие современные Unix, ну там Linux, FreeBSD, они достаточно хороши. То есть то, что в NixOS они там сделали какой-то там замороченный package manager с парой прикольных фичей, это здорово, но Ubuntu, она достаточно хороша. Ради вот таких мелочей никто не будет с нее переходить. На самом деле здесь плюсы вот этих систем, они в том, что фактически можно обкатать какую-то новую технологию на независимых дистрибутивах, а потом, возможно, внедрить ее в какие-то более шикарно расходяные фичи. Да, плюс к этому комментарию, потому что создают конкуренцию, и так или иначе, производители систем, которые распространены, они смотрят, что у конкурентов происходит и пытаются как-то у себя-то внедрять каким-то образом. И это, в любом случае, плюс к развитию. Да. Так, я предлагаю еще про кодогенерацию. Дмитрий Свидерский спрашивает, интересно было бы послушать о кодогенерации, можно ли на Haskell, например, писать программы на PHP и так далее. Мы использовали кодогенерацию, я так понимаю, Саша, ты тоже использовал, а вот в мире Java, например, кодогенерация насколько используется? В принципе, можно ли считать кодогенерацию, когда ты из Java servlet'ов делаешь какие-то страницы для веба. Это не совсем... Я думаю, речь скорее идет о каком-нибудь Trifty или Protobuf, когда ты файлы описываешь. Ну, понимаешь, смотри, когда мы говорим про Protobuf, то, окей, ты будешь пользоваться сгенеренными классами, но ты же не будешь их сам генерировать. У тебя есть компилятор, проток, который тебе по протофайлам сгенерирует классы для любого языка программирования фактически, потому что их сейчас уже хватает, этих генераторов. Да, и мы пользуемся, это отлично, это прекрасно работает. Конечно, оно не предназначено для чтения, хотя у него есть ключи. Что касается Protobuf, то есть ключи. Вариант первый, мы делаем максимальную производительность, вариант второй, мы делаем максимальную читабельность. Нужно что-то выбирать одно из этих. Разумеется, все доберут максимальную производительность, потому что эти классы не предназначены для чтения. Но работает, но работает хорошо. Конечно, есть тонкие моменты благодаря тому, что если ты собираешься добавить какое-то новое поле в твое сообщение в Protobuf, то если оно будет иметь тип обязательным, то это тонкие моменты, нужно хорошо понимать, где оно будет использоваться, иначе получишь проблему несовместимости версии протокола. Просто нужно понимать. И так оно хорошо работает. А чтобы из Java что-то такое делать для себя, мне как-то не приходилось. Я думаю, что Дмитрий спрашивает именно об этом. Когда ты не используешь какую-то готовую штуку, а пишешь что-то свое новенькое для того, чтобы языком более высокоуровневым, скажем, Haskell, как он для примера, генерить что-то на PHP, на котором ты не защищен от... То есть компилятор тебе не подсказывает какие-то ошибки типов и так далее. Мне вспомнились эти DSL. Да, фактически это и есть DSL. Я думаю, что вещь вполне живущая. Я имею в виду, что можно использовать, если вы понимаете плюсы, то, конечно, используйте. У нас такие вещи использовались, у нас JavaScript генерировался с помощью Haskell. То есть это удобная вещь, и она позволяет большие какие-то программы достаточно генерить из маленьких декларативных описаний. Это удобно. Это крутая фича. Дмитрий спрашивает, какие языки программирования для этого подходят. Haskell подходит, Clojure, в Scala есть макросы какие-то, не знаю, не работал. В фреймворке, ну мы там обсуждали ESOD-DSL, который REST-сервисы генерирует. Еще мне недавно скинули для Java есть... Вот я долго докапывался, как называется аналогичная фигня для Java. Есть такая штука Swagger. Я в шоу-ноуты прикреплю ссылку. Да, обязательно. Вот, она похоже тоже генерирует... Так, ну давайте тогда дальше. Свет, давай предложим, может быть, ты какой-нибудь вопрос. Вот тут про Java 8 можно ли уже в продакшен? Вы используете уже, Свет, Java 8 в продакшене? А что так? Страшно. То есть вы все еще на 5 сидите? На 4, конечно же. Я считаю, что для себя, конечно, можно пользоваться, а в продакшен, наверное, пока рановато. У нас 7 используется и страданий по этому поводу нет. Единственное то, что когда уже будет прекращена какая-то поддержка 7, тогда действительно стоит переходить. А пока, ну пускай еще патчей выйдет туда на 8, тогда можно переходить. Я не вижу большой необходимости в этом пока что. Вот еще интересный вопрос. Также от fi5t. Я думаю, это должно читаться как fist. Как вы видите, процесс проектирования большой системы с нуля? Ну, с нуля большая система, она маленькая. А потом она со временем растет. И ты как бы итерация за итерацией ее постепенно развиваешь. Ну, как-то так. То есть ориентируешься на требования твоего заказчика, кем бы он ни был. Бывает так, что тебе надо и большую сразу проектировать. Ну, приведи пример. Что-то большое нужно написать сразу с нуля. Но ты будешь прям с нуля писать, я не знаю, Google. Чтобы он сразу работал. Ну, не Google, но Twitter, например. То есть тебе прям ходят и говорят, напиши мне Twitter с нуля, но при этом сразу сделай, чтобы он был производительный и эти миллионы пользователей мог обеспечивать. Но ты понимаешь, что тебе не придет сразу миллион пользователей. У тебя по-любому как минимум поначалу будет какая-то закрытая бета. Я бы так сразу не гарантировал. Почему? Ну, потому что подобные задачи бывают. У нас были. То есть у вас появилось тысяча пользователей. Нет, не появилось, но задачи такие могут появляться. То есть не тысячи, а миллионы. В любом случае, когда ты проектируешь что-то, ты сразу начинаешь думать, окей, каким образом мы... Давайте разделим, вот это будет слой какой-то UI, это будет Core, это будет еще что-то. И ты будешь от этого отталкиваться. Ну, и не только это. Там еще приходится думать о компонентах, как они будут взаимодействовать между собой. Ты думаешь о горизонтальном масштабировании, об интерфейсах между компонентами и пользователем. Даже load balancing можно сразу заранее думать, если, например, ты собираешься делать какие-то хитрые фичи, а не просто раундробин. Ну, к примеру, если часть серверов будет для отдельного пользователя хранить какой-то кэш. Но все подобные штуки, они всегда требуются от высокопроизводительных систем, когда у тебя большое количество пользователей или большой трафик. В любом случае, все нужно исходить от требований, какие требования, и дальше уже прикинуть, какие части системы будут это реализовать. Разбивать на какие-то модули как можно раньше. То есть, делить на какие-то отдельные, отдельно стоящие части. И между ними уже как-то связывать. Хорошо? Разделяй и властвуй. Да, да, да, этот подход. Так, ну и все, наверное, да? Но тут еще Иван присяжный спрашивает про Ziki. А, да, да, интересная штука. Но это прикольная штука, я ее, правда, но я так понял, я особо глубоко не вникал. Это сама по себе Ziki, это утилита, которая через плагины цепляется к текстовым редакторам, и она, если ты специальные скрипты напишешь, то при определенных ходкеях может очень круто тебе подставлять название файлов и, не знаю, грубо говоря, писать твиты. Всякие такие странные вещи делать. Кроме того, есть XShell, XSH, у него, правда, нет, врать не буду, по-моему, может быть, есть DEPPacket, это основанный на Ziki Shell, в котором, ну вот, например, ты в типичном Shell, как делаешь, ты пишешь, хочешь убить процесс, ты сначала узнаешь его PID, пишешь там PSVUIX, там креп, название, да, как-то так. Потом копипастишь PID и говоришь там kill-9 этот PID, ну или каким-то таким образом. А здесь ты можешь, ну вот как там, например, в Z Shell есть там всякие автодополнения каталогов, и даже в баше ты можешь там к Git checkout и нажать Tab, и он тебе подставит название ветки, да. То есть ты по аналогии можешь там сказать там kill, потом там нажать какой-то хитрый ходкей, из списка выбрать процесс и как бы его прибить. И писать много таких подобных вещей, делать какие-то заметки прямо в Shell, писать твиты опять же прямо в Shell. И все это так очень круто программируется. Это то, что касается Ziki, и вопрос в том, ну да, в Change.log о нем целый подкаст посвящен, кому интересно послушать. Вопрос в следующем, понимает ли кто-нибудь, зачем это? Ну, я, честно говоря, не особо понимаю. Мне баша хватает вполне. Я думаю, что вот эта вещь может быть полезна для разработчиков юзер интерфейсов. То есть вот сам разработчик Ziki, он в том числе UI дизайнер, и все вот эти вещи, то есть там посмотреть, попробовать на лету сгенерить на Bootstrap какую-то формочку и вывести там в ней какие-то пунктики нарисовать, я не знаю, там листы и так далее. Он все это делает, встраивает в том числе в Ziki и позволяет очень быстро прототипировать. То есть он рассказывает, что они за полчаса во время парного программирования запрототипировали какой-то достаточно сложный интерфейс, и ему бы не удалось это сделать ни в какой из существующих систем. Вполне возможно, для подобных вещей она будет полезна. Но вот реально я для себя не вижу больших плюсов. А вообще я еще хотел добавить, что Ziki – это от слова Wiki с заменой одной буквы. Разработчик предполагает, что это будет система а-ля Wiki, то есть ты можешь написать большую страничку, и каждая новая строчка в этой страничке может быть отдельной командой, которая представляется в виде какого-то интерфейса в Markdown или еще чего-то. То есть такая несколько другая концепция Shell и взаимодействие с системой. Но я не вижу большого применения для себя пока что. В шоу-ноутах будут ссылки на сайты Ziki и XShell. У них там совершенно чумовые есть видеодемонстрации. Там просто зарывает мозг, когда это смотришь. Я советую посмотреть. У вас лучше сложится впечатление. В том числе человек, грубо говоря, в редакторе что-то пишет, и у него там в соседнем окне сразу в Bootstrap верстается сайт прям на лету. То есть довольно… Там есть очень интересные примеры. Вот. Ознакомьтесь. Ну и мы как-то вроде у нас и сякли. Вот еще интересная тема. Интересно услышать мнение про ниши для C++ и D-Lang в сравнении с первой парой. Первая пара это C и Go. Что касается C++, на мой взгляд это игры. Самая интересная сфера для C++. Игры, как я это понимаю, их сейчас пишут в Unity на C Sharp или на каком-нибудь скриптовом языке. Нет. То есть берется движок, берется толпа народу, которые читают какую-нибудь книжку с описанием скриптового языка для этого движка. То же самое касается, например, Torque. Есть такой движок. И ты просто рисуешь модельки, импортируешь их, пишешь какие-то скрипты. Там уже нет какого-то C++, если ты разработчик движка. Знаешь, разработчики C++ говорили, что Unity это плохо и это не то, что нужно.",
    "result": {
      "error": "API request failed: Error code: 400 - {'error': 'Trying to keep the first 5472 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': 'Trying to keep the first 5472 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}\n"
    }
  }
]
[
  {
    "segment_id": "063c71c4-2063-4165-9537-5d0917b2d10c",
    "episode_id": "4af62eff-7a5d-4687-87c1-47058c9f4f3c",
    "episode_number": 178,
    "segment_number": 3,
    "text": "То есть, опять же, если мы не найдем проблемы со звуком, то, наверное, и нет. А, немножко раздражает, что он включается довольно странно. Потому что частота дискредитации, он по умолчанию является как 48-килогерцовый, при том, что по умолчанию выбрано на самом девайсе 44 килогерца. И на самом деле приходится или на стороне MacOS переключать на 44.1, или на стороне микрофона перебрасывать на 48. Вот. Это немножко такая вещь, которую каждый раз нужно не забыть ткнуть, иначе получается странный артефакт, но в остальном все хорошо. В общем, я тоже думаю. Я тоже задумался о покупке. Мне потому что в поездках я с собой беру всегда не очень удобные инсталляции, которые дают не очень хороший звук. В общем, да, если вы, уважаемые слушатели, отобряете, возможно, мы все на это безобразие перейдем. Вот, собственно, пример того, как мы тратим вашу поддержку на патреоне, кроме как на постинг и всякое такое, и на метапы. Я думаю, стоит для протокола сказать, где ты сейчас находишься. Да, я сейчас, если что, в Москве. В командировке. Ну, уже на самом деле я в отпуске. У меня командировка в Холланд-Бритиш перетекла в отпуск, но на самом деле с точки зрения подкаста нам действительно интересно, почему я был в Москве в командировке. Потому что в Москве прошла конференция PGCon. Я знаю, что это всеми любимая тема конференции, но поскольку это конференция про Postgres, и Саша даже, вот, у нас до сих пор сотрудник Postgres Professional, никуда не сбежал, и компания проводила конференцию, то Саша как главный причастный, и он обязан в этом поверить. Ну, я-то поверить могу, но я не сильно в этом преуспею, потому что саму конференцию я мало посмотрел, а связано это с тем, что мне где-то в начале первого дня к кофебрейку подошел Ваня Банченко и сказал, что Саша, ты знаешь, что у тебя завтра доклад? Я такой, да, а на какую тему? Он такой, ну, откуда я знаю, это твой доклад. Вот, и я судорожно делал слайды, ну, причина в том, что один из докладчиков слился и были перестановки. И получалось так, что первый день я делал слайды, второй день я бегал, пытался поймать кого-нибудь, узнать во сколько же у меня доклад и в каком зале, потому что на эту тему тоже были противоречивые сведения. Да, но в результате свой доклад я сделал и слайды уже выложил, ссылки будут в шоу-ноутах, доклад про то, как хранить в подграсе пожатые документы, либо сжатые JSON-B, либо протобав, и там для, скорее, развлекательных целей, такие всякие фанфэкты про то, как можно уменьшить размер таблицы в подграсе. Считаю, что очень сильно повезло с погодой для иностранных докладчиков, потому что вот прям ровно за два дня до конференции началась настоящая русская зима с пушистым снегом, с гробом и вот этим всем, потому что очень многие иностранные докладчики приезжают именно посмотреть на зимнюю Россию, это как бы часть их приключений. И вообще в целом у меня такое теплое, ламповое ощущение от конференции, потому что я там очень многих людей знаю, и вот ты прям смотришь налево, там какие-то друзьяшки, смотришь направо, там какие-то друзьяшки. И лично у меня вот такие вот всякие теплые чувства от конференции. А еще Валера нас всех заморозил. Да, я в принципе успел поиграть в Волчару, но кроме этого я успел заморозить, потому что я очень хотел поснимать коллег на фоне здания МГУ, ночью, чтобы было снег видно, и у меня была с собой в камере вспышка, и Саша под рукой тоже оказался, и в общем я всех таял в снег и пытался над ними измываться. Но у меня, к сожалению, все очень плохо. У меня есть один кадр, где все в фокусе, один кадр, где мне нравится свет, третий кадр, где мне нравится композиция. Я не знаю, как мне из этого всего будут сшивать. Возможно, я это просто выброшу, и это будет очень грустненько. Или я, может быть, их как-то сошью в пост, и там при помощи какой-то матери и немножко фотошоп-магии оно, может быть, получится нормально. Посмотрим. Мне на самом деле было странно услышать, что у тебя не получается сфотографировать так, чтобы было в фокусе. Ты не пробовал его вручную наводить? К сожалению... Смотри, вручную я наводить... Когда я тогда не пробовал, потому что было холодно, я пытался, типа, чтобы это было быстрее, но получилось, наоборот, медленнее. Проблема в том, что у никоновских камер, когда снимаешь снизу, я переключился на экранчик, и у них резко отваливается фазовый автофокус, и у них включается контрастный автофокус, и контрастный автофокус у них из рук он плохой. И поэтому все было очень плохо. Если это каким-то полутора фото с задротом, о чем ты сказал. Тем временем я хочу сказать, что мне очень понравилось... В целом уровень докладов был неплохой. Очень много докладов про всякие рароколоночные штуки. Я не буду называть конкретно, но там было довольно много. Мне, к сожалению, не посмотрел сам доклад, но я буду смотреть глубже, потому что это было на другом треке, чем позже. Но я буду смотреть на то, что называется Vectorized Operations. Это экстеншн для Postgres, который запилил Сашин коллега, и который, я так понимаю, должен дать нам более векторное исполнение для Postgres фигни. Подозреваю, там как это называется, видимо, паркетный лояйвот, когда у нас не совсем колоночная структура. Я, может, путаюсь с чем-то другим, но так понимаю, что не совсем колоночная структура используется. Там у нас внутри страницы, если не ошибаюсь, она хранится как бы поколоночно, а каждые страницы, они построчно хранятся как-то так. И типа там, так понимаю, что какое-то оптимизированное исполнение есть. В общем, мне интересно это посмотреть, интересно с этим поиграться, но я еще не успел. Вот. Еще было очень много докладов, там всякие Green Plum, еще всякие подобные использования. Очень жду 11-го Postgres, в котором завещают завести партиции, которые смогут через... Хотя парти... Ну, как это... Отдельные партиции смогут быть for and data wrappers, например, на другой Postgres, или вообще на какую-то неведомую фигню. И они смогут поддерживать агрегат pushdown. Почему-то интересно, потому что для очень многих аналитических задач, типа того, что есть сейчас в Adjust, мы сейчас эту агрегацию, последний шажок, мы собираем не Postgres, а мы собираем кастылями, честно говоря. То есть, ну, application logic мы собираем, последний шаг агрегации, приходится дублировать немножко логику между сервером API и базой данных. А вот такое вот партиционирование умное, которое сможет агрегат посчитать максимально на шагах, и потом уже самый конец доагрегировать на вот той машине, от которой запрос пошел, это очень клево. И я очень жду Postgres 11, чтобы запустить свои ручонки и просить код в своем приложении выкинуть не нужно. Вот, еще был очень холливольный... Извини, у меня только маленький вопрос. Я правильно понимаю, что этот патч сейчас в ревью? Я так понимаю, да. Но он нам обещали. Ну, это как-то то, что было такое партиционирование, да, там часть из этого было в ревью, но они довольно уверенно высказывались про то, что вся эта штука будет в 11-ом Postgres. Ну, может быть, конечно, и не будет. Тогда будет опечален. Но я так понимаю, что там еще есть pgpathman, и для него есть shardman, вот, можно при помощи них, по-моему, то же самое собрать, и я так понимаю, что это была тестовая площадка для этих фичей для 11-го, поправь меня, если я не прав. Я вот этот момент не могу прокомментировать, я просто не в курсе именно про FDW в партициях. То есть я немного не в теме. Окей, вот. И последнее, что я хочу отметить, был дико холливорный доклад, собственно, который меня перетащил, мое внимание от вот этого vectorized operations, потому что название звучало дико холливорно, что типа Postgres с плодежкой блокчейна, я такой, чё? А там при этом выступал господин Коробков, тоже Сашин коллега, и вроде бы человек создает впечатление, который как бы задело обычно говорить, и мне вот этот вот холливорный, ну, не холливорный, как-то хайповый доклад у меня просто резко поджег мое внимание, и вот я на горящем своем внимании залетел в аудиторию, послушал, это было действительно очень интересно, ребята делают очень интересную штуку. Там на самом деле в самом Postgres, конечно, никакого блокчейна нет. Идея в том, что мы сертифицируем содержимое Postgres, при помощи тех же механизмов, при конечном, которые сертифицируют транзакции в блокчейне, и делаем так, что у нас, ну, как бы если у нас какая-то часть истории базы сертифицирована, то можем эти хэши, которые сертифицировали, положить в публичный какой-нибудь блокчейн или еще куда-то, и знать, что база на какой-то момент, она, так скажем, ну, как это, согласовано, очень избыточное слово как это, что те, кто в нее писали, и те, кто, ну, они согласны с ее содержимым, они расписались за ее содержимое своими цифровыми подписями, скажем так. Вот, и что, как бы если вот там все хэши всех блоков сходятся, то, соответственно, там Merkle-3 истории, там не совсем Merkle-3, неважно, я не хочу вдаваться, пересказывать доклад здесь, но смысл в том, что там довольно интересная конструкция, которая позволяет сказать, что вот история базы на такой-то момент, таким образом ее содержимое, она юридически правильна, назовем это так. Вот, вам больше не нужен юридический нотариально заверенный скриншот, у вас теперь может быть нотариально заверенная база. Вот, и нотариально заверенную базу, ее хэш можно положить, как уже сказал, на публичный блокчейн, или там можно периодически их туда складывать, или там еще куда-то что-то с ними можно делать, и таким образом получать такое состояние, для чего это может быть нужно. Например, не знаю, как бы вы хотите контракт со страховой средой заключить, и вы там какие-то опции включаете, все в базе и так далее, и в какой-то момент вы, как там, с самого мобильного приложения, создаете там подпись, и там, не знаю, вам, соответственно, присылается хэш того, что вы подписали, хэш блока, который вы подписали, после этого вы узнаете, что вот то, о чем вы договорились с вашей страховой, у вас локально на вашем мобильном приложении есть, не знаю, хэш вашего договора, и там ваша страховая не может там что-то у себя потихонечку в базе поменять, и сделает так, что вам очень плохо. Другой вариант, просто в похожем случае, там, страховая не страховая, а если даже у нас владелец сервера не злонамеренный, он все равно этот сервер может там, не знаю, держать не у себя где-то в хостинге, он может держать, не знаю, в какой-нибудь облаке, или вообще просто где угодно, где какое-то еще злонамеренное лицо пошло и что-то кому-то поменяло. Вот, после этого у нас хэши разъедутся. А вот благодаря вот такой системе они не должны быть могли разъезжаться. Ну, то есть идея какая-то такая. В принципе, это пока что, я так понимаю, скорее исследование, чем практическое применение, но вот идея интересная. Мне было занято. Я все. Лично мне из тех немногих докладов, которые я смог посмотреть, очень понравился доклад Дорофея. Дорофея про Лесковского, про POSGES и про то, как они используют в своей компании Djuna. Это, я боюсь набрать, но, по-моему, это, по сути, белорусский Uber или как-то так. Ну и про разные интересные проблемы, которые возникают у него с POSGES, потому что, ну, собственно, мы чем занимаемся, это пытаемся исправлять проблемы в POSGES. Вот, в частности, после доклада с ним пообщался и такой составил эту душечку. А разве Djuna это не нью-йоркский Uber? Я могу гнать на эту тему. Мне лучше здесь не верить. Кстати, вам грозилось прийти в один из следующих выпусков и рассказать, как на самом деле. Я могу здесь добавить, потому что Djuna – это белорусская компания, действительно, которая, по сути, является офисом разработки компании из Израиля и оперирует. И у них операционная деятельность развернута была в Нью-Йорке. А потом их купил Gett. И теперь они частью Gett являются. У меня есть интересная история про Gett. Данная не в тему, но он был установлен у мамы на телефоне. И она столкнулась с такой неприятной ситуацией, что она по ошибке несколько раз заказала такси на другую сторону улицы. Ну, бывает, все ошибаются. Отменила. После этого Gett я ей сказал, что… Кстати, как правильно называется? Gett или Getty? Или это разные совершенно приложения? Gett. Ну, окей. Приложение ей сказало, что мы вам не вызовем никакой такси, пока вы не введете свою карту. Мама начинала вводить карту, и у нее как бы ничего не получалось. Там поле красное, карта не принята. Потом уже расследуя этот случай, я выяснил, что идея Сбербанк сделала карту Маэстро, которую, в принципе, мало кто понимает и принимает, потому что там, например, не 16 или сколько там? Я не помню, сколько на нормальных картах цифр, но там на 2 больше, в общем. И нормальная система работает с визой, с мастер-картой, но не с Маэстро. И вы можете представить себе отчаявшуюся женщину, которая пытается вызвать такси на улице минус 20, карта не вводится. Это к вопросу про пользовательский интерфейс и его удобство и вообще адекватность. А что еще? Адекватность. Это конференция про C++ Russia в Санкт-Петербурге. Да, которая пройдет с 19 по 20 с 1 апреля, но уже стоит готовиться, записываться. cpp.conf.ru, ссылка будет в шоу-ноутах. А что еще будет в шоу-ноутах? Это ссылка на количество багов, которые подчислили в POSGES 10.2. Все говорят в фейспалм, что там больше 60 багов. А в чем фейспалм? То есть в каждой версии какое-то количество багов чинится? Или здесь их просто слишком много? Я не знаю, это много или мало, но мне вообще интересно, как сделать так, чтобы багов было меньше. Чтобы их не было. Ну, в идеале, да. То есть кто-то говорит, что каким-то образом поможет баг-трекер, не знаю, каким образом он поможет. Но есть и такая точка зрения. Мне кажется, что проблема, она частится в том, что код уже далеко не новый, и, ну, говоря нормальным языком, это легоси, в котором много ифчиков на разные случаи натыканы. И вообще не очень понятно, что с этим делать, потому что это C. Это вообще довольно трудно там отрефачить. Ну, смотри, как бы Linux код тоже C. Это, мне кажется, не очень правильный аргумент. Мне кажется, что интересно, что подгресовая комьюнити, что выделяет подгресы, в виде много чего другого, в подгресе очень не любят дропать поддержку чего-то старого. Есть какой-то, не знаю, железка, которую использует полтора человека в мире, и вот ребята не бросят поддерживать это железо, они продолжат на нем собирать. Это, с одной стороны, хорошо, портабельность, вот это все, с другой стороны, это усложняет код. Как раз вот оттуда появляются чудесные ифчики. Второй момент? Нет-нет-нет, сейчас не совсем прав, позвольте, я поправлюсь. То есть позиция комьюнити такая, что поддерживать там еще одну железку несложную, мы как раз наоборот заинтересованы в том, чтобы собирать другим компилятором другую платформу, потому что это позволяет находить баги. И в коде нет ифчиков, связанных именно с кросс-платформенностью. И дефайников там нет, ничего такого. То есть максимум, что там есть какой-нибудь отдельный совершенно файл, в котором атомики для, не знаю, какого-нибудь особенного спарка, но это не те ифчики, про которые идет речь. Я говорю про ифчики, которые связаны именно с поддержкой транзакционности, например. То есть поддержка транзакционности – это реально большая сложная штука. С восстановлением после сбоев, там с изоляциями, со всем этим, притом изоляциям много уровней. Саша Бондаренко буквально запостил в Gitter, что один из фиксов – это фикс спинлоков для Motorola 68K. Ну, правда же. Но это 1 из 60 багов, и ты именно оттуда прилез. Ну, хорошо. Ну, значит, их 59, но это не сильно улучшает ситуацию, согласись. Ну, вообще там списки довольно стрёмные есть. Я хочу сказать, что Postgres, несмотря на то, что он C, я не знаю, насколько какой-нибудь Enterprise DB или Postgres Professional внутри, что-то такое, но мне кажется, что снаружи из Postgres точно ничего такого не торчит. То есть намазать какой-нибудь, как же его назывался-то, Infer от Facebook, намазать какие-нибудь property-based test или что-то такое. Если есть какие-то кейсы, если есть какие-то очень понятные транзакционные случаи, которые нельзя намазать, какие-то конкретные варианты индексов, то это штука, которая бы генерировала такие SQL транзакции, ну, по ценам этих транзакций, SQL с запросами на основе какой-то модели, где бы должна работать база на каком-то там уровне изоляции. Там уже намазано такого. И должны быть какие-то случаи. Уже намазано такого, речь идёт про такие баги, что А вот если ты создаёшь партицию, когда у тебя, условно говоря, выполняется вакуум и ещё там при этом параллельный recovery, то у тебя там, не знаю, 10 байт памяти утечёт. Ну, то есть ты вот про такое вообще хрен подумаешь и хрен покроешь какими-то property-based. Согласен. А там хочется сказать, что там есть? Можешь с этого подробнее? Проблема в том, что вообще в Postgres есть много всего. И оно с друг другом взаимодействует. Иногда очень неочевидным образом. Нет, подожди, ты не уклоняйся от ответа. Какие тесты в WSU есть в публичном ПОСе? Ну, вот на все изоляции, на всевозможные партиции и так далее. Ну, то есть на любую фичу или фича. Фича не попадает в Postgres, если на неё нет адекватных тестов на все corner cases. Ну, блин, откуда ты возьмёшь все corner cases, если... Вот он тоже мой аргумент, что они там скорее всего как-то руками забиты кейсы. Но они забиты руками, но они не статичные. То есть там есть фреймворк именно из разряда поднимаем там две ноды Postgres, настраиваем между ними репликацию, ну, например. Там делаем то-то-то и получаем такой-то результат GDM. Не уверен насчёт генерации, там конкретно случайные данные или они там статичные. Но тесты там не такие, что вот просто данные на входе, данные на выходе. Просто если я смотрю на багов, там есть crashes, там есть incorrect query results и так подобное. То есть такая хорошая, хорошая модель, на которой параллельно, может быть, год разработки, может быть, полтора года разработки уйдёт. В принципе, возможно, многое бы из этого находило, если бы там была такая comprehensive data. Даже не data, это чувак-модел. Это модель, не знаю, исполнения, наверное. Это так. Я думаю, что половина этих багов, она как раз была найдена на каком-нибудь SQL Smith, который, собственно, фазинг SQL framework, по сути, это property-based way. Подожди, ты у меня прерывался. С кем была найдена? SQL Smith — это утилита, которая генерирует SQL и проверяет результат, что он соответствует, не соответствует, ожидаемо, крашится, не крашится и так далее. Как минимум, у тебя есть вариант, что на любой SQL ничего не должно крашиться. Ну да, я про это и говорю. То есть да, SQL Smith, но почему вы не запускались перед релизом 10.0? Разумеется, запускали. Но это же файзер, он... Но потому что этот файзер, он иногда находит, иногда нет. В зависимости от того, что сгенерил. Ещё раз, в Postgres очень много фичей. Они взаимодействуют. Я согласен. Очень неочевидным образом. Ну короче, в любом случае, мой пойнт в том, что нужно как-то улучшать, не знаю, даже не покрытие тестами, а способы запуска этих тестов. Так, чтобы они как можно больше, в таком случае, покрывали перед каждым релизом. Не знаю. Помню, что Бошо хвастались тем, что они, не знаю, днями гоняют эти тесты, прежде чем сказать что-то стабильное. И мне кажется, что Postgres, у которого вообще всё очень плохо, ну или ты по какой-то момент жалуешься, что всё плохо с инфраструктурой тестирования, может быть, всё стало лучше. Мне кажется, что вот как бы есть некоторое количество компаний, которые внутри себя что-то потестили. Общего понимания того, насколько оно стабильно, ну оно такое, просылки договорились, опять же, это моё понимание этого вопроса, и после этого решают выпустить. А какого-то открытого, не знаю, сервера, который прогонит какой-то большой-большой-большой номер тестов, не знаю, за неделю, и скажет, что вот эти все штуки прошли, или не знаю, какой-то кейс такой странный появляется, что он потом тоже покрывался специальным, не знаю, каким-то отдельным тестом, который бы отдельно галочку показывал. И да, это будет занимать кучу времени, чтобы прогнать, но зато будет понятно на каких-то платформах стабильно. Валера, а вот что ты думаешь по поводу сложных, ну то есть проверки корректности сложных тестов? То есть сложные тесты, вот как ты сказал, компрехенсив, которые будут все кейсы проверять и генерить там рандомные данные, это они сами по себе будут являться довольно сложными программами. И более того, они не просто сложные программы, так они еще как-то описывают спецификацию поведения системы. То есть кто будет... Ну то есть как следить за корректностью этих тестов? Как писать тесты для них? Ну смотри, как я это себе представляю, пока я не случусь в Postgres. У нас главная цель — это поймать всякие креши, поймать всякие корапты на диске и зависание. Мне кажется, это треть или даже половина багов, которые перечислены вот в этом списке. То есть соответственно, нам не нужна прям сильно точная модель, так как нам база отвечает. Нам действительно нужна модель какого-то SQL языка, который понимает Postgres, но она у нас уже есть, это SQL описано грамматикой. В принципе, написать что-то, что может генерировать текст по грамматике, это я думаю, Смит тоже делает. Да, этот код нужно будет отдельно протестировать, что он не генерирует в алибный SQL. Но это можно протестировать где-то вообще отдельно. Дальше, возможно, если мы даже хотим моделировать Postgres, мы можем это, наверное, представить, как из этого SQL каким-то образом получать или даже первично делать какое-то алгебрическое выражение на языке религиозной алгебры, хотя это резко сужает количество тестов, которые мы можем реально гонять, потому что очень многие фичи Postgres от религиозной алгебры могут не ложиться. Но неважно, какую-то формальную модель того, что мы хотим получить, мы ее отдельно строим, отдельно тестируем. Тут, конечно, всегда встает вопрос, как тестировать то, что эту модель выполняет, кроме Postgres. Если у нас такая сущность есть, которая должна предсказывать ответ Postgres, тогда все становится сильно сложнее. Да-да-да, именно об этом. Но, короче, смотри, мой пойнт в том, что она может быть или очень простой, она предсказывает количество строк или что-то такое, или даже просто, не знаю, говорить, например, не к самому ответу, не знаю, это стриминговый ответ, там должен быть, это фурсор или что это. То есть она может какие-то очень базовые свойства говорить про ответ, который ожидается, и не отчекать сам реальный ответ, потому что вот здесь я, конечно, не могу так сейчас пройтись по всем пунктам, вот прямо сейчас, и точно с уверенностью сказать, что там нет ничего, типа возвращает некорректные данные. Но, мне кажется, такое рода вещи замещаются гораздо проще и гораздо при помощи гораздо более простых способов, как раз типа вот этих вот заранее закожных. А то, что нас здесь волнует, это падение, коррапты, это все. И для этого не то, чтобы прямо очень нужно точно предсказывать, что база ответит. Вот почему я за всякие такие фазы, подходы. Потому что, на самом деле, нам нужно предсказуемо генерировать какое-то множество запросов и предсказуемо обходить, в отличие от полнейшего файзера. С другой стороны, нам не очень важно, как ты уже сказал, знать, что именно база ответит. Нам важно, чтобы она не упала, не повисла, не покорраптилась. Ну, это странно, конечно. А функциональность проверять? Еще раз, функциональность, уже есть вещи, которые уже проверяют функциональность. Нет, они проверяют базовую. Ну, то есть, представь, у тебя есть 10 опций, которые могут быть в состоянии 1 и в состоянии 2. Ну, то есть, 2 состояния. У тебя получается автоматически 2 в 10 возможных состояний базы, при которых она должна вести себя по-разному. А таких опций не 10, и не 100, и не 1000. То есть, получается, у тебя куча бывает состояний, именно системы, при которых она может вести себя по-другому. У тебя чаще всего покрываются тестами базовые юзкейсы. Там 5 самых часто используемых переличателей в состоянии on и off. Ну, я утрированно говорю, но там чаще всего не по 2 состояния, а побольше. И получается, что у тебя все вот эти базовые вещи, они покрыты функциональными тестами. Все остальные, допустим, проверяются какими-то фазерами или так далее, но там ты не проверяешь тогда функциональность. То есть, мне это тоже больно, потому что у нас с проектом, с компилятором, там ровно то же самое. У нас из-за этого очень сильно росла большая тестовая база. То есть, мы это обходили тем, что мы создавали огромное регрессионное тестирование. Полное регрессионное тестирование работало больше недели. То есть, ты хочешь выпустить следующую версию, ты запускаешь на кластере из скольки машин, из 20, из 50, тест, который работает больше недели, для того, чтобы покрыть все старые известные случаи, что они не сломались. И оно постоянно нарастает, постоянно нарастает, постоянно находятся новые ошибки, что вот при таком сочетании опций у тебя оно работает совершенно не так, как мы хотели. Это боль. И я не знаю ее правильного решения. То есть, падение компилятора или падение базы – это совершенно не тест. Это тест, знаешь, как это, северить и ноль. Но 1, 2 и 3 уровня никто не отменял тоже. Я согласен с Ивани, что решение, оно вряд ли именно там, типа, давайте больше тестов и гоняйте их дольше. То есть, это не бесполезный вектор, он тоже полезный, и более того, так уже делают. Но я немного про другое. Что мне кажется, здесь проблема где-то в смысле нарушения принципа keep it simple и подобного. Плюс один, да. То есть, нельзя просто так взять, 20 лет писать систему, а пишет ее не один программист, то есть, типа, это 100 человека лет, 200 человека лет кода. Написать туда транзакционный движок с таким-то SQL, с другим SQL, там, оконные функции, неоконные функции, транзакционность, не транзакционность, с партицированием, с двумя видами репликации, с его там и так далее. Идем по фичам, их там очень много. И надеются, что оно просто будет вместе во всех сочетаниях, со всеми параметрами на всем железе просто хорошо работать. Мне кажется, проблема она вот где-то в случае, давайте не делать таких сложных вещей для начала. То есть, давай откажемся от Postgres? От него уже не откажешься, но я сейчас даже не про Postgres. Вот, допустим, мы делаем новый проект, как нам в нем не попасть в такую ситуацию? В эту же ситуацию. Ну да, распиливать на микросервис или типа того? Я что-то не уверен, потому что ты знаешь, что ты распиливаешь на микросервисы, у тебя создается такая иллюзия, что у тебя есть иллюзия контроля, у тебя каждый один микросервис работает. Но потом у тебя глобально на всю систему получается та же самая проблема, ты не знаешь, какая своя система, за каком работает. Я для примера сказал, я для примера сказал, ну, хорошо, я по-другому скажу, давайте сделаем Monolith, но не будем в нем делать настолько сложных вещей и в таком сочетании. А завтра к тебе приходит клиент и говорит, что ну, чувак, делай. И потом к тебе приходит такой бизнес и говорит, слушай, чувак, делай. Ну, то есть это не конструктивное решение. Наверное, понимаешь, если у тебя такой бизнес, что ему одному нужно одновременно вот именно сочетание там два вида репликации с партицированием многоуровневым, с четырьмя уровнями изоляции и вот со всем этим, вот одному бизнесу все одновременно, ну, возможно, тебе лучше выходить из бизнеса такого. Ну, то есть я говорю про то, что вот большинству пользователей им вот это все вместе взятое одновременно нафиг не нужно, им нужна простенькая репликация на одну реплику и крут с snapshot изоляцион, словно говоря, все. Нет, а почему, Валер, ты считаешь, что разделение на уровне абстракции не работает? То есть, на мой взгляд, это как раз очень хороший способ решения проблем. Подожди, я про разделение на уровне абстракции ничего не говорил. Микросервис в данном случае это тоже разделение на уровне абстракции, просто вид сбоку. Ну, то есть, к примеру, если ты делаешь пять микросервисов, ну, в рамках позрискей, это, конечно, сложно придумать, но допустим, которые четко выполняют свою функцию. Слушай, в случае позрискей, все как раз очень даже придумывается. Там можно отдельно вынести транзакционный менеджер, отдельно вынести, наверное, движок сиквеля, отдельно вынести дисковую подсистему. Мы про модули больше говорим, не микросервис, а модули, получается. Да, получается про модули. Это более действенно, если не какие-то одноранговые сущности, а это вещи, из которых все больше и больше собирается, как из конструктора, да, там это может сработать. Это, наверное, я даже бы согласился, что это такая проблема, которая у позриса есть, потому что мы посмотрим на, не знаю, вот текущие, вот мы в прошлом выпуске много про это говорили, про текущие существующие бигдатные системы. Посмотрите, как они собираются, их никто не пишет с нуля почти, кроме, не знаю, единственного исключения этого кликхауса. И даже кликхаус, он полагается на зубки, например, он не полностью все изобретает. Они все собираются из каких-то более мелких кусочков, которые уже написаны, не знаю, там типичная система собирается, HDFS, ZooKeeper, Kavki, Parketta, еще чего-нибудь. И там какой-нибудь Apache Drill или там какой-нибудь SparkSQL, они будут для запросов и так далее. То есть это все такие отдельные компоненты, которые отдельно писались, тестировались, и они все потом собираются и на это навешивают какое-нибудь прикольное имя. Или там может быть какой-нибудь один компонент, который их не устраивает, они берут сами и пишут, какая-нибудь система. И это в принципе так или иначе работает. Для этих бигдатных систем, но у них есть другая системная проблема, они все очень дико сложно собираются и поднимаются, потому что они все... То есть в случае с POSVIS плачут разработчики и те, кто пытаются эту сложную систему менеджировать, разработку сложной системы. А здесь получается, что мы берем компоненты, которые, допустим, они как-то протестированы, допустим, мы даже как-то протестировали, что они у нас вместе работают. Учитывая, что они имеют некоторые контракты, от которых мы от них ожидаем, скорее всего, она действительно работает. Но потом мы вот всю эту гору Apache штук даем админу, админ на это смотрит и говорит, да ты что, долбанулся, убери от меня это. Ну то есть там сложность получается. Ну не админу, не важно, я про другое. Не, если бы я был компанией, которая делает вот такую штуку, я бы говорил, ребята, мы готовим версию номер один, которая работает на закипере, и в всех остальных компонентах таких-то версий, вот вам скрипт, который однозначно заработает. А лучше еще докеры выпускаете. На самом деле, что я имел ввиду, что не потому что админ злой, а потому что ты это в продакшене за большим количеством сложно взаимодействующих компонентов, то есть почти никто совсем в кишочке поздрейца, особенно прямо сейчас работающего, особо не лазит, мне кажется, кроме его разработчиков. А здесь тебе так или иначе приходится вот в эту штуку, работающую на многих машинах, как-то там с каким-то сложным взаимодействием, не знаю, между дисковой подсистемой, движком запросов, еще какой-нибудь фигней, в это приходится практически лазить, потому что она может развалиться. В смысле развалиться? Ну, если у тебя хорошо протестированная система, она не будет разваливаться. Это все отдельные компоненты, они все отдельно версионируются, я понимаю твой аргумент, что давайте завернем в докер. Но не обязательно в докер, а в какой-то пакетный менеджер. Накатим это аккуратненько, единообразно, да, оно так даже должно работать, в принципе оно куда-то туда идет, я думаю, что вся эта контейнерная фигня появилась не в последнюю очередь, потому что вот этим ребятам с такими системами нужно было это как-то разворачивать и не сойти с ума. Но я все еще чувствую, что там есть вот эта сложность, она там все еще есть, ее просто перекладывают с одного места в другое, вот про что я говорю. Ну, то есть мы соглашаемся, что правильная модульность с хорошими четко обозначенными интерфейсами, которые протестированы на всех возможных входящих, о, вот и кукушка, на всех возможных входящих параметрах, то это как раз поможет решить проблему тестирования.",
    "result": {
      "error": "API request failed: Error code: 400 - {'error': 'Trying to keep the first 8882 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': 'Trying to keep the first 8882 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}\n"
    }
  }
]
[
  {
    "segment_id": "903ab6e9-425e-4d0a-b63a-383cec9c3c67",
    "episode_id": "42ae9a78-2d45-40f2-b976-2a170f7d34c7",
    "episode_number": 407,
    "segment_number": 12,
    "text": "Поэтому всё сделано просто и понятно. Да почему? Ну вот как-то не получается, а как ты реализуешь? Ну в смысле, я никогда не реализовывал логфри, префиксные деревья. Мне интересно, в чём там принципиальный затык. Я не знаю, я тоже не реализовывал. Я за что купил, за то и продаю. Но мне кажется, что если сесть и подумать, то наверное какой-то алгоритм ты сможешь придумать, вот как с BW придумали, такой вопрос будет ли он чем-то выгоден в плане производительности. Не знаю, это хороший вопрос, ты большой молодец, что задал вопрос, что надо. Саша, а зачем ты меня троллишь? Я тебя не троллю, я правда считаю, что это хороший вопрос, просто у меня нет ответа на него. А ты считаешь, что у меня должны быть все ответы? Конечно. Ты же посмотрел, как это, я забыл название курса, извини, всё. У меня вообще никаких ответов нет, я просто, я ребёнок даун. Advanced Database Systems. Да. Этот докладчик в рамках этого доклада не говорит, почему префиксное дерево плохо ложатся на лог-фри. Я думаю, это хороший вопрос и предлагаю нашим слушателям над ним подумать, я тоже над ним подумаю, если какая-то блестящая мысль мне придёт, то в будущих DevZon'ах поделюсь. Я также, наверное, подумал, что я херню сказал, я просто глупенький, я ничего не хочу сказать про людей с синдромом дауна, это было неправильно с моей стороны. Ну вот, а возвращаясь к нашим деревьям, приводится бенчмарки, по бенчмаркам получается, что МАС-3 как будто бы не сильно лучше B плюс деревьев, то есть иногда лучше, сейчас я графических открою, то есть если вы занимаетесь только вставкой, то есть напомню, почему нас вообще всё это интересует, потому что мы интересуемся in-memory индексами, и вот если вы делаете только вставку, тогда вроде как у вас МАС-3 будет сильно быстрее B плюс деревьев, но на чтение они примерно одинаковые, на чтение запись B плюс деревьев получается побыстрее. BW деревья сливают по этим бенчмаркам, мы это уже обсуждали, ART всех дерёт, но у него есть большой недостаток, то есть он очень быстрый на только вставку, он очень быстрый на чтение, он очень быстрый на чтение запись, но будучи префиксным деревом, он плохо делает сканирование по диапазонам, то бишь. И получается, что если вы хотите более-менее универсальную структуру, которая хорошо работает на большинстве нагрузок, то ничего лучше B деревьев так и не придумали. С другой стороны, если вы знаете, что у вас нет сканов по индексу, по какой-то причине вы пишете такой индекс, что в него можно только вставлять, удалять и искать по точному значению, тогда точно нужно брать ART, и он очень-очень быстро работает. Вот такой вот доклад. Это всё по этой теме, вопросы, возражения, комментарии. Чем дальше мы идём по этому курсу, тем больше я понимаю, что это курс про не базы данных, а оптимальность построения индексов, причём база данных – это индексы, это понятно, плюс данные. А в данном случае мы погружаемся больше в реализацию каких-то маленьких деталей, каких-то отдельных взятых индексов. У тебя не складывается такое впечатление? Ну, действительно много внимания уделено индексам, но я смотрю вперёд по курсу, нас ждут сжатия данных, нас ждут протоколы рекавери, нас ждёт исполнение запросов, в том числе компиляция, генерация кода, векторизация, оптимизация запросов аж в четырёх частях. И ещё одна лекция про Hardwire. Так что действительно, мы немного поговорили про индексы, о чём мы поговорили, у нас было только два доклада про индексы, а до этого было на ВССР. Ну, я соглашусь, что воспринимать алгоритмы и структуры данных чисто на слух трудновато. К сожалению, слайды в подкасте не покажешь, но то, что ты сказал, что дальше по курсу, это звучит интересно, так что продолжаем. Да, спасибо большое. Я предлагаю, Валер, тебе передать слово с CRDT и, наверное, в целом покрыть парочку коротких тем. Давайте поприветствуем Свету сначала. Света, привет! Привет, привет, привет! Привет, привет, как меня слышно? Отлично слышно. Ура, ура. Интересно, я опоздала на полтора часа, либо на час? На полтора. На полтора. Ну, почти, без двух минут. Вот главная Света пропустила как бы все темы не про базы данных и пришла на тему про базы данных. Ты не любишь базы данных. Ты просто в глубине души продолжаешь их очень любить. Я маскируюсь под менеджером, на самом деле, да. На самом деле, это не совсем правда, я припас специально тему не про базы данных и вообще не совсем про программирование, поэтому как это, bear with me. На короткую тему. Я же вам взяла хит-зап, вы же тоже специально так подстроили. Кстати, нет, я тему оставлял специально, что ты пока не придешь, а вот тему про базы данных они не специально здесь оказались. Я думал, мы их обсудим, к тому времени, когда ты придешь. Валера, тебе слово про CRDT. Коротко. Ну, и даже не то, что про CRDT, в общем, есть такая компания SuperBase, они делают, если прям совсем их короткий письмец, я его правильно помню, это Firebase поверх Postgres. Вот, у них тут была неделя запуска всяких штук. Меня заинтересовали две вещи. Одно прям совсем экспериментально, они еще сами его нигде в продакшене не используют, расширение для Postgres. А второе, я так понимаю, оно пока довольно экспериментально, но они планируют его катить прям в свой продакшен. Первое – это CRDT поверх Postgres. Вот, то есть прям в Postgres-овое расширение заимплементированные CRDT. Что такое CRDT, мы много раз обсуждали в этом подкасте, я не хочу сейчас даваться подробностей. Такой тип данных, который можно подмерживать. Вот Саша тут выше по тексту говорил про мастер-мастер репликацию. Если вы в вашем триггере на Resolve конфликта напишите, будете использовать такой CRDT, вы сможете, например, в мастер-мастер репликации просто автоматически разрешать конфликты, используя логику вот этих вот типовых данных, которые переживают мерч без конфликтов. Вот. Я с ним сам не игрался и, скорее всего, у меня нет сейчас задач, где бы я с ним поигрался. Второе – это в Postgres есть такой механизм foreign data wrappers, позволяет вам ходить, как бы позволяет вам другие системы, например, другой Postgres или что-то вообще, что не является Postgres, например, не знаю, parquet файл или CSV файл представить как таблицу в Postgres. Тут даже не столько расширение, сколько фреймворк. Я рассказывал про PGX, это такой фреймворк на REST для того, чтобы писать расширения, но PGX никак не оборачивает интерфейс для foreign data wrappers, супабейс поверх PGX. Сделали фреймворк, который оборачивает этот интерфейс и позволяет вам писать foreign data wrappers с достаточно маленькой кровью, ну или во всяком случае не заниматься обертыванием C-шного интерфейса вместо того, чтобы писать в VW, в wrapper на REST. Почему вы можете это хотеть? Потому что в REST довольно хороший набор библиотек для того, чтобы ходить во всякие внешние штуки. И вот прямо сейчас у меня нету задачи на работе, но у меня прям руки чешутся поиграться с этой штукой, в смысле с foreign data wrappers на REST. И как это? PGX в моей работе использую, поэтому есть шанс, что у меня дотянутся руки, но не знаю. Как обычно ничего не обещаю, но звучит здорово. Вот, это был краткий обзор интересных штук. Я все. Саша, давай твою короткую тему. Да, у меня короткая тема про Snowflake. Слышали кто-нибудь про такую систему? Snowflake. Даже не знаю. Звучит знакомо, но как-то не слышали, нет. Это гостевая лекция из Injured to Database Systems этого года, 2022-го. Мы раньше разбирали записи из 2021-го, и тогда была гостевая лекция, по-моему, в прошлом или позапрошлом Докзине мы ее обсуждали. Про что она была? Про Google BigQuery. Был Валера, значит, в позапрошлом. А в этом году гостевая лекция от Snowflake. И, честно говоря, лекция, она такая... Мне она показалась немножко скучноватой. Сейчас поймете, почему. То есть, говорится, что вот у нас есть Storage Layer, у нас есть Compute Layer. У нас есть свой формат хранения данных, мы их называем микропартицией. В целом идея в том, что они нарезают данные в иммутабельные колонки, примерно по 10 МБ. Там есть указатели, там есть заголовки. Глядя на заголовок, ты можешь понять какие-то агрегаты из этой микропартиции. Ну, там, min, max, такие вот вещи. В целом ничего такого, чего бы мы не обсуждали в этом подкасте. Дальше говорится, ну, у нас есть оптимизатор запросов, и он cost-based, и у него есть статистика. И вообще этот же докладчик говорит, что вообще вот всё, что вы в рамках курса Intel to Database System обсуждаете, это всё релевантно, всё актуально. Пожалуйста, не надо переписывать учебники, базы данных, они именно так и работают. Ну, в смысле, да, мы немножечко в облаках, немножко по-другому данные сложили, но это как раз особой сложности не представляет, а вот оптимизатор, планировщик и вот это вот всё, оно работает так же, как раньше, и это всё ещё большая и сложная проблема. Вот, дальше говорится, что Snowflake может в векторизацию синт и, соответственно, в компиляцию забросов. Потом они говорят, ну, мы можем посмотреть на селект, понять, какие колонки хочет пользователь, и в зависимости от его желания достать только нужные колонки, потому что у нас колоночный storage. Вот так вот. А ещё у нас snapshot isolation и MVCC, ну, потому что это был резонный выбор, учитывая, что у нас колонки мутабельные хранятся. Вот, а ещё поскольку колонки мутабельные, то мы можем в time travel, это у нас прямо фича в Snowflake. Дальше говорится, что ещё мы можем в distributed hash join с consistent hashing, а при том, когда мы исполняем вот этот distributed hash join, мы можем понять, что у нас между worker и data skew, то есть на один worker прилетает больше, чем на другую, и прямо в процессе исполнения мы можем это митигировать. Ещё мы используем в Snowflake фильтры bloom, используем локальные кэши, чтобы постоянно в облако не ходить за колонками. Вот, но они мутабельные, поэтому их можно спокойно кэшировать и знаем, что они не поменяются. Вот, а ещё мы используем FoundationDB для метаданных. В FoundationDB у нас пользователи, роли, схемы, в общем, вся метаинформация. FoundationDB – это k-value с ACID, кислотный k-value. Вот, в целом и весь пересказ лекции, то есть мы делали нормально, у нас получилось нормально, какое-то такое содержание. Вопросы, возражения, комментарии? Валера, отменяем переписывание всех учебников? Отменяем, отменяем. А что нельзя отменить, это следующая тема, которую Валера бережно берег. Да, она не про базы данных, а вообще почти не про программирование. В общем, мне интересно со всеми присутствующими обсудить. Я тут рефлексировал немножко над прошедшим годом и понял такую вещь. Я уже не на первой работе, а ловлю себя на таком баге мышления. Искренне считаю, просто прям аж горит, считаю, что вот эта очень важная штука, ее нужно сделать. На прошлой работе мы это или не сделали, там не знаю, и все взорвалось, или мы эту штуку решали и решили ее вот так. Я очень активно участвую в обсуждении этой штуки. В итоге такие все, Валер, кажется, ты имеешь большой опыт с этой штукой, давай ты ее сделаешь. Я такой, ну ок, ну да, правда, разумно, давайте так и сделаем. Потом приходит время ее делать, я понимаю одну из двух вещей. Или я это делаю уже реально в десятый раз, и мне уже просто скучно в десятый раз это делать, мне прям очень тяжело приходится себя заставлять это делать, я страдаю. Или другой вариант, я даже начинаю, засучиваю рукава, мне интересно, и потом постепенно утрачиваю интерес, и как бы, а что делать? Как вы с таким справляетесь? Потому что это правда какой-то баг мышления. То есть что-то, что казалось невероятно важным, и типа самым важным, что можно сделать в данный момент, вдруг становится чем-то, что ты такой, блин, берите это от меня, не могу больше на это смотреть. Мне кажется, это что-то, что, прости, если это прозвучит немножко снисходительно, я просто не знаю, как это по-другому сформулировать. Что-то, что приходит с опытом, потому что я имел схожее природу бага мышления, когда вот ты видишь какую-то проблему, и ты такой, блин, это же такая проблема, ее точно надо решить. Но когда ты вот… Не-не, в смысле, я не то чтобы пушу всех решать проблему, а допустим, я уже и так решил, что это проблема. Я понял сценарий. Я понял сценарий, у меня немножко другой был баг мышления, но в чём-то схожий, что вот ты что-то видишь, что этим надо заняться, и часто это бывает даже не техническая проблема, а может быть у нас какой-то баг в процессах, а давайте это как-нибудь соберёмся, обсудим, ну какой-то такой сценарий. И ты, если вот на секундочку вздохнуть, подумать и вспомнить, как это проходило раньше, ты такой ловишься на мысли, блин, а я точно вот тот человек, кому это больше всех надо? Вот, а может быть просто забить и… Честно говоря, вот в последнее время мне удаётся просто забить, потому что я понимаю, что это… Я не тот человек, кто должен бросаться решать эти проблемы. Это не совсем тот сценарий, который ты, Валер, описываешь, но в чём-то схожий. И может быть, если формулировать… Если вот к тем сценариям, которые ты описываешь, подойти немножко иначе, то есть, например, собрать команду и сказать, ребята, вот я не знаю вообще, как это решать. Как вы думаете, как мы могли бы это решить и дать команде возможность высказать свои мысли, может быть, появилось бы какое-то альтернативное решение, в котором ты даже не специалист? Мне нравится вариант, хороший вариант. У меня есть вариант, который наполовину наброс, наполовину серьёзный. Твоё решение – надо стать техледом. Тогда твоя работа будет определять, что надо делать, но большую часть из того, что ты определяешь, как надо делать, ты всё равно делать не будешь, потому что ты всё сам не сделаешь. В этом и суть техледа. Это интересный вариант, но я не техлед, и я не думаю, что я им стану завтра. Глобально я догадываюсь, что можно так решить эту проблему, но это не краткосрочное решение проблемы. Глобально, то есть, понятное дело, что это не вполне практичный ответ, но есть форма этой проблемы, с которой я сталкиваюсь, и, возможно, есть похожие решения. Смотри, я работаю в команде Reliability Engineering, и у нас есть партнёрская команда продуктовых разработчиков, и часто возникает такой паттерн, знаешь, вот они написали новую систему, теперь надо её, значит, сделать готовой для продакшена. Это значит, что надо её инструментировать мониторингом, написать алерты, запилить дашборды, вот это всё. Кто это делает? Конечно, это конкретное сырье, потому что они же знают, как всё это делать, они же самые эффективные в этом деле, они постоянно этим пользуются. Ну да, это ближе к моей проблеме, чем ты думаешь. Вот, и, соответственно, довольно долгое время наша команда попадала вот в эту ловушку, что типа, о, принесли очередной продукт, и, короче, понеслось, там опять облепляем его мониторингом, и это уже все масточертело, и приходится там…",
    "result": {
      "error": "API request failed: Error code: 400 - {'error': 'Trying to keep the first 4283 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': 'Trying to keep the first 4283 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}\n"
    }
  }
]
[
  {
    "segment_id": "af715e58-60bc-4160-8bd1-a6b8fb81a6c2",
    "episode_id": "57a1d4c2-88cc-46ac-be9e-6282aceed41a",
    "episode_number": 229,
    "segment_number": 5,
    "text": "Или там, не знаю, посреди транзакции сходили в другую систему, что-то с ней сделали, и на основе того, что они сделали с внешней системой, там докатили что-то в текущей транзакции. Такое на практике встречается сплошь и рядом. То есть казалось бы, это, конечно, клево, избавиться от каких-то таких взрывающихся сайд-эффектов, и клево все сериализовать отдельно от клиента, и все классно склеилабл, вот только на практике я такого видел, к сожалению, мало. Вот, какие-то такие мои 5 копеек, я не буду пытаться пересчитать, в чем собственно суть того, что он предлагает, потому что, если честно, я уже не помню, я читал 2 недели назад. Можно я тогда добавлю? Давай, давай. Во-первых, он разделяет на 2 класса проблем, которые могут привести к откату транзакции. Первое – это откат транзакции из-за того, что так написан код транзакции. И вот здесь он как раз сводит к тому, что надо как-то менять, не меняя семантику, менять графы исполнения фактически. То есть на каждую отдельную шарду, когда ты посылаешь заявку на какую-то команду, это должна быть уже хитро измененная логика, чтобы у тебя аборта на данной шарде не было, потому что данные так сгруппированы. И давайте я пример приведу, потому что без примера очень сложно привести. То есть он говорит, давайте в одной транзакции мы будем присваивать x равняется 42, в одной и той же транзакции мы будем присваивать x равняется 42, и будем вычитать из y единичку и присваивать это число z. То есть z равняется y минус 1 и y равняется y минус 1, но в случае если y меньше 0 в результате, то мы будем откатывать транзакцию. И он говорит, давайте теперь посмотрим, к примеру, на одной шарде у нас там находится, на одной ноде у нас там находится x, а на другой ноде y и z хранится. И тогда получается, что на ноде x у нас будет следующая вещь, что x равняется 42 только в случае, если y больше, чем 0 на другой шарде. И поэтому он говорит, получается, что наш код для этой транзакции можно поменять следующим образом, что мы посылаем на ноду, где хранится x, код следующего содержания. Прочитай, пожалуйста, значение y на соседней ноде, и если он больше 0, то тогда присвой 42 текущему x. И получается, он говорит, посмотрите на код, видите, у нас нет аборта в данной ситуации, а на второй ноде у нас, соответственно, точно так же аборт исчезает, потому что если y больше 0, то тогда y минус равняется единичке, и z равняется y. О, смотрите, волшебным образом аборт опять же исчез. И получается, хитрая манипуляция рук, без изменения семантики, мы поменяли полностью всю проблему, убрали фактически, потому что мы внезапно убрали аборт. Но меня это вообще взрывает мозг. То есть мы не убрали аборт, мы закопали аборт в глубины логики. На самом деле, ты знаешь, это не то, что мы закопали, мы пришли, я плохо попытался это объяснить, что мы переписываем логику так, но конкретно этот шаг делается довольно автоматизированно, у нас же SQL, поэтому он декларативный, а вот по этому императивному ловшу можно по-разному сгенерировать. Вместо того, чтобы давать шагу, возможность сказать, ой, я не шмок, просто все засунем в большой иф, или в нужное количество больших иф, которые всегда по какой-то из веток доходят до конца, просто какие-то ветки, это наша логика, которая получается при аборте, другие ветки, это наша логика, которая получается при все хорошо. То есть мы в транзакцию сразу включаем и rollback, и все нормально, ветку, поэтому говорим, что у нас нет отдельно какого-то аборта rollback, просто у нас как бы сразу все, что может произойти, зашито в транзакцию, и ее отправляем. Но это же закапывание аборта. Это не закапывание аборта. Да подожди, давай я поясню свою мысль. Смотри, вот у нас есть транзакция, происходящая на шарде икс, возьмем тот же самый пример. В ней написано, прочитай, пожалуйста, состояние икс на соседней шарде. Что это значит? Это значит, что мы должны либо синхронно в момент выполнения транзакции сходить реально на соседнюю ноду, посмотреть, что там написано, прийти обратно и сказать, слушай, там икс в тот момент, когда я читал этот икс, он был единичка, что будем делать? Блин, для меня это настолько... На самом деле, по-моему, даже у подгруза есть фича такая, что можно взять и как бы такой типа snapshot, который с точки зрения snapshot isolation, мне нужно на такой-то момент, я не уверен, если это в подгрузе, но по-моему, там похожая фишка была, зафиксировать какое-то состояние базы. В МВЦ базах это делается легко, как правило, мы просто не удаляем что-то. И вот мы его держим, и все эти чтения будут происходить на момент какого-то среза времени. Это реализуемо, и в том же самом ККО, скорее всего. Ну то есть получается, мы приходим к МВЦ. Ну в смысле, просто считается, что МВЦ или похожие механизмы есть много где. Но здесь у нас МВЦ с распределенной базой данных, то есть мы приходим к eventual consistency. На самом деле нет. Как это? Ну в смысле, то есть у того же Google, тот же самый TrueTime, нужен для того, чтобы типа... Но здесь мы не говорим про TrueTime, давай не будем к этим InfiniBand, TrueTime и прочим исключениям добавляться. То есть он говорит general purpose базы данных. Если честно, я не помню, как он там вводит это в чтение. Ты все правильно говоришь, он делает MVCC. Ребята, у нас будет такая система. Это он не говорит в статье, это он говорит в комментах на Hacker News. Я пошел, прочитал все комменты на Hacker News. У него там какой-то помощник еще, они вдвоем разъясняют, как они примерно хотят. И насколько я понял из комментов, они хотят делать систему, когда, ну во-первых, одна из проблем, которые на Hacker News там указали, это представьте, что у вас есть транзакция, которая читает код всех других шардов. Ну, бывают такие большие базы данных, которые распределяются везде, и вам нужно данные всего прочитать. Получается, у нас будет квадратичная complexity, понимаешь, да? То есть ты на каждой ноде должен сходить на каждую другую ноду. Вот. И они говорят, как вы решаете это? Они говорят, ну, вообще, вы совершенно правы, у нас тут есть с этим сложности. Мы собираемся это решать, как это называется, в общем, когда каждая нода посылает в каждый момент времени свое правильное состояние на все остальные ноды. А на всех остальных нодах у нас будет какая-то Q, которая будет потреблять и, соответственно, рассовывать. И потом у нас есть еще garbage collector, который должен поверх всего этого работать. И я в конце концов понимаю, что, в принципе, уход от двухфазного коммита привел к такому большому нагромождению уровней абстракции, что мне даже представить это сложно. Ну вот да, и на самом деле, даже до тех тем, где ты сейчас полез, у меня гораздо более приземленная проблема против этого, ну, то есть используя вот эти интерфейсы с новыми гарантиями, гораздо труднее писать реальный практический код. То есть зачастую у тебя есть еще какой-то клиент с какой-то логикой, который что-то еще делает, и ему просто реально может быть нужен аборт. Ему нельзя просто забрать вот эту возможность в любой момент сказать, что-то какое-то говно случилось. Или там, не знаю, это транзакции, которые не должны вызывать недетерминированные функции. Блин, да есть код, который в транзакции вызывает недетерминированные функции, так бывает нужно, возьми. Ну и так далее. То есть это просто непрактично. Вот для этого он как раз вводит второй тип абортов, это как это, system.induced.abort, когда система вводит эти аборты, и у него там какое-то сложное махание руками, я вот этого вообще концепции не понимаю. Если я его правильно понимаю, он говорит, что system.induced.abort быть не должно. А при этом у него есть два типа system.induced.abort, и один из них он умеет удалять, а второй он не умеет удалять, и он говорит, надо поменьше иметь вот этих первого типа, которые мы не умеем удалять. Ну, как бы надо бы... Ну, а вред теперь. Надо бы поменьше иметь, бы неплохо было бы, а давайте напишем все-таки real-time базу данных, которая будет как-то работать с транзакциями на нескольких шардах. Ну, давайте так, надо немножко похвалить, это хорошая идея для тех, кому реально нужно много шардов, но довольно ограниченные по типу транзакции. То есть, это знаешь, это нужно, наверное, обойти просто такой любителем, давайте придумаем универсальную замену, на самом деле рассматривать такой... На самом деле это хорошо работает на узком частном случае. Ну это же все равно eventual consistency. Нет, нет, нет, это можно сделать хорошо, консистентно, клево. На... как его, на true-time. Ну на true-time, true-time тебе не нужны для этого GPS-клокки, если ты помнишь. GPS-клокки просто интервалы эти true-time-овые делают как бы более tight, как-то, ну, тесные, маленькие, узкие. А у тебя true-time как протокол будет работать на любом железе. Но там просто мы приходим к тому, что... Эвенчуальность этой консистенции становится довольно большой. В смысле, нет, при чем здесь вообще? Ну я к тому, что... не, не, подожди. Вот эти вот window, которые, как мы, true-time-window, которые там были. .. Uncertainty. Да, да, да, да. Они на... Смотри, true-time сам по себе, он вообще не говорит, он вообще не имеет консистентности, не имеет никакого отношения к true-time. Это такая штука, которая тебе позволяет потом, если у тебя есть такой API для времени, она тебе позволяет транзакции так сериализовывать, что они у тебя гарантированно не будут пересекаться. И она тебе позволяет сказать, я хочу snapshot на такой-то момент времени, и поскольку если ты транзакции сериализуешь при помощи true-time, так что точно не пересекались, это же тебе дает возможность делать snapshot просто по timestamp. И кроме true-time, там у того же... Нет, подожди, подожди. Есть другой подход, там после этого уже true-time, был более поздний ресерч, логические гибридные часы. То есть возможность делать консистентные snapshot в распиленной базе, она есть. Если у нас есть МВЦ. То есть это не какая-то магическая суперсила, которая работает только с сатанными часами. Это реально можно делать на обычном железе. Нет, нет, я, возможно, плохо помню, но насколько я помню, как бы здесь у меня в голове не пересекаются две идеи. Первая – это то, что вот этот true-time, и второе, какие логические часы, я забыл, как они называются. Гибридные логические часы. Да, да. Они при отсутствии правильных атомных часов, они приводят к тому, что у тебя окно становится слишком широким и долго идут транзакции. Что-то типа такого, что у тебя latency увеличивается. У true-time, да, у LHC в меньшей степени, потому что, ну, то есть там они немножко по-разному себя ведут в этих случаях. Ну и опять же, там можно, наверное, даже... Мне сейчас тяжело вот так вот на слух, в HandWave без правильного распределения. Да, да. Просто как бы идея всей этой статьи – это была следующая, ребята. Нам не нужно двухфазный commit, потому что он, во-первых, ненадежный, а во-вторых, он долгий. И так как бы вот с этой долгостью это один из ключевых... Ну смотри, он не просто долгий, он букирующий долгий. То есть там проблема в том, что у тебя во время двухфазного коммита, его классической как бы хорроризации, у тебя начинает накопиться backlog всякого говна, который не может выполниться, потому что... Или не может закоммититься до конца, потому что у тебя в это время еще висит заприпаренный какой-то... Конфликтующий... Ну даже не... Ну да, да, да. А вот этот его протокол, он довольно, как бы такой, локлесс, короче. И если у тебя реально есть какая-то система, то есть, не знаю, Dropbox, например, писали нетанную статью, как они там клево сделали систему, в которой для них работают двухфазный коммит. Вот это значит, что у тебя есть какая-то большая production система, где реально нужны cross-share транзакции, у тебя при этом ограниченный набор выразимости со стороны приложения, то есть тебе не нужно делать какие-то... Тебе не нужно рандомно падать, грубо говоря. Или там не нужно вызывать интерминированные функции, не нужно там... В общем, ты вылезаешь в эти ограничения. И тебе, например, устраивает, что транзакция, может быть, там полсекунды выполняется, ну да, так, с заметной latency. Но при этом тебе главное, чтобы эта транзакция, которая полсекунды выполняется, главное, чтобы другие полсекунды выполняющиеся транзакции, в общем, чтобы она минимально мешалась в системе. То есть, вот, как бы это хорошая штука, которая решает, в принципе, существующие проблемы, просто не так, как он вот пытается сказать, что это замена двухфазному коммиту. Нет, ну не так, совсем не так. Это прикольная идея, но вот, да, в ту сторону нужно двигаться, возможно, кому-то полезно. И плюс я хочу добавить, что вот наши с Валерой сейчас обсуждения, это в основном додумывание того, что в статье отсутствует. То есть вот эти вот прикручивания сюда MVCC, это в статье нет. Это есть только в комментах, и то в глубине где-то. Прикручивание сюда TrueTime, это вообще в нигде я этого не видел. То есть это чисто Валера сейчас предложила, мне кажется, это логично. То есть я к тому, что статья в целом, она дает слишком поверхностное описание того, как это, что надо сделать, и мне вот этим как раз она не понравилась. Это какая-то популистский... То есть хочешь делать по-нормальному, напиши пейпер, мы с удовольствием его почитаем и рассмотрим. А так получается какая-то популистская ерунда, двухфазный коммит не нужен, все приходите ко мне, а у меня деталей, кстати, нет. Знаешь, потом мне кажется, Абади, я за ним уже не первый раз замечаю набросы прям. У него есть статьи, честные статьи, то есть он когда хочет написать нормальную статью, он пишет статью. Но периодически он набрасывает. И для этого он использует блог. Я уже не первый раз за ним это вижу. Мне нечего добавить. Мне кажется, нормально обсудили, но надо перечитать мне и TrueTime, и вот эту вторую. Потому что у меня деталей я понял, что в голове не осталось. Хорошо, а следующая тема совершенно никак не связана с 2PC или чем-то таким, а также не проплачена. Хотел рассказать про сервис, наверное, по доставке еды, называется Level Kitchen. И таких сервисов на самом деле достаточно много. Которые, короче, это еда по подписке. То есть вы оплачиваете услугу, скажем, за месяц, и вам возят еду, в которой уже там посчитанные, ну предполагается, что посчитанные калории, забалансированные белки, жары, углеводы и всякое такое. И ты просто ешь только эту еду и питаешься таким образом правильно. Вот, я на этом сервисе уже около 2 месяцев, получается, наверное, чуть больше может быть. И всячески им доволен. То есть с одной стороны еда разнообразная и достаточно съедобная. Я, впрочем, не очень прихотлив в этом плане, но мне нравится, мне не приедается. Немного спадает вес постепенно, ну где-то по килограмму в месяц. И просто хотел порекомендовать, если вы чем-то таким пользуетесь. Вы, кстати, чем-то таким пользуетесь или пользовались? Может, есть какой-то опыт? Не таким, к сожалению. Это очень прикольная фича по подбору рациона. Мы используем сервис еды по подписке, называется HelloFresh. Но он скорее просто, что он решает проблему для того, что тебе не нужно придумывать рецепты, тебе не нужно ходить в магазин за очень клевыми продуктами. То есть он довольно хорошего качества продукты и плюс рецепты довольно разнообразные. То есть это как раз таки решает проблему того, чтобы не приедалось. И при этом не нужно тратить деньги на рестораны. Вот прям зожную часть. Это интересная сторона, которую я не знаю. В Берлине таких сервисов, наверное, есть, но я не знаю. Вроде бы Level Kitchen это франшиза, поэтому она должна быть много где. Я в Москве и у нас есть Level Kitchen Moscow, но я... Ну то есть это типа как KFC, только Level Kitchen. И кстати, Валер, если я не ошибаюсь, то чем ты питаешься, там надо готовить, не так ли? Да. В Level Kitchen тебя привозят готовое. Ты просто разогреваешь и ешь. А-а-а, вот как. Ну да, тогда совсем что-то другое. Вот такая информация. В общем, если вы интересуетесь здоровым питанием, ознакомьтесь. Темы и вопросы слушателей я, к сожалению, забыл открыть заранее. Первой темой, я надеюсь, я неправильно сортировал на секунду, похоже на правду, предлагает слушательница... Свет, как правильно? Слушательница. Слушательница Ксю Андрейчук предлагает нам новую статью на Forbes.com. Годовая... Давай расскажу, давай расскажу. Давай расскажи, я не понял, что происходит. А, собственно, в чем дело. Наша слушательница говорит о том, что на годовом ревью ее менеджер сказал, что она большая молодец, но ей нужно развивать лидерские качества, чтобы компании, больше людей ее знали. И, соответственно, было больше доверия к ее решениям. Поэтому стал такой вопрос. Каким образом интроверту развивать лидерство? И статья, она показывает некоторые способы для лидерства, но она более общая. Я не всегда вижу хорошо связь между работой инженера, а мы предполагаем, что девушка работает на инженерной роли. Каким образом для инженера и вообще для IT показать свое лидерство? И, в частности, особенно для интроверта. И мне кажется, это очень интересная тема, потому что буквально недавно тоже поднималось на работе про то, что промоушены зачастую как раз таки поощряют экстравертов больше, чем интровертов. А интровертов довольно много в компании, среди программистов. И каким образом сделать процесс таким, чтобы он был честным и справедливым для всех людей? И у нас в подкасте разгорелась такая большая дискуссия, кто такой интроверт, кто такой экстраверт.",
    "result": {
      "error": "API request failed: Error code: 400 - {'error': 'Trying to keep the first 4929 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': 'Trying to keep the first 4929 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}\n"
    }
  }
]
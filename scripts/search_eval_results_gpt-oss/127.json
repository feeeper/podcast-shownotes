[
  {
    "segment_id": "d88c419c-93a7-47c2-adda-0a86002d7c0a",
    "episode_id": "3056aedc-a54e-4580-8d6e-bfc214db0f2e",
    "episode_number": 127,
    "segment_number": 3,
    "text": "И это уже вполне себе рабочий формат. С ним вполне можно жить. Ну да, я... Я не знаю, имеешь ты какую-то точку зрения на это или нет, но вот у нас пока имеется маленький рынок, он еще не вырос, ему только предстоит вырасти, а у нас уже всякие чудесные производители, особенно вот Facebook, например, страстно уже сегментируют рынок, делают эксклюзивы только под Oculus, только в Oculus Store, и вообще на Oculus нельзя ничего, кроме того, что из Oculus Store. Какого черта? Ты спрашиваешь, ну почему они так закручивают рынок, пытаются? Ну уже да, почему они так рано это делают? Ну потому, ну тут рано, рано не сделаешь, потом не дадут. Я уверен, что это для того, чтобы сразу стать платформодержателем. То есть кто платформа, тот на коне. Платформа выигрывает в любом случае. И да, Oculus многие ругают сейчас за слишком такие строгие меры, но не забывайте, что Facebook, у Facebook-компании немаленькая. Им наверняка интересно либо быть платформой, либо вообще в этом не участвовать. Они пытаются стать как-нибудь платформой, и вот закручивают вот так, да, может быть это слишком агрессивные меры, но не нам уж их судить, они же Facebook. Они в целом действительно местами, ну с нашей точки зрения, с точки зрения разработчиков, нам кажется, что они типа очень злые ребята, потому что нас один раз, я помню, не пускали в Store, потому что у нас в билде, который мы заливали на Oculus Store, где-то там в файликах лежала, но не использовалась DLL, которая позволяла, которая просто от стима, ну то есть это DLL принадлежащая стиму, но она не использовалась у нас, мы просто, чтобы не делать отдельные совсем разные билд-процессы, сделали просто, что перебилдило все, а файлики не стали почищать, просто не подумали про это. Вот, они нас разругнули, сказали, ребята, мы посмотрели, у вас в файликах лежит DLL, она Steam называется, что-то как-то нам не нравится, давайте вы уберете, а потом перезальете еще раз. Ну, я думаю, что не стоит на них обижаться, потому что их на растущем рынке такое регулирование быстро станет понятно, имеет ли оно право быть или нет, то есть если у них сразу дела будут из-за этого сильно ухудшаться, ну, они быстро сделают выводы явно, они в это вбрасывают большие деньги, они держат руку на пульс. Меня же волнует не благосостояние компании Facebook, меня волнует как благосостояние VR, как направление, у меня вот есть такое опасение, что из-за такого поведения отдельных компаний у нас VR как технология может не взлететь, потому что если так немножко посмотреть в прошлое, году где-то начиная с 95-го и заканчивая в 2000-м, когда я еще ходил под стол практически, кругом был хайп VR'а, тоже тогдашнего поколения еще, вот с этими treadmill'ами, в которых можно было безумно огромными, в которых можно было ходить со странным VR'ом, который огромным кабелем толстым подключался к этому treadmill'у, я это видел только на картинках, но это выглядело очень впечатляюще и в кино тоже. И как бы оно тогда не взлетело. Уж не знаю по каким причинам, не взлетело. Сейчас как бы тоже есть риск, что оно не взлетит, и компании которые в этом которым выгодно, чтобы оно взлетело делают вещи, которые сегментируют рынок и чем сегментированнее рынок, тем труднее очевидно быть, потому что консюмер даже не знает, что покупать в итоге. У нас расклад сейчас очень похож на ну то есть с определенной горе абстракции, конечно, но расклад похож сейчас немножко на начало мобильных телефонов, смартфонов, в смысле не самых первых мобилок, а смартфонов. У нас есть компания, значит, которая закручивает гаечки, тогда это был Apple, сейчас у нас это Oculus. У нас есть компания, которая вся такая за супер открытость open source, тогда это была ранняя версия Android'а, сейчас это HTC с OpenVR'ом. У нас есть такие игроки рядышком, которые вроде как да, но мы как-то без крупного товарища за спиной. В VR'е это Open Source VR, это Razer, а в мобильных телефонах это были какие-нибудь там, не знаю, Symbian'ы, смартфоны или кто-нибудь такие. Ну, в общем, это на благо. У нас сразу три бизнес-модели обкатываются, кто-нибудь из них выживет, кто-то нет. Шансы не взлететь у индустрии от этого не падают, они наоборот вырастают. Вот если бы конкуренции не было, тогда была бы беда. Был бы только какой-нибудь OpenVR, и все бы такое было очень открытое и так далее, но вот обычно чисто на Open Source не взлетает. Надо, чтобы кто-нибудь крутил гайки, чтобы это все конкурировало, и тогда очень польза будет для всех, в первую очередь для кастомеров. А насчет того, что сейчас для пользователя непонятно что покупать, если... Меня вот когда друзья, там товарищи спрашивают, какой шлем купить, и так далее, если это вопрос для вас небольших денег, то есть если у вас там очень больших доходов, и вы можете сейчас в целом купить шлем и забыть про него, не расстроившись, то, ну, купите себе Vive или Sony PlayStation VR. А если у вас это такая хорошая для вас сделка, ну, там, это такие значительные для вас деньги, то лучше ничего не покупать их пока. Ну, не займете вы свой шлем. Достаточно сильно сейчас. Если у вас Samsung телефон вдруг последний, или там один из последних, купите Gear VR дешевый, поиграйте с ним, вам станет примерно понятно, как смотреть видео, как смотреть фотографии. И в общем, на этом пока остановитесь, а как будут следующие версии, как только беспроводные версии шлемов будут хорошие, так можете начинать убирать. Окей, мы тут много говорили про всякие не технические вещи, наверное, стоит немножко потыкать палочкой в технические вещи. У нас все-таки обычный технический подкаст. Ну, не знаю, мне было очень интересно. Мне тоже было очень интересно, но мне кажется, пора задать такой как это, сокроментальный вопрос. Чем сейчас рендерить в VR? Ну, то есть, я знаю, что там были вопросы с тем, что ну, то есть, как бы рендерить двуглазы дорого, и ты уже выше про это говорил, и вот начнем с того, что даже с простого вопроса, где сейчас, на каком движке сейчас лучшая поддержка VR? К сожалению, тут всегда надо сегментировать. Ну, теперь уже в 17-м году, уже должен ли до того, что нам надо посегментировать, прежде чем отвечать на этот вопрос. В общем, если вы про мобильный VR, то, наверное, все-таки пока имеет смысл оставаться на Unity и с Unity жить. Если вы PC VR, то, к сожалению, у нас возникло некоторое количество сложностей с этим, и мы... Это, собственно, был решающий аргумент после того, как мы очень долго сомневались, думали и так далее. У нас, очевидно, кода базы на Unity большой, опыт большой, и все процессы построены были. И мы, как только вот Unreal вышел, самая-самая, одна из первых версий, когда еще подписка платная у него была, мы его потыкали, посмотрели, попробовали наш опыт с третьего Unreal туда переложить, вот. И как-то вот мы на него так смотрели, все время выходили, мы скачивали, там, наши ноты читали, но все как-то не решались. Но вот PC VR все-таки нас добило, мы таки ушли на Unreal. А что там такого? Потому что управление рендером и скорость рендера в VR это невероятно... Ну, в общем, невозможно недооценить это. Это просто самая-самая большая проблема. Потому что у тебя самые первые версии VR вообще рендерили следующим образом. У тебя просто брался второй глаз, и еще один проход делался, как будто у тебя две камеры, и все. Ну, то есть, это, очевидно, не оптимальный подход, никаких вообще оптимизаций, ничего не было, просто рендерилось две камеры, и все. И это снижало тебе перформанс, условно говоря, в 2,7 раз. Примерно в 2,8 раз. И значит, вот с этим поигравшись, поняв, что у нас там в цикле разработки 30-40% времени уходит на то, чтобы впихнуть вот это, это еще после того, как ты это впихнул, оно еще и не красиво, потому что у тебя глаз уже наточен на PC игры какого уровня. То есть, ты же там уж привык. Потом ты это все еще впихиваешь в мобилку, у тебя вообще слезы текут уже рекой. И ты, значит, потом получаешь письмо от какого-нибудь Oculus'а, что, знаете, мы на ревью вашу мобильную версию InMind и InCell'а, там, InMind'а второго посмотрели, к сожалению, там есть одно место, у вас там FPS падает до 52-60, надо бы пофиксить, короче. Ты там, я не знаю, уже с какой-то матерью все это дело ужимаешь и вправляешь каким-то макаром. В общем, это было очень тяжело. Не жалеть себя, но, в общем, это было весело. Извини, перебью небольшая ремарка для слушателей, которые не очень в теме. Почему была названа цифра 50 FPS? Обычно, вот там какие-нибудь большие консольные игры под телевизоры считаются таким нижним порогом при порядке 30 FPS, иногда даже ниже падает. Это выглядит стрёмно, но... Ну, 60 уже, 60, уже все, уже. Ну, не знаю, вот как бы Until Dawn прекрасно своей синематики рендерил на 30 FPS и немножко даже рвался экран, ну, как бы терпимо. Ну, короче, 30 FPS вы чувствуете себя вполне отлично, вот так. Ну да, как это, на телевизоре. Все, что ниже 60 FPS в VR'е, вы себя плохо чувствуете. Я же правильно говорю? Почти. Все, что ниже герцовки экрана, вы себя чувствуете, ну, условно говоря, герцовки экрана, вы себя чувствуете хуже. В целом, чем больше FPS, тем в целом вам комфортнее в VR'е. И сейчас расклад примерно такой. Так, вот не перепутать бы Vive с Oculus, в общем, или Vive, или Oculus, кто-то из них 90 FPS релизный, кто-то из них 75, мобильный Daydream 70, по-моему, кардборд 60-50, и Gear VR, по-моему, почему-то у меня цифры в голове 80, но я что-то как-то засомневаюсь, по-моему, я неправильно помню. В общем, эти циферки, они общедоступны, они, ну, масштаб цифр, вы примерно поняли, вот такой. И падение FPS, оно не может быть, например, там, на секунду уронили FPS на 20. Вот за такое вас не пустят в стор, сразу табу нельзя, потому что игрок повернёт голову в это время, данные с датчиков уже придут в шлем о том, что голова повёрнута, а отрендериться это не успеет, и отрендерится кадр как будто он повернул ещё голову не так сильно, как он на самом деле повернул. И в связи с этим у нас получится, что игроку покажется, что у него что-то такое, головокруглый, в общем, визуальная информация не совпадает с той, что ожидалось, как бы, алярм, беда, в общем, как-нибудь доложи в мозг о том, что человеку плохо. И в мозг докладывает, что человек иногда начинает тошнить из-за этого. И, в общем, вокруг этого всего начали из-за того, что высокий тревелинг FPS, начали придумывать разные вещи, там вот знаменитый Джон Кармак работает в компании Oculus, великий программист, который занимался как раз мобильным VR-ом, и всякие придумывал штуки как это делать, в общем, там придумывали технологии Time Warp, всякие там Preframe Translation и прочее, в общем, вся их суть сводилась к очень простому, к очень простой вещи, как можно сильнее сократить время между отрисовкой кадра, то есть отправкой его на экран и временем считывания с датчиков, последние получения последних датчиков. Условно говоря, с датчиков, с девайсом мы можем информацию считывать довольно часто. И делали так, рендерим кадр, этот кадр пока рендерится, все еще продолжаем принимать с датчиков новые координаты, физические датчики шлема, и как только вот кадр готов, берем самые последние известные датчики, данные с датчиков, и прямо этот двумерный кадр, некоторой хитрой математикой, немножко искажаем прямо двумерный в 2D Space, так, чтобы он чуть-чуть больше подходил под эти подозмененные данные с датчиков, которые пришли, пока мы этот кадр готовили. И, в общем, вот такого рода всякие технологии применялись в оптимизации, а потом параллельно с этим уже были вполне себе очевидные оптимизации про то, что, например, если у нас в VR есть огромная гора, и она очень далеко, то, очевидно, параллакс будет маленький, и не надо ее отрисовывать два раза для двух глаз. Давайте ее один раз отрисуем, и в два глаза поставим одинаковые, никто не заметит. И, в общем, благодаря вот этому и длительной работе сейчас ситуация гораздо лучше, чем два года назад, и уже можно в целом жить. Ну, вообще, как сейчас рисуют, нет рисования дважды, сейчас движок делают или все еще руками, и как вообще сейчас рисуют? Вот ты говорил, что 2.8 раз overhead, как сейчас? Я так понимаю, там сейчас не две камеры. Сейчас там двух камер никуда не деться, просто они рисуют хитрее, и не все в правильном порядке. В общем, в основном все на себя берет движок, пока у вас не нужный шаг влево, шаг вправо. То есть, SDK, OpenVR и Oculus, то есть, двух самых главных платформ, ну, вот сейчас Daydream еще, они в движке интегрированы хорошо, то есть, там, ну, бывают, конечно, проблемы, но, в общем, можно считать, что для вас можно это использовать как blackbox. Вот. И с этим жить. То есть, у вас просто условно говоря, все превращается в то, что вы ставите галочку, типа, хочу VR на камере, у вас получается VR. Если вам надо шаг влево, шаг вправо, вот тут уж извольте открыть и импортировать прямо SDK с ROI, посмотреть, что там, да как, подкрутить действийку, и, в общем, вот это все очень занято и интересная задача. Но я думаю, что для 99% проектов это не нужно, ну, инди-проектов, в смысле, и можно с этим прекрасно жить. На заре, вот, на самом... когда только-только начиналось, я помню, что у ребят из Екатеринбурга, я думаю, что в стиме могли некоторые ребята играть в игру Blazerush, называется. Это про машинки, там машинки такие ездят, стреляют друг в друга, в общем, все здорово, весело. Они, у них свой движок, насколько я помню, и они интегрировали Oculus SDK прямо вручную, прямо вот эти все отрисовки в нужные места поставили и так далее. И вот первый, я не знаю, первый год, наверное, вообще просто не глядя можно было отличить, где игра на Unity и где их, как бы, вот этот Blazerush. Blazerush был самым офигенным с точки зрения перформанса, тебе просто, ты у него отдохнуть захотел, тебе настолько нравилось то, что там не тормозит ничего, настолько было круто по сравнению с Unity, то есть ты просто берешь, там игра Blazerush с эффектами, машинки, все дела, а тут в Unity просто кубик собираешь пустой. Пустая сцена, но не один кубик. И вот пустой кубик, он медленнее работал, чем вот этот Blazerush. Это настолько было круто, вот, посмотреть вот этот в Native Render, что, конечно, подмывало желание что-нибудь сейчас переписать, но, в общем, мы продержались, и теперь это стало сильно лучше. Вот, а ты говоришь про SDK, я, честно говоря, ни разу в жизни не смотрел ни на тот, ни на другой, и мне очень интересно, какие ручки он все-таки отдает. То есть, что такое SDK отдает в девелоперу, то есть, понятно, там контроллеры у них кастомные, но что еще такое он отдает девелоперу или движку, чтобы как-то рендеринг оптимизировать? Он обычно в себя берет, то есть он не стоит, как бы, как сейчас сказать, короче, он не вклинивается в твой рендер-процесс, он у тебя после, как бы, того, как ты отрисовал текстуру, принимает ее и готов что-то делать. То есть он тебе отдает координаты и прочее от своего шлема, от контроллеров и так далее, то есть input, ну, если девайс, сам поворот головы и шлема можно считать input, вот, а ты в него условно говоря получаешь, вставляешь его вызовы в нужные места, например, у тебя текстурка отрендерилась уже, ты теперь говоришь, вот, разверни ее варпом правильно, вот, с такими координатами, а то это они потом в поздних версиях втащили прямо себе в дейлильку, ты, грубо говоря, писал там Oculus SDK, типа, просто с фрейм и все, и вперед. И он из своего SDK сам выплевывает это правильно на шлем, ну, то есть там у него очевидно в Oculus это все закрыто, и ты не знаешь, как именно он это выплевывает, у тебя просто такой blackbox дейлилька, вот. А в OpenVR там ручками является все, что существует в системе, потому что ну, open source, собственно, ты себе протаскиваешь то, что тебе нравится. Базовый API примерно такой же, как у Oculus, чтобы ты его использовал, примерно, как blackbox, но там еще очень большой модуль работы с Lighthouse, это, в общем, у HTC Vive, пожалуй, соразмерное со всем вот этим вот отрисовкой и шлемом технологии, это Lighthouse. Это две такие коробочки у вас висят в комнате в углах, или там, куда вы их повесили, они, значит, сканируют у вас, условно говоря, комнату. Одна сканирует сверху вниз, другая слева направо. Вот, и типа, они между собой связаны проводом, и, грубо говоря, они во все девайсы, которые входят в HTC Vive, то есть это два контроллера, шлем, плюс еще кастомные контроллеры, которые вот сейчас можно собирать из подручных средств, вот это такой у них типа конструктор, собери себе сам VR-контроллер, они в них обновляют последнюю известную позицию в комнате, условно говоря. И вот с Lighthouse там, конечно, пруд пруди, чего можно делать, а с самим VR-ом и с рендером вот примерно как в Oculus, как я и описал. Но, в общем, если кому-то прям очень интересны супер глупые детали, то прям на этом, на GitHub, по-моему, OpenVR лежит, можно зайти и посмотреть на паблик API, понять, что он делает. Там же есть примеры, но в общем, я подозреваю, что в VR количество ни Unity, ни Unreal проектов стремится к нулю, в общем, их очень мало, потому что довольно... в общем, 17-й год, короче, никто уже не пишет всё вручную, и мало кто что-то отрисовывает. Говорят, что будет новый движок от Valve, который будет новый сурс, и там будет такая довольно нативная интеграция, прям с открытым кодом интеграции в рендер, но, в общем, этого я еще не видел, никогда не видел тот движок, и никто, по-моему, еще не видел его из паблики. Окей, ну я не очень понимаю, как то, что ты сейчас писал, помогает не рисовать гору дважды. Да, так очень просто, ты не рисуешь гору дважды на своей стороне, а не на стороне SDK. Окей, как движок знает, что тут гора, её можно не рисовать дважды, а вот это там уже персонаж, которого нужно рисовать дважды? Просто по удаленности? Это просто какой-то сеттинг у движка, что он... Не-не-не, мы прям... Это всё на руках создателя сцены, кто собирал её, потому что он должен промаркировать, вот это мы рисуем, это задний план мы рисуем, это так, это передний план мы рисуем, это эдак, и по-другому-то никак. Но он там маркирует именно для движка, а не для кода какого-то кастомного рендеринга. Ну да, ну а что такое код? Ну, то есть у тебя, смотри, у тебя два прохода есть с каждой камерой. Эта камера, предположим, типа... Так, чё, давай в Unity терминах попробуем. Мы типа говорим, что задний план — это у нас lawyer background, его не рисуют камеры, которые глаза. Камеры, которые глаза, рисуют просто всё, что на слоях, которые им нужны, а есть ещё одна камера, которая в один проход тупо рисует задний план. Этот задний план просто накладывается сзади, всё за камер, которые глаза нарисовали. И всё, у тебя получается, что камеры, которые глаза ту гору вообще не рисуют саму, они берут уже её отрисованную. И всё, отдельная камера рисует весь задний план. То есть там как камера верит, на самом деле три сейчас камеры? Ну, это имплементация, которую мы с тобой придумали за 15 секунд. То есть там базовых подходов много, все по-разному делают. Кто-то вообще заморочено делает, кто-то рисует в сферу это всё. И выдаёт это как такой статичный скейтбокс, который у тебя там крутится. Кто-то делает при билд даже отрисовки и, условно говоря, ты когда играешь в игру, у тебя передний план трёхмерный, задний план это видео на сфере. Там, короче, знай только воображение проявлять. Понятно, то есть какого-то супер-пупер метода пока не придумали. Я ещё когда выходил.. . Только жест практис, да. Когда выходил 1080, они там рубили, что он весь такой, ещё более VR, чем ваш VR. Мы, по-моему, даже обсуждали, но вот мне хотелось бы спросить у кого-то, кто этим занимается, в чём там более VR-ность VR-а в вашем 1080? Вот я, когда они анонсировали все вот эти вот, что мы теперь супер VR и так далее, я, честно, пытался понять. В общем, моя финальная реприза такая. Скорее всего, просто в драйверах 1080, так подпёрты, что с товарища с SDK VR он имеет некоторые специальные... Какие-то хорошие договорённости у SDK и у драйверов. Драйверы изначально заложены, что вот именно эти пути, которыми SDK использует видеокарту, они точно протестированы на стороне NVIDIA и точно исправлены там базовые проблемы. Я думаю, что там только полировка дров. Потому что всё, что с хардварной точки зрения, там, ну, то есть я особо не понял, что они сделали, там хоть и описано это, я прочитал, мне не хватило ума понять, по-моему, это выглядело просто как запутанные слова. Вот, и я думаю, что это просто красивое описание того, что мы всё проверили как следующее именно с SDK. Единственное, что там было, что были хорошие надежды, это на то, что мы с кэшем получше сделаем ситуацию. Что, типа, ну, условно говоря, мы рисуем персонажа в VR, он стоит перед нами. Вот мы, чтобы его отрисовать в видеокарту, скормили там его модельку, текстуру и так далее. А потом взяли, посчитали матрицу камеры и с этой матрицы камеры его нарисовали. Вот не правда ли, когда мы его сейчас рисуем для второго глаза, нам скормить эту видеокарту всё ещё раз не надо. Нам надо просто как бы с другой матрицы камеры его нарисовать и всё. Вот. И типа, ну я не думаю, что это нужно опускать до уровня Hardware. Я думаю, что это вполне себе софтверное решение. Ну, кстати, а всякие там GeoRetix 12 и прочие, Vulkan, они разве так не могут? Там же, насколько понимаю, довольно ручное управление, что в командбуферы пихать. Да, там более low-level API, как в консолях. Раньше был. Сейчас я в современный консольный SDK, вот 4-ый, я ещё не смотрел. Но там... Их никто не позиционирует, я ни у кого не видел, что они бы позиционировались как Best for VR.",
    "result": {
      "error": "API request failed: Error code: 400 - {'error': 'Trying to keep the first 6241 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': 'Trying to keep the first 6241 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}\n"
    }
  }
]
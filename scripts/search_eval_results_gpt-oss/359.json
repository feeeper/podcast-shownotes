[
  {
    "segment_id": "d28abf07-5494-4b5f-b0ae-05301e2b9108",
    "episode_id": "3883efb7-cfe0-4dcd-a91c-944d7173f2c8",
    "episode_number": 359,
    "segment_number": 6,
    "text": "Я вот не понимаю, что они считают самым сложной областью, потому что тут сложность как раз в том, что у тебя обычно много разных команд колбасит код и исключаю вариант, когда ты можешь просто взять все свои данные, короче переместить своего какого-то огромного мусорного HDFS или там S3, на котором лежит все говно за все там 10 лет существования компании в какой-нибудь чудесный блестящий Data Warehouse, который обмазан очень производительной базой данных, за который ты платишь как ассеки просто бесконечные и в нем значит все бесконечно быстро работать даже в этой ситуации у тебя будут какие-то особо сложные задачи, которые просто не ложатся в Data Warehouse, они требуют какой-нибудь All-Time и Pipeline или еще какую-нибудь херню, вот если у тебя нет такого блестящего дорогого Data Warehouse, у тебя скорее всего в принципе как бы нет какой-то возможности единообразно все это порешать и у тебя тогда в любом случае будет ситуация, когда у тебя много тимов, каждый что-то колбасит и потом нужно интегрировать. У них здесь есть отдельная секция которая описывает вот этот вот Airflow и в противовес ему они рассказывают про Data Mesh. Я про него кажется год назад приносил статью про Data Mesh и Data Virtualization вещи, я работал Data Virtualization продуктом, проблема с идеей Data Mesh в том что ну я если честно пока не видел ни одного инструмента на котором реально его можно построить, то есть это пока что я вижу Data Mesh как фантазии какие-то, которые нам пытаются продать, какие-то консультанты, которые собираются обычно из чего-то существующего и как только ты короче перестанешь следовать чудесным практикам, у тебя все развалится, я могу ошибаться, но я вот серьезно я не в курсе Data Mesh продуктов, обучитель когда-то придите мне расскажите мне что есть. Тогда как это же самое Data Warehouse и Data Virtualization они существуют, ими даже удобно пользоваться, но там возникает проблема, которую я вот уже пытался озвучить, что у тебя что могут быть в компании use-кейсы, которые не покрываются продуктами которые это реализуют, то есть типичный пример будет это какой-то совсем реалтаймовый поток данных, прям очень реалтаймовый с каким-то там милисекундами задержки, которая будет написана как-то в Apache Flink или Twitter Storm, эти штуки они очень херово интегрируются с чем угодно еще, потому что скорость через которую через них проносится данные и любое стриминговое решение оно внутри очень сильно своеобразное, потому что у него есть свой стейт, который скорее всего никто и кроме этой системы менеджить не умеет, никуда ты его не подсунешь, это стоит, то есть ну как вот можно в стейт Flink или стейт Storm, его же нельзя как Relation выгрузить в Date Warhouse Кавка и пульсары, поэтому они и говорят кавка или пульсар, может они на кавке пульсары строят подобные штуки? Так нет, ну кавка или пульсар это просто очередь, а Storm и Flink это процессинг, ну то есть потрясающе, да, ты положил данные в свою кавку, тебе что-то тут должно вгребать с очень большой скоростью. Да, да, слушай, я тебя ненадолго остановлю, они говорят, что несколько команд на которые они смотрят смогли построить Data Mesh архитектуру, они создали какие-то дополнительные абстракции, построили вот это все, единственная ссылка, которая оттуда ведет, она ведет на статью Мартина Фаулера, то есть нет пока никаких открытых решений, которые все",
    "result": {
      "query": "Data Mesh architecture tools"
    }
  }
]
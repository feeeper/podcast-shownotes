[
  {
    "segment_id": "8b78a0c4-b51e-4d7b-8eb0-e34ff9704cfe",
    "episode_id": "220b4480-c968-4329-95a8-5c2917d998a7",
    "episode_number": 155,
    "segment_number": 3,
    "text": "Мы какое-то время пропушили это и пришлось скатиться в консалтинг. Но этот консалтинг привел нас к биткоину, потому что один из клиентов пришел и сказал, что нам очень хочется биткоин-биржу. И это было начало 2013 года, если не изменяет память, ровно в районе того, когда Mt. Gox накрылся. Но денег у них все равно было мало, поэтому мы предложили им, что давайте мы сделаем биржу, но мы ее не продадим вам, а продадим ее как лицензию. И вот с этого начался проект, который еще мог найти следы, Bax.io, и вот оттуда началось такое относительно серьезное вовлечение в биткоин и блокчейн. К сожалению, компания тоже не выжила, но не по техническим причинам, а скорее по причинам нестросшихся кофаундеров. У нас не сложились дела с моим кофаундером, который присоединился ровно перед тем, как мы решили делать биржу. Но тот слово мы писали как раз на REX, то есть много тех контрибьюшенов, которые видны еще от меня и от других ребят в команде, они приходили, когда мы разрабатывали биржу под ключ для биткоинов. Биржа под ключ для биткоинов. Ой, а мне очень интересно узнать про ситуацию с кофаундером. Ну, это тяжелая ситуация, я предпочитаю обычно особо не вдаваться в детали в этой истории, но я могу, наверное, как-то обобщить experience. Ну, то есть нам же нужно не влиться, а нам скорее интересно, что может быть не так, когда есть какой-то свой проект, какие-то отношения с учреждениями. Да, это на самом деле очень важная тема, я очень долго рефлексировал на эту тему после того, как все это было. Главное, мне кажется, это очень четко в таких ситуациях, когда сложно выстроить отношения, очень четко выстроить границы. В плане того, что как бы позволено на межличностном уровне делать. То есть, грубо говоря, я не люблю это слово специально, кодов контакт, но кодов контакт для кофаундеров – это тема, наверное, в принципе, интересная для конфликтных, сложных ситуаций. А как это вообще можно описать? Вот не знаю, на самом деле пока. Как я говорил, я рефлексировал на эту тему, и тогда все равно возвращался к тому, что мы просто не были совместимы. Но на самом деле, мне кажется, что если действительно глубоко копать, то у всех можно найти какой-то режим сосуществования, или почти у всех найти такой режим. Вопрос в том, что является acceptable behavior, а что является неacceptable behavior, то есть как вообще решать конфликты. По этому поводу я читал книжку тогда, очень хорошую книжку, мне нравилась, да и сейчас нравится, называется Crucial Conversations. Я пытался и кофаундера взмушить ему, чтобы он прочитал, но, к сожалению, он ее так и не начал, по-моему. Но эта книжка дает действительно интересные инструменты по тому, как вести, я даже не знаю, как на русский правильно перевести, то есть важные разговоры, да, то есть где ставки высоки, эмоции на пределе, как их выводить, что решает задачи и цели участников разговора. А можешь еще раз рассказать название, я ее сейчас найду и прикреплю в шоу-ноут. Да, Crucial Conversations. Я могу... куда записать? Я сейчас найду, не надо, все, спасибо. Слушай, а как долго вы проработали вместе? Вместе мы проработали, ну, получается, где-то год. То есть, получается, он наверняка свою часть доли взял, потому что вестирование обычно, ну, клиф один год. Да, но там на самом деле немножко по-другому было. Меня ситуация, которая у нас сложилась, самых мягких терминов достала, и я вынужден был просто сказать, что я больше работать не могу, и я ушел. То есть, по моему договору у меня что-то оставалось из доли, но так как компания в итоге все равно не сложилась после того, как я ушел. То есть, компания еще как-то там протянула, наверное, 9 месяцев, плюс-минус. Дальше там совсем все стало грустно, и тот equity, который у меня оставался, он был бесполезен все равно. А мне интересно, а как ты нашел кофаундера? Кофаундера? Его знали в городе, где я живу, тут, в Ванкувере, его знали все. То есть, это был очень известный стартап-человек, у него было много митапов, и небольшие стартапы делал до этого. То есть, просто очень большой человек в плане социализации и общения. Ну, как известно, нужно, чтобы в команде был, грубо говоря, дизайнер, хакер и хастлер. То есть, вот он был хастлер. Я его знал несколько лет уже до этого, но никогда с ним не работал. В тот момент, когда все это развалилось, я для себя вынес урок, ну или хотя бы напоминание, что, наверное, если что-то серьезное начинать, то лучше бы начинать с теми людьми, с которыми я уже работал. Слушай, ну вообще, в итоге, как урок глобальный, получается, надо описать заранее рамки, то есть написать код of conduct между основателями, что разрешается, что не разрешается, и прочертить границы, где заканчивается твоя область и начинается моя. Я правильно понимаю? Даже может не область, там понятно, что это даже возникают регулярно конфликтные ситуации, по крайней мере, в наборе компаний, где не совсем понятно границы, где моя ответственность, где твоя ответственность. Но это именно по поводу контакта, как мы себя ведем. То есть, verbal abuse, physical abuse, passive aggressiveness, everything. То есть, модель поведения, которая, скажем так, неэффективна для компании. То есть, они приводят, собственно, либо к развалу, либо просто приводят к дисфункциональным компаниям, по-видимому. Давай просто, как-то сказать, суммируем это таким образом, что не начинайте стартап с мудаками. Это очень хороший вариант подсуммировать, да. Нет, ну с другой стороны, настолько расплывчивый определение, если у кого-то есть детектор мудака встроен, то очень счастливый человек по жизни. Ну, я, может быть, не знаю, очень счастливый человек по жизни, но, как правило, достаточно долго пообщавшись с человеком, можно быстро понять, работаешь ты с ним или нет. В общем, да, наверное. То есть, получается, что более такой практический совет – не начинайте стартап с людьми, с которыми вы раньше не работали никогда. Ну, почему же? Я, опять же, могу судить по Аксератору, в котором я была. У них немножко другая политика. Они дают тебе такой trial period, когда вы можете посмотреть, как вы работаете вместе. И, в принципе, наверное, первые пару недель большинство всего видно, наверное, процентов 80. И потом, конечно же, эти 20% очень часто играют. И я видела развалы команд впоследствии, там через год работы, через полгода работы, по-разному бывает. Но, в принципе, модель, когда ты начинаешь работать с человеком, с которым раньше не работал, но при этом у вас цели сходятся, вы и первый, и второй кофаундер ушли, например, с места работы для этого – это, в принципе, такая рабочая схема. Я могу добавить, у меня есть очень хороший пример на эту тему. Один мой знакомый решил сделать поворот в бизнесе, решил сделать новую подкомпанию в компании. И поэтому он взял всех своих сотрудников, которые у него были в тот момент в компании, и решил определить, кого взять в следующую подкомпанию. И он взял их и вывез всех в пеший поход на неделю. Специально с целью определить, с кем он хочет работать, с кем не хочет. Он говорит, на четвертый день я точно знал ответ, с кем я буду работать, а с кем не буду. Все сложные ситуации, я имею в виду физически сложное окружение, очень хорошо открывает человек. Особенно, когда ты находишься с ним в одной упыряшке. Что самое интересное, мы с моим кофаундером собирались сделать нечто подобное еще и в зимних условиях, но до этого так и не дошло. Потому что вы не смогли договориться? В общем-то да. Но я еще в следующий раз думал, что второй сумматор здесь был бы в том, что читайте сигналы. Если есть какие-то сигналы, лучше не откладывать, что может быть потом все будет лучше. Решать проблему сразу. Извини, что перебиваю, прям вот столько отсылок на следующую бомбическую тему, но я не могу, надо держаться. Слушай, а у меня еще подходы. Значит у нас еще там много вопросов. Отлично, продолжайте. Да, по поводу кофаундера. А можно на технические темы немножечко? Мы сейчас разбавились. Вот последний вопрос, я тогда отстану со своей стартаперской темой. Слушай, а вот у вас не было такого заведенного правила, например, раз в неделю, либо раз в три недели говорить по душам с кофаундером? И рассказать, что мне не нравится, что мне нравится, какие у меня есть опасения. Чтобы каждый человек рассказал, чтобы можно эту проблему было как-то предотвратить, но не разваливать компанию. Просто кажется оно назревало, обычно такие вещи назревают, они не случаются внезапно. Традиции такой не было, но я вот сейчас вспоминаю, как это все происходило. Такие разговоры у нас происходили спонтанно и обычно ни к чему хорошему не приводили. Они уже случались не до проблемы, а после проблемы. И соответственно эмоции, и все. Мы немножко заглаживали то, что происходит и пытались двигаться дальше, но каждый раз все становилось хуже и хуже. Есть свои подробности, которые я не буду разглашать, потому что связаны с человеком, с которым я работал. Я думаю, что такая традиция была бы неплоха, конечно, говорить до проблемы. Понятно, что лучше в любое время поговорить до или после проблемы, чем вообще не говорить. Но лучше, конечно, поговорить до проблемы. Ура! Пошли на технические темы. Валер, давай, прежде чем пампкинг ДБ, ты хотел что-то еще подсфрешить. Да я как раз на самом деле хотел к пампкинг ДБ перейти. А там дежели, то есть про Раску уже поговорили. Но я думаю, что стоит для начала сказать, почему она такая отдельная база и что в ней такого интересного по сравнению с каким-нибудь, прости господи, нашим любимым позгрессом. Ну если с позгрессом сравнивать пампкинг ДБ, то это очень интересная база. Ну если с позгрессом сравнивать пампкинг ДБ, то это очень интересная база. Нет, ну подожди, то это другая ЛТП-база. Пампкинг ДБ на самом деле, по-честному если смотреть на нее, пампкинг ДБ это не база данных. Это как бы движок для базы данных. То есть в принципе все, что в ней есть, это сортированное по дереву и небольшой почти язык программирования. Откуда это все выросло в плане устройства? Наверное больше всего MAMPS, если кто-то вообще знаком с этой системой. У нас последний выпуск АТРИФ всплывает, то в выпуске, то в комментариях. Да, я очень много лет пытался как-то встроить MAMPS, в том числе GTM реализацию, в какие-то свои рабочие проекты, последние наверное лет 10. Но всегда как-то безуспешно, я начинал и где-то оно все затыкалось. Но мне не давало покоя эта мысль, что это как бы такой инструктор для баз данных. То не я должен подстраивать мое приложение под что-то, а это как бы я делаю базу данных для своей системы. Ну справедливости ради, там не знаю, при некотором количестве желания, тем же Postgres так можно. У нас по большому счету глубоко заточены под задачи нашей компании Postgres. Другое дело, что для этого у нас пишут на C и PRPJSQL местами, и это не всегда приятный экспириенс. Но это уже отдельная история, но так технически я бы не сказал, что это самая уникальная фишка. Конечно не уникальная. С моей стороны я хотел просто найти какой-то очень такой минимальный вариант. В принципе, PumkinDB в своей сути это вообще просто библиотека. То есть ее можно просто встроить в любое приложение. Понятно, что там есть еще и приложение, которое ее встраивает и которое работает как сервер. Но это как бы последствия того, что это библиотека. Хотелось что-то очень маленькое, встраиваемое, с которым можно и удаленно работать, если очень хочется. Можно и локально работать. И что-то, естественно, что очень легко контролировать, где идеи реализованы не как second-class citizens, а которые изначально так были задуманы. То есть это не бороться с устройством какой-то более большой базы данных. Я пытался это сделать с проектом, который был направлен в более общее направление. Мы можем чуть позже на это затронуть. Лейзи, вендсорсинг и все, что рядом. И там я как раз пытался использовать Postgres. Но я столкнулся с тем, что я зачастую просто сражаюсь с самим Postgres, в плане того, что у него есть какие-то свои идеи о том, как устроено все. И как устроены типы, и как устроен storage. И что он от меня ожидает отличается от того, что я хотел бы в идеальном случае иметь. С другой стороны, я не хочу в данном случае в очередной раз произносить слово на БКП. Но есть в базах, которые за нас уже сделаны, есть много такого интересного. Я, конечно, понимаю, что для базы, которая себе ставит сервис, быть минимальной и вообще дать все на себя запрограммировать, возможно, не самоцель. Тем не менее интересно, как это все относится. Большинство баз имеют SQL или какой-то еще движок, оптимизатор запросов. Некоторые из них имеют какие-то возможности распределения по машинам. Здесь получается просто B-дерево с языком скриптования, если я правильно понимаю. И, собственно, почему ты считаешь, что это в хорошем месте в плане баланса фичей, или возможно, я не вижу каких-то фичей. Почему тогда не просто B-дерево с просто API? Я пытаюсь понять, как ты видишь использование этой базы, учитывая, что от нее оторвано довольно большое количество вещей, которые обычно ожидаешь от базы данных. Понятно, да. Конечно, это многоуровневый вопрос. Несколько моментов я хотел бы обозначить по поводу фич. Одна из фич, условная, но тем не менее определяющая для того, как с ней работает, это то, что она иммьютабл. Когда ключ, значения определены, то их уже перезаписать нельзя до того, как будет произведен процесс экспирашена, когда они будут выведены из системы. То есть нельзя просто взять и перезаписать. Понятно, что это не фича, а по себе это ограничение, которое заставляет писать программы по-другому. С учетом того, что мы не можем взять и переписать что-то по какому-то ключу. Откуда все это началось, я могу, наверное, немножко затронуть, и может быть станет лучше понятно, откуда это все идет. Что я пытался сделать с ней, это система, в которой я могу описать операции для записи, условно говоря, событий на каком-то примитивном языке, который полностью интегрирован с движком базы данных. И я хотел избавиться максимально от абстракции, которую SQL дает или еще что-нибудь, все оптимизаторы, и посмотреть, в некотором смысле это экспериментально, посмотреть почти на физическом уровне, как можно запрашивать данные и, грубо говоря, сколько стоит их достать. И данные, которые мы не перезаписываем, то есть исторические данные, как мы их собираем в одну модель, которая сейчас нам интересна. И вот я вижу тут в чате, упоминается Datomic, да, в некотором смысле это похоже на Datomic, но не сам PumpkinDB. То есть сам PumpkinDB, он просто дает примитивы для работы с этим деревом и описания простых pipelines для данных в виде этого PumpkinScript, который на самом деле очень просто простой фортеподобный язык. В плане Datomic я сейчас потихоньку разрываю VueDB, есть вот ссылка тоже в чате. VueDB это максимально приближенно, в некотором смысле, к Datomic, это, собственно, система записи фактов и движок, который компилирует запросы в маленькие PumpkinScript скрипты, которые, собственно, реализуют это. То есть в некотором смысле PumpkinDB это такая вот Data Machine, возможно, экспериментальная даже с моей точки зрения. То есть я хочу, может, даже скорее для самого себя понять, как это всё должно работать, если мы выбрасываем все эти уровни абстракции, к которым привыкли. У меня такой другой момент, то есть, в принципе, я понял твой текущий point, тогда мне другое непонятно. Но вот есть сейчас такой проект, который, на мой взгляд, уже немножко overengineered. С другой стороны, там столько фичей, что, в принципе, оно может быть даже и то, что ты хотел бы в каком-то смысле. То есть берём RocksDB. Да, там нет устроенного языка, но там настолько развесистый API, что из него можно собрать более-менее то, что хочешь. И тогда возникает вопрос вообще, если хочется низкого уровня абстракции и работы с какой-то сущностью, которая, по большому счёту, ничем не занимается, кроме перекладывания данных на диски, даёт тебе курсор и фильтр, то пусть зачем там вообще целый язык программирования встроенный. Собственно, язык там только для одной цели, это для того, чтобы описывать простые алгоритмы в виде набора инструкций. Грубо говоря, если представить себе, что у нас есть инструкция по записи, скажем, факта базы данных, журнализации факта. Она раскладывается на несколько стандартных инструкций в основном по pumpkin script, то есть стандартную библиотеку. И это даёт нам возможность записывать эти программы в компактном виде, стандартным сервиллём. То есть не нужно писать эти кусочки кода на RAST или ещё на чём-то. И можно передавать их по сети. Протокол общения стандартный для pumpkin db, когда мы работаем с удалённым pumpkin db и локальным db, это просто передача вот этих pumpkin скриптов, которые исполняются там. Идея в том, что с этим языком, почему он отдельный язык, я пытаюсь максимально интегрировать его с областями памяти, с которыми я работаю. Сейчас это ещё не идеально, но это work in progress. Данные для фортепотомного языка минимально копировались. Если есть у нас возможность прочитать из базы данных, и если мы используем map, как это сейчас используется, потому что сейчас единственный backend — это lmdb, то эти данные должны копироваться в контекст какого-то другого языка. Попытка здесь была соединить виртуальную машину этого языка с моделью памяти базы данных. И это ещё будет интереснее, когда дойдут уже до конца руки заняться SSD дисками. Я несколько месяцев назад написал binding для очень интересной библиотечки, называется SPDK, для работы с NVMe контроллерами. И там мысль в том, что если мы полностью интегрируемся с той памятью, с ссылкой, на которую передаём контроллеру, то зачастую у нас никогда не будет копирования для того, чтобы просто переслать данные на диск. И максимально приближая язык к вот этим областям памяти, мы достигаем определённого уровня эффективности. Можно я спрошу, пока мы далеко не ушли? То есть фактически ту задачу, которую ты сейчас решаешь генерально, её все решают на уровне кода, то есть берут CC++, чтобы сделать зерокопию при получении через сеть или при чтении с диска или откуда-то ещё, и при использовании этой информации. Ты хочешь сделать систему, которая генерально решит эту проблему, то есть у тебя есть некая база данных, я в кавычках сейчас это говорю, потому что на самом деле это не база данных, а это просто способ серилизации, и ты делаешь зерокопию-обёртку вокруг этой серилизации, чтобы её можно было легко встраивать в любое приложение. Ну что-то вроде, да. А почему ты вообще думаешь, что эта идея генерально решаема? Пока я не знаю, насколько она генерально решаема, но я пытаюсь её решить на том уровне, на котором мне её достаточно, я просто пытаюсь изначально разработать инструмент, которого мне не хватает. Мне, честно говоря, всё ещё, извини, что перебиваю, всё ещё для меня пока остаётся загадкой, я попытался сформировать опрос, видимо, попытаюсь его спросить ещё раз, я понимаю, зачем нужна база с высокоуровневым языком, он в принципе настолько полезный абстракт, что даже есть отдельные проекты, типа Apache Calcite и Presto, которые дают просто движок запросов, типа SQL, когда хочется писать мало кода, и чтобы за тебя какая-то умная система придумала, как это исполнить. Это я понимаю. Я ещё понимаю, когда делают совсем низкоуровневые движки, типа ROX, типа LMDB, потому что, ну, вот вам хранить, оно хранит надёжно, не теряет данные, а как из этого выглядят данные, вы решаете сами. А вот всё выше озвученное про какой-то эффективный язык запросов, который бы при этом... То есть, как бы, с одной стороны, абстракция очень низкая у этого языка, с другой стороны, это всё ещё какой-то отдельный язык, мне при этом не очень понятно, в чём преимущество перед просто голым движком базы данных. Сорри, голым движком хранения, я хотел сказать. Можно определить дополнительные инструкции, которые связывают низкоуровневые инструкции с логикой без того, чтобы рисовать что-то в сам движок. То есть, что такое журналирование, что такое вот это и вот это. То есть, эти инструкции очень легко определяются просто как небольшой набор памкинг-клип инструкций и позволяют нам быстро экспериментировать с разными устройствами, скажем так, моделей данных и моделей поиска данных в этом виде. То есть, это, собственно говоря, отсылка к тому, приблизительно как работает MAMPS, он, конечно, немножко по-другому работает, у него своя специфика. Да, в некотором смысле, это вот макросы для определения новых инструкций, которые позволяют инкапсулировать дополнительную логику. PumpkinDB не задумывался как совсем высокоуровневый инструмент, скажем, для написания конечных приложений. Это возможно, но это не самый простой процесс. Он задумывался как, собственно, storage layer для проекта, который я год писал до начала PumpkinDB, Event Sourcing for Java, который позволял бы сохранять события и строить запросы, искать данные через индексы. Идея была в том, что PumkinScript дает возможность определить модель данных, скажем, этих ивентов, или как сейчас в UDB называют факты, и делегировать все storage и итерирование курсора туда, но иметь возможность определить следующий уровень, очень компактный дополнительный язык, потому что всё выглядит одинаково, в принципе, просто инструкции, которые берут данные из стека. И вот это позволяет определить еще 5-10 дополнительных инструкций. И эти инструкции, когда используются удалённые, например, через соединение, они становятся протоколом общения между клиентом и сервером. То есть если мы записываем, например, журналируем события, мы просто пишем, условно говоря, вот у нас данные, и дальше идёт инструкция journal, для примера. И мы их передаём именно в таком виде. То есть это сразу даёт нам интерфейс в базу данных для клиента. То есть мета протобаф? Что-то вроде того. Протобаф в некотором смысле, но как язык программированный. Это всё является инструкцией. Мы передаём некий пакет, который говорит, что журналируем вот это, вот это, вот это. И клиенту не надо знать, что означает журналируя, в плане как это реализовывается. Для него это в принципе может выглядеть просто как почти declarative язык, который как описываем пакеты, которые передаём на сервер, что делать. И там просто вот эта прослойка, которая между pumpkin db и последним уровнем, которая описывает, что можно делать с этой базой данных. Если это журналировать, то это вот это делать. Следующим уровнем ты захочешь описывать эту прослойку тоже в языке программирования, и у тебя получится какой-нибудь этериум, я не знаю. Ну посмотрим, пакет на самом деле достаточно простый. В принципе, этот язык, когда описывается этот язык, это просто определение новых инструкций, которые базируются на других pumpkin script инструкциях. То есть, скажем, если нам нужно что-то найти по индексу, то это просто интерьеруем по курсору, используя стандартную библиотеку pumpkin script. Просто это прячет всю сложность от конечного клиента, который уже выражает свои пожелания на практически DSL его задач. То есть, во view.db есть свои инструкции, которые позволяют записывать атрибуты фактов, и это выглядит как DSL. Но внутри это просто-напросто раскладывается в гораздо более простые pumpkin script инструкции. Ну набор этих инструкций заранее предопределён, их штук 7-10, как ты говоришь? Ну в pumpkin script гораздо больше, это всё связано с типами данных и прочее, там много всего разного. Но набор инструкций, которые в более высоком уровне, в view.db, которые настройки на pumpkin.db, там их очень немного. Порядок действительно может быть 10-20, в зависимости от сложности, система, которая пишется. Слушай, ну вот я возвращаюсь к предыдущему вопросу. То есть, я понимаю, что ты решаешь свою задачу, но при этом ты пытаешься её как-то генерализировать. Вот ты пытался определить список юзкейсов для pumpkins в view.db? То есть, я имею в виду, что это вообще в целом полезно, у тебя уже по крайней мере 1-2 примера есть, может просто их заранее 100 штук сделать, ну ладно, 5 штук сделать, и пытаться решить именно эти 5 проблем? У тебя они может быть есть? Я к чему? Я хочу, как и Валера, разобраться, что же ты делаешь? То есть, если бы ты сейчас хотя бы парочку этих примеров описал, было бы более ясно слушателям тоже. Понятно. Насчет примеров. Все это в основном вылезло в районе условного финтека, опять же, этих блокчейн задач, где потеря данных была очень неприятным событием, то есть где-то чего-то перезаписали, и поэтому начал возвращаться активно к моделям типа event sourcing, которые я трогал немножко раньше, с другими проектами, типа Genome. И, собственно, задача, которую я там увидел, в том, что если у нас есть разнообразные варианты, как можно посмотреть на область, то есть, скажем, на пользователя человека можно посмотреть одним способом, с точки зрения, например, UX дэшборда для человека, или с точки зрения fraud detection. Какие данные приходят об этом человеке, они важны по-разному, для разных компонентов, для разных ответственностей в проекте. Скажем, очень простой пример, который я много раз использовал, объясняя идеи за lazy event sourcing. Например, есть у нас ивент, что пользователь поменял имя, просто там свой имя. И с точки зрения, например, дизайна дэшборда, где нам нужно просто показать имя человека, нас интересует только последний ивент, нас интересует, сколько раз он себя переименовывал. Но с точки зрения компонентов fraud prevention, нам, естественно, важно понять, во-первых, паттерны, то есть, как человек себя вёл, и важно проводить cross-reference. И весь этот стэк с pumpkin db и с vt, это попытка дать, в первую очередь, инструмент, который позволяет записывать много multifaceted событий или фактов, и строить доменные модели в сути в рантайме. То есть, скажем, в классическом event sourcing мы не читаем стримы ивентов и применяем их к некому стейту. Здесь идея была другая, что мы собираем всё, что к нам приходит, и когда нам нужно принять решение той или иной модели, мы строим её по сути как набор запросов. И вот это на самом деле основной мой движущий компонент. В системах, где требуется разная интерпретация одних и тех же событий, эти модели мне кажутся достаточно интересными. Я переслушаю этот кусочек потом в записи, чтобы понять окончательно. Значит, плохо объяснил. Хорошо, но не заходит сразу, с первого раза. Окей. Я на самом деле примерно сообразил, куда было бы интересно это использовать. Я примерно понял, зачем, но мне в таком случае непонятно... То есть, скажем так, это настолько узко специализированная штука сейчас, что без какого-то следующего шага она, мне кажется, не то чтобы супер применимо. Не то чтобы супершироко применимо, несмотря на то, что вроде бы и в open source. Да, то есть без VDP это пока очень не с того уровня инструмент. Из этого у меня два вопроса растёт. Первое, будет ли какая-то история с репликацией, будет ли какая-то история с шардированием в пампкине или вокруг? Вот давай пока на это ответишь, а потом я второе спрошу. История, очевидно, будет, но пока просто не касаясь этого, просто чтобы сфокусироваться на тех задачах, которые сейчас есть. Один момент, который мне кажется достаточно важен заключается в том, что так как мы не перезаписываем данные, у нас есть некоторое облегчение в плане того, как мы запрашиваем данные. Мы можем, грубо говоря, указать метку timestamp и мы будем знать, что все данные, которые получены с разных серверов, они уже не изменятся никогда. Как именно это будет сделано, пока ещё совершенно не ясно. Репликации тоже пока не очень понятно, но в принципе история выглядит гораздо проще, потому что фактически всё, что нас здесь интересует, это просто поток событий и как мы их отсылаем на другие узлы. И в принципе это ещё станет гораздо проще, если строить не на уровне PumpkinDB, а в UDB, где каждая запись всегда содержит timestamp. То есть гораздо проще будет отследить, где мы остановились в подписке на репликацию. Слушай, можно такой вопрос? А вот это PumpkinDB, это твоё основное занятие сейчас? Я имею в виду, ты большую часть времени своего тратишь именно на неё сейчас, да? Последние месяцы да, но наверное это будет ещё меняться. Последние несколько месяцев я хотел обеспечить просто фокус на этом, но сейчас собираюсь заняться дополнительными задачами, просто чтобы обеспечить существование себя и интересных задач. Последние несколько месяцев это было всё вокруг PumpkinDB, в UDB и где-то рядом. И всё на расте? Ну, по сути да. А как долго ты этим проектом занимаешься? Ну, сам PumpkinDB начался 1 февраля, но по сути у него история, конечно, дольше, она ещё должна включать в себе историю Eventsourcing for Java, проект, который я год до этого делал. Он где-то открыт? Да, он тоже открыт, если зайти на eventsourcing.com, это мой домен, точнее не совсем мой, но маленького нон-профита, который я организовал в прошлом году. И там есть ссылка на этот проект, он где-то как раз с января уже не развивался, потому что я свои силы перебросил на PumpkinDB. И UDB, как настройка на PumpkinDB, это полный перенос идеи из Eventsourcing for Java с ещё более интересной, как мне кажется, и более гибкой моделью данных. То есть там, где Event или Fact не зажат в одну схему, но скорее это набор схем, как трейдов, скажем так, в расте. Об этом можно прочитать в Redme в UDB, это описано. Ну и немножко другие проекты были, Genome, например, тоже где-то на GitHub ещё лежит. Это была попытка очень ранее реализовать что-то Event-соурсинговное в своём виде на Ирландии или на Эликсире, я уже не помню, в какой именно момент это было. Это такой процесс, который меня привёл, где я сейчас. Я написал набор статей в прошлом году, в основном, которые касаются идей, которыми я сейчас занимаюсь. Я в прошлом году называл Lazy Eventsourcing, но сейчас пытаюсь потихоньку прекратить использовать название Eventsourcing, чтобы не возникало конфликтов с пониманием, о чём идёт речь. Потому что ребята в Eventsourcing-комьюнити достаточно зажато воспринимают, что является Eventsourcing, и у них есть свои терминологии. И мне изначально казалось, что это хорошая идея, назвать это Lazy Eventsourcing, но год спустя общение показывает, что это только порождает конфьюжн. Люди пытаются найти понятные им примитивы из классического Eventsourcing, и они не особо их там находят, и это тяжело. Поэтому я пытаюсь сейчас найти новую терминологию, которая отдельно бы описала эту модель, где мы просто собираем факты и строим запросы в рантайме. И таким образом собираем доменные модели, вместо того, чтобы накатывать изменения к доменным моделям в момент получения событий. Я, кстати, плюсую по поводу этого, потому что твоя идея не просто продолжение Eventsourcing, это немножко другая концепция, и хотелось бы другого термина, если можно. Вопрос у меня следующий. Вообще, одна из проблем Eventsourcing является то, что постоянно, каждый раз, когда мы получаем новый ивент, не всегда, но часто приходится прямо перечитывать всё с самого начала, всю историю ивентов, чтобы получить нужное состояние объекта. Я часто слышала эту проблему от людей, которые хотят использовать Eventsourcing. Что ты думаешь по этому поводу? В первую очередь, конечно, важно понимать, что в принципе варианты решения таких задач у ребят в Eventsourcing есть, там есть те же снапшоты, что не нужно переигрывать всё. И опять же, если у нас есть уже какой-то стейт, какой-то базы данных, то если пришёл новый ивент, то в принципе перечитывать ничего не нужно. Нам просто нужно применить через агрегат, если используется DDD или ещё что-нибудь. Разные есть мнения на эту тему. То есть можно накатить ивент на стейт. Можно. А в твоём мнении, какой подход лучше? Или для каких конкретных случаев, какой подход лучше? Мне кажется, что при всей любви к изначальным Eventsourcing, проблема в том, что она заставляет нас заранее определить фактически доменную модель. Мы, конечно, можем её поменять потом и переиграть её, но мне всегда не нравился этот момент, что нужно взять и переиграть все события, чтобы получить доменную модель. И возникает, естественно, проблема, например, с чем отвечать пользователям, пока у нас она не перестроена, потому что она занимает время. Это один момент. А второй момент в том, что если мы принимаем эти Events и по факту вынуждены сразу что-то строить, это на уровне психологическом сужает наше понимание доменной модели. То есть мы уже выстраиваем эти таблицы, если я так скажу, таблицу на базе данных. И это просто сужает наше понимание того, что возможно с этим сделать. И это, опять же, требует активного вовлечения в дизайн модели данных. То есть, грубо говоря, у нас есть какие-то Events, связанные с регистрацией пользователей, чтобы не уходить далеко. И мы должны взять все данные, которые пришли из них, скажем, имя пользователя, пароль, дата, все это как-то сложить в реляционный обзор данных, чтобы потом делать запросы туда. То есть это требует сразу построить какую-то достаточную модель данных. Идеи, которыми я пытаюсь сейчас заниматься, говорят фактически о том, что когда мы выбираем какие-то данные, мы выбираем только то, что нам нужно сейчас. И как я туда пришел, я просто пытался понять, что вообще происходит у меня в Events системе. А то, что происходило, было очень просто. Что я беру Events, я их раскладываю в какие-то модели данных, скажем, в Postgres. А потом, чтобы найти какие-то данные, я все равно вынужден их индексировать в том же Postgres. Потому что, естественно, перебирают просто напрасно какие-то модели. И идея была, что они попробовали нам просто убрать, скажем, реляционную или любую другую базу данных, как middleman, между Event и Index, просто вычеркнуть и оставить только события и только индексы. И искать исходные данные, определяя наши запросы как темпорально-событийный набор фактов. Кто такой пользователь? То есть человек, который сделал то-то, то-то и не был удален, например. Я, наверное, немножко упрощаю все это дело для разговорного формата. И мне кажется, что это дает гораздо более открытый инструмент к моделированию разных ситуаций, моделированию разных возможностей. И для меня лично он убирает design anxiety. То есть если я вынужден писать схему всего, что связано опять же с теми пользователями, мне хотелось бы максимально приблизиться к идеалу с самого начала. Понятно, что это все равно невозможно, все равно психологически хочется создать что-то более-менее приличное. В случае с этим лэйзи-подходом я просто записываю то, что приходит. То есть практически as is. Понятно, что я все равно принимаю какое-то участие в создании собственно структуры этого события или факта, но при этом я не пытаюсь сразу вывести какую-то модель из него. Я просто откладываю это, насколько я это могу. Естественно, надеюсь при этом, что часть данных вообще не появится, и соответственно часть решения мне никогда не понадобится принимать. Но это же trade-off latency ответа. То есть когда тебе понадобится ответ, тебе в этот момент придется принимать решение, что стройки, как это строить. И собственно основная бумажная работа, которой я сейчас занимаюсь, это просчет и анализ, какие максимально эффективные индексы я могу построить в плане того, чтобы максимально быстро найти ответы на запросы, которые максимально часто возникают в таких системах. Опять же в системах, которые я пишу. То есть я хочу понять, как их максимально эффективно исполнять, чтобы не было нужды в большинстве случаев что-то заранее выстраивать для них. Понятно, что есть исключения, без них никуда. И естественно где-то нужно будет фактически кешировать в том плане, что нужно сразу будет какие-то модели просчитать, закешировать. Но это как бы неизбежность дизайна любых серьезных систем. Но как общая ментальная модель я хочу перейти от построения то, что называется eager domain binding на deferred domain binding. Слушай, ты мне сейчас доказал, что lazy это нормальное название для этой темы. Я имею ввиду lazy events, даже нет? Ну lazy может быть правильно, events наверное неправильно. Может быть, да. То есть это ленивые модели данных, я не знаю даже как это правильно сказать. Я до сих пор пытаюсь найти название, я сейчас кручусь вокруг слов типа fact, domain, inference, но это пока еще точно не соскакивает с языка, поэтому я все еще. Второй довольно большой проблемой в eventsourcing является разное версионирование. Потому что зачастую трудно представить модель в том виде, в котором она будет постоянно. И она часто меняется, какие-то новые поля приходят, еще что-то обновляется. И как эту проблему ты решаешь и какие вообще пути решения этой проблемы ты видишь или из своей практики ты видел, что бы ты мог порекомендовать? Если касаться именно самого eventsourcing, то есть то, что понимается под eventsourcing, понятно, что там есть свой массив инструментов со всеми кастингами версий. Во-первых, понятно, что есть версии еще и самих событий, и есть, понятно, версии доменных моделей. Насколько я понимаю всю эту модель, по-хорошему с версиями доменной модели надо просто, по сути, переигрывать. Либо делать умные эмиграции, где можно добавить модель для того, чтобы не переигрывать все события на полный набор данных, а только на те данные, которые новые пришли или которые мы раньше не доставали и не клали в доменные модели, а теперь будем класть. Это прям пугающая история, попробуй сделать такую эмиграцию без остановки системы. Я просто об этом думала и у меня как-то волосы зашевелились от этого всего. Если немножко eventsourcing оставить в покое, то на самом-то деле подобные вопросы Google решал, у них даже был paper, где они даже показывали, что любую эмиграцию можно разбить на набор, или почти любую эмиграцию можно разбить на набор шагов, которые приведут систему в нужное состояние, и все они не блокирующие с точки зрения... В этом прикол что? В этом таблице. Именно в eventsourcing я вот поэтому и делаю акцент. Нет, ну понимаешь, eventsourcing же по большому счету, у тебя есть слог событий, ты по ним устроишь какой-то, ну, по большому счету индекс, и потом тебе нужно смигрировать индекс. Ты имеешь в виду, что он мало отличается от остальных систем или что? Ну, это как бы чисто технически отличается мало. Там дальше вопрос в том, что если у тебя какая-то одноцельная система, то в ней, возможно, такой вариант как-то можно написать, что там типа оно не разваливается на плесень или пупырь мед. А если это собрано из, не знаю, разных кусков, и ты что-то такое попытаешься сделать, там на самом деле, понятно, можно налететь на какие-то неприятные разъезжения данных, проблемы с консистентностью, просто где-то немножко не подумали и получилось ой. То есть тут в этом смысле как раз специализированные решения типа PointPuDb в будущем могут помочь решать именно проблемы того, что инварианты на систему должны писаться в одном месте, и миграции должны, даже если она каким-то гибридным образом накатывается, где-то там перечитывается история, где-то просто индексы мигрируются. Вот если это миграция, описанная в одном месте, которая имеет осмысленные инварианты относительно того, как состояние системы должно измениться, то хорошо, когда и какая-то единая красивая система может эти инварианты проконтролировать. Это такая хорошая история, но звучит она довольно теоретизированно, потому что я бы хотела услышать практически примеры того, как это происходило, потому что даже вот, например, с SQL базами данных есть готовые инструменты, которые помогают тебе держать версионирование в порядке. А что есть из такого для Event Sourcing? И мне кажется, ничего пока нет. Ну, с моей стороны как раз большая часть пожеланий, которые у меня были, к тому, чем я занимаюсь, это, собственно, было связано с версионностями, потому что в самом корне того, чего я пытаюсь решить, я пытаюсь снизить стоимость решения, точнее не стоимость, а импакт тех решений, которые я принимаю. То есть если я принял какое-то решение, я не хочу, чтобы оно мне потом обошлось очень дорого. И вот, скажем, в концепции VDB, на которой я сейчас страдаю, я вот, например, разбил, собственно, факт. Она множественной атрибуты, то есть факт не является просто там один кусочек данных, скажем, JSON или еще что-то не очень важно. Факт — это просто что-то проидентифицированное, про которое сказано много атрибутов, то есть такие statements. И идея в том, что, например, если мы говорим о версированных данных, то тут, в принципе, особого вопроса не возникает. То есть если мы говорим о моделях доменных, то мы просто меняем наш набор запросов, который приводит нас к доменной модели, и это уже новая версия. То есть она не требует, по сути, модификации каких-то доменных моделей на диске. А что касается фактов, что гораздо более интересное, то здесь получается такой момент, что так как факт разбит на отдельные атрибуты, то мы можем по-хорошему развивать схему факта как набор вот таких трейдов, что вот этот трейд содержал такие-то атрибуты, этот трейд содержал такие-то атрибуты, и развивать то, чем мы можем наполнить какой-то факт, не затрагивая, по сути, того, что было раньше. То есть когда мы будем делать запросы, мы можем делать, который сможет выбрать все версии фактов, и в них набор трейдов опадает. То есть, грубо говоря, все данные, которые у нас были раньше и продолжились до конца, мы можем построить и на запрос на измененные, или точнее, добавленные, то есть вышший факт. Понятно, что есть свои интересные случаи, когда мы перестаём собирать какие-то данные, по какой-то причине перестали ходить к нам, или нету ценности никакой в них, но это уже отдельный момент, который мы тоже пытаемся рассмотреть, пока нет никакого конкретного решения на эту тему. Но мне кажется, это интересно рассматривать, потому что, в принципе, мне кажется, что версии — это очень понятное внутреннее для нас, скорее, как для людей. Мы их видим линейно, по сути, но версии, если рассматривать как наборы, субсет атрибутов, они по сути своей не линейны. То есть, если для одного факта мы собрали один набор атрибутов, большой, скажем, а для другого факта, даже позже по времени, собрали другой набор атрибутов, меньше, там, сет какой-то, то, в принципе, как понимаете, версионность? Является ли она разными версиями, или это просто разный набор атрибутов, которые мы можем запрашивать? То есть, является ли вообще версия просто некоторым упрощением ментальным, которым проще думать нам, или является чем-то таким более встроенным в модели событий, которые мы строим? Мне кажется, ещё не до конца у меня этой вопросы, в том числе, исходя из того, что разные люди по-разному понимают, что такое версия. Насколько я общался с людьми, нет общего понимания, что именно является версией чего-либо, в принципе. А скажи, пожалуйста, сколько людей работает над этим проектом сейчас? Сейчас, условно говоря, полтора. Весной чуть больше было. Сейчас у всех свои разные задачи. Сейчас в основном я и ещё немножко один человек со мной занимается, то есть немножко кода и по обсуждениям, по каким-то там дизайн моментам. То есть пока это всё очень маленькое, просто это, понятное дело, экспериментальный проект. Собственно, хотел спросить, второй мой вопрос был, который я ещё не успел спросить. Это, собственно, в рамках чего это делается? На какие деньги это живёт? Или на каком энтузиазме это живёт? Пока это живёт на мои деньги, и плюс там чуть-чуть приходит через Open Collective. То есть у нас есть страничка или pumpkin.db на Open Collective. У нас, собственно, один, по-моему, контрибютер. Ну это не серьёзные деньги, это 75 долларов, по-моему, в месяц приходит. Иногда оплачиваем сервер, который берут, разрабатывать всё, что связано с SSD. На Linux, потому что у меня не Linux машина. А так пока, да, в основном мои деньги. А нету планов для привлечения инвестиций, например? Для инвестиций пока нету. Мне кажется, об этом пока думать рано. Я хочу довести это до какого-то кейза, где это уже можно по-серьёзному шокизить. Пока это просто экспериментальная удочка заброшенная. С одной стороны, конечно, можно попытаться условно продать это как, ну опять же, продать в кавычках как open-source datomic. Но опять же, datomic это только с точки зрения как устроены данные. Я, например, совершенно не занимаюсь пока историей с распределёнными транзакциями и тому подобное. Я пока не вижу особого смысла это делать. Я смотрел вокруг, в принципе, да, есть набор компаний, которые занимаются базовыми данными. Но это достаточно тяжёлое дело с точки зрения строить бизнес вокруг этого. Мне кажется, что скорее проще профинансировать это, когда там pumpkin db и udb дорастут. То более-менее production варианта. И когда они будут частью очередного проекта, которым я или кто ещё будет заниматься. И это просто будет возможность профинансировать те или иные работы. А знаешь ли ты сейчас, какие компании, другие люди используют pumpkin db для своих pet-проектов? Либо для чего-то более существенного? Я не знаю. Вряд ли что-то серьёзное происходит. Опять же, от анонса до сейчас прошло не очень много времени. Я знаю, что несколько людей туда-сюда игрались. Некий объём хайпа был случайно сгенерирован в феврале. Мы получили несколько сотен звёздочек на гитхабе. Но это как было. А как это вы его сгенерировали? Как это вышло? Это было совсем случайно. Мы выпустили первый релиз 0.1. И просто запустили на Reddit и на Hacker News. И как-то оно попало. И принесло на тот момент, по-моему, за неделю 600 звёзд. Что ещё помогло? Мы из-за этого попали в db и выехали в рассылку. Я точно знаю, что наш спонсор, который у нас есть, пришёл через эту рассылку. За что им большое спасибо. Но как-то это всё было не спланировано. Это просто какой-то аудит. Просто так получилось. Целенаправленно они занимались этим. А у тебя есть какое-то понимание, куда проект дальше развивать? И в плане того, как на это начать зарабатывать? Как я говорил, я не думаю, что прямо сейчас, именно на самом проекте, проект as is, можно зарабатывать. Даже если бы он был доведён до хорошего состояния. Мне кажется, что реальные деньги лежат в задачах, которые он помог бы и мне решить. Просто в плане скорости и качества написания продуктов. В плане того, чего делать. Я недавно публиковал небольшую статейку, такой условный roadmap. Понятно, что там вопросы со стабильностью, вопросы с UDB. Интересные задачки возникли. Например, хотим доделать типизированный pumpkin script, который позволит на этапе... Ну, не компиляция, там компиляции нет. Но перед тем, как интерпретировать любой скрипт, можно сказать, он имеет смысл или нет. Интересные такие задачки возникают. Это пока как milestone. На заработок пока ещё... Я не думаю, что там что-то есть пока. Слишком рано. Ты же сам используешь pumpkin db для своих... Для своих внутренних задач использую. Так как у меня сейчас, по сути, своих коммерческих проектов нет. Пока есть только наброски на то, чем я в будущем буду заниматься. Я курсирую между прототипами и pumpkin db. Я смотрю, как pumpkin db к ним применяется. Получилось что-то, не получилось что-то. Если не получилось, то back to the drawing board и выяснять, чего можно делать дальше. И, наверное, последний мой вопрос по поводу event sourcing. Поскольку, очевидно, у тебя намного больше опыта с этой концепцией. А может быть какие-то советы людям, которые думают использовать event sourcing? Или, например, какие-то красные флаги. Например, для какого-то конкретного кейса никогда в жизни не используйте event sourcing. Либо для какого-то конкретного кейса используйте его обязательно. Что-то из практики, что не то, что бы очевидно с первого взгляда. Не знаю, очевидно или не очевидно. Но, например, есть ряд убеждений, которые достаточно общие в event sourcing community, которые хотелось бы зачеланить. Например, Greg Young, один из главных известных фигур в этой концепции. Он, например, утверждает, что event sourcing не должен быть применен везде, во всех частях системы. Что нужно компонентно применять его. То есть где это полезно, где это бесполезно. Я лично и у меня есть еще коллеги, которые занимаются обычным классическим event sourcing. Мы считаем, что на самом деле, если серьезно задуматься, то event sourcing можно в принципе встроить практически в любой бизнес-процесс. Вопрос, конечно, заключается в изначальной дополнительной стоимости этого процесса. Понятно, что если начинать с нуля, то это очень сложно все перевести туда. Но мне кажется, что важно рассматривать event sourcing не как инструмент для специальных задач, а как подход вообще к интерпретации мира. Понятно, что мир никогда не является стейтом, нет стейта реальности вокруг нас. Просто есть некий поток, что-то происходит совершенно параллельно. И соответственно любые business-процессы могут быть описаны в событийном характере. И записывать можно и быстро и дешево, и тиски дешевые, и скорость записи очень высокая. В принципе терять данные, перезаписывая их, особого смысла нет. Понятно, что этот constraint существовал в 70-80-90-е даже в некоторых объемах. Но сейчас терять данные просто потому, что база данных имитирует концепцию состояния, она лично для меня выглядит жарной. Соответственно, если даже не реализовать какие-то подсистемы, как event sourcing, то мне кажется, что это очень помогало бы просто сесть и подумать о каждой подсистеме. А что если бы мы ее дизайнили в таком виде? Как бы она выглядела вообще? Какие у нас происходят вещи тут? Это позволяет увидеть другую природу немножко. События, процессы, что происходит, что мы делаем с данными, и вообще, что у нас за business-процессы. Слушай, мы тебя еще не достали, потому что мы тебе обещали отпустить пораньше, а мы тебя мучаем уже полтора часа. Если хочешь убежать, у тебя сейчас хорошая возможность что-нибудь попиарить и убежать. Ну, пока еще не очень замучаю, я могу еще немножко повисеть. Мы будем тогда мучить дальше. Да, но я думаю, что минут 20 у меня еще есть. Ну и хорошо. Отлично, может тогда по другим ссылкам пройдемся, которые ты дал? Потому что там куча всего непонятного для меня. Можно и по другим пройти. Я бы лично хотел пропиарить C4. Давай. Это совершенно не моя тема изначально. То есть, я не автор этого всего дела, но я могу небольшой ввод дать, откуда оно ко мне пришло. Есть такой проект ZeroMQ, наверное, в принципе, все знают. Или почти все знают ZeroMQ. И был у них лидер проекта Питер Хинченс, который, к сожалению, в прошлом году умер. И хотя он был, конечно, и программистом, но он просил, чтобы его запомнили как писателя. Он много говорил и писал о том, что создание софта — это в меньшем мере о софте самом или написание кода или еще чего-нибудь. Это, в общем-то, о людях. И у него было несколько интересных токов, которые на Ютубе можно найти, по поводу того, как создавать сообщества, communities в опенсорсе и как привлекать людей. И мне кажется, эта тема очень важна, особенно в наш век сейчас. Я помню, когда я начинал заниматься опенсорсом в конце 90-х, может быть, в начале 2000-х, картинка была совершенно другая. То есть, если кто-то что-то публикует... Во-первых, у нас фрешмит был. То есть можно было каждый день знать, что происходит, в общем-то, почти везде. И проектов было не так много, и шума было меньше. То есть найти что-то было в некотором смысле проще. И если создаешь какой-то проект, найти людей, которые услышат о тебе и придут хотя бы посмотреть, что у тебя было создано, было гораздо проще. Но сейчас производится все с совершенно невероятной скоростью и очень много всего сразу. И это приводит нас к проблеме в том, что за внимание людей надо бороться. И если нет людей в проекте, если нет целого потока контрибьюторов, то в сути эти проекты рано или поздно умирают. И как бы нам эту проблему решить? Как бы нам привлекать людей? И вот первая вещь, которая меня зацепила в мыслях и идеях Питера, в том, что было очень интересно. Когда входит pull request, вместо того, чтобы критиковать его и разбирать, делать его диаграмму, сразу и мёрджи. Идея в том, что у нас всё это в ките, правильно? Историю всегда можно изменить, откатить, ничего страшного не происходит в том, что если бы сразу мёрджим. Идея за этим такая, что это создаёт позитивный фидбэк. Мы все были в проектах, когда засыпаем pull request, может быть, кто-нибудь через месяц проснётся, скажет, что мне это не нравится. Или это не совпадает с моим видением, или ещё что-то такое. Или просто не ответят вообще. У меня какое-то количество pull request висит до сих пор, которые никому не стали интересны. Или начну сильно критиковать до такого момента, что в принципе уже ничего не хочется делать, не хочется уже контрибьюти. Разные возникают сценарии. И его идея была дать вот этот кик, чтобы человек позитивно ощутил своё влияние на проект, а дальше уже можно общаться. Если что-то не понравилось, самый простой способ изменить это – прислать ещё один патч. Чтобы кто-нибудь другой, другой мейнтрейнер ещё замёрзнул его. И, соответственно, таким образом можно реализовать модель, в которой мы избегаем ситуации, когда дёшево что-то сказать, но дорого что-то сделать. Очень дёшево сказать, что мне нравится это, не нравится то. Вопрос, действительно ли это настолько плохо для проекта, в твоём понимании, что нельзя пропустить вот это в этом патче. Идея такая, что если действительно плохо, то это должно быть настолько плохо, что человек, который заметил эту проблему, должен прислать свой патч, который исправит это. А если он не пришлёт, значит проблема того не стоила. Убирает это как бы зону конфликта, и по моим даже ощущениям это позволяет частично решить проблему с Code of Conduct, потому что Code of Conduct решает проблемы после того, как они, по сути, происходят. Что нельзя делать вот это, нельзя делать то, надо разбирать ситуацию, когда произошла проблема. Подход оптимистичного мерджи позволяет избежать конфликтов изначально, потому что мы, по сути, убираем гейткипера. C4 это формализация этого подхода, не только по поводу мерджи, но в основном, какого мерджи, и несколько идей рядом, конкретный набор правил, к которым можно даже сослаться и знать, как оно работает. Мне это кажется очень важным, потому что, когда приходишь в очередной проект, во-первых, нет у всех времени разбираться, как каждый проект работает. А если в проекте есть какое-то описание, какие у нас процедуры, как мы делаем вот это, как засылать pull request, что в нём должно быть, это существенно упрощает жизнь. C4 описывает набор, начиная с optimistic merging и заканчивая, как мне кажется, другой очень важной темой, это способ написания commit messages, в которые я изначально туда влюбился и до сих пор использую с большим удовольствием. Подход очень простой, в первой строчке написать problem и очень краткое проблему, которое этот commit решает. Потом можно, понятно, развернутый написать, а вторая часть в commit message это solution и, собственно, как мы эту проблему решаем. Это даёт огромное наполнение, то есть это, во-первых, даёт контекстную информацию по любому изменению, зачем это вообще было сделано, и это даёт огромное понимание, зачем был прислан pull request. То есть вместо того, чтобы описывать, что было изменено, описывается, какая проблема была решена и как. Я ещё слышно? Да, да, просто как-то. Я думал, что кто-то ещё что-то спросит, но видимо нет. Но, на самом деле, я лично очень сильно согласен вот с второй частью про commit message. Про pull request это, наверное, зависит от проекта, потому что большинство проектов действительно пострадает, там вот с другой стороны в какой-нибудь postgres там другая крайность. И вот если так просто задуматься, то проект, в котором годовые кольца кода на C, наверное, тяжело как-то иначе развивать. Ну, понятно, что есть у всех своё легэти. Мне кажется, самая главная проблема даже не в самом коде, а в традициях, собственно, как код приходит в проект. Соответственно, если бы писали и администрировали его одним способом, то меняв его сейчас, там будет огромное количество трения, это очевидно. И я опять же в своих проектах пытаюсь сразу внедрить эту модель, чтобы просто потом не думать о ней. Но опять же, идея такая, что в принципе истории версии сломать по сути ничего невозможно, если что-то замёрзшили. Всегда всё откатываем, правильно? Если только у нас не построено, что мастер каждый день релизится, то в общем-то проблем я не вижу. По моему личному опыту я иногда всё равно пытаюсь обсудить с теми, кто засылает pull-request, их request, но в очень минимальных моментах. То есть если что-то совсем off, я просто предлагаю либо сразу, мы решаем эту проблему, если чек недоступен, то сразу не отвечает, я просто за чека поправлю этот момент. Либо в commit-мерж, в смысле в мерж-коммите, или отдельным чем-то, зависит от уровня этой проблемы, если одну букву поменять или что-то не хватает, то я просто от его же имени маленькое исправление сделаю, так чтобы совсем не сломанное было. А если большое изменение, то я замёрзшу и зашлю свой патч, просто как follow-up. Помимо наблюдений со всеми, с кем я общался, в целом воспринимается как позитивный процесс, потому что нет разговора туда-сюда, особенно тяжело вести такие разговоры, когда разработчики разных контактов мира, и соответственно лаг мерзнет. Между вопросом и ответом, по полдня, по дню, и растягивает разговор на вечность. Когда мердж происходит моментально, мне кажется, это создаёт другие incentives, это убирает понятие гейт-кипера. Когда считают, что мейнтейнеры, грубо говоря, старики проекта, и они знают лучше, и они имеют некое право быть гейт-кипером, что входит, а что не входит в проект. И понятно, что это большой философский вопрос, должен быть гейт-кипер или нет. Но если хочется создать окружение, которое привлекает людей и убирает причины для потенциальных непониманий конфликта, то это интересный подход, мне кажется. Ну короче, ТЛДА, мне кажется, любой молодой опенсорс так делать должен, а тот, который старый, может еще повепендриваться. Я думаю, что в поздгаре, чем меньше контрибьюторов, тем лучше, чтобы их не доставали. Понятно, что в любом проекте есть свои специфики, особенно если это старый проект, я думаю, что им особо меняться не надо. У них есть свои проблемы, они сами их решают, но мне кажется, это было бы неплохо, если бы мы могли передавать эту информацию о таких концепциях, о подходах в более широкие массы комьюнити. Потому что чаще всего я сталкиваюсь именно с ситуацией гейт-киперов. В принципе, больших причин, почему изначально автор должен быть гейт-кипером или нет, в принципе нет, по-хорошему. Если за модель мира принимать, что люди в целом делают хорошие вещи, то гейт-кипер это позиция, которая по сути уменьшает дайверсити. Если затронуть немножко тему дайверсити, она ведь по сути не о цвете кожи или ориентации, а на самом деле о дайверсити в идеях. Потому что люди с разными бэкграундами, с разными пожеланиями, настроениями и так далее, их идеи будут отличаться от идей гейт-киперов. И вот это, мне кажется, важный момент. Потому что как только возникает гейт-кипер, у него осознанно или неосознанно, в любом случае, будут байосес. Не помню, как это называется. Но они будут уже просматривать любые эти контрреволюции через разнообразные призмы своих предпочтений и байосес, которые они имеют по отношению к миру, потому что все имеют байосес. А если правило состоит в том, что мы всегда мерджим к миду, то это убирает возможность для ограничения дайверсити идеи. Может быть, но мне почему-то тяжело обхонять эту мысль. Я всячески плюсую по поводу идей о дайверсити. Я просто сама с этим сталкивалась и я очень хорошо понимаю, о чём сейчас говорит наш гость. А что такое CI наоборот? Другая ссылка. Вот да, я только хотел как раз спросить. CI наоборот, это был просто экспериментальный проект, просто попробовать, как это будет выглядеть. Идея была банальной, наверное. Я просто пытался использовать разные CI-системы на протяжении последних лет. И Дженкинсы, понятно, и чего там только не было, и последний конкурс, и ещё что-нибудь. Но что я заметил, что они всегда выглядят как, наверное, самое лучшее слово, которое можно подобрать, как framework.",
    "result": {
      "error": "API request failed: Error code: 400 - {'error': 'Trying to keep the first 15318 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': 'Trying to keep the first 15318 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}\n"
    }
  }
]
[
  {
    "segment_id": "d98c964e-8cd1-4e06-bf88-cfdb99fdf2b4",
    "episode_id": "ae35d15c-e4b4-40ea-a84c-4530eef08725",
    "episode_number": 318,
    "segment_number": 24,
    "text": "Это та же тема, на самом деле она еще тоже на два часа, поэтому, мне кажется, можно уже расстаться с мыслью о том, что мы не укладываемся по времени. Да, вы точно не укладываете. Я как раз таки просто хочу свернуть тему совсем кишочных дискуссий и как бы с твоего угла спросить вопрос, потому что мне тоже интересно послушать. На самом деле это тоже кишочный вопрос. То есть вопрос был на самом деле про то, что мы говорили про то, что есть разные семейства промитивса, есть там таймскилл, кортекс, стагнелли. На самом деле все эти решения, да, наверное, за некоторыми исключениями, они все используют так или иначе промкиллежок самого промитивса. То есть, большинство из них тоже написано на год, и прямо их пакет берут и используют. Виктория Метликса написала собственный пакет, они потом его инвесартируют в самом начале, и вот так называют или нет. Сейчас он называется MetrixQL, то есть не промкилл, а MetrixQL, то есть, типа, язык совместимый и является там супермножеством языка запросов промитивса. До этого мы, кстати, еще... Леша отвалился. Да, это что-то... что-то не добру. Возможно, у него тоже есть какой-то DPI, который отключает Лешу, когда он начинает спрашивать сенситивные какие-то чувствительные вопросы. Вообще, да, конечно, такой ключевой момент пропасть надо было. Я хотел сказать про драмму, на самом деле, только я подошел к драмме, так как меня отключило. DPI, я же говорю. Вот, да, короче, к вопросу о том, что позволяет держаться компанией Polymetrix на полу, это количество драммы, ассоциируемой к нему с ней. То есть все вот эти вот люди, они как бы взяли промкейль движок, как есть, и его используют. У них 100% совместимость. Polymetrix взяла свою собственную совместимость, и это постоянный какой-то источник какой-то перепалки, я не знаю, в титре, на медиуме, в комментариях, на гитхабе, в вышесах и так далее. Валер, можешь про это всем сказать? Да, могу рассказать. Вначале наш движок назывался Extended from KEO, но это не понравилось разработчикам Prometheus, они с нами связались и сказали, настойчиво рекомендовали переменоваться под угрозой там всяких лыр, и сами, кстати, подсказали как название. Dmitriy Skviov это Brian Brazev, это разработчик Prometheus, это его идея, как называть движок, язык запросов наш. Так что можно написать ему благодарность. Так вот мы его переименовали в Metrix KEO, и да, там частично есть какие-то несовместимости с Prometheus, но эти несовместимости сделаны намеренно, потому что в Промкейле пользователи сечение времени обнаружили какие-то части, которые работали не так, как мы ожидали пользователи. Например, там функция Rate, там при увеличении масштаба, когда вы там делаете Zoom In, иногда перестала возвращать данные. То есть вы смотрите, хотите посмотреть, что у вас там произошло на минутном интервале, с часового интервала, вы включаете на минутный, и видите, что у вас там данные пропали. Вот так вот там Prometheus работает. Еще, например, пример функция Increase, есть такая функция, которая возвращает разницу между начальной точкой и конечной точкой, там на интервале, который указан в параметре этого Increase. Например, если хотите узнать, сколько у вас там трафик было из расходов за последний час, Increase пишет в квадратном скобке один час, и видите, сколько у вас там трафик было из расходов за последний час. Вот так вот работает. Но в Промкейле эта функция может возвращать дробное значение для целочисственных изменений временного ряда, что пользователь ставит тупик. Например, если у вас там количество запросов в секунду, вы меряете, да, я хотел представить, количество у вас там за последний час пришло 10 запросов. Вы делаете Increase за последний час, а он показывает 9,5, например, что такое, как там уже 9,5 запросов. Вот такие вот особенности реализации Промкейла, они не нравились. Ну, и до сих пор не нравятся разработчикам, а пользователям Промкейла. Но разработчики не хотят фиксить это, потому что говорят, что это же обратная совместимость поломает, и так должно работать, вообще вы пользуетесь не правы, правы мы разработчики. Ну, давай я в этом месте ворвусь. У нас вот пмм, много постей, много фейбэк-постей идет ровно по всем этим более точкам, которые сейчас я перечислил. То есть ты реально смотришь на графику, ага, отлично, давайте как фильмом, Enhance, Enhance. Вот увеличиваешь, и все пропадает. И дальше выясняется, что это значит, там, такая вот, значит, особенность промитpowerоWance, разработчики промит komplett правильно показывают пальцем на графон, разработчикиounce достаточно правильной показielen на промит acontec уровней, вот это, как бы, кesele svki которые, чтобы у нас есть какая-то функция которая, и birthоWance вам нужно написать и BADCày, большое выражение, или Liam, на большое, strategies ль же выражение. еще там, правильно поставить интервалы, еще правильно Yuan от Hacken, а dubbed, и тд, join, Was Brown confirming against 11, да.Classified yeah, коробочный прелок как, не знаю, как PMM, это возможность сделать, да, это очень сложно, а если, вот, как бы, нормальный человек захочет написать какое-то более-менее там, стимуальное выражение, ну, даже среднего сложности выражения, это удивительно сложно, вот, и вот в этом месте разработчики промит, мне кажется, свою, как бы, свои худшие черты, вот, в плане упертости, вот, мы, мы знаем, как это должно работать, это вот, правильно, это вот мы сидим в своей башне сломала кое-что, и мы нашим, абсолютно идеально математическую модель, то есть, как бы, они, так сказать, они правы, да, в каком-то абсолютном смысле, но с фрегматичностью у них явно есть проблемы, то есть, количество всяких не очень красивых дискуссий у них вычет лекарем довольно велико, когда люди приходят, говорят, с циклярными проблемами, предлагают реальные решения, там, вот, был пропозал про функцию X-Ray, который бы эти проблемы решил, они это, то, все отказывают, и, кроме Метрикс, помимо все прочего, то, о чем вы говорили раньше, мне кажется, еще вылезло на том, что они все эти практические решения, просто, мне кажется, собрали и все реализовали, то есть, как бы, вот, все вещи, все вещи, которые, вот, у нас болели, они все решены, не только Метрикс, насколько я знаю. Да, мы в этом плане более идем по поводу пользователей, стараемся идти, если, конечно, если пользователи предлагают какие-то идеи, которые выглядят с драмами для нас, то стараемся их реализовать. Можно здесь сразу вопрос? У меня сразу вопрос возникает такой, что это же имеет и обратную сторону, скажем, если вы реализовываете эту проблему, то получаете автоматически то, что ваш продукт ведет себя не так, как ведет себя Prometheus, и, как следствие, если люди просто переставили одно на другое, фактически в графане нужно там поменять настройку, у меня был там сервер там-то, теперь сервер там-то, оно начинает работать не так. То есть, даже мы столкнулись с этим на нескольких, в нескольких случаях, и это вызывает удивление. То есть, с одной стороны, я понимаю, вы решаете проблему пользователя, а с другой стороны, вы меняете поведение системы, и это совсем неожиданно, и этого бы не хотелось. У меня был такой вопрос, если RAID ведет себя не так, как вы хотите, но почему вам не сделать RAID 2? И пусть RAID ведет себя точно так же, как ведет себя в Prometheus, а RAID 2, если ты хочешь поменяй на RAID 2, он будет вести себя лучше. Да-да-да, я согласен, что было бы лучше, если мы стали функцией RAID 2, и increase дала, и которые бы работали так, как пользователи хотят, чтобы RAID и increase были совместимы полностью с Prometheus, с реализацией. Более того, это же можно автоматизировать, то есть, вы можете дать скрипт, который всю графану прибежит, и везде, где используется RAID, поставит RAID 2. То есть, если пользователь хочет, он это может поменять одной кнопкой. Да-да, есть такое, но, к сожалению, уже поздно что-то менять, я думаю, потому что многие пользователи Victoria Metrix полагаются на текущее поведение. Подожди, ты хочешь сказать, что разумочки Prometheus не сделали это из обратной совместимости, теперь вы это не делаете из обратной совместимости? Ну получается так, да. Потом придет третий продукт к вам и скажет, что у вас неправильно. Мы сделаем лучше и всех клиентов уведет. Не, разработчики Prometheus просто отказывались добавлять XRAID функции, мы не отказываемся добавлять XRAID или RAID 2 функции, просто уже поздно. Но если надо будет необходимость такая, то я думаю, что можно добавить. Да, Вань, ну вообще отвечаем за вопрос, это вот интересный момент, мы тоже с этим столкнулись, то есть со мной свое поведение меняется. А за ростом ты начинаешь смотреть на каждую конкретную ситуацию, понимаешь, что каждая конкретная ситуация стала лучше. Если бы это был General Porthos база данных, прикинь, ты берешь базу данных, пишешь в нее данные, достаешь другие данные, это было бы натрашно, мягко говоря. А за счет того, что мы знаем, что это там Serious база данных, что это там Serious база данных не для бизнес-эвентов, для метка телеметрии и так далее, то есть я думаю, что весь этот бизнес-эвент написать, наверное, тоже был бы немножко не очень хорошо. Но поскольку мы знаем, что это данные телеметрии, они там вот так вот округляются, вот так вот округляются, и если мы знаем, что мы применяем вот такую функцию, то типа она будет лучше только, то за счет этого можно сделать всякие афемизации. Я, кстати, тут искал, искал проект, есть даже такой отдельный проект, называется Trickster, я уж не знаю, он еще живой, нет? Ну хотя, судя по комитам, что-то еще происходит. Это такая прокси, которая ставится перед промитивом и пытается большую часть этих проблем решить. Он там границы нормализует, загадывает вперед немножко, вперед-назад, чтобы там правильные точки были и так далее. То есть понимаешь, эти проблемы реальные, люди реально как бы этот какус едят уже пару лет, если не больше. Я бы еще хотел добавить, что это разница, когда ты меняешь data source и у тебя чуть-чуть меняется график. Она, возможно, видна только, если ты переходишь с промитивусом. То есть четкая связь, ты перешел с промитивусом на Victoria Metrix и поведение поменялось. Как Саша сказал, подход направления компании чуть поменялось с начала года, и Victoria Metrix, это не просто TSDB, это решение для мониторинга. И есть люди, которые переходят с Influx, с Graphite, и для них это уже нативное поведение, то есть родное. Они не знают, что не так работало или работало с какими-то допущениями. Это уже как бы следующий шаг. Не обязательно быть с помитивусом, потому что всегда в этом есть здравый смысл. Не всегда надо повторять чужие ошибки, просто для того, чтобы быть совместимым другим продуктом. Как следствие, у всех этого поведения есть компания Promlabs. Вообще все разработчики промитивуса сейчас ушли в какие-то свои компании, либо в соседние компании, типа тоже графана Laps. Сейчас все пытаются делать бизнес на промитивусе и его форках. И компания Promlabs, это один из основателей, сделанная Julissa Wals, мне кажется. Это тоже консалтинг в сфере промитивуса. Они поликовали блокпост 1 декабря, хотя странно, в роли 26 ноября, в тексте 1 декабря, но не важно. Примерно в этом время. Про совместимость Prom.Key в разных организациях. Тут если посмотреть, все Cortex, графана Cloud, M3, Prom.Scale, Thanos, все 100%. Я извини, меня слушатели, конечно, проклянут, но гарнитура, она трется, мои уши. Сорян, сорян. Сейчас я пытаюсь, попробую. Все Cortex, M3, Prom.Scale, Thanos, у всех 100% совместимость, а Telemetrix 60%. Если смотреть чисто на цифры, то как? Telemetrix несовместима, как же так? Что же делать? И тут, кажется, борьба будет какая-то вечная. Сейчас, во время, пока вы разговаривали, пошел в Twitter почитать, что там автор Prom.Scale написал. Конечно, там как-то это... Мне кажется, там чувак какой-то пишет, что у вас есть проблема, у вас токсичный маркетинг. Так что выясненого маркетинга у вас вообще особо никакого нет, но он, оказывается, токсичный. Так я думаю, кто это такой? Смотрю, судя по всему, разработчик графита. Ну и вообще, вся эта тусовка какая-то, мне кажется, и он был бы неплохо как-то более дисколлировать на уровень какой-то объективности. Потому что и в ваших блокпостах, мне кажется, и в их блокпостах не хватает каких-то важных деталей. То есть, каких-то параметров конфигурации. В конце концов, вы не думали просто все вместе собраться, полностью прикладывать все детали, не знаю, всех этих бенчмарков, всю конфигурацию со всеми параметами целиком, может быть, не знаю, буквально образ фиртуальной машины выложить, чтобы вообще никаких сомнений не было. Думали над этим. Мы думали сделать собственные бенчмарки и потом предложить всем остальным включать свои решения туда, эти бенчмарки. И эти бенчмарки, скорее всего, будут основаны на бенчмарк сюты, да, фактически, который будет тестировать производительность на ставку, производительность на селепты. Но отличие от текущих всех бенчмарков будет в том, что это будет производиться на данных, которые с продакшн взят. Ну, сейчас все эти бенчмарки генерят данные через рандом какой-нибудь, и это далеко от продакшн. А у нас будут бенчмарки, которые будут сохранять данные с продакшна. То есть, мы вначале соберем эти данные с продакшна, создадим какой-то golden набор датасет, опор данных. И потом бенчмарки будем скармливать его разным решением и смотреть на их поведение, сколько они ресурсов регуляют при записи и потом запросах. И запросы тоже будут браться не абстрактные какие-то, как в TSBS, как в бенчмарки, а конкретные, с наиболее вукулярных дешбордов в графане. Вот есть такие планы сделать такой бенчмарк. Мне кажется, было бы очень неплохо, потому что вот этот уровень фуда, который сейчас есть, он мне кажется довольно велик. Возможно, с одной стороны это, наверное, да, то есть как-то это полезно с точки зрения продвижения продукта, что люди как бы там почитают, как они об этом узнали, а потом пошли попробовали, он как Ваня. И все гораздо проще запустилось, оказалось. Но в какой-то момент, мне кажется, начало отпугивает. То есть вот это вот чистое, опять я здесь смотрю на эту табличку 100-100-100-100-100-60%, это довольно сильно отпугивает. Да, по поводу этой таблички, где там VictorMetrics 60%, если посмотреть конкретно по тестам, там есть можно нажать на ссылку и посмотреть, какие тесты там VictorMetrics не прошли, то можно увидеть, что там большинство тестов, они однообразные, но те, которые не прошли, да, то есть это фактически один класс тестов. То есть они намеренно не будут никогда проходить на VictorMetrics, потому что мы намеренно поломали совместимость с промки овы в этом, чтобы решить болевые точки пользователей. То есть это 40% которые там VictorMetrics не добирает, соответствует парам нескольким кейсам, на самом деле. Ну просто они написали так этот benchmark, то есть этот тест, что вот эти несколько кейсов расписали на 40% всех тестов. Ну то есть тоже неправильно, я считаю с их точки стороны, неправильная конкуренция, но с нашей тоже бывает, наверное. Вообще я бы рассмотрел консорцию промки Эль и выработать стандарт, а потом вам соответственно сказать, что мы этот стандарт поддерживаем, но еще чуть дальше пошли чего-нибудь типа такого. Ну я имею ввиду поддерживайте на 80%, но эта проблема возникает из-за того, что нет описания стандарта, из-за того, что нет описания тестов, то есть не выработать набор тестов, не выработать какие-то бенчмарки, а именно вот пойти с точки зрения спецификации. Может быть, не знаю. Ну вообще я скептически отношусь к стандартам новым. Например, вот сейчас есть пример, промитию разработчики промитию сделали стандарт OpenMetrics называется. Они сделали на основе того, как промитию на основе данных, формата данных, которые экспортятся сейчас стандартными экспортерами для промитию. Но они вместо того, чтобы просто взять и стандартизировать этот формат, то что он сейчас везде используется, он фактически стал де-факто это стандартом, экспортно метрик. Они взяли его, поменяли и поменяли в таких местах неожиданно, что ужас прямо. И типа создали новый стандарт, то есть он выглядит с первого взгляда так же, как и формат, который все используют для экспортеров, но потом если приглядеться, там есть в мелких местах такие несомместимости, что в первый раз их не рассмотрели, и вот я не понимаю смысл этого стандарта, который они сейчас сделали. Как следствие, самое смешное, что промитию сейчас не выдают в метрике в формате OpenMetrics. То есть он сам становится несомместимым с этим стандартом. То есть мне когда кто-то говорит про стандарты или я вижу какие-то новые стандарты появляются, у меня сразу возникает в голове картинка, вот эта кто все знает, наверное, с сайта XACD, там где у нас есть несколько стандартов и они все там плохие, давайте сделаем новый стандарт. И вот там последняя картинка, что у нас есть N плюс один стандартов и все они плохие. Вот такая картинка у меня возникает в голове, когда разговор заходит со стандартов. Причем OpenMetrics это только стандарт именно для формата метрики, то есть это формат данных, просто тексты и строчки и все такое. Стандарт на промкель будет сильно сложнее, потому что там помимо как бы описания функций и все такое, там еще нужно описывать execution model, то есть там может ли этот engine загадывать вперед, загадывать назад, как он должен себя вести, если там данных не хватает и так далее. И это как бы сейчас для всех почти это не проблема, потому что они будут просто использовать готовый код промитию. Да, и по OpenMetrics еще бы хотел сказать, что это стандарт вроде простой, там фактически написывает формат, в котором экспортери отображают данные, которые потом промитию собирают. То есть там текстовый формат очень простой. И метрики в фигурных скобках лейбла, и потом пробелы и значения, floating point число. Но они этот стандарт делали OpenMetrics больше трех лет рожали и в итоге родили какое-то тригнение непонятное. Я предлагаю на этом закругляться, мы проговорили еще полчаса про Victoria Metrics, а я предлагаю, наверное, быстренько, вот Леша что-то хотел про Co1.6 и ARM сказать, мне это очень интересно, поэтому я не хочу это выпускать, а потом совсем Джон, наверное, пойдем закругляться. Во-первых, я хотел рассказать про метрики в Co1.16, но мне кажется, про метрики уже так много, что уже все не могут, слишком много метрик. Там будет пакет Metrics. Да, да. Ну, короче, вышел BetterList Co1.16, BetterList означает, что вся новых еще не будет уже до выхода, выход планируется по расписанию первой ферли, но по факту где-то ферли будет. Не всегда в начале, но ферли должен быть. И снова, да, там появился порт на Apple Silicon, на M1 Apple. Там интересно, в блокпосте написано, что Apple и Google вместе работали над тем, чтобы портировать и все такое. Brad Fitzpatrick, это бывший автор Менка Ша, про который мы говорили, создатель LiveJournal, он там несколько лет работал в Google, в команде Go. Вот недавно он ушел, он уже частью официально Go команды в Google не является, но при этом все еще там, контрибьютор в Go, там один из участников комитета, который там обы пропозлы рассматривает, то есть такое. Он как раз twittled, что Apple на своей пресс-конференции обещал, что он будет отправлять Open Source патчи в разработку, в проекты важные, в V1, V8, Electron и так далее. И среди этого всего есть Go. Сейчас прямо во время эфира я ему написал в Twitter, говорю, в блокпосте написано, что Apple и Google вместе работали, а ты говоришь, что они ничего не отправили. Она обратила внимание, что в том месте, где написано Apple и Google, слова инженера не упоминаются, инженеры они дальше есть. И там есть куча компаний с инженерами, которые помогали с портированием на Apple, а там нет. А он говорит, что Apple помог всем тем, что сделал M1. Ну, конечно, итог такой, что Go в итоге портировали на Apple, Silicon и поэтому... Леша опять ушел. Леша опять отключают за то, что он рассказывает какие-то секреты, секретные. Но мне просто даже интересно... О, Леша вернулся. Это какой-то эпик. Меня во время этого подкаста вырвало 3 раза, 3 раза, когда я говорил. Тебя явно хотят забанить. За что? Рассказываешь секретные секреты. Я забанул. Ну да. На чем я снес? В итоге Go портировали на M1 и 11.16 будет уже иметь возможность найти и компиляции, и кросс-компиляции на Apple, Silicon. Ну да, если подразделять, оно все нормально работало, но тем не менее. Там есть ссылка на чинч-логи, я бы отметил несколько моментов. Самое главное, что Go, runtime.go всегда был хорош с длинной транспекцией, то есть там всегда есть много возможностей, чтобы понять, что в нем происходит. Но доступ к этому всем был через разные интерфейсы, некоторые нормальные функции, некоторые какие-то переменные окружения, типа Go-дебаг и так далее. Сейчас они сделали универсальный такой интерфейс для доступа к метрикам. И что интересно, с Нортной билетеки Go есть нортный пакет для метрик, для поисковских метрик, как он там называется, X-PAR. У него очень странный, очень удобный интерфейс для использования, по факту из-за этого его почти никто не использует. Он реально очень такой самобытный. А новый интерфейс явно под впечатлением вот этих всех современных трендов в мониторинге, когда у тебя там есть разные типы, там типа есть различия между гауджами и каундрами, есть гистограммы и все такое прочее. Вот теперь все эти возможности, которые были до этого, теперь доступны через общий интерфейс. На самом деле большое дело, но странно, что теперь это только для веры runtime, и никакого механизма сделать свою метрику через этот новый хороший интерфейс нет. Может быть появится, конечно, потом через BoxFar, но пока нет. Вот, а так довольно много небольших изменений, в основном полезных хороших. Все быстрее, лучше, там, я знаю, памятная, теперь быстрее выключается апельсиновая система и так далее. Не знаю, что интересно по поводу Apple Silicon, у них же уже был порт на iOS, что там радикально поменялось такого, что им понадобилась прям какая-то существенная работа для этого? Ну, судя по числу объема, да, на самом деле никакой существенной работы там особо нет. То есть порт на iOS уже действительно был, но все равно есть какие-то различия. Я понимаю, что там еще плюс регистрационные всякие моменты, типа там, Builder нужно было завести, там вот этот вот DevKit поставить, подключить и всякое такое. То есть сами изменения, да, они не очень большие. Да, насколько я знаю, там самые существенные изменения, которые нужно было сделать, это побороть систему подписей или проверки подписей на Apple Silicon, которая там, это очень хитрая, то есть там она не исполняет бинарник, если он не подписан правильной подписью. А чтобы эту подпись сделать, там нужно было заморочиться. И там есть ищу на GitHub, Go, по этому поводу, многостраничное, можно почитать, как они боролись с этой штукой и как они боролись. Интересно. Ну да, я понимаю, там еще основная проблема, что в это время BuildSystem, то есть, которые это нужно делать, с довольно высокой евроидом подписывать, это все. И тогда, я так понимаю, что проблемы были больше от такого плана, я бы сказал, организационные, чем технические. Да, еще в этом в Гознишне, что мне нравится, там я мало как освещен, в ReleaseNotes, то, что размер бинарника опять, с выходом новых версий Go, обычно размер бинарника для одной и той же программы растет. Есть исключения, там несколько версий, когда именно этому уделяли много внимания и все направленно уменьшали размер бинарника. Так вот, Go 1.16, размер бинарника, правда, для Vitoria Metrix, уменьшается по сравнению с Go 1.15, там где-то на проценту 20-30. И это очень существенное из изменения, мне нравятся маленькие бинарники. И непонятно, почему про него так мало сказано в ReleaseNotes, и вообще мало про него говорят. Ну, кстати, да, это довольно большое дело, причем, потому что, пока что там черталка не написана за Linker, наверное, скидываясь. Да, да, это связано с Linker, он стал быстрее работать, меньше память потреблять, и, соответственно, его как-то там оптимизировали, переписали, и вот получается он генерирует меньший размер бинарника. Вот, на самом деле есть еще одно большое изменение, тоже которое надо сказать, это вот в Go есть довольно такая пулярная тема, что вы поставляете один статистический сликованный бинарник, ну, всем это удобно, все это знают, но что делать, если нужно приложить какие-то дополнительные файлы, типа, я не знаю, HTML-страницы, картинки, и всякое такое. Очевидно же, Docker. Ну, да, да, но, с другой стороны, Docker, это у тебя тоже один бинарник, и в Docker есть и, собственно, UI, и этот UI нужно куда-то положить, а положить Docker в Docker не получится. В смысле, в UI в Docker? Какой UI? Ну, я имею в виду, что ты можешь там, ну, не знаю, там Docker Desktop, Docker Desktop плохой примерно, это не один бинарник, а Go. Ну, я не знаю, вроде примеров Consul, например, да, вот есть Consul, и все такое, но ты можешь там сделать ConsulServe и открыть страничку в браузере, там будет HTML, картинки, JavaScript и все такое. При этом это все отдаётся не с файлов на диске, а прямо из этого самого бинарника. Вот, Go это обычно называется ассетами, и эти ассеты на самом деле просто вкомпилируются в программу, как есть разные кучи, кучи утилит, самопулярные GobinData, там которая была в свое время первая, самая популярная, потом там была какая-то драма с тем, что я автор удалил с GitHub, что-то такое было. На сути в том, что это популярная тема, когда статические бинарники по сути просто конвертируются, не знаю, в стольковые константы, грубо говоря, и вкомпилируются в Go код. Но я упрощаю, потому что там довольно много оптимизации, там пожать, как их так положить, чтобы они лежали в правильном месте в памяти, чтобы они там, не знаю, не в хипе лежали, в которой EGC будет проходить где-то еще и так далее. И вот в новой версии Go появится снархный механизм. Для этого основанный там механизм Go Generate, который до этого был, из хорошего, то что он как бы... Одна из идей в год, что когда ты ставишь какой-то пакет или там включаешь какой-то пакет, ничего такого автоматически не происходит, то есть тебе нужно эти действия делать рука. И при этом, если бы это был просто Go Generate, ты не мог бы так взять и включить пакет, поэтому тебе нужно было бы еще там явно, чтобы там Go Generate запускать или что-то такое. А этот механизм, он как бы такой, он не супер гибкий, там, не знаю, там нет никаких плагинов, там особое расширение и так далее, но снархный будет строен визыв, компилятор, поэтому как бы это автоматически все будет просто работать. То есть если вы это там включаете в пакет в своей программе, оно будет просто работать. Ну и там как следствие, там возможность именно адресации этих виртуальных файлов, такой в некие виртуальные файлы с теми там два связных пропозла, один про встраивание файлов, другой вот такой общий интерфейс виртуальной файлы сети. И вот оба должны завести в следующий релиз. Я думаю, на этом мы перейдем. А, у Саши еще была закладка, да? Да, у меня новость одной из строкой. Есть такая широчайшая, известная в очень узких кругах книга, автора Карл Ротхамель, называется Antennenbuch, оригинал на немецком, и книга переводилась на много разных языков, есть несколько переводов на русский.",
    "result": {
      "error": "API request failed: Error code: 400 - {'error': 'Trying to keep the first 7352 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': 'Trying to keep the first 7352 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}\n"
    }
  }
]
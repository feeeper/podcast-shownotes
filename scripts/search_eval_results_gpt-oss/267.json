[
  {
    "segment_id": "3b3c2fd6-c57f-49cd-a512-75c97790ce8e",
    "episode_id": "40a82723-603a-4623-81df-1dea38df0003",
    "episode_number": 267,
    "segment_number": 4,
    "text": "Егор не сказал, каким образом это решается. Он, типа, скоро должен появиться в мастере, но сама эта концепция того, что вы можете получить лог просто на последовательных апдейтах, она для меня, это просто шокирующе. То есть я вообще не ожидал, что такое возможно. Я только, наверное, имелся в виду не сам индекс, который что-то меняет, а то, что у тебя копится статистика по таблице, и один из запросов начинает использовать какие-то более эффективные индексы, наверное. Я так и хотел сказать, спасибо большое за пояснение. Был на докладе Петра Зайцева про BPF trace, как замена dtrace в Linux, но он очень хорошо в summary провел того, что добавлено в Linux, что такое eBPF, как оно работает, куча ссылок. Полезно, но в целом я всю эту информацию уже знал, но, возможно, кому-то будет очень интересно. Что мне еще запомнилось? А, еще мне очень запомнилось, Facebook пришел на highload. Facebook пришел на highload, у них был стенд, они на стенде что-то там раздавали, я не сильно подходил. И у них было два доклада подряд в одном из залов. Первый доклад про взгляд изнутри на надежность сервисов. Это было веселые истории про разные поломки в Facebook. Было очень интересно послушать именно в реальной жизни, что происходило в Facebook. Одна из самых веселых историй, это то, что одна из первых поломок, которая полностью, ну, когда Facebook лежал там полчаса или час, это то, что шериф одного из округов публично выступил то ли по телевизору, то ли по радио и сказал, ребята, мы никак не можем починить Facebook, пожалуйста, не звоните в полицию, если у вас не открывается Facebook. Вот, это было прям реально смешно. И второй был доклад Артемия Колесникова про cluster and resource management at Facebook. Вот это было очень интересно лично для меня, потому что это альтернатива кубернетусу Facebook. Facebook начал разрабатывать свою систему кластер менеджмента еще до того, как кубернетус появился на радаре. И они время от времени приходят посмотреть, в каком состоянии кубернетус и стоит ли им переходить на кубернетус и так далее. Они пока не могут, потому что кубернетус в настоящий момент там около 5000 серверов может обслуживать, а у них миллионы. Вот, и у них из-за этих миллионов немножко по-другому построена схема, немножко по-другому построены способ управления данными, по-другому построена система, которая обрабатывает ивенты от всех серверов. И вот про это все Артемий рассказывал на докладе. Насколько я понимаю, в зале было человек пять, которым это было по-настоящему интересно, которые разбираются в этом вопросе хорошо достаточно. Все остальные слушали дополнительную информацию. То есть, как бы, доклад очень интересен Артемию тем, что он не только рассказывает про архитектуру того, как это устроено и почему таким образом устроено, но еще и какие-то примеры из жизни, почему нельзя сделать по-другому, как мы столкнулись с этой проблемой. При том, что доклад технически очень сложный, он получился интересный даже если вы не очень понимаете в этой теме. Это прямо было очень интересно. Хотя я с Артемием после этого общался, он говорит, он был разочарован, он сказал, что доклад, похоже, вообще не зашел, и я, не знаю, наверное, больше никогда не поеду.",
    "result": {
      "query": "Facebook highload cluster management"
    }
  }
]
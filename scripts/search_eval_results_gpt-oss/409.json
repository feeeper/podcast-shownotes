[
  {
    "segment_id": "c1d4351e-2819-4d34-b72e-716b7e58360b",
    "episode_id": "6ce72374-78e6-4b1a-91f2-3e8feb91df7b",
    "episode_number": 409,
    "segment_number": 4,
    "text": "На самом деле, это же еще и снижает количество необходимых вакуумингов, потому что тебе надо фактически не по количеству ридов сделать подсчет, а по количеству райтов. Да, да, да. Это, я думаю, было серьезное изменение с точки зрения улучшения изабилити. Но вообще, когда я повнимательнее поговорил, как оно на самом деле сейчас работает, ксетерапрам для меня не звучит как безумно огромная проблема. То есть, на большинстве нагрузок, это должна быть очень специфичная нагрузка, где ты очень-очень много пишешь, почти не читаешь данные. Какой-то сервер типа в warehouse, куда ты все складываешь, а иногда приходишь что-то сагрегировать, очень редко, но в основном ты пишешь. Или ты пытаешься создать для читающих транзакций ID? Вот, ну и даже в худшем случае, допустим, ты налетел вот в это состояние, но, допустим, твоя система перешла в ридонлиди, ну там, представим, все большое число, на 12 часов на сутки. Это для каких-то задач, конечно, критично, но, опять же, если вы аккуратно это мониторите, то вы об этой проблеме узнаете заранее и займете ее заранее, ну там, живец получше заведете. Вот, ну, краткая история, транзакция XID не так страшна, как мы думали. А еще мы узнали, что документации нельзя верить даже вот в PostgreSQL. Верить только коду? Да, истинно, только в коде. На самом деле, это как-то печально, что программисты не умеют писать, я себя, естественно, включаю в этом множество, программист не умеют писать документацию даже в серьезных Open Source проектах. Как пользователям узнавать, как оно на самом деле работает? Мне интересно, можно ли, и как быстро появятся продукты, которые позволят сказать, вот, код, но это же можно chat.jpg попросить, сказать, глядите сюда на код и описывай то, что в коде в виде документации, и исправляй, если что-то поменялось. И в форме поэмы обязательно. В форме поэмы на французском 17 века, да. Вот, ну, есть, конечно, Docsage, но он не сильно помогает, потому что, ну, да, у тебя есть документация, она как бы в коде, в комментариях, но, во-первых, она низкоуровневая, а во-вторых, ее все еще пишет программист. Чаще всего, когда ты хочешь сделать описание большого куска с точки зрения, как это работает, и почему так было сделано, это реально большой кусок текста, и этот большой кусок текста редактироваться будет реже и с меньшим желанием, чем код, потому что код надо исправить там, ошибочки и так далее, новую функциональность дописать, и маленькое желание писать в код, оно приведет к тому, что в документации, маленькое желание писать документацию приведет к тому, что эта документация не будет правиться и в отдельных файлах, и внутри кода, и так далее, потому что везде будут большие какие-то, было бы текста. Мне в этой истории еще понравилась реакция моего коллеги, когда я послал ссылку на этот трек. Ну, вот представь себе, ты там сколько-то лет работаешь с Postgres, да, тебе прислают ссылку на трек, где сказано, что в документации сказано неправильно, на самом деле система не выключается, она переходит в аридонлию. Какая твоя реакция? Ну, я бы сказал, вообще классно, все гораздо лучше, чем я думал. Знаешь, какая у него была реакция? Хе. Ну, так это неизвестно, это не то чтобы прям все поголовно знают, но это же многим известно, но да, в документации сказано неправильно, да, но работает не так, и кстати, вот еще один баг, который, ну, в смысле, еще одна ошибка, которую ты не учел. Да. Довольно забавно. Забавно, согласен. Что еще забавно? Это следующая тема про базу данных? Да, которую принес я, и она почти не про подгрос. Это девятая лекция в серии Advanced Database Systems, курс, читает Инди Павла, записан в 2020 году. Этот доклад посвящен сжатию данных, и я думаю, пересказ будет не очень длинный, потому что мне он показался не таким уж безумно интересным, но я предполагаю, что слушатели этого подкаста более-менее имеют представление о том, как работает сжатие данных, но если нет, то это все равно в подкасте сложновато объяснить, но есть парочка книжек по этой теме, в том числе на русском языке, название не помню, но если поискать по зону сжатия данных, то найдется. В докладе говорится, что сжатие данных — это важная штука, в частности, для базах данных, потому что и в частности для In-memory баз данных, потому что курс называется Advanced Database Systems, и у Энди особый интерес к In-memory базам данных, и сжатие важно, потому что позволяет поместить больше данных в эту самую память. И, ну, несмотря на то, что вот в современных реалиях можно купить терабайт оперативной памяти, зажимать данные все равно желательно, чтобы в этот терабайт памяти влезло 3 терабайта данных. В докладе этого не говорится, но сжатие полезно еще не только в этом контексте, например, если сжимать write a headlock, то он будет быстрее писаться в диск, а write a headlock есть даже в In-memory базах данных, и он будет быстрее пересылаться по сети на реплике. Но это уже мое дополнение. Ну, вообще сжатие данных и база данных, они вот прям дружат. Применительно к СУБД еще желательно иметь не просто сжатие данных, а позднюю материализацию, то есть распаковывать данные как можно позднее, то есть не так, что ты вот идешь, видишь кортеж и сразу распаковываешь его, чтобы получить результат с плане запроса, а желательно распаковывать данные как можно позже и вообще не распаковывать. Или вообще не распаковывать. Или вообще не распаковывать, но ты имеешь в виду распаковывать на клиенте, правильно? Да, или избавляться от каких-то записей в процессе отфильтрования, или так далее. Может быть, тебе не понадобится распаковывать именно эти данные. Ну, про отфильтрование я согласен. Вот про клиента. Моя первая реакция тоже была такая, что вообще в идеале это не распаковывать данные и передать их на клиента и пусть клиент распакует. Но потом я вспомнил, как ты думаешь, про что я вспомнил? Про какой-нибудь Джейсон? Джейсон, нет, нет, я вспомнил не про Джейсон, я вспомнил про безопасность. Мы же помним, в чем связь, зажатие безопасности. И в чем связь зажатия безопасности? В уязвимости к райм. Как же ты мог забыть? Боже мой, было так много дозынов назад, что я уже совсем не помню. Расскажи мне про это. А я не смогу это пересказать, я не так сильно интересовался, так сказать, по правде. Но краткая история, что у тебя между клиентом и СУБД может быть зашифрованный канал по разным причинам, потому что клиент в одном дата-центре, а СУБД в другом, например. И канал этот не обязательно прямо в протоколе СУБД реализован, а это может быть в ВПН, шифру и трафика. И оказывается, что если гонять в зашифрованном туннеле сжатые данные, то это может приводить к последствиям. Я не уверен каким, к частичному восстановлению ключа шифрования сессионного или чему-то такому. В общем, есть уязвимость, называется crime. Краткое содержание, что нежелательно передавать сжатые данные, которые потом шифровываются. Но, опять же, применительно к нашему текущему обсуждению, выдавать на клиента сжатые данные не всегда может быть желательно, но зачастую может быть окей. Дальше докладчик говорит, что применительно к СУБД сжатие обязательно должно быть без потерь, lossless сжатие. Я, кстати, не уверен, что это обязательно правда. Наверное, можно придумать сценарий, когда сжатие может быть и с потерями, как в JPEG, например, или в mp3. Чаще всего я согласен, что если я сохранил что-то в СУБД, я ожидаю, что, как правило, СУБД мне это же и вернет. Дальше говорится, что сжимать можно разные вещи и сжимать по-разному. Можно сжимать страницы, можно сжимать кортежи в страницах, можно сжимать конкретные атрибуты, как, например, вот в Postgres делает механизм Toast. Можно сжимать колонки, как, например, это уже мои дополнения, например, в Timescale есть колоночное сжатие. Дальше Энди долго и мучительно перечисляет разные варианты сжатия. Есть RLE. Как расшифровывается RLE? Ты помнишь, Ваня? Нет, нет, не помню. Я тебе хотел спросить. Run Length Encoding, по-моему. Дай-ка посмотрим. Run Length Encoding. Да, так расшифровывается. Но это классическая схема, то есть, если у тебя есть поток данных, ты его преобразуешь в последовательность типа 12 букв A, потом 18 букв B. Это классическая схема и в колончных храняющих часто применяется. Еще есть слова расжатия. В этом докладе вы не узнаете, как работает LZW или LZSS, подобный алгоритм, он применительно к базам данных в основном InMemory предлагает разные схемы, чтобы у нас в память побольше влезло. Самым интересным в этом докладе мне показалась часть про страничное сжатие, и она объясняется на примере INNODB, который сторожил для MySQL. Я не сильно разбираюсь в MySQL, но вот согласно этому докладчику INNODB поддерживает сжатие, и оно работает так, что страницы в INNODB занимают 16 килобайт. Опять же, я не знаю, правда это или нет, но в докладе так говорится. И вот мы берем целиком страницу и сжимаем. Затем сжатая страница, ее размер округляется до ближайшей кратности до одного килобайта, двух, четырех, восьми или шестнадцати килобайта, если она не пожаловалась. Соответственно, у тебя есть на диске... Я, кстати, вот этот момент не пояснился, но я предполагаю, что у тебя... Кстати, это может быть и флаг в PageID, возможно, но я бы это реализовал так, что у тебя есть разные сегменты, что вот в этом файле мы храним все, что пожаловался в один килобайт, в другом совершенно файле мы храним все, что пожаловался до двух килобайтов и так далее. Соответственно, ты читаешь страницы, целиком их распаковываешь, и в разделяемой памяти у тебя уже страница распакована, и дальше все как обычно. Когда ты записываешь страницу, ты пытаешь ее сжать, и в зависимости от того, как она сжалась, ты ее пишешь в соответствующий полу страниц. Ну принцип, как у слаполокейтера. Причем, почему мне это понравилось, звучит прикольно, звучит как что-то, что относительно, очень относительно несложно реализовать, и можно занести в Postgres как либо фичу ядра, либо как отдельный table access метод. Вот, но нужно посидеть и немножечко подумать, вот, над тем, как ты по идентификатору страницы поймешь, где точно ее искать или куда ее конкретно записывать. Тут одна из сложностей, что ты можешь прочитать страницу, допустим, она старая версия сжималась в один килобайт, ты ее переписал, начинаешь писать в диск, а теперь она стала сжиматься хуже, ну или лучше, и в этот момент у тебя, если ты решил размер сжатой страницы хранить в ее ID каким-либо образом, у тебя проблем, потому что ID меняется, и вот в Postgres так, наверное, не прокатит, значит, тебе нужно какое-то отображение, вот то, что вот эта страница, ее нужно искать там-то, а это становится уже чуточку дороже, вот, но вообще вот страничное сжатие было бы прикольнее иметь. В принципе, это все из этой лекции, вопросы, возражения, комментарии. Звучит понятно, но все выглядит так, как будто бы это все достаточно, это, известно было заранее, ты что из этого нового узнал сильного, только про посторонничное сжатие? Ну да, что-то, о чем я не задумывался, что вообще в странице, в Postgres добавить посторонничное сжатие должно быть относительно несложным, ну сочетается того, что это потом нужно протолкнуть, и обычно сложность в том, что всегда найдется люди, которые скажут, зачем нам делать Postgres, кому нужно, запустят поверх ZFS, а в ZFS есть сжатие и вообще-то будет прав. Вот, то есть, ну, вопрос в том, а хочет ли сообщество поддерживать такой функционал, при условии, что он будет взаимодействовать со всем остальным функционалом, а сообщество хочет еще и страницать, ну, в сообществе много людей, у людей много идей, и разные люди предлагают разные идеи, то есть, например, есть идея, давайте мы разрешим указывать размер страницы не во время компиляции Postgres, а на уровне таблиц, потому что, как мы ранее обсуждали, иногда выгодно иметь страницы побольше для Allat-нагрузок, а иногда поменьше для LTP-нагрузок, а еще предлагалось, что-то там было, а, ну, то же самое применимо к размерам сегментов, то есть, файлов на диске, куда складывает Postgres страница, тоже почему бы его не менять для заданной базы данных или для заданной таблицы, и вот, ну, такие же желания, такие идеи, они копятся, и они все будут как-то взаимодействовать вот с тем, что ты предлагаешь, и это можно вообще не реализовывать в этом проекте, это можно реализовать в другом проекте, в том же ZFS, или как отдельный сторож, который вот для Postgres можно теперь написать через stable access methods, ну, наверное подход stable access methods, он наиболее... Неверсальный. Наиболее правдоподобный, да. Слушай, а ты сказал, что вот на ZFS и автоматически будет компактирование, как-то сжатие, много людей сейчас на ZFS запускает Postgres Gale в продакшне.",
    "result": {
      "query": "PostgreSQL page compression techniques"
    }
  }
]
[
  {
    "segment_id": "e2ace199-05af-4b0e-9958-d987577347a3",
    "episode_id": "e46f1823-2804-4842-bb2d-139f9d4dfedd",
    "episode_number": 298,
    "segment_number": 4,
    "text": "И еще есть довольно много всяких модулей уже написанных, ну как, не знаю, как вот выставить убунту, и с ней идет в комплекте куча какого-то софта базового, которым можно прямо сейчас пользоваться. Например, фильтры Калмана для того, чтобы фильтровать показания датчиков. По-моему там есть уже какой-то софт для построения карт, там есть скорее всего что-то для того, чтобы подключить внешнее управление, не знаю, какие-то джойстики, там есть, по-моему, модули для того, чтобы начать управлять сразу же какими-то приводами, ну и стандартного набора. То есть, особенно если у вас какой-то там DIY проект или вот вы начинаете только какой-то проект связанный с роботами, это прям очень здорово, вам не надо писать прям все с нуля, вы можете взять что-то готовое, оптенсорсное, а дальше, если вы упираетесь с какие-то ограничения, или вас что-то не устраивает по качеству работы или по быстродействию, вы можете это начать потихоньку переписывать. То есть, это похоже на то, что там есть какая-то шина данных, через которую происходит обмен сообщений между различными систем, подсистемами в роботе. Да, ну да, еще очень важная штука, которую он отдает, он дает сразу же возможность запускать ее на нескольких машинах, то есть, не знаю, у вас там есть робот, на котором три разбери пай, грубо говоря, на одной вы, например, обрабатываете картинки, на другой, не знаю, там пишете логи, на третьей, не знаю, что-нибудь еще, управляете манипулятором и там, не знаю, распознаете какие-то предметы, все это может быть разнесено, они друг на друга не будут сильно влиять, в смысле там, загрузки процессоров и так далее, и они могут эффективно взаимодействовать друг с другом, ну то есть, вот эти процессы, которые на разных машинах, и вам не надо будет сильно много чего-то там кодить, настраивать, довольно легко запускается. Думаю, что это тоже полезная вещь, хотя у нас беспилотники там, процессы работают на одной очень большей машине, ну вот. А можешь рассказать про то, каким образом было устроено распознавание светофоров? Да, может быть, я вам расскажу сначала, как вообще, что из себя представляет софт, который работает на беспилотной машине? Да, вот прям сразу стало интересно, упомянуло, что оно работает на одной жирной машине, и сразу возникает вопрос, там тогда крутится какая-то реалтаймовая операционная система, чтобы гарантировать, что, ну, какие-то слайсы временные модулям, или как? Нет, ну я сказала, что основная часть кода работает на одной большей машине, но не вся. У нас есть управление машиной, конечно же, на РТОС, но реально, на операционной машине система реального времени работает, но, поскольку я в этой части не очень много чего делал, то есть вообще ничего, поэтому я, наверное, не смогу там что-то рассказать, понятно. Давайте я расскажу про архитектуру вообще софта-беспилотника, потому что кажется, что про это есть очень много мифов, очень много каких-то странных представлений, и думаю, что это много кому будет интересно, потому что очень часто есть представление, что беспилотная машина, ну, например, вот я слышала, что Яндекс записывает поведение всех своих таксистов за рулем, и дальше просто учит гигантскую нейронную систему, и, конечно, это очень интересно. Ну, я могу попробовать что-нибудь покрутить, если надо. Я сомневаюсь, что проблема на твоей стороне, потому что мы не одинаково теряем пакеты от тебя, возможно это как-то связано с дичной лаушой, чем-то еще по дороге от тебя до нас. И, похоже, Саша все-таки слышит тебя хорошо, поэтому у нас есть как минимум одна запись. Так что, тренирует Яндекс большую нейросеть? Как вы можете подумать, предположить, идея с записью поведения таксистов и обучение потом на этом нейросете это плохая идея, потому что на машинах такси нет достаточного набора датчиков, и водят они не всегда так, как хочется. Надо установить? Да, надо установить, но это, к сожалению, очень-очень дорого. Кажется, что быстро стартовать так нельзя. Ну и, кроме того, большая проблема таких толстых нейросетей, это что вы не очень можете точно гарантировать ее поведение в разных ситуациях, особенно когда речь идет об управлении машиной. И пока что кажется, что на это положиться на 100% сложно. Поэтому у нас, ну я думаю, что большинство проектов по разработке беспилотных машин, есть такое модульное, не знаю, многоуровневое такое архитектура софта, когда сначала из данных датчиков попадает в такой слой, который называется perception. То есть это восприятие, когда мы, по данным датчиков, пытаемся понять, что вообще вокруг машины происходит. Ну, то есть, например, каким светом горит нужен нам светофор, сколько тут людей, куда они идут, пешеходы, велосипеднисты, где тут другие машины, где мы находимся вообще. Следующий слой это prediction, то есть мы пытаемся предсказать на какое-то небольшое время вперед, что тут будет происходить вообще. Вот не знаю, там эта машина сзади, она будет нас сейчас обгонять или нет. Вот этот человек идет, подходит к пешеходному переходу, он сейчас будет переходить, и он просто мимо идет, что-то такое. Дальше у нас есть planning, то есть когда мы уже на основании данных о том, ну и наших предположений о том, что будет дальше, и на основании наших знаний о том, что сейчас здесь происходит. И еще у нас есть какое-то там представление о том, куда нам надо ехать, грубо говоря. Мы планируем, как мы проедем вот этот участок, с какой скоростью, по какой траектории и так далее. И дальше есть уровень поведения, на котором, ну не-не, я запуталась. Да, после planning дальше мы просто, ну как бы вот эту запланированную траекторию, там ее определенным образом скорим, как-то выбираем лучшую из всех вариантов. И дальше уже есть control, который, грубо говоря, дает ответ на вопрос, как надо повернуть руль и как сильно нажать на газ или на тормоз, чтобы вот по этой траектории проехать с одной скоростью. Вот как-то так. И получается, что у вас есть несколько вот таких сайов с фиксированными входами и выходами. Примерно представляет себе, что должно быть на входе, что должно быть на выходе, как он должен вести себя в случае, если там что-то поменяется, в отличие вот этой идеи с толстенной гигантской нейросетью. И, например, внутри пленнинга какого-нибудь у нас там довольно мало машин-лернинга, потому что поведение машины в разных ситуациях иногда лучше просто запрограммировать каким-то понятными алгоритмами, чтобы потом было понятно, почему вся машина в этом висце повела так, а не иначе. Наверное, у вас возникли какие-то вопросы про это? Интересно знать, как эти вот, позже эти такие логические части системы, а как эти логические части системы маппятся на техническую реализацию? Это какие-то, не знаю, отдельно модули вы устанавливаете или это какие-то сервисы? То есть как это взаимодействует на техническом уровне? Ну, этот уровень, это скорее несколько процессов, которые занимается примерно, например, несколько процессов, которые занимаются рецепшном. Не знаю, грубо говоря, на это прям честно думала. Там есть процесс, который трекает пешеходов по данным с датчиков, есть процесс, который трекает машины, есть процесс, который трекает светофора. То есть это скорее такая абстракция, то есть в живой реализации у тебя нет там, скорее всего, гигантского процесса персепшн. Скорее это просто способ объяснить, из чего система состоит. Но это все хорошо, опять же, алгоритмически я вообще отлично понимаю, как сделать машину. Но дело всегда откроется в деталях. То есть вот эти вот процессы, которые теоретически независимы между собой, они же работают на одной и той же машине. Они должны как-то между собой делить эти ресурсы. Это что, у них многоакторная вытесняющая модель или что там вообще происходит? Кубернет запускается? Каким образом они между собой с шинами данные обмениваются? Что за шина данных? Каким образом они запускаются в операционной системе? И операционная система гарантирует, что она не будет тормозить на каком-нибудь системном вызове. Там как real-time operation system или что вообще используется? Смотри сколько вопросов. Как-то вот так в верхнем уровне помыслить, я сам себе могу рассказать. Но самое интересное это всегда в деталях, потому что добиться хорошей работоспособности с этими техническими мелкими проблемами очень тяжело. В этом самая большая сложность. Ты прям вальна бросаешь и это такой наезд. Почему наезд? Это мне правда любопытно? Я, наверное, не смогу внятно на эти вопросы ответить. Во-первых, потому что я этого не программировала. Я скорее работаю над одним из процессов, который работает. Над ним из модуля, который работает в Perception. Даже со светофорами. Откуда приходит сигнал? Вот этот сигнал, ты уверена, что он приходит? Приходится ли тебе программировать то, что сигнал не приходит в какое-то время и ты должна как-будто... Безусловно у нас есть система диагностики, которая проверяет, что камеры работают, картинки оттуда выходят. Если что-то в этих потоках прерывается, естественно машина начинает... Переходят в аварийный режим, пытаются остановиться, сказать водителю, что все плохо. То есть ты на себя это не берешь? Если тебе не приходит долго сигнал, ты не должна ничего делать, она сама остановится и сделает, как это сказать, мигание фарами и так далее. Это система, которая независимо от этих всех Perceptions, Pretictions и так далее работает. Просто потому что если у тебя один из процессов упадет, машина все равно должна остаться в адекватном состоянии, как-мин. быть готова и безопасно остановиться. А с точки зрения релтайма, то есть ты пишешь процесс, который где-то запускается или ты пишешь просто библиотеку, которая как-то устраивается и методами фреймворка начинают взаимодействовать с остальными процессами и с операционной системой? То есть ты пишешь сервис, который полностью подключится и запускается в кубернет оси или я отрирую на любой другой обычай. Нет, конечно. Когда я говорила про ROS, я как раз наверное не очень хорошо объяснила. ROS предоставляет тебе возможность не писать вручную все эти вещи, связанные с обменом сообщений. То есть ты просто собираешь, ну в общем, но это прям, по-моему, это хорошо. Хорошо к нему подходит все-таки описание, что это фреймворк, а не операционная система. То есть там есть такие вещи, как ноды, как сервисы. Ты просто можешь как бы подобрать то, что похоже на то, что тебе надо из этих абстракций. И дальше воспользоваться просто библиотечными пункциями для обменов сообщениями для того, чтобы какие-то события реагировать и так далее. То есть, как правило, тебе не нужно задумываться о том, как это все будет взаимодействовать уже под капотом. Подожди, ты же упомянул, что у вас не ROS. Ну у нас что-то очень похоже на ROS, на базе ROS. Просто ROS это очень хороший пример, который все могут попытать. А можно для систем этих чайников? Что такое ROS? Как расшифровывается? Что это такое? Выложил в звание, ты невнимательно слушай. Роботник, это Роботник. Ага, соответственно, да-да-да, точно-точно. В общем, это фреймворк, который написали ребята в Калифорнии для одного какого-то робота. Я уже не помню, как он назывался. Да-да-да. И потом он разросся в очень популярную систему. Все-таки, по-моему, это фреймворк. Это очень операционная система, на базе которого строят, я думаю, почти все... На базе которого строят свои по крайней мере прототипы. Почти все, кто делает что-то связанное с роботами, с Сэлдрайвин Карс. Я знаю, бывают даже беспилотники, у которых там ROS крутится. Ну, с мессомолета. И это очень удобная штука, с которой можно стартовать, чтобы дальше куда-то двигаться, что-то делать. Потом можно переписать что-то под себя, вот как мы сделали. Вот тут я, наверное, тоже сильно много не расскажу, потому что я скорее потребитель этой системы. То есть, я представляю, что там происходит под капотом. Но, как правило, вдаваться мне в эти подробности не надо. Вот что действительно важно, это то, что твой модуль не должен жрать, не знаю, какой-то большой кусок оперативной памяти и процессора. И это действительно то, зачем надо следить, когда ты работаешь в беспилотнике. У тебя нет бесконечных гигантских серверов. У тебя нет, не знаю, какой-то... А может быть, как ты это делаешь? Да. Ну, у нас есть просто тесты, которые... Да. У нас есть тесты, которые, во-первых, проверяют, что твой процесс... Ну, то есть, у нас есть, во-первых, возможность запустить прямо на процессы на машине, на сервере, аналогичном тому, который стоит в машине, но который стоит в стойке. То есть, hardware and loop теста. Ты можешь там прямо посмотреть, насколько твой процесс новый загружает машину. Ну, и кроме того, у нас есть мониторинг, который ослеживает, насколько вообще машина... Насколько какие процессы во время работы уже в реальном мире загружают процессор, память, графические карты и так далее. И вот, как-то так. Если ты делаешь какую-то объемную штуку с нейросетями или там, где надо много чего-то быстро пересчитывать, очень важно обратить внимание на то, чтобы твой процесс не съедал слишком много ресурсов. Вот. Ну, то есть, идею поставить туда шедуле, она не пошла. Мне просто интересно порассуждать на тему, как этот рост устроен, и каким образом он работает с операционной системой. Я бы лучше все-таки отдал это на откуп не программисту, который может описать неправильно, а выяснять задачу или давать ей меньше ресурсов, если она слишком жирная. Ну, из исключения случаев, когда ей намеренно дали разрешить это делать. Вань, там есть особенности. Поскольку это все-таки машина на улице, то из того, что я слышал о подобных системах, там обычно заранее слайсы времени выписываются. Ну, поясни, что ты имеешь ввиду. У тебя есть бюджет, который всегда такой. То есть, грубо говоря, у тебя модуль, который тачается, ну, скажем, посмотреть на светофоры, он будет всегда отрабатывать, например, за, там, он будет занимать, в общем, отрабатывать за определенное количество миллисекунд или секунд на определенном ядре, и он будет там припыль гвоздями и всегда работать столько. Я не знаю, как так-то его... Ну, а вдруг, если он начнет больше времени тратить? Его убьют. Ну, если он начнет больше времени тратить, скорее всего, там, начнут тут же быстро сигнализировать всякие диагностики, и машина просто остановится и напишет водителю, что дальше ехать небезопасно на этой версии софта. Передай разработчику, чтобы он все это починил. Грубо говоря, так. Это как выглядит, когда ты что-то новое тестируешь, что-то такое происходит. Мне кажется, мы так и не узнали, как работает распознавание на светофорах. Светофоров. Конец фразы С. Так, что-то совсем плохо с потерями. Не знаю, как у Саши, в которую все хорошо работало, но я прямо вообще Гостю перестал слышать. Гостя говорит, что не разобрала конец фразы Света, насколько я понимаю. А я не услышала, что спасибо, Гостя, прекрасно. У нас какой-то спритбрейн в прямом эфире. Мне было интересно узнать, как все-таки работает распознавание светофоров, потому что мы вроде до этого так и не дошли. Мы, кажется, не дошли до того, чем я занимаюсь, потому что пока что мы как-то ходили вокруг. Я просто знаю это примерно. Ну, светофоры вообще штука, как вы понимаете, важная для беспилотников. Когда ты ездишь по городу, пытаешься адекватно двигаться. Поэтому мы довольно много усиливаемся. Поэтому я занимаюсь этой задачей уже полтора года. Там много чего интересного выясняется в процессе. Прежде всего... Извините, затупила. Сейчас заново начну лучше. В общем, светофора такая важная штука, поэтому важно распознавать хорошо. Но есть много проблем. Первая проблема, это то, что когда машина подъезжает к какому-то перекрестку, на нем может быть не один светофор, который понятно, что тебе указывать, а целая куча. Например, в Америке может в каждой полосу висеть по светофору. И когда ты неподготовленным взглядом на это смотришь, тем более, как-то компьютерными способами понять, что это все значит, бывает непонятно. Поэтому первая вещь, которую мы пользуемся для того, чтобы на первой пыти соших перекрестках выйти из положения, мы пользуемся картами. У нас есть... Не знаю, даже если вы на Яндекс.Картах посмотрите Москву, нарисовано на каких перекрестках стоит ожидать светофора. И если у нас какой-то очень сложный пересек, то можно даже в картах прописать, какой светофор, в какую полосу регулирует. Дальше есть просто несколько проблем со светофорами, как с визуальными объектами. Почему сложно распознать? Во-первых, большинство светофоров, которые не могут быть визуальными объектами, и в России, в Америке, в Израиле, в всем уже мире, они светодиодные. А камеры, которые их снимают, зачастую не могут... Снимают с фиксированной частотой кадров и с выдержкой, которая, конечно, сильно меньше, не знаю, 1,30 или 1,24 секунды. Поэтому мерцание светодиодного светофора не может быть не очень сложным. То же самое происходит, когда вы пытаетесь снимать камеры, например, жидкокристаллический экран, или какие-то другие светодиодные штуки. То есть, если вы снимаете с камерой, то вы не можете сделать это с камерой, и вы не можете сделать это с камерой, и это не может быть не очень сложным. Поэтому, конечно, нужно сделать это с камерой. А почему не поставить... Ну, я подозреваю, что много чего на дороге может себя так вести. Почему не поставить несколько камер, которые будут снимать разной выдержкой? То есть, поставить выдержку под линей для тех вещей, которые слишком быстро, слишком тяжело заметить за маленькую выдержку. Я боюсь, что выдержка это понятие из... из-за того, что мы не можем сделать это с камерой. Я боюсь, что выдержка это понятие из... из фотографии. То есть, тебе ты не можешь на сенсоре, на вот прям на матрице сказать, что вот делай высокую выдержку. Ну, там разная чистота, все равно, вновление. Ну, там я думаю, что можно... Она у тебя очень-очень быстрая, и ты можешь аккумулировать в буфере, и даже можешь одной железкой сделать два кадра с разными выдержками, просто аккумулировав и сделав averaging. Между другими с всякими кадрами. Во-первых, идея про то, что поставить много камер, она, конечно, хорошая, но чем больше камер, тем больше тебе нужно обрабатывать визуальных данных. Поэтому, вот, честно говоря, поставить там 30 камер, как на последних автомобилях Waymo, это прям, конечно, очень круто, но потом нужно будет очень много компьютеров, чтобы все это обрабатывать. Это данные туда маленькие. Мы проводим эксперименты с камерами, которые позволят это побороть, но, особенно, когда я пришла в проект, у нас были камеры вообще сильно попроще. Поэтому это прям было большой проблемой. Я первыми чем не занималась, я пыталась побороть фикеринг. В конце концов, ну, то есть, просто кроме, грубо говоря, нейросетки, которая тебе по одной картинке говорит, что светофор горит красным, горит зеленым или там выключен, тебе нужно еще штуку, которая называется трекер, приделать в ней, которая будет аккумулировать знания о том, что происходило со светофором за последнее время и говорить о том, что он сейчас нам пытается показать. Да, еще важно сказать, что есть важная такая штука, как мигающие светофоры. И они мигают все немножко по-разному. Не все, а некоторые. То есть, вообще-то, похоже, что есть какие-то стандарты того, как светофор должен мигать, но не все светофоры работают по этому стандарту, поэтому нужно еще уметь отличать, например, мигающий зеленый от фикеринга, или там мигающий желтый, по значению, что цветово мне работает, или мигающий красный, в Соединенных Штатах. Все это лечится трекером, который аккумулирует эти знания во времени. Конечно, там в самом начале, когда я пришла, только у нас было довольно мало данных, поэтому мы пытались с помощью вристика побороть. Но потом уже мы стали просто манить данные с камер и учить размечать их. И теперь у нас есть просто машина обучения, которая как бы по модели, которая умеет посмотреть на какое-то время назад и понять, что происходило с сетфором чуть раньше, чтобы точно сказать, что сейчас он показывает нам, что зеленый мигает, значит скоро надо будет притормозить на перекрестке, не надо через него ехать, грубо говоря. Вообще, если думать про светофоры и то, что вы рассказываете, что есть в фикеринге, есть другие нюансы при распознавании, как было бы здорово, если бы у светофоров был какой-то API и можно было достоверно точно знать, какое состояние сейчас светофора, ведь было бы настолько проще делать систему для самодвижущихся машин. И исходя из этого вопрос, может быть в эту сторону нужно тоже смотреть, есть ли какие-то подвижки в этом направлении? Действительно существует светофора, которые умеют посылать по радио сигнал о том, каким они светом сейчас горят, решено ли приезжать по этому перекрестку или нет, но, во-первых, такие светофоры не очень распространены, во-вторых, тоже довольно бывает сложно гарантировать, что это все будет работать именно так, как нам хочется, если они не",
    "result": {
      "error": "API request failed: Error code: 400 - {'error': 'Trying to keep the first 5637 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': 'Trying to keep the first 5637 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}\n"
    }
  }
]
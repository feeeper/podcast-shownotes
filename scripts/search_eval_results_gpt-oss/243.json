[
  {
    "segment_id": "a7368c7f-2f0d-443b-9b4a-98a875bda8c6",
    "episode_id": "8705fc39-b11d-4a6d-9404-dd77913bbaa2",
    "episode_number": 243,
    "segment_number": 4,
    "text": "Нам не понравилось, мы пытались и ушли на Team City. Это странный выбор, конечно, по мне так. Ну ладно, это вы каждый и сам выбираете. Ну у нас Jenkins вообще че говорит. Хотя, конечно, он в компании, но для другого используется, не для тестов. Вообще, что касается самой статьи, во-первых, всем, кто пишет на Горьке, рекомендую почитать пейпер. Пейпер, в отличие от многих других пейперов, которые в дизайне обсуждаются, его можно прочитать. Он вполне простой. Он любопытный. Во-первых, у них очень крутая методология, да, Саша об этом как раз сквозь упомянул. Они походили по большим проектам, по дифам, по коммитам, поискали баги и коммиты, которые их исправляют, сделали выборку, по-моему, порядка 2000 багов, ну автоматическим образом, и потом вручную проанализировали 171. Довольно не слабая такая работа и очень хорошая структура, то есть статистика, которую они собрали, довольно осмысленная. Потому что очень много сделано было именно вручную. Из того, что мне запомнилось, интересно, что они в том числе делают статистику, как люди фиксили эти баги. Есть баг, есть deadlock, есть блокировка, есть livelock, когда программа работает, но плохо. Как они фиксили? Очень многие фиксы это просто добавление mutex там, где его не было. При этом, из того, что я представил, я понимаю, что часто люди ставят mutex, грубо говоря, на какую-то операцию с каналом. То есть, например, в простейшем случае вам нужно терминализировать закрытие канала между разными вещами, и для этого используется mutex. Что вообще говоря, очень-очень странно, да, то есть, соответственно, у нас есть механизм взаимодействия, организация конкернсии между разными грудинами при помощи каналов, но потом вы закрытие канала ограничивается mutex. Но в целом, как бы, работает, и ладно, наверное, в особенности. Но с другой стороны, конечно, как правило, это говорит о том, что люди не очень понимают, как работает их собственная программа, да, не очень понимают модель выполнения этой программы, и поэтому просто добавляют туда больше симп-мутексов, синквансов, кондишнов, больше грутин, еще атомиков, и, в общем, до тех пор, пока это становится... пока разистокер не может со всем этим разобраться, оно вроде работает. Это такая вещь, которая все больше и больше приходит к нам по мере толка, я пишу на го. Чаще всего все проблемы с конкернсивом в го решаются упрощением, а не добавлением mutex-ов и локов, и чего-то еще. Есть интересные примеры, да, когда, например, закрытие канала через mutex или использование синкванса, для того, чтобы закрыть канал ровно один раз, откуда бы он не закрывался, чтобы он закрылся ровно один раз, и так далее. В общем, статья интересная, да, но рекомендую все-таки paper почитать, он очень хорош. У нас недавно была конференция Go4Con Russia, и там, в частности, был доклад про то, как не накосячить с конкернсивом в го. Там очень много всякой информации, в этом докладе он очень хороший, он довольно плотный по информации обыскал. И там, в частности, этот paper обсуждается. Он, в общем-то, не слишком новый, ему пару месяцев, наверное, уже есть. Вот, наверное, у меня все на эту тему. Еще такая мысль, что не в последнюю очередь от проблем к конкернсии помогает нормально продуманная архитектура, которая прошла серию итераций с RFC, с ревью переделыванием, перед тем, как садиться писать код. Потому что часто бывает наоборот, люди сначала пишут код, а потом уже это документируют, как они понаписали. Я бы вот здесь сказал, знаете, сбитую фразу Эйнштейна, что все должно быть как можно проще. Ну, не более проще, чем возможно, но как можно проще. Про конкернси вообще это очень хорошо подходит, да. И про конкернси в Go особенно, потому что, соответственно, там очень часто люди так, блин, конкернси, канал, как офигенно, потом читают первую страницу пейпера про CSP и такие, давайте делать архитектуру, которая там, да, смотрит еще доклад про конкернсизм, про лизм, смотрит доклад про пайпы известный, видошный, и начинает использовать конкернси, гаррутинные каналы как способ организации кода. На самом деле вот в Ирландии такая же проблема, абсолютно такая же, там как бы каналы встроены, там их не нужно закрывать, но то, что начинают абьюзить процессы, прям налево и направо. Вот, я как раз хотел как-нибудь перейти к опыту, ну, последнему опыту с конкернси у Фоликса и у Валеры. Валер, ну раз ты начал, продолжай. А у меня, кстати, последний опыт, у меня сейчас нет особо опыта с конкернси, потому что я сейчас пишу же всякие дейта, как это, аналитику, процессинг и так далее, и у меня особо сам конкернси не делаю, потому что, ну, за меня это делают там фреймворки, по сути. То есть у меня веб-сервис на Elixir, где за меня конкернси сделан веб-сервере, я просто слежу за тем, чтобы не сильно больше процессов наплодить, чем нужно. И, там, не знаю, в каком-нибудь Флинке-Спарке, там все уже в Флинке-Спарке сделано. Туллинг вокруг, он там вообще пара трэдов всего. Так что сейчас у меня нет никакого опыта с конкернси. Мой прошлый опыт с конкернси был довольно интересный. У нас был такой проект, где, в общем, было решено сделать по процессу на каждую стадию агрегации, это сильно еще до Adjust, это еще давным-давно. И по процессу, короче, на каждый поток данных, на каждую стадию агрегации, внутри каждого потока данных, который эта штука обрабатывала. И, в общем, это в конкретном случае лонговая имплементация, поскольку посылка сообщений – это копирование. И поскольку процессы, они хоть и дешевые, когда их много, они начинают друг другу мешать выполняться, то в итоге может так получиться, что, наплодив процессов, и если они очень много между другом коммуницируют, вы сводите все к тому, что вы будете, в случае с Шиверлангой, кучу времени проводить просто в том, что вы копируете память, а потом гарбочек коллектите. И это на самом деле не очень клево. И, ну, как бы, да, это позволяет иногда упростить организацию кода, но излишней конкарнсии, то есть обычно, во всяком случае, с Шиверлангом, ну, и, мне кажется, наверное, во многом с Go точно так же, что в случае с конкарнсией должен быть поток данных, который вы обрабатываете, но внутри потока данных, скорее всего, с конкурентностью дополнительные появляются, или не должно вообще, или не должно почти появляться. То есть там бывает иногда, что проще сделать, чем не сделать. То есть, не знаю, если у вас есть какая-то отдельная библиотека, которая процессы запускает, то, ну, как бы, и бог бы с ней. Отдельностью бороться, наверное, не стоит, но своим дополнительным процессам, наверное, надо избегать. Ну, именно внутри потока данных. Мне понравилось то, что ты описал про фреймворки, которые делают за тебя конкарнсию, потому что это, на самом деле, достаточно эффективный способ борьбы с конкарнсией, написать фреймворк, в котором весь конкарнсис сосредоточен, и потом пользователь этого фреймворка, с его перспективы, весь код, который он пишет, он однопоточный. Но если этот подход можно применить, то его всегда следует применять. Ну, он не обязательно однопоточный, особенно, не знаю, в случае с парка, там бывают некоторые вещи, которые нужно самому, короче, как-то руками доделать, но там это, знаешь, обычно из разряда, ну, типа, по дополнительному потоку на каждый поток боробочек, или что-то типа такое, ну, это не какая-то безумная конкарнсия, то есть мы не говорим о тысячах гарутин, которые там друг с другом в тысячи каналов общаются. Вот мне кажется, у Лёши, который фоликс, очень неинтересный должен быть опыт. Ну, прежде чем мы перейдём к моему опыту, у меня есть такой вопрос к тебе, Саш. Почему, ты же так понял, что вам пришлось писать очередь с приоритетами самостоятельно, а почему вы не взяли какую-нибудь библиотечную имплементацию? Краткий ответ, я точно не знаю, потому что это было написано до меня. А вообще, как, в Go больше, я просто больше Go-код читаю, чем его пишу, пишу я в основном на скале, и мне интересно, в Go больше принято самому что-то имплементировать, такие вот вещи, такие примитивы конкарнсии, или принято их откуда-нибудь брать из библиотек? Ну, у меня, конечно, опыт в Go не очень большой, но по сравнению с Лёшей, но, по-моему, по-разному, то есть вот пример с парсерами и лексерами, как мне Лёша рассказывал, в Go типично принято их писать всегда с нуля. Если что-то небольшое, ну, на самом деле, очередь с приоритетом, а именно как очередь сообщения, это не такой уж прям огромный кусок кода, мне бы, возможно, даже не пришло в голову искать для этого библиотеку, просто это реально там несколько строк. Лёша, ты как считаешь? Ну, очередь с приоритетом, да, то есть в Go её самому сделать довольно просто, то есть примитивы а-ля канала, грутины, синхронизация какая-то через mutex или что-то ещё, она уже вся есть. Поэтому какая-нибудь очередь с приоритетом, это будет небольшой кусок кода, с одной стороны, да, то есть принято его писать, потому что это просто приятно, удобно и так далее до тех пор, пока, понимаешь, это работает. Потом, конечно, кто-нибудь другой сможет, находит там кучу багов, рейсов и так далее, но зато это прикольно, это опера. А второе, что язык, в общем-то, в нём не хватает выразительности, ну, дженериков в нём нет, да, для того, чтобы сделать... Ага, краснопросить хотел. Ну да, то есть это вот реально тот кейс, где дженерики реально нужны, то есть сложно сделать обобщённые алгоритмы, в частности с конкуренцией, которые были бы типа безопасны. То есть если ты хочешь сделать, допустим, очередь с приоритетом для твоего типа тэг, то есть есть варианты. Ты можешь сделать пустой интерфейс и дальше работать через рефлексию или через type assertion и так далее, но это компьютер тебя не проверяет. Ты можешь положить единичку, ты можешь до стекла положить, и оно в работе будет. Ну, если твой код не ждать. Либо ты можешь сделать какую-то код-генерацию и дальше разбираться со всеми этими прикольными код-генераторами. И ты можешь сходить не пустой интерфейс, то есть взять конкретный интерфейс и все твои вещи, которые... интерфейс, да, реализовывать. Это самый хороший способ, но если тебе нужно туда реально базовый тип и класть, то это тяжеловато, тебе приходится боксить и анбоксить постоянно. Это тот кейс, где дженериков реально не хватает. Поэтому да, принято делать самому по этим двум ключам. Ну, в целом, в какой-нибудь скале есть фреймворк актерный ACCA, и там тоже, можно сказать, что интерфейс гошный туда-сюда кидается. Ну, в том смысле, что там кидается Any, это любой тип. И там тоже не видно, что туда-сюда приходит. По крайней мере, так было раньше, потом уже появились typed actors, и там история немножко изменилась, стало все получше. Но я этим не пользовался в продакшене, так что не знаю. А когда я пользовался ACCA в продакшене, там было Any, и мы всячески оборачивали его сверху type assertion'ами, и с этим жили. Делали type safe-опертку над Any, и все более-менее работало. Но если говорить про мой текущий опыт, то сейчас у меня нет какого-то такого конкуренции с high-load'ом. У меня есть конкуренции в том смысле, что у меня есть приложения со сложным циклом, приложения, которые платят другие приложения и менеджат все это. И им регулярно нужно какую-то ветку жизненного цикла унести в background-поток, там крутиться, как-то хитро обрабатываться. Одно приложение может ждать сообщения от другого, и пока оно не придет, не совершать каких-то действий, это должно быть какой-то асинхронной блокировкой, а не блокировкой потока, потому что рано или поздно с блокировками потока все может стать плохо. Если у вас будет заблокировано достаточное количество потоков, система у вас будет чувствовать себя не очень хорошо. Все это достаточно классно, на мой вкус, выражается через CATS и через FS2, через CATS Effect какой-нибудь. Там есть всякие встроенные аналоги семафоров, различные примитивы конкуренции, там всякие очереди есть. Из этого, как из таких кубиков, ты собираешь достаточно сложные алгоритмы, и все это очень хорошо ложится на функциональные парадигмы вроде брекетов, где ты вначале стартуешь какой-нибудь зеленый поток, а потом, когда кусок системы, его жизненный цикл подошел к концу, оно все через брекеты у тебя потихонечку канцелит. И у тебя все потоки останавливаются, ничего не течет. Это достаточно классно, и все очень детизировано. Очень я доволен тем, как все это пишется. Но у этого есть своя цена, и эта цена — порог входа. Все это достаточно нетривиально. Понять, как оно работает до самого конца, потому что там очень много уровней абстракции. С одной стороны, API не самое простое. Оно классное, когда ты его понял, а с другой стороны, прийти к нему и понять, как делать правильно, не так уж и просто. Ну и, как я уже сказал, понять, как оно работает, действительно, в твоей системе тоже непросто. Я, кстати, подтверждаю, я тут хвалил не так давно FSTU, несколько раз даже, и мне буквально недавно прислал домашнее задание на, да, кстати, shameless-пак, adjust, как обычно, все еще нанимает программистов на Elixir, на Scala, на NGO и так далее. Поэтому я ссылочку в шутку добавлю. Так вот, проверял домашнее задание, прислали на Catya и Doobie. И, в общем, смотришь, и думаешь, так, окей, здесь открыли connect, оно автоклозебл, но оно тут закроется или нет, потому что он не флэтмапится, а вот правильно, там оно, короче, попало ли, ну правильно, короче, вот этот ресурсный брекет или что-то где-нибудь нечаянно протекло. Вот, поскольку у меня нет большого опыта работать с этим, то бывает действительно нетривиально понять, как некоторые хрени вообще произойдут и действуют со всем остальным. Согласен на эту проблему, иногда ты смотришь на код и видишь, что он работает, и ты его можешь прочитать, и он читается практически как английский язык, все очень компактно и выразительно, но оно не работает. Где-нибудь гонкой ты сидишь и пытаешься прочитать сорцы или по типам вывести, где же ты. Но на самом деле это приводит в такую ситуацию, меня, например, что я начинаю больше думать прежде, чем кодить.",
    "result": {
      "query": "Go concurrency best practices"
    }
  }
]
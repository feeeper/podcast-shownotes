[
  {
    "segment_id": "5ec91192-067d-4d1b-8258-8d112f6a1f5e",
    "episode_id": "17efc184-7508-48a0-b736-57091831c631",
    "episode_number": 218,
    "segment_number": 11,
    "text": "Ну ладно, да, можно разменить тему. Да, да, согласен. Тогда пошли дальше. А следующая тема, это опять моя тема, про Робина Гуда. Вышла статья, и мы ее, конечно же, читаем в пересказе на Adrien Collier, наш любимый morning paper, и статья про кэши. Мы все очень любим кэши, кэши – это очень важная часть любой системы, я сейчас даже не знаю, есть ли система, которая бы с кэшей хорошо работала. Я ненавижу кэши. Да, вот, многие их не любят, многие их любят, и система очень интересная. То есть давайте рассмотрим кэши. Кэши чаще всего покрывают… то есть у вас есть запросы, которые исполняются очень быстро, средненько и медленно. Чаще всего это происходит в виде такой гиперболы, то есть те запросы, которые исполняются часто и имеют маленькое время, они нам, конечно, очень интересны. У нас есть всегда запросы, которые исполняются очень редко, но и бывают очень долго, а может быть тоже быстро. Но в любом случае, мы заинтересованы в том, чтобы ускорить… только те запросы, которые чаще всего приходят к нам в систему. Вот этот вот длинный хвост, который может быть придет, а может быть не придет в следующий час, нам вообще не интересен. Поэтому все системы, все кэши всех систем чаще всего настроены как раз на этот узенький диапазончик слева, а вот этот хвост справа его не трогают, и поэтому существует такое, как это, поверь, я не знаю, как правильно сказать, что нет вообще смысла брать кэш для всей системы, всегда берите кэш для какого-то количества ваших запросов, которые приходят к вам в систему чаще всего. Но иногда возникает проблема, что, к примеру, у вас один сервис, а внутри в нем несколько подсервисов, перед каждым стоит какой-то кэш, и получается, что если у вас исполняются эти все запросы последовательно, то есть сначала мы стукнулись в одно место, вытащили какую-то часть, потом пошли в другое место, вытащили вторую часть, потом это все сложили, нельзя это делать параллельно, но, к примеру. Получается, что у нас есть несколько кэшей, в которые мы по очереди стукаемся, и можем попасть в него, можем не попасть в него. И получается такая система, что нам без разницы среднее время выполнения одного запроса, если они попадают в кэши, если в этой последовательности один раз мы попадем не в кэш, и он будет выполняться в 10 раз дольше. Ну какая нам разница эти миллисекунды или десятки миллисекунд, если мы на 100 миллисекунд застрянем в третьем сервисе и будем там долго висеть, потому что оно не попадает в кэш, оно пошло в бэкэн и так далее. И получается, что тут такая правильная стратегия будет попытаться определить, какой сервис у нас хуже всего ведет себя и попытаться дать ему больше кэша, чтобы как можно шире покрыть все запросы, происходящие там. Но это не всегда работает, к сожалению, очень часто, во-первых, сами бэкэнды, сами вот эти части вашей системы ведут себя по-разному с течением времени. Очень часто бывает бизнес-логика построена таким образом, что клиенты, которые приходят к вам, они ведут себя по-разному, это по-разному влияет на вашу систему и, соответственно, по-разному влияет на кэши, и поэтому это невозможно определить статикой. И единственный вариант – это попытаться определить это в динамике. Вот как раз эта Robinhood-система, Robinhood по кэшированию хвоста она как раз становится очень эффективна. То есть в чем она состоит? Мы берем и каждый какой-то короткий промежуток времени, каждый 5 секунд, забираем у каждой подсистемы по 1% его объема, используемого для кэша. Забираем себе, это как бы налог. И мы отдаем его в тот сервис, который ведет в настоящий момент себя хуже всего. Каким образом это они определяют? Это мы определяем с помощью, то есть мы берем стандартную нашу статистику по запросам к нашему общему сервису и берем, система Robinhood пытается оптимизировать 99% и, соответственно, небольшую область вокруг 99% мы проверяем. Если у нас запрос как раз попадает в эту область, там обычно 98,5% до 99,5%, мы этот запрос начинаем анализировать, мы проверяем, кто больше всего времени потратил в этом запросе, берем ту подсистему, которая дольше всего обрабатывала этот запрос и, соответственно, для нее прибавляем счетчики плюс единичку во всех счетчиках. Соответственно, после того, как мы 5 секунд это делаем, мы смотрим статистику и понимаем, что сейчас больше всего проблем было у сервиса номер 15, и мы всю нашу память отдаем ему. Ну или не всю, а 90%, а 10% следующему. И получается, что эта система на лету перераспределяет память кэша, которая нужна именно в данный момент именно этому горячему сервису. И получается, что эта система по их замерам, и у них есть какое-то количество тестирования подобных систем, ведет себя оптимальным образом, она очень хорошо реагирует на изменения поведения клиентов, очень хорошо реагирует на изменения поведения самих сервисов, и вот в этом большой-большой профит. В статье дается дополнительные ссылки, показатели, как они измеряли, чем это хорошо и как вы должны поменять систему, потому что это, к сожалению, не всегда работает, не всегда можно легко добавить кэш и так далее. Но кому интересно, добро пожаловать под кад. Мне показалось, что система довольно оригинальная и интересная. Хотя я слабо себе представляю, как это реализовать на практике, когда у вас куча разных систем. Вот это я как раз хотел сказать, что в идее кэша забавная, но во-первых, ее тяжело в реальный продакшен присунуть. Я подумал, знаешь, о чем? Я подумал о том, что если у тебя есть единообразие в сервисах, ну, к примеру, мы всегда используем mmcash для кэша, к примеру, да? Я даже не про это, смотри, ты же кэшируешь разные довольно, можешь хотеть кэшировать довольно разные штуки и там типа, не знаю, у тебя сервисы могут банально иметь разные требования к тому, насколько много им кэша этого нужно. Или там, не знаю, то есть мне не очень понятно, как это, то есть они тут процентами оперируют, а может уже там не один процент целый отдать, а совсем чуть-чуть, нужно буквально добавить кому-то, и ему будет хорошо. Эта система, мне кажется, начнет это сцелировать, отбирать, добавлять, отбирать, добавлять, отбирать, добавлять. Но из-за того, что это один процент, это не так много. Ну в том-то и дело, что для какого-то сервиса один процент это, короче, дофига, то есть там, может быть, сервис, скажем, у тебя есть 200 гигабайт кэша, к кому-то сервису, какой-то сервис влазит, сейчас, подожди, пусть будет 100 гигабайт кэша, чтобы было легко рассуждать об этом, какой-то сервис целиком влазит в полтора гигабайта, ну и ты понял, что начнет происходить. Если ему по проценту начнут туда-сюда добавлять, убирать, добавлять, убирать. Я понимаю, о чём ты говоришь, но мне кажется, что, во-первых, это легко обходится, во-вторых, ну ты цепляешься к мелочам. Ну да. Ну в смысле, я к тому, что тут мало того, что есть такие случаи, в общем, у меня очень странное ощущение от того, что ты сейчас рассказал, и ещё, как бы, вот мне тяжело припомнить систему, где если какой-то компонент реально упирается в кэш, чтобы мы просто не поставили выделенный кэш, чтобы он туда целиком влез и все эти смарт-штуки становятся, ну, наверное, это важно на масштабах типа Фейсбука, где выделенный кэш, ну, дороговато, а на масштабах большинства проектов, мне это кажется оверкилом. Мне больше не нравится здесь тот факт, что фактически у тебя никогда нет единой системы кэширования, то есть чаще всего оно где-то разрознено, растащено, и сделать единую базу, куда можно сваливать кэш, там, или давайте мы отсюда заберем 5%, положим туда 2%, но это становится очень тяжело и нереально. Это может иногда сработать, и я, скажем, вот помню, что у нас на позапрошлом проекте оно бы, наверное, сработало, потому что нас реально везде использовался ММКэш, где можно, и перенастроить его, сделать его динамически настраиваемым было бы полезно, при том, что у нас довольно много было кэша, ну, то есть как бы у нас огромные машины стояли, и мы на самом деле добавляли там иногда машинами. Сделать это динамически, возможно, мы бы пользовали там на пару машин меньше и экономили себе бы какое-то количество бюджета, но это настолько редко применимо, что… Ну вот знаешь, возникает вопрос, а вы не экономили бы вы бы денег, которые покрыла бы стоимость разработки интеграции? Ну, если бы это из коробки было, как вот с EBPF экспортером, да, ну, поставил и не мучаешься, ну, проверил, что оно работает, протестировал, почему бы нет? Но вот если взять это пейпер и начать это все разрабатывать, да ну в баню, я лучше поставлю еще одну машину с ММКэшом и не буду мучиться. Вот, но мне больше нравится подход, то есть я имею в виду стандартное кэширование уже получается такой динамической системой, это прямо интересно, это реально интересно, то есть ты смотришь самые горячие участки, перераспределяешь использование кэша и затыкаешь фактически вот только какие-то узкие направления наиболее критичные. Это интересный подход. У нас все получаются системы в дальнейшем, то есть как бы чем мы больше обсуждаем, тем больше мы, ну, то есть как бы тот же самый лод-балансер, который мы недавно, чем мы рассматривали, что он на лету подменяет и точно так же анализирует 90-е годы. Ты наверное про гитхабовский. Да, да, да. Ну, там я, если честно, вижу больше смысла, потому что там решается проблема. Да не то, что больше системы, у тебя в любом случае есть проблема сделать отказоустойчивый первый слой балансеров, то есть у тебя в какой-то момент, ну, даже если ты используешь много DNS, даже если ты используешь много, там, не знаю, Nginx или чего-нибудь или HAProxy в самом передней области, если ты вылезаешь за 2-3 машины в одном дата-центре, то тебе резко начинает быть сложно добавлять, убирать машины. Там, в принципе, может быть два варианта, или ты логику на клиент тащишь, или ты вот какие-то такие штуки типа GLB начинаешь пилить. Ну, или третий вариант, у тебя добавление-удаление такой машины, это долго, дорого и больно. Не, не, это ты говоришь про stateless load balancer, которые, ну, у нас до этого была еще одна load balancer, это у Netflix, edge load balancer, и где они делали… А, там где они пробы делали, да? Да, да, да, да. Они делали пробы и автоматически сбрасывали с сервисов нагрузку если они ухудшают показатели. То есть это фактически то же самое, ты берешь самые горячие сервера и немножко с них снимаешь нагрузку для того, чтобы улучшить их показатели. Здесь же то же самое ровно. Ну нет, здесь как бы… Не, не, я понимаю, что все произошли… Сепаратисты забирают у всех, отдают тому, кому плохо. Да, ну и там то же самое, там забирают тех, кому плохо и раздают всем остальным. Я не про то, я говорю про одинаковый принцип, что у тебя вместо статической архитектуры, которой мы изначально все привыкли, то есть лет 10 назад вообще не было динамики здесь, здесь появляется у нас динамика на уровне лодбалансинга. То есть мы как бы это, с помощью Netflix мы ослабляем, уменьшаем нагрузку на самые больные сервера для того, чтобы пользователь ничего не почувствовал. Здесь мы динамически начинаем кэш раскидывать. То есть получается, что у нас вообще нет статической архитектуры, все становится плавающим. И вот эта вот тенденция к увеличению динамичности, она меня прям интересует, это гибкость, повышенная гибкость постоянно и одновременные усложнения. Ну это, наверное, логично, учитывая, что системы пухнут и пухнут. Ну то есть, хотя с другой стороны, по моим наблюдениям, большинство сервисов, ну то есть понятно, что со временем будет становиться больше и больше проектов с миллиардами пользователей, но среднему проекту это будет становиться все менее и менее нужно. То есть людей на земле больше не становится. Очень успешные проекты, они будут запускаться в Индии, Китае и все-каком-таком, где людей прям очень много живет и, опять же, просто масштабируется на много стран. Им это будет все больше нужно, мы от них это будем все больше слышать. В то же время у нас машины все мощнее, как не так давно обсуждали, наверное, года два назад, хотя уже давно получается, да, уже два года назад обсуждали, что сейчас там дейтасеты, которые раньше приходилось обслуживать кластером Кассандры или Ряка, заблазят в раму одной машины, которая при том недорогая, то мне кажется, да, среднему проекту это будет становиться все меньше нужно, потому что средний проект, там, лям пользователей пришло уже в день, это уже очень успешно и лям пользователей в день можно обслуживать довольно малыми силами сейчас. Ну то есть мы все больше будем читать этих пейперов и все больше будем смотреть на подобные системы. Но нам все это будет менее нужно. Да, интересный вывод. Так, ну в общем я все рассказал про Робин Гуда. Кстати, а почему, интересно, они его Робин Гудом называли? Да потому что забирают у тех, у кого есть кэш, и отдают тем, у кого нет. А, ну логично, согласен, да. Расскажи, Саш, про сумку, что за сумка? Это небольшое продолжение истории про мою поездку на Ментор Саммит в Сан-Хосе.",
    "result": {
      "query": "Robin Hood cache dynamic allocation"
    }
  }
]
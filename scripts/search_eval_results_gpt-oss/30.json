[
  {
    "segment_id": "30d461ff-bdd8-46f2-b2c5-2bb3787811cf",
    "episode_id": "863c3e7c-a34d-464c-a09a-ccaebed10810",
    "episode_number": 30,
    "segment_number": 4,
    "text": "Можно посмотреть, у него частично есть элементы его доклада в этом блоге. Там очень красивые фотографии рэлли, ну, фотографии, скриншоты. Мне понравилось, как оно сделано на Bootstrap'е, за графиками. Я не знаю, это встроенные такие графики в Bootstrap'ы, или они подключаются какими-то модулями. Он все это в действии показывал, была демонстрация с ноутбука. Прям красивые графики, мне тоже такие хочется. Вообще, это рэлли — клевая система. То есть, Валер, знаешь, как в Ирландии Common Test'ы прогоняешь, и у тебя отчет в вашей стимеле генерится. Очень похожая штука, но красивее с графиками. Ну и на вторую часть я не особо задержался. Я послушал про возможности расширения, так, в полуха, и ушел, потому что там начали рассказывать про Ironic. Ironic — это штука для OpenStack'а, которая позволяет тебе поднимать не виртуалочки, а реально рулить физическими машинами. То есть, у тебя есть какой-то пул физических машин, и ты с помощью OpenStack'а их выделяешь под какие-то задачи, и потом опять освобождаешь. То есть, в целом, что такое OpenStack? Штука для построения private cloud'а, то есть, ты делаешь как бы Amazon, но сам. И ты можешь делать MapReduce, свой аналог IC2 — вот это все. Это, например, в госсекторе может быть нужно. Или, ну не знаю, понятно, Яндекс ему странно хостится в Амазоне. Но вообще, аналогов OpenStack'у, они есть хоть какие-то? Я потому что кроме OpenStack'а подобных решений не знаю даже. Ну, как минимум, есть OpenNebu, есть еще решение, есть такие ребята — Joint, которые все хостят на Solaris. Вот у них есть решение, они недавно за OpenSource'или, я не знаю, как с этим можно, как не будучи Джоентом, с этим можно разобраться, но, наверное, можно. Еще есть Project FIFA, который тоже поверх Solaris работает. Ну, в общем, я думаю, еще найдется с десяток менее известных. Но если OpenStack тяжел, потому что у него недостаточно большое сообщество, в смысле, недостаточно людей, которые пишут грамотную документацию, нет простых тьюториалов типа «нажмите кнопку, и вся спина в мыле», то для более маленьких проектов это еще более сложная вещь получается. Кстати, насчет тьюториалов, ну, как называется, ну, это не совсем кулуары, но там, когда за столиками со всякими людьми общаешься, мне посоветовали посмотреть доклады предыдущих лет, там, говорят, есть один из докладов из серии «Как иметь две машинки, поднять, условно говоря, мастера OpenStack'а, агента OpenStack'а, и вот на двух машинах иметь небольшое облачко». Я прилиплю ссылки в шоу-ноты, но, честно говоря, еще не нашел этот доклад сам. Ты знаешь, я сам не копал OpenStack, но сколько ни сталкиваюсь с людьми, которые копают вокруг меня, всегда одно и то же выражение, что пока ты делаешь простейшую вещь, все окей, как только тебе надо что-то от стандарта отойти, все, начинается боль. Ну вот в экзенте пытались использовать OpenStack, на моей памяти еще, но в результате забили, потому что сложно и нам не совсем нужно и так далее. Я, кстати, задал этот вопрос первому докладчику, типа в каких случаях нужно поднимать свой Private Cloud и что делать, если сложно не получается. Он посоветовал всяких ссылочек, но я уже в шоу-ноты добавил OpenStack.ru, например, и там можно просто посмотреть видео с докладом с первым самым. Там в конце будут всякие ссылки, у них есть список рассылок, прямо русскоязычный даже. Там какие-то туториалы, вот это все. А, в IRC они там, в Freenode есть. То есть, если знать, где спрашивать, то в принципе тебе могут помочь. Кстати, как вы вообще считаете, Private Cloud это нужно, не нужно? Лично я считаю, что вообще было бы здорово. То есть, ты, например, идешь, ну не знаю, скажем в Хэсснер, заказываешь там 100 машин. Ты знаешь, сколько они у тебя стоят в месяц, потому что ты фиксированно платишь. И вот на этих 100 машинах, прямо вот у тебя Amazon, ты там выделил, поднял свой балансер, пришли пользователи побольше, ты там ресурсов выделил побольше под виртуалочки, потом тебе нужно какой-то отчет почитать, ты выделил ресурсы под MapReduce и так далее, потом их грохнул, ну то есть было бы прямо здорово. Я думаю, что для каких-то компаний это прямо необходимо. То есть, те, которые на самом деле наружу не имеют права данные выносить. И поэтому такие решения, конечно, очень нужны. Но в целом, для каких-то своих маленьких, небольших проектов, а чаще всего, я думаю, слушатели у нас и мы сами, это все-таки небольшие, маленькие проекты, которые могут быть в Амазоне, DigitalOcean или в Dessin. Легче, конечно, использовать уже готовые IaaSы. Ну и потом в нашем таком типичном вебе поднимать свой private cloud, ну это слишком. Если ты хочешь даже просто на виртуалках хоститься, вот как у нашего спонсора, то тебе намного проще туда катись какими-нибудь докерами, чтобы одну виртуалку завязать под разные задачи. И то много, получается, на это времени уходит. То есть, тебе все равно больше хочется писать приложение, а не заниматься тем, как ты разворачиваешь, что ты там делаешь, когда одна машина упала, или масштабирование и так далее. То есть, эти все вещи, их приходится решать, но в случае, например, OpenStack, тебе не хватает машины, и что? Надо новые машины ставить, надо до них снова поднимать, нужно расширять сетку, нужно добавлять. Короче, там столько дополнительных проблем, которые... На самом деле, даже Амазон, скажем так, не всегда идеально работает, потому что я столкнулся с тем, что я хочу облачный полнотекстовый поиск. Ты смотришь, что есть на эту тему в Амазоне. Есть Cloud Search. Ты создаешь себе индекс, а потом решаешь добавить еще одно поле. И у тебя эта задача висит 5-10 минут. Блин, у меня вообще пустой индекс, я хочу туда одно текстовое поле добавить. Если в Амазоне такие вещи плохо работают, а они плохо работают еще и с RDS, и я про многое слышал такое, то как они в OpenStack работают, я вообще боюсь представить. Ну, я думаю, что в OpenStack просто нет никакого Cloud Search. Печалька. Так, ну что, пошли дальше? Да, я еще на этой конференции встретил Антона Лебедевича, вот Валера его знает. Он собирается к нам в подкаст зайти на следующей неделе, если ничего у него не поменяется. Отлично, отлично. Кстати, он должен рассказать интересные вещи про то, как он статистическим анализом находит узкие места в приложении. Вот и поспрашивай. То есть не по логуме или запросам, а по статистическому анализу. Ну, он делает же анализ на основе логов и метрик, как я понимаю. В смысле, не на основе логов глазками, а на основе логов по науке, получается так. Нет, Валер, это все магия. Просто настоящая магия. Окей, пусть будет так. Еще он советовал посмотреть... выложили видео на YouTube с Cassandra Summit'а, там, говорят, есть совсем клевые доклады, но, к сожалению, они в перемешку с bullshit докладами из Сирии. Ну, у нас там, не знаю, все было плохо, ничего не работало, потом мы перешли на Cassandra и все стало здорово, замечательно. То есть я прилепил в шоу-ноты ссылку на плейлист, я его нашел. Но ты не успел посмотреть все 20 часов, не успел поглядеть, да? Я вообще не понимаю, как рассмотреть видео. У меня там книжки, новости, вообще еле-еле времени хватает. А вы еще какие-то видосы? Курсы на Курсире еще, не дай бог. Ну, так можно скорость ставить полтора раза быстрее, будет быстрее проходить. А, точно-точно. Я вот так все видосы смотрю сейчас. Вообще я понял, зачем ходить на конференции. Вот ты... знаете, как там у Шерлока Холмса было, что... Ну, там у него был прочердак, что он забивает с ним ненужную информацию, вот это все, знаете. Проземля вокруг Солнца. Вот это, конечно, фигня, то, что бесполезная информация вытесняет полезную, в плане хранения в голове. Но процессинг, обработка полезной информации, то есть, например, ты слушаешь Девзен, намного больше вероятность, что от него у тебя в голову придут какие-то интересные мысли, чем от чтения новостей о политике, просмотра сериалов, вот это все. То есть, процессить нужную информацию, ее полезно. Поэтому ходите на конференции. Да. Во время конференции, участия, когда слушаешь какие-то лекции, все время такая мотивация поднимается. То есть, хочется сразу пойти и попилить что-нибудь, вот то, что сейчас он рассказывает, вообще классная штука. Потом возвращаешься домой и думаешь, блин, мне чуть серьезно хотелось это попилить. Так, ну что, пошли дальше. Значит, следующая тема у нас примерно про то же самое. То есть, казалось бы, если никому не нужен OpenStack для маленьких решений, используйте все облака и все будет в таретке. То здесь тоже не все гладко, как хотелось бы. На сайте Амазона появилось новое предупреждение, что из-за новых уязвимостей в Xen они обязаны рестартовать около 10% машин к 10 марта. И похоже, что опять вы ничего с этим сделать не можете. То есть, у вас в какой-то момент времени машина отключится и перезагрузится. То есть, там опять большое количество вопросов-ответов на тему, а если я буду постоянно перезагружать, возможно, они у меня там попадут на хорошие ноды. И они советуют этого не делать. Ну, вернее, как, они говорят, нет, все равно нам придется перезагружать машины. Что-то типа такого. Ну, в смысле ты не можешь ничего с этим сделать. У тебя Амазон, он по определению дает инфраструктуру. Он тебе не гарантирует, что у тебя там дата-центры ему не сгорают и так далее. То есть, если ты все делал по-человечески, там с EC2 за ELB и так далее, то тебе это вообще не коснется. Да, то есть, если ты делаешь на нескольких зонах одинаковые рабочие, которые в случае падения одной зоны подхватывают с другой зоны работы, то есть, у тебя все будет в порядке. Но если ты не следовал их советам, то у тебя могут быть проблемы. Как-то так. Тут так написано. Менее 10% EC2 инстансов кастомерских. То есть, во-первых, это касается только EC2. То есть, там динамо не отвалится. А EC2, любые нормальные люди, держат за балансировщиком нагрузки. Балансировщик не поможет, если у тебя все ноды находятся в одной зоне, и они, скажем, все одновременно пойдут на перезагрузку. То есть, ты считаешь, что вот эти менее 10% инстансов EC2, это вот все твои инстансы, они попали в эти 10%? Ну, вот в прошлый раз, когда было, там было несколько человек на форумах, которые говорили, что у них было, что около 80% их нод в их кластере пошло на перезагрузку одновременно. Да, но у тебя ELB не поднимет новые? Ну, скажем так, пока он поднимает новые, пока у тебя стартует приложение, пока у тебя какой-нибудь паппет доразворачивает и так далее. То есть, все сильно зависит от того, как ты все это сделал. Если ты следуешь советам Амазона, все будет в порядке. Ну, что ты можешь сказать. Что-то happens. Да. Я лично не вижу проблемы. Кому-нибудь интересно вернуться немножко назад и снова про GML уточнить? Я просто тут, пока вы обсуждали это, пристал статью, посмотрел на описание тузов, которые там использовались, и я тут имею добавить. Кому-нибудь интересно? Давай, давай, жги. Короче, я все-таки был не прав, что GML это какая-то новая разработка. Нет, нифига подобного. Действительно, every-like синдекс для описания свойств, но, как я сказал уже выше, вот это кажется Ване, что свойства в любом типе систем все равно нужно сформулировать в виде как-то, потом их как-то доказать. Так вот, GML это только способ спецификации свойств, ничего больше. Дальше к GML есть plugable всякие штуки, которые с этими свойствами могут обращаться по-разному. Конкретно ребята использовали штуку под названием key, ну, то бишь, как ключ. И это теряемо доказательством. Да, это действительно так. И вам. Подождите, я открываю. Теряемо доказательство каким образом работает, Валер? Ты не можешь нашим слушателям мне рассказать об этом? То есть, имея свойства, имея при и после условия, они доказывают полностью корректность. Да, но это от случая к случаю работает сильно по-разному, я не знаю, как это можно устно... Это нужно брать и просто с этим поиграться, и я еще раз повторюсь, это от случая к случаю очень по-разному работает. Я с этим key не работал, я не представляю, как он экстрактит. То есть, обычно из твоей программы, аннотированной какими-то свойствами, экстрактируется какая-то модель, в которой есть какие-то утверждения, и какие-то про нее известные аксиомы. То есть, обычно аксиомы описывают твою модель памяти, твою еще какую-нибудь фигню. И ты берешь этой системе и говоришь, что вот из-за этого, смотри, следует вот это. Следует? Следует, проверил. Дальше, а вот из-за этого, следует вот это и вот это. Окей, мы доказали леммочку небольшую. Дальше, значит, вот у нас есть такая штуковина, вот такой факт и вот такой факт. У нас есть такая лемма, и вот по этой лемме, которую мы выше доказали, из этого факта следует вот этот. И так вот, шаг за шагом, мы приходим к доказательству чего-нибудь хорошего. Например, типичный пример, что мы хотим доказать, что у нас какая-то итерация, какой-то цикл имеет ограниченное количество итераций. Мы говорим, что у нас этот цикл, он оперирует с ограниченным множеством, и каждая итерация уменьшает размер множества. Если мы можем это доказать, на основе наших аксиом, лемм и так далее, то мы успешно доказываем свойство, что цикл не зацикливается навеки вечно. Как-то так. Еще, например, мы иногда хотим сказать, что у нас такое свойство, что у нас, например, выходной массив по размеру будет, например, не больше, чем размеры входных массивов. Что-нибудь такое, например. Ну и это все очень сильно, получается, зависит от тех свойств, которые ты записал, и, соответственно, от того кода, который ты написал. То есть, если ты сделал большую лапшу... Да, и от твоей системы экстракции это при том, что тоже зависит. Да, да. Ок, ну что, пошли дальше? Дальше снова твоя тема про то, как интервьюируют в Apple. Я ее полистал, могу только сказать, что не только в Apple так интервьюируют, просто, ну... Да, да. Вероятно, только Apple после этого, можешь сказать, но... Вот я не читал. Расскажите мне, как там интервьюируют. Ну тут же в тизере все написано. Да неужели, правда? То есть наши слушатели, они знают это, да? Нет, в смысле, окей, ладно, да, ты прав, что мы это не озвучиваем. Суть в том, что мистер поимел 3 предварительных звонка, ну то есть, видимо, по телефону имеется в виду, потом 5 интервью по FaceTime, мы там скайповали чему-то, потом ему оплатили поездку в Купертино, отинтервьюировали его там, потом сказали, извини, чувак, ты на меня подходишь. Отинтервьюировали, это прямо очень здорово, вот, описывает ситуацию, то есть... Ну да, часа 4 мы там беседовали. 6, по-моему, 6 или 7 часов, да. То есть, ну это очень жесткий вариант, как бы я и по себе знаю, меня подобным образом отинтервьюировали как-то пару раз. То есть, к концу рабочего дня мозг вообще отказывается уже соображать. Это, конечно, довольно интересно. В целом мне понравилось, что несколько моментов. Во-первых, вот это большое количество интервью, то есть у него, получается, было, он-сайт уже было 5 интервью, то есть, итого у него было 13 интервью за все время. Вот. И ему в конце концов сказали нет. И общее впечатление у него, ух, как круто, как было здорово, типа такого. Вот. Отинтервьюируйте меня еще раз по-правдой. Да-да-да-да. Позовите меня еще разик. Это я к чему вообще хотел поднять вопрос. У меня сейчас несколько знакомых компаний ищут себе людей, и все вокруг удивляются людям, которые приходят как соискатели, которые приходят, возможно, устраиваться на работу, и в случае, когда им говорят, ну, вы знаете, вот здесь неплохо бы, чтобы вы дома сделали маленькое домашнее здание, вот такое вот. Ну, маленькое – это все, конечно, относительно, то есть оно может быть и большое, и все зависит от человека, как он рассматривает этот вопрос. Вот. И бывают такие ответы, там, не знаю, 10-20% случаев, когда люди говорят, ну, вы знаете, наверное, нет, я настолько крут, что я никогда не буду больше делать домашнее задание типа такого. Вот. Ну, то есть, когда посмотришь вот на эти 13 интервью и кучу потраченного времени, пару, тройку месяцев, ну, не то, что постоянной работы, но все равно какого-то ты должен следить за этим процессом. Вот так, что человек приходит на первое интервью с ответом, ребят, я вообще не готов тратить на вас время, хотя я ищу работу. Ну, это как-то немножко смешно. Ну, давай начнем с простого. Твои знакомые компании – это не Apple. Аааа, и? И, наверное, у них не так много людей на одно место, как в Apple. Почему так думаешь? Ну, есть такая чуйка. А, я думаю, ты можешь быть и не прав, нет? Ну, то есть, это твоя знакомая компания, она как Apple, ну, чуть-чуть хуже, ну, или там чуть-чуть лучше, ну, примерно как Apple, плюс-минус. Разницы нет, она как Apple или не как Apple. Разница есть, если чувак не хочет, ну, как бы он пришел в компанию, он, может быть, хочет, может не хочет, какая-то непонятная контора, он о ней первый раз вообще услышал, и ему там дают какие-то задачки, а рядом точно такая же контора, ну, такая не очень понятная, он о ней первый раз слышал, но там уже все понятно, его уже хотят взять, ему уже дают денег, его уже устраивает рабочее место и так далее. А, в таком регулировке, да, я согласен с тобой. То есть имеет значение, насколько компания хороша или плоха? То есть, сколько, скажем так, вот если рассматривать Москву, да, ну, я живу в Москве, и рассматривать компании, про которые я что-то знаю, ну, то есть, вообще слышал их названия, да, например, то ям, а эти компании, то ям, ну, мне в голову максимум придет штук, не знаю, 10 от силы, и это при условии, что в них вряд ли используют то, с чем мне хочется работать, ну, потому что я не знаю питона, мне не очень хочется возвращаться обратно на перл и так далее. А на С++ меня никто не доверит писать. Остается куча-куча маленьких компаний, про которые я вообще ничего не знаю. И если, ну, то есть они для меня примерно одинаковые. И я иду туда куда проще. То есть компания должна доказать тебе, что у них интересно, что у них хорошо и что они лучшие, типа такого? Нет, я просто, я реально, у меня нет времени решать задачки, ну, потому что, ну, если, скажем так, если это задачка на часик, то как бы окей. А если, ну, это там вот как в Эхо, знаешь, там в серии, там, напишите свой лидер элекшн, то нет. Но тут все сильно же зависит, ты правильно говоришь, что в Москве очень большой выбор, а Эхо все-таки работает не в Москве. То есть если, скажем, в Москву придет Эппл, то это тоже, ты тоже должен будешь доказывать, что тебе стоит там работать. Точно так же и с Эхо ты должен доказать, что хочешь там работать. Поэтому нам необходимо было вводить подобную вещь. Не, ну подожди, ты так легко со мной согласился. Давай я наоборот тогда встану на твою сторону. Потому что я как человек, который проводил интервью, я прекрасно понимаю всю значимость... Отсева. Отсева, да, потому что у тебя огромная очередь желающих. Ну как огромная, ну она для себя одного человека огромная. Подожди, подожди, я, слушай, мы поменялись в регламентах. Тут опять же зависит от крутости компании. То есть если ты рога и копыта, то у тебя нет этой огромной очереди. Так нет, не имеет значения рога и копыта ты или не имеет. Это вообще не имеет ни малейшего значения. Потому что у тебя, не знаю, условно говоря, ну скажем, 30 человек желающих, да? Ну они не одновременно, не в один день, но скажем там в течение месяца 30 человек. Это если ты активно ищешь, то находится. И после того, как к тебе пришло 5-6 человек из серии «Ну я знаю Руби, но если там очень нужно, то я готов и Нейрланги писать». То есть я готов писать Нейрланги, я готов его выучить, понимаешь уже позиция какая. Да, да. Я настолько крут, что я рассмотрю ваши предложения. Вот ты, наобщавшись с такими людьми, ты начинаешь думать, а как бы мне вот так проводить собеседование с людьми, которые чего-то знают. И ты проводишь отсев, ты говоришь, а вот решить эту небольшую задачку. И у тебя уже не 30 желающих, а 3, с которыми есть о чем поговорить. При этом ты получается стоишь перед дилеммой. Либо ты не пытаешься доказать, что твоя компания – это та компания, в которую они хотят пойти, и тогда ты получишь свои 3 желающих, просто отсеяв тех, кто не знает ничего и боится рисковать и тратить свое время. А если ты всем докажешь, что ты самая крутая компания, и Apple ничто по сравнению с тобой, то отсеются наоборот те, кто побоится брать сложные задания. И это как раз останутся те люди, которые тебе нужны. То есть опять же приходим к тому, что реклама нужна. Например, реклама в подкастах. Так что если вы знаете кого-нибудь из IT-компаний, кому это будет интересно, вы знаете… Если вы знаете какой-нибудь хорошо известный подкаст, то идите туда и заказывайте там рекламу. Нет, ну не обязательно самый хорошо известный. Ладно, пошли дальше. А мораль какая? А мораль такая, что нужно… Вот лично моя мораль, которую я делаю отсюда, нужно быть очень гибким. То есть лично мне кажется, что те люди, которые отсекают, потому что они не хотят и не могут, это просто показывает негибкость их мышления и стратегии. И компаниям тоже надо быть чуть гибче, давая задачки реально на час. То есть… Но я не готов там… Понимаешь, я когда меняю работу, я обычно рассматриваю штук 10 разных новых мест, и мне в каждой, если даю задачку, то это вообще жесть. Я сейчас пишу пост на тему, как я делал одну задачку для одной конторы. Я думаю, тебе понравится. Там большая задачка. Жду с нетерпением. Хорошо. Валера. Что, Валера, я могу только сказать про то, что я обычно, когда куда-то иду, я доверяю зимой в нескольких компаниях. Просто чтобы быть уверенным в том, что хоть куда-то. Но вот сколько раз у меня было, я… Даже не совсем так. Я два раза… Так получалось, что мне предлагали работать в компанию. То есть, первый раз, когда я устраивался, я собирался пойти собеседоваться в Gaijin Entertainment, но не успел даже им резюме отправить. Написали в ВКонтакте. Эй, чувак, вот хочешь поработать вот такая-такая штука? Меня пособеседовали и сказали, да. У меня в это время была сессия, я не успел пойти куда-то еще, что-то там подаваться. Я просто согласился, и мне все понравилось, и я работал. Второй раз мне сказали, эй, чувак, тут можно писать на Ирландии за деньги, в фулл-тайм. Хочешь пойти? Я подумал, блин, офигеть, на Ирландии за деньги в фулл-тайм, все, я иду. А вот уже потом, в следующие два раза, у меня был какой-то, так скажем, заведомо фаворит, куда я хотел бы пойти, потому что я что-то уже знал про компанию, общался с людьми оттуда или что-то такое. И было несколько бэкап-планов, и оба раза выстрелило мне тот вариант, который я изначально хотел. И вот в последний раз меня конкретно так собеседовали, конечно, не как в Apple, но тоже было, по-моему, всего лишь одно Skype-собеседование, там лайк полуторачасовое. Потом собеседование в Берлине, и оно было семичасовое. Задачку давали? Задачку нам не давали, нет. А если бы давали? Я бы решал. Конкретно для этих ребят, куда я в итоге устроился работать, для них я бы решал задачку с удовольствием. Хорошо. Валера? Следующая тема. Да, действительно. Ну, мы же знаем, что у нас скоро всех захватят машины, и Google усиленно приближает этот день. В этот раз они опубликовали результаты. К сожалению, сама статья, она опубликована в каком-то журнале, который за Paywall'ом, поэтому статью прочитать не было ни малейшего возможности, даже если вы не подписаны на этот журнал.",
    "result": {
      "error": "API request failed: Error code: 400 - {'error': 'Trying to keep the first 6696 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}",
      "stack_trace": "Traceback (most recent call last):\n  File \"/home/andrei/Projects/podcast-shownotes/scripts/build_search_eval_dataset.py\", line 157, in generate_search_query\n    response = await self.client.chat.completions.create(\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 1927, in create\n    return await self._post(\n           ^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1767, in post\n    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1461, in request\n    return await self._request(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/andrei/Projects/podcast-shownotes/envs/lib/python3.12/site-packages/openai/_base_client.py\", line 1562, in _request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': 'Trying to keep the first 6696 tokens when context the overflows. However, the model is loaded with context length of only 4096 tokens, which is not enough. Try to load the model with a larger context length, or provide a shorter input'}\n"
    }
  }
]